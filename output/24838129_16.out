âœ… Set input_type to box
Filtered dataset: 64 / 851 images kept.
LatentDiffusion: Running in eps-prediction mode
DiffusionWrapper has 859.52 M params.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 4, 32, 32) = 4096 dimensions.
making attention of type 'vanilla' with 512 in_channels
Restored from /work3/s203557/checkpoints/v1-5-pruned-emaonly.ckpt with 0 missing and 199 unexpected keys
Unexpected Keys: ['model_ema.decay', 'model_ema.num_updates', 'cond_stage_model.transformer.text_model.embeddings.position_ids', 'cond_stage_model.transformer.text_model.embeddings.token_embedding.weight', 'cond_stage_model.transformer.text_model.embeddings.position_embedding.weight', 'cond_stage_model.transformer.text_model.encoder.layers.0.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.0.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.0.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.0.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.0.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.0.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.0.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.0.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.0.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.0.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.0.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.0.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.0.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.0.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.0.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.0.layer_norm2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.1.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.1.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.1.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.1.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.1.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.1.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.1.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.1.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.1.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.1.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.1.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.1.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.1.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.1.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.1.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.1.layer_norm2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.2.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.2.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.2.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.2.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.2.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.2.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.2.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.2.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.2.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.2.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.2.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.2.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.2.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.2.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.2.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.2.layer_norm2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.3.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.3.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.3.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.3.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.3.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.3.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.3.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.3.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.3.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.3.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.3.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.3.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.3.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.3.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.3.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.3.layer_norm2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.4.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.4.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.4.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.4.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.4.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.4.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.4.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.4.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.4.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.4.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.4.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.4.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.4.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.4.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.4.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.4.layer_norm2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.5.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.5.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.5.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.5.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.5.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.5.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.5.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.5.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.5.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.5.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.5.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.5.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.5.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.5.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.5.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.5.layer_norm2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.6.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.6.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.6.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.6.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.6.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.6.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.6.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.6.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.6.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.6.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.6.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.6.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.6.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.6.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.6.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.6.layer_norm2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.7.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.7.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.7.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.7.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.7.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.7.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.7.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.7.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.7.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.7.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.7.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.7.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.7.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.7.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.7.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.7.layer_norm2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.8.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.8.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.8.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.8.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.8.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.8.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.8.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.8.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.8.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.8.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.8.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.8.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.8.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.8.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.8.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.8.layer_norm2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.9.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.9.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.9.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.9.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.9.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.9.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.9.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.9.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.9.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.9.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.9.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.9.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.9.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.9.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.9.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.9.layer_norm2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.10.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.10.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.10.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.10.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.10.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.10.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.10.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.10.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.10.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.10.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.10.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.10.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.10.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.10.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.10.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.10.layer_norm2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.11.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.11.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.11.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.11.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.11.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.11.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.11.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.11.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.11.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.11.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.11.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.11.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.11.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.11.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.11.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.11.layer_norm2.bias', 'cond_stage_model.transformer.text_model.final_layer_norm.weight', 'cond_stage_model.transformer.text_model.final_layer_norm.bias']
load checkpoint from local path: /work3/s203557/experiments/control_net_vpd/iter_12000.pth
The model and loaded state dict do not match exactly

unexpected key in source state_dict: sd_model.lvlb_weights

[                                                  ] 0/64, elapsed: 0s, ETA:[                                  ] 1/64, 0.3 task/s, elapsed: 3s, ETA:   220s[>                                 ] 2/64, 0.6 task/s, elapsed: 4s, ETA:   113s[>                                 ] 3/64, 0.8 task/s, elapsed: 4s, ETA:    77s[>>                                ] 4/64, 1.0 task/s, elapsed: 4s, ETA:    59s[>>                                ] 5/64, 1.2 task/s, elapsed: 4s, ETA:    48s[>>>                               ] 6/64, 1.4 task/s, elapsed: 4s, ETA:    41s[>>>                               ] 7/64, 1.6 task/s, elapsed: 4s, ETA:    36s[>>>>                              ] 8/64, 1.7 task/s, elapsed: 5s, ETA:    32s[>>>>                              ] 9/64, 1.9 task/s, elapsed: 5s, ETA:    29s[>>>>>                            ] 10/64, 2.0 task/s, elapsed: 5s, ETA:    27s[>>>>>                            ] 11/64, 2.2 task/s, elapsed: 5s, ETA:    25s[>>>>>>                           ] 12/64, 2.3 task/s, elapsed: 5s, ETA:    23s[>>>>>>                           ] 13/64, 2.4 task/s, elapsed: 5s, ETA:    21s[>>>>>>>                          ] 14/64, 2.5 task/s, elapsed: 6s, ETA:    20s[>>>>>>>                          ] 15/64, 2.6 task/s, elapsed: 6s, ETA:    19s[>>>>>>>>                         ] 16/64, 2.7 task/s, elapsed: 6s, ETA:    18s[>>>>>>>>                         ] 17/64, 2.8 task/s, elapsed: 6s, ETA:    17s[>>>>>>>>>                        ] 18/64, 2.9 task/s, elapsed: 6s, ETA:    16s[>>>>>>>>>                        ] 19/64, 3.0 task/s, elapsed: 6s, ETA:    15s[>>>>>>>>>>                       ] 20/64, 3.0 task/s, elapsed: 7s, ETA:    14s[>>>>>>>>>>                       ] 21/64, 3.1 task/s, elapsed: 7s, ETA:    14s[>>>>>>>>>>>                      ] 22/64, 3.2 task/s, elapsed: 7s, ETA:    13s[>>>>>>>>>>>                      ] 23/64, 3.2 task/s, elapsed: 7s, ETA:    13s[>>>>>>>>>>>>                     ] 24/64, 3.3 task/s, elapsed: 7s, ETA:    12s[>>>>>>>>>>>>                     ] 25/64, 3.4 task/s, elapsed: 7s, ETA:    12s[>>>>>>>>>>>>>                    ] 26/64, 3.4 task/s, elapsed: 8s, ETA:    11s[>>>>>>>>>>>>>                    ] 27/64, 3.5 task/s, elapsed: 8s, ETA:    11s[>>>>>>>>>>>>>>                   ] 28/64, 3.5 task/s, elapsed: 8s, ETA:    10s[>>>>>>>>>>>>>>                   ] 29/64, 3.6 task/s, elapsed: 8s, ETA:    10s[>>>>>>>>>>>>>>>                  ] 30/64, 3.6 task/s, elapsed: 8s, ETA:     9s[>>>>>>>>>>>>>>>                  ] 31/64, 3.7 task/s, elapsed: 8s, ETA:     9s[>>>>>>>>>>>>>>>>                 ] 32/64, 3.7 task/s, elapsed: 9s, ETA:     9s[>>>>>>>>>>>>>>>>>                ] 33/64, 3.8 task/s, elapsed: 9s, ETA:     8s[>>>>>>>>>>>>>>>>>                ] 34/64, 3.8 task/s, elapsed: 9s, ETA:     8s[>>>>>>>>>>>>>>>>>>               ] 35/64, 3.9 task/s, elapsed: 9s, ETA:     8s[>>>>>>>>>>>>>>>>>>               ] 36/64, 3.9 task/s, elapsed: 9s, ETA:     7s[>>>>>>>>>>>>>>>>>>>              ] 37/64, 3.9 task/s, elapsed: 9s, ETA:     7s[>>>>>>>>>>>>>>>>>>>             ] 38/64, 4.0 task/s, elapsed: 10s, ETA:     7s[>>>>>>>>>>>>>>>>>>>             ] 39/64, 4.0 task/s, elapsed: 10s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>            ] 40/64, 4.0 task/s, elapsed: 10s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>            ] 41/64, 4.1 task/s, elapsed: 10s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>           ] 42/64, 4.1 task/s, elapsed: 10s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>           ] 43/64, 4.1 task/s, elapsed: 10s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>          ] 44/64, 4.2 task/s, elapsed: 11s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>          ] 45/64, 4.2 task/s, elapsed: 11s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>         ] 46/64, 4.2 task/s, elapsed: 11s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>         ] 47/64, 4.3 task/s, elapsed: 11s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>        ] 48/64, 4.3 task/s, elapsed: 11s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>        ] 49/64, 4.3 task/s, elapsed: 11s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>       ] 50/64, 4.4 task/s, elapsed: 11s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>       ] 51/64, 4.4 task/s, elapsed: 12s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>      ] 52/64, 4.4 task/s, elapsed: 12s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>      ] 53/64, 4.4 task/s, elapsed: 12s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>     ] 54/64, 4.5 task/s, elapsed: 12s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>     ] 55/64, 4.5 task/s, elapsed: 12s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 56/64, 4.5 task/s, elapsed: 12s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 57/64, 4.5 task/s, elapsed: 13s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 58/64, 4.5 task/s, elapsed: 13s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 59/64, 4.6 task/s, elapsed: 13s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 60/64, 4.6 task/s, elapsed: 13s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 61/64, 4.6 task/s, elapsed: 13s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 62/64, 4.6 task/s, elapsed: 13s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 63/64, 4.7 task/s, elapsed: 14s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 64/64, 4.7 task/s, elapsed: 14s, ETA:     0sper class results:

+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        | 43.39 | 57.43 |
|       building      | 81.56 | 91.37 |
|         sky         | 94.91 | 97.78 |
|        floor        | 25.19 | 85.52 |
|         tree        | 81.61 |  92.3 |
|       ceiling       |  54.8 | 97.18 |
|         road        | 67.39 | 80.45 |
|         bed         |  nan  |  nan  |
|      windowpane     |  0.0  |  0.0  |
|        grass        | 82.13 | 94.77 |
|       cabinet       |  nan  |  nan  |
|       sidewalk      | 52.42 | 78.76 |
|        person       | 81.17 | 90.25 |
|        earth        | 56.23 | 84.51 |
|         door        |  0.0  |  nan  |
|        table        | 68.83 | 72.87 |
|       mountain      | 59.08 | 61.46 |
|        plant        | 54.04 | 58.95 |
|       curtain       |  nan  |  nan  |
|        chair        | 72.07 | 96.64 |
|         car         |  92.8 | 97.33 |
|        water        | 76.87 | 95.43 |
|       painting      |  nan  |  nan  |
|         sofa        |  nan  |  nan  |
|        shelf        |  nan  |  nan  |
|        house        | 53.71 | 81.53 |
|         sea         | 42.74 | 63.16 |
|        mirror       |  nan  |  nan  |
|         rug         |  nan  |  nan  |
|        field        | 32.21 | 42.34 |
|       armchair      |  nan  |  nan  |
|         seat        |  nan  |  nan  |
|        fence        | 40.89 | 63.92 |
|         desk        |  nan  |  nan  |
|         rock        | 56.11 | 92.31 |
|       wardrobe      |  nan  |  nan  |
|         lamp        |  nan  |  nan  |
|       bathtub       |  nan  |  nan  |
|       railing       | 49.58 | 60.89 |
|       cushion       |  nan  |  nan  |
|         base        |  0.0  |  0.0  |
|         box         |  nan  |  nan  |
|        column       |  0.0  |  0.0  |
|      signboard      | 32.95 | 37.03 |
|   chest of drawers  |  nan  |  nan  |
|       counter       |  nan  |  nan  |
|         sand        |  0.1  |  0.62 |
|         sink        |  nan  |  nan  |
|      skyscraper     |  nan  |  nan  |
|      fireplace      |  nan  |  nan  |
|     refrigerator    |  nan  |  nan  |
|      grandstand     |  0.0  |  nan  |
|         path        | 35.13 | 37.96 |
|        stairs       | 42.39 | 50.42 |
|        runway       |  nan  |  nan  |
|         case        |  nan  |  nan  |
|      pool table     |  nan  |  nan  |
|        pillow       |  nan  |  nan  |
|     screen door     |  nan  |  nan  |
|       stairway      |  20.5 | 29.05 |
|        river        |  8.05 |  9.11 |
|        bridge       |  0.0  |  nan  |
|       bookcase      |  nan  |  nan  |
|        blind        |  nan  |  nan  |
|     coffee table    |  nan  |  nan  |
|        toilet       |  nan  |  nan  |
|        flower       |  0.0  |  0.0  |
|         book        |  0.0  |  0.0  |
|         hill        |  0.0  |  nan  |
|        bench        |  0.0  |  0.0  |
|      countertop     |  nan  |  nan  |
|        stove        |  nan  |  nan  |
|         palm        | 26.25 | 26.49 |
|    kitchen island   |  nan  |  nan  |
|       computer      |  nan  |  nan  |
|     swivel chair    |  nan  |  nan  |
|         boat        |  nan  |  nan  |
|         bar         |  nan  |  nan  |
|    arcade machine   |  nan  |  nan  |
|        hovel        |  nan  |  nan  |
|         bus         |  nan  |  nan  |
|        towel        |  nan  |  nan  |
|        light        |  nan  |  nan  |
|        truck        |  nan  |  nan  |
|        tower        | 82.37 |  87.2 |
|      chandelier     |  nan  |  nan  |
|        awning       |  0.97 |  1.01 |
|     streetlight     | 43.82 |  47.6 |
|        booth        |  nan  |  nan  |
| television receiver |  nan  |  nan  |
|       airplane      |  nan  |  nan  |
|      dirt track     |  0.0  |  nan  |
|       apparel       |  nan  |  nan  |
|         pole        | 43.53 | 53.32 |
|         land        |  nan  |  nan  |
|      bannister      |  0.0  |  0.0  |
|      escalator      |  nan  |  nan  |
|       ottoman       |  nan  |  nan  |
|        bottle       |  nan  |  nan  |
|        buffet       |  nan  |  nan  |
|        poster       |  0.0  |  0.0  |
|        stage        |  nan  |  nan  |
|         van         |  nan  |  nan  |
|         ship        |  nan  |  nan  |
|       fountain      |  nan  |  nan  |
|    conveyer belt    |  nan  |  nan  |
|        canopy       |  0.0  |  0.0  |
|        washer       |  nan  |  nan  |
|      plaything      |  nan  |  nan  |
|    swimming pool    |  nan  |  nan  |
|        stool        |  nan  |  nan  |
|        barrel       |  nan  |  nan  |
|        basket       |  0.0  |  0.0  |
|      waterfall      |  nan  |  nan  |
|         tent        |  0.0  |  nan  |
|         bag         |  0.0  |  0.0  |
|       minibike      |  nan  |  nan  |
|        cradle       |  nan  |  nan  |
|         oven        |  nan  |  nan  |
|         ball        |  0.0  |  0.0  |
|         food        |  nan  |  nan  |
|         step        |  0.0  |  0.0  |
|         tank        |  nan  |  nan  |
|      trade name     |  0.0  |  0.0  |
|      microwave      |  nan  |  nan  |
|         pot         | 10.96 | 17.62 |
|        animal       |  0.0  |  0.0  |
|       bicycle       |  91.2 | 97.83 |
|         lake        |  nan  |  nan  |
|      dishwasher     |  nan  |  nan  |
|        screen       |  nan  |  nan  |
|       blanket       |  nan  |  nan  |
|      sculpture      |  0.0  |  0.0  |
|         hood        |  nan  |  nan  |
|        sconce       |  nan  |  nan  |
|         vase        |  nan  |  nan  |
|    traffic light    |  0.0  |  0.0  |
|         tray        |  nan  |  nan  |
|        ashcan       | 51.48 | 77.72 |
|         fan         |  nan  |  nan  |
|         pier        |  0.0  |  nan  |
|      crt screen     |  nan  |  nan  |
|        plate        |  nan  |  nan  |
|       monitor       |  nan  |  nan  |
|    bulletin board   |  nan  |  nan  |
|        shower       |  nan  |  nan  |
|       radiator      |  nan  |  nan  |
|        glass        |  nan  |  nan  |
|        clock        |  0.0  |  0.0  |
|         flag        | 49.36 | 62.22 |
+---------------------+-------+-------+
Summary:

+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 82.92 | 31.09 | 44.15 |
+-------+-------+-------+
