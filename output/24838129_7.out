âœ… Set input_type to box
Filtered dataset: 57 / 851 images kept.
LatentDiffusion: Running in eps-prediction mode
DiffusionWrapper has 859.52 M params.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 4, 32, 32) = 4096 dimensions.
making attention of type 'vanilla' with 512 in_channels
Restored from /work3/s203557/checkpoints/v1-5-pruned-emaonly.ckpt with 0 missing and 199 unexpected keys
Unexpected Keys: ['model_ema.decay', 'model_ema.num_updates', 'cond_stage_model.transformer.text_model.embeddings.position_ids', 'cond_stage_model.transformer.text_model.embeddings.token_embedding.weight', 'cond_stage_model.transformer.text_model.embeddings.position_embedding.weight', 'cond_stage_model.transformer.text_model.encoder.layers.0.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.0.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.0.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.0.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.0.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.0.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.0.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.0.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.0.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.0.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.0.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.0.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.0.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.0.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.0.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.0.layer_norm2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.1.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.1.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.1.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.1.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.1.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.1.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.1.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.1.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.1.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.1.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.1.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.1.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.1.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.1.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.1.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.1.layer_norm2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.2.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.2.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.2.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.2.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.2.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.2.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.2.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.2.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.2.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.2.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.2.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.2.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.2.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.2.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.2.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.2.layer_norm2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.3.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.3.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.3.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.3.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.3.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.3.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.3.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.3.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.3.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.3.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.3.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.3.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.3.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.3.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.3.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.3.layer_norm2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.4.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.4.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.4.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.4.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.4.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.4.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.4.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.4.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.4.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.4.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.4.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.4.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.4.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.4.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.4.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.4.layer_norm2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.5.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.5.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.5.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.5.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.5.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.5.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.5.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.5.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.5.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.5.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.5.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.5.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.5.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.5.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.5.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.5.layer_norm2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.6.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.6.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.6.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.6.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.6.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.6.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.6.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.6.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.6.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.6.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.6.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.6.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.6.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.6.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.6.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.6.layer_norm2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.7.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.7.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.7.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.7.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.7.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.7.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.7.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.7.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.7.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.7.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.7.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.7.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.7.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.7.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.7.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.7.layer_norm2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.8.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.8.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.8.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.8.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.8.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.8.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.8.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.8.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.8.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.8.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.8.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.8.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.8.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.8.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.8.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.8.layer_norm2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.9.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.9.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.9.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.9.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.9.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.9.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.9.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.9.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.9.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.9.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.9.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.9.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.9.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.9.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.9.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.9.layer_norm2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.10.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.10.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.10.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.10.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.10.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.10.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.10.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.10.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.10.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.10.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.10.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.10.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.10.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.10.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.10.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.10.layer_norm2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.11.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.11.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.11.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.11.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.11.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.11.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.11.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.11.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.11.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.11.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.11.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.11.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.11.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.11.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.11.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.11.layer_norm2.bias', 'cond_stage_model.transformer.text_model.final_layer_norm.weight', 'cond_stage_model.transformer.text_model.final_layer_norm.bias']
load checkpoint from local path: /work3/s203557/experiments/control_net_vpd/iter_12000.pth
The model and loaded state dict do not match exactly

unexpected key in source state_dict: sd_model.lvlb_weights

[                                                  ] 0/57, elapsed: 0s, ETA:[                                  ] 1/57, 0.2 task/s, elapsed: 7s, ETA:   366s[>                                 ] 2/57, 0.3 task/s, elapsed: 7s, ETA:   185s[>                                 ] 3/57, 0.4 task/s, elapsed: 7s, ETA:   124s[>>                                ] 4/57, 0.6 task/s, elapsed: 7s, ETA:    94s[>>                                ] 5/57, 0.7 task/s, elapsed: 7s, ETA:    76s[>>>                               ] 6/57, 0.8 task/s, elapsed: 7s, ETA:    63s[>>>>                              ] 7/57, 0.9 task/s, elapsed: 8s, ETA:    54s[>>>>                              ] 8/57, 1.0 task/s, elapsed: 8s, ETA:    48s[>>>>>                             ] 9/57, 1.1 task/s, elapsed: 8s, ETA:    42s[>>>>>                            ] 10/57, 1.2 task/s, elapsed: 8s, ETA:    38s[>>>>>>                           ] 11/57, 1.3 task/s, elapsed: 8s, ETA:    35s[>>>>>>                           ] 12/57, 1.4 task/s, elapsed: 8s, ETA:    32s[>>>>>>>                          ] 13/57, 1.5 task/s, elapsed: 9s, ETA:    29s[>>>>>>>>                         ] 14/57, 1.6 task/s, elapsed: 9s, ETA:    27s[>>>>>>>>                         ] 15/57, 1.7 task/s, elapsed: 9s, ETA:    25s[>>>>>>>>>                        ] 16/57, 1.7 task/s, elapsed: 9s, ETA:    24s[>>>>>>>>>                        ] 17/57, 1.8 task/s, elapsed: 9s, ETA:    22s[>>>>>>>>>>                      ] 18/57, 1.9 task/s, elapsed: 10s, ETA:    21s[>>>>>>>>>>                      ] 19/57, 2.0 task/s, elapsed: 10s, ETA:    19s[>>>>>>>>>>>                     ] 20/57, 2.0 task/s, elapsed: 10s, ETA:    18s[>>>>>>>>>>>                     ] 21/57, 2.1 task/s, elapsed: 10s, ETA:    17s[>>>>>>>>>>>>                    ] 22/57, 2.1 task/s, elapsed: 10s, ETA:    16s[>>>>>>>>>>>>                    ] 23/57, 2.2 task/s, elapsed: 10s, ETA:    15s[>>>>>>>>>>>>>                   ] 24/57, 2.3 task/s, elapsed: 11s, ETA:    15s[>>>>>>>>>>>>>>                  ] 25/57, 2.3 task/s, elapsed: 11s, ETA:    14s[>>>>>>>>>>>>>>                  ] 26/57, 2.4 task/s, elapsed: 11s, ETA:    13s[>>>>>>>>>>>>>>>                 ] 27/57, 2.4 task/s, elapsed: 11s, ETA:    12s[>>>>>>>>>>>>>>>                 ] 28/57, 2.5 task/s, elapsed: 11s, ETA:    12s[>>>>>>>>>>>>>>>>                ] 29/57, 2.5 task/s, elapsed: 11s, ETA:    11s[>>>>>>>>>>>>>>>>                ] 30/57, 2.6 task/s, elapsed: 12s, ETA:    10s[>>>>>>>>>>>>>>>>>               ] 31/57, 2.6 task/s, elapsed: 12s, ETA:    10s[>>>>>>>>>>>>>>>>>               ] 32/57, 2.7 task/s, elapsed: 12s, ETA:     9s[>>>>>>>>>>>>>>>>>>              ] 33/57, 2.7 task/s, elapsed: 12s, ETA:     9s[>>>>>>>>>>>>>>>>>>>             ] 34/57, 2.8 task/s, elapsed: 12s, ETA:     8s[>>>>>>>>>>>>>>>>>>>             ] 35/57, 2.8 task/s, elapsed: 12s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>            ] 36/57, 2.9 task/s, elapsed: 13s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>            ] 37/57, 2.9 task/s, elapsed: 13s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>           ] 38/57, 2.9 task/s, elapsed: 13s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>           ] 39/57, 3.0 task/s, elapsed: 13s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>          ] 40/57, 3.0 task/s, elapsed: 13s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>         ] 41/57, 3.0 task/s, elapsed: 14s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>         ] 42/57, 3.1 task/s, elapsed: 14s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>        ] 43/57, 3.1 task/s, elapsed: 14s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>        ] 44/57, 3.1 task/s, elapsed: 14s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>       ] 45/57, 3.2 task/s, elapsed: 14s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>       ] 46/57, 3.2 task/s, elapsed: 14s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>      ] 47/57, 3.2 task/s, elapsed: 15s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>      ] 48/57, 3.3 task/s, elapsed: 15s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>     ] 49/57, 3.3 task/s, elapsed: 15s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 50/57, 3.3 task/s, elapsed: 15s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 51/57, 3.4 task/s, elapsed: 15s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 52/57, 3.4 task/s, elapsed: 15s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 53/57, 3.4 task/s, elapsed: 16s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 54/57, 3.4 task/s, elapsed: 16s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 55/57, 3.5 task/s, elapsed: 16s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 56/57, 3.5 task/s, elapsed: 16s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 57/57, 3.5 task/s, elapsed: 16s, ETA:     0sper class results:

+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        | 79.66 | 89.62 |
|       building      | 76.27 | 92.19 |
|         sky         | 97.38 | 98.36 |
|        floor        | 74.28 | 90.93 |
|         tree        |  86.1 | 89.84 |
|       ceiling       | 81.99 | 87.89 |
|         road        | 89.98 | 98.88 |
|         bed         | 93.06 | 97.14 |
|      windowpane     | 66.67 | 80.38 |
|        grass        |  4.15 |  4.67 |
|       cabinet       | 68.42 | 81.09 |
|       sidewalk      | 43.63 | 46.98 |
|        person       | 85.92 |  93.7 |
|        earth        |  0.31 |  0.31 |
|         door        | 72.56 | 86.54 |
|        table        |  65.6 | 84.64 |
|       mountain      |  nan  |  nan  |
|        plant        | 45.13 | 55.15 |
|       curtain       | 74.39 | 89.75 |
|        chair        |  79.0 | 89.74 |
|         car         |  68.3 | 77.16 |
|        water        |  0.0  |  0.0  |
|       painting      | 83.97 | 89.55 |
|         sofa        |  52.3 | 69.67 |
|        shelf        |  6.43 | 14.81 |
|        house        |  0.0  |  0.0  |
|         sea         | 11.24 | 11.69 |
|        mirror       | 85.57 | 96.15 |
|         rug         | 68.56 | 76.53 |
|        field        |  nan  |  nan  |
|       armchair      | 32.64 | 58.57 |
|         seat        | 90.72 | 95.57 |
|        fence        |  nan  |  nan  |
|         desk        | 20.53 | 84.57 |
|         rock        |  0.0  |  0.0  |
|       wardrobe      | 84.98 | 95.91 |
|         lamp        | 69.68 | 86.98 |
|       bathtub       | 88.66 | 91.79 |
|       railing       | 32.52 | 52.73 |
|       cushion       | 62.64 | 81.06 |
|         base        |  0.0  |  0.0  |
|         box         | 36.09 | 50.82 |
|        column       | 42.86 | 53.23 |
|      signboard      | 23.33 | 29.71 |
|   chest of drawers  |  8.9  |  9.05 |
|       counter       |  0.0  |  0.0  |
|         sand        |  nan  |  nan  |
|         sink        | 84.61 | 92.63 |
|      skyscraper     |  nan  |  nan  |
|      fireplace      | 59.83 | 77.93 |
|     refrigerator    | 85.09 | 90.08 |
|      grandstand     |  0.0  |  nan  |
|         path        |  nan  |  nan  |
|        stairs       |  5.21 |  5.21 |
|        runway       |  nan  |  nan  |
|         case        |  0.0  |  nan  |
|      pool table     | 84.96 | 91.18 |
|        pillow       | 47.66 | 50.95 |
|     screen door     |  46.5 | 46.75 |
|       stairway      | 11.85 | 48.15 |
|        river        |  nan  |  nan  |
|        bridge       |  0.0  |  nan  |
|       bookcase      | 58.61 | 70.94 |
|        blind        | 55.82 | 58.44 |
|     coffee table    | 18.32 | 20.22 |
|        toilet       | 87.53 | 91.09 |
|        flower       |  59.2 | 76.86 |
|         book        | 59.73 | 70.89 |
|         hill        |  nan  |  nan  |
|        bench        |  4.09 |  4.09 |
|      countertop     | 57.47 |  92.0 |
|        stove        | 90.91 | 96.01 |
|         palm        |  nan  |  nan  |
|    kitchen island   | 38.03 |  74.5 |
|       computer      |  0.0  |  0.0  |
|     swivel chair    | 25.58 | 36.23 |
|         boat        |  nan  |  nan  |
|         bar         | 52.41 | 54.36 |
|    arcade machine   |  nan  |  nan  |
|        hovel        |  nan  |  nan  |
|         bus         |  nan  |  nan  |
|        towel        | 71.48 | 89.42 |
|        light        | 53.84 | 62.18 |
|        truck        |  nan  |  nan  |
|        tower        |  nan  |  nan  |
|      chandelier     | 69.69 | 78.17 |
|        awning       |  nan  |  nan  |
|     streetlight     | 21.83 | 26.36 |
|        booth        |  nan  |  nan  |
| television receiver | 90.37 | 90.89 |
|       airplane      |  nan  |  nan  |
|      dirt track     |  nan  |  nan  |
|       apparel       |  0.0  |  nan  |
|         pole        |  0.0  |  0.0  |
|         land        |  nan  |  nan  |
|      bannister      |  0.0  |  nan  |
|      escalator      | 12.91 |  15.2 |
|       ottoman       | 12.62 | 40.54 |
|        bottle       | 28.95 |  44.6 |
|        buffet       | 85.85 | 90.53 |
|        poster       | 76.89 | 83.72 |
|        stage        |  0.0  |  nan  |
|         van         |  nan  |  nan  |
|         ship        |  0.0  |  nan  |
|       fountain      |  nan  |  nan  |
|    conveyer belt    |  0.0  |  nan  |
|        canopy       |  0.0  |  nan  |
|        washer       |  nan  |  nan  |
|      plaything      |  13.3 | 14.41 |
|    swimming pool    |  nan  |  nan  |
|        stool        | 59.98 | 63.04 |
|        barrel       |  nan  |  nan  |
|        basket       |  7.01 |  7.07 |
|      waterfall      |  nan  |  nan  |
|         tent        |  nan  |  nan  |
|         bag         |  0.0  |  0.0  |
|       minibike      |  nan  |  nan  |
|        cradle       |  nan  |  nan  |
|         oven        | 49.05 | 89.74 |
|         ball        | 76.92 | 83.68 |
|         food        | 43.62 | 52.24 |
|         step        |  24.2 | 67.79 |
|         tank        |  nan  |  nan  |
|      trade name     |  nan  |  nan  |
|      microwave      | 67.38 | 69.74 |
|         pot         | 58.25 | 64.58 |
|        animal       | 72.79 | 74.15 |
|       bicycle       |  nan  |  nan  |
|         lake        |  nan  |  nan  |
|      dishwasher     |  0.0  |  0.0  |
|        screen       | 22.22 | 22.22 |
|       blanket       |  0.0  |  0.0  |
|      sculpture      |  nan  |  nan  |
|         hood        | 42.13 | 42.92 |
|        sconce       | 60.34 | 81.77 |
|         vase        | 54.67 | 69.67 |
|    traffic light    |  nan  |  nan  |
|         tray        |  9.75 |  12.2 |
|        ashcan       | 88.99 |  93.9 |
|         fan         |  nan  |  nan  |
|         pier        |  nan  |  nan  |
|      crt screen     |  0.0  |  nan  |
|        plate        | 67.04 | 83.18 |
|       monitor       |  nan  |  nan  |
|    bulletin board   |  0.0  |  0.0  |
|        shower       | 36.32 | 36.41 |
|       radiator      | 85.86 | 92.52 |
|        glass        | 14.99 | 16.17 |
|        clock        |  0.0  |  0.0  |
|         flag        | 61.21 | 77.35 |
+---------------------+-------+-------+
Summary:

+-------+------+-------+
|  aAcc | mIoU |  mAcc |
+-------+------+-------+
| 82.12 | 43.5 | 57.11 |
+-------+------+-------+
