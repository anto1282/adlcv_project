âœ… Set input_type to dot
Filtered dataset: 38 / 851 images kept.
LatentDiffusion: Running in eps-prediction mode
DiffusionWrapper has 859.52 M params.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 4, 32, 32) = 4096 dimensions.
making attention of type 'vanilla' with 512 in_channels
Restored from /work3/s203557/checkpoints/v1-5-pruned-emaonly.ckpt with 0 missing and 199 unexpected keys
Unexpected Keys: ['model_ema.decay', 'model_ema.num_updates', 'cond_stage_model.transformer.text_model.embeddings.position_ids', 'cond_stage_model.transformer.text_model.embeddings.token_embedding.weight', 'cond_stage_model.transformer.text_model.embeddings.position_embedding.weight', 'cond_stage_model.transformer.text_model.encoder.layers.0.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.0.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.0.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.0.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.0.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.0.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.0.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.0.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.0.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.0.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.0.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.0.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.0.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.0.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.0.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.0.layer_norm2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.1.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.1.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.1.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.1.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.1.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.1.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.1.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.1.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.1.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.1.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.1.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.1.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.1.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.1.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.1.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.1.layer_norm2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.2.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.2.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.2.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.2.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.2.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.2.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.2.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.2.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.2.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.2.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.2.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.2.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.2.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.2.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.2.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.2.layer_norm2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.3.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.3.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.3.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.3.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.3.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.3.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.3.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.3.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.3.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.3.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.3.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.3.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.3.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.3.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.3.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.3.layer_norm2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.4.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.4.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.4.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.4.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.4.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.4.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.4.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.4.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.4.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.4.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.4.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.4.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.4.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.4.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.4.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.4.layer_norm2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.5.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.5.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.5.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.5.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.5.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.5.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.5.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.5.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.5.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.5.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.5.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.5.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.5.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.5.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.5.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.5.layer_norm2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.6.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.6.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.6.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.6.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.6.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.6.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.6.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.6.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.6.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.6.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.6.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.6.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.6.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.6.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.6.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.6.layer_norm2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.7.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.7.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.7.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.7.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.7.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.7.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.7.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.7.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.7.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.7.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.7.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.7.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.7.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.7.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.7.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.7.layer_norm2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.8.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.8.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.8.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.8.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.8.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.8.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.8.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.8.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.8.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.8.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.8.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.8.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.8.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.8.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.8.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.8.layer_norm2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.9.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.9.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.9.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.9.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.9.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.9.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.9.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.9.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.9.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.9.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.9.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.9.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.9.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.9.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.9.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.9.layer_norm2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.10.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.10.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.10.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.10.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.10.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.10.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.10.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.10.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.10.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.10.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.10.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.10.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.10.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.10.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.10.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.10.layer_norm2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.11.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.11.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.11.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.11.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.11.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.11.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.11.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.11.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.11.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.11.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.11.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.11.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.11.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.11.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.11.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.11.layer_norm2.bias', 'cond_stage_model.transformer.text_model.final_layer_norm.weight', 'cond_stage_model.transformer.text_model.final_layer_norm.bias']
load checkpoint from local path: /work3/s203557/experiments/control_net_vpd/iter_12000.pth
The model and loaded state dict do not match exactly

unexpected key in source state_dict: sd_model.lvlb_weights

[                                                  ] 0/38, elapsed: 0s, ETA:[                                  ] 1/38, 0.1 task/s, elapsed: 7s, ETA:   253s[>                                 ] 2/38, 0.3 task/s, elapsed: 7s, ETA:   127s[>>                                ] 3/38, 0.4 task/s, elapsed: 7s, ETA:    85s[>>>                               ] 4/38, 0.5 task/s, elapsed: 7s, ETA:    63s[>>>>                              ] 5/38, 0.7 task/s, elapsed: 8s, ETA:    50s[>>>>>                             ] 6/38, 0.8 task/s, elapsed: 8s, ETA:    42s[>>>>>>                            ] 7/38, 0.9 task/s, elapsed: 8s, ETA:    35s[>>>>>>>                           ] 8/38, 1.0 task/s, elapsed: 8s, ETA:    31s[>>>>>>>>                          ] 9/38, 1.1 task/s, elapsed: 8s, ETA:    27s[>>>>>>>>                         ] 10/38, 1.2 task/s, elapsed: 9s, ETA:    24s[>>>>>>>>>                        ] 11/38, 1.3 task/s, elapsed: 9s, ETA:    21s[>>>>>>>>>>                       ] 12/38, 1.3 task/s, elapsed: 9s, ETA:    19s[>>>>>>>>>>>                      ] 13/38, 1.4 task/s, elapsed: 9s, ETA:    18s[>>>>>>>>>>>>                     ] 14/38, 1.5 task/s, elapsed: 9s, ETA:    16s[>>>>>>>>>>>>>                    ] 15/38, 1.6 task/s, elapsed: 9s, ETA:    15s[>>>>>>>>>>>>>                   ] 16/38, 1.7 task/s, elapsed: 10s, ETA:    13s[>>>>>>>>>>>>>>                  ] 17/38, 1.7 task/s, elapsed: 10s, ETA:    12s[>>>>>>>>>>>>>>>                 ] 18/38, 1.8 task/s, elapsed: 10s, ETA:    11s[>>>>>>>>>>>>>>>>                ] 19/38, 1.9 task/s, elapsed: 10s, ETA:    10s[>>>>>>>>>>>>>>>>                ] 20/38, 1.9 task/s, elapsed: 10s, ETA:     9s[>>>>>>>>>>>>>>>>>               ] 21/38, 2.0 task/s, elapsed: 11s, ETA:     9s[>>>>>>>>>>>>>>>>>>              ] 22/38, 2.0 task/s, elapsed: 11s, ETA:     8s[>>>>>>>>>>>>>>>>>>>             ] 23/38, 2.1 task/s, elapsed: 11s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>            ] 24/38, 2.2 task/s, elapsed: 11s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>           ] 25/38, 2.2 task/s, elapsed: 11s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>           ] 26/38, 2.3 task/s, elapsed: 11s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>          ] 27/38, 2.3 task/s, elapsed: 12s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>         ] 28/38, 2.4 task/s, elapsed: 12s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>        ] 29/38, 2.4 task/s, elapsed: 12s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>       ] 30/38, 2.5 task/s, elapsed: 12s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>      ] 31/38, 2.5 task/s, elapsed: 12s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>      ] 32/38, 2.6 task/s, elapsed: 12s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>     ] 33/38, 2.6 task/s, elapsed: 13s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 34/38, 2.7 task/s, elapsed: 13s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 35/38, 2.7 task/s, elapsed: 13s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 36/38, 2.7 task/s, elapsed: 13s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 37/38, 2.8 task/s, elapsed: 13s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 38/38, 2.8 task/s, elapsed: 14s, ETA:     0sper class results:

+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        | 79.41 |  92.6 |
|       building      | 64.68 | 98.88 |
|         sky         | 98.26 | 99.12 |
|        floor        | 75.99 | 82.61 |
|         tree        |  0.0  |  0.0  |
|       ceiling       | 89.45 | 92.71 |
|         road        |  nan  |  nan  |
|         bed         | 85.04 | 97.16 |
|      windowpane     | 68.93 | 83.05 |
|        grass        |  0.0  |  nan  |
|       cabinet       | 29.54 | 63.06 |
|       sidewalk      | 89.24 | 89.49 |
|        person       | 67.22 |  84.5 |
|        earth        |  0.0  |  nan  |
|         door        | 56.69 | 73.66 |
|        table        | 57.34 |  73.7 |
|       mountain      |  nan  |  nan  |
|        plant        |  34.1 | 78.92 |
|       curtain       | 44.99 | 55.18 |
|        chair        | 43.96 | 62.33 |
|         car         |  0.0  |  nan  |
|        water        |  nan  |  nan  |
|       painting      | 66.53 |  88.8 |
|         sofa        |  0.0  |  nan  |
|        shelf        | 32.43 | 52.91 |
|        house        |  nan  |  nan  |
|         sea         |  nan  |  nan  |
|        mirror       |  58.9 | 71.54 |
|         rug         | 17.98 |  47.0 |
|        field        |  nan  |  nan  |
|       armchair      | 28.72 | 28.83 |
|         seat        |  nan  |  nan  |
|        fence        | 10.72 | 92.73 |
|         desk        | 28.97 | 33.29 |
|         rock        |  nan  |  nan  |
|       wardrobe      | 46.75 | 47.68 |
|         lamp        | 58.81 |  71.1 |
|       bathtub       |  nan  |  nan  |
|       railing       | 81.95 | 82.99 |
|       cushion       | 61.22 | 71.28 |
|         base        |  11.6 | 13.39 |
|         box         | 13.92 | 16.04 |
|        column       | 78.31 | 93.43 |
|      signboard      |  0.0  |  0.0  |
|   chest of drawers  | 70.48 | 82.38 |
|       counter       |  nan  |  nan  |
|         sand        | 80.32 | 81.22 |
|         sink        |  0.0  |  nan  |
|      skyscraper     |  nan  |  nan  |
|      fireplace      | 92.36 | 99.83 |
|     refrigerator    |  nan  |  nan  |
|      grandstand     |  nan  |  nan  |
|         path        |  nan  |  nan  |
|        stairs       |  0.0  |  nan  |
|        runway       |  nan  |  nan  |
|         case        |  nan  |  nan  |
|      pool table     |  nan  |  nan  |
|        pillow       | 64.22 |  68.3 |
|     screen door     |  0.0  |  nan  |
|       stairway      |  nan  |  nan  |
|        river        |  nan  |  nan  |
|        bridge       |  nan  |  nan  |
|       bookcase      | 50.42 | 69.01 |
|        blind        | 12.34 | 12.67 |
|     coffee table    | 52.82 | 92.99 |
|        toilet       |  0.0  |  nan  |
|        flower       |  0.0  |  0.0  |
|         book        | 36.66 | 73.95 |
|         hill        |  nan  |  nan  |
|        bench        |  0.0  |  0.0  |
|      countertop     |  nan  |  nan  |
|        stove        |  0.0  |  nan  |
|         palm        |  nan  |  nan  |
|    kitchen island   |  nan  |  nan  |
|       computer      | 69.68 |  78.1 |
|     swivel chair    |  0.0  |  nan  |
|         boat        |  nan  |  nan  |
|         bar         |  nan  |  nan  |
|    arcade machine   |  80.4 | 95.15 |
|        hovel        |  nan  |  nan  |
|         bus         |  nan  |  nan  |
|        towel        |  0.0  |  0.0  |
|        light        | 69.83 | 77.75 |
|        truck        |  nan  |  nan  |
|        tower        |  nan  |  nan  |
|      chandelier     |  62.1 | 90.23 |
|        awning       |  nan  |  nan  |
|     streetlight     |  nan  |  nan  |
|        booth        |  nan  |  nan  |
| television receiver | 67.92 | 70.45 |
|       airplane      |  nan  |  nan  |
|      dirt track     |  nan  |  nan  |
|       apparel       |  0.0  |  0.0  |
|         pole        |  nan  |  nan  |
|         land        |  nan  |  nan  |
|      bannister      |  nan  |  nan  |
|      escalator      |  nan  |  nan  |
|       ottoman       |  0.0  |  nan  |
|        bottle       |  0.0  |  0.0  |
|        buffet       |  nan  |  nan  |
|        poster       | 37.13 | 39.46 |
|        stage        |  nan  |  nan  |
|         van         |  nan  |  nan  |
|         ship        |  nan  |  nan  |
|       fountain      |  nan  |  nan  |
|    conveyer belt    |  nan  |  nan  |
|        canopy       | 77.49 | 79.79 |
|        washer       |  nan  |  nan  |
|      plaything      | 28.94 | 50.78 |
|    swimming pool    |  nan  |  nan  |
|        stool        |  2.03 |  2.07 |
|        barrel       |  nan  |  nan  |
|        basket       | 13.06 | 15.31 |
|      waterfall      |  nan  |  nan  |
|         tent        |  nan  |  nan  |
|         bag         |  0.0  |  0.0  |
|       minibike      |  nan  |  nan  |
|        cradle       |  81.9 | 98.31 |
|         oven        |  nan  |  nan  |
|         ball        |  nan  |  nan  |
|         food        |  nan  |  nan  |
|         step        |  0.0  |  nan  |
|         tank        |  nan  |  nan  |
|      trade name     |  nan  |  nan  |
|      microwave      |  nan  |  nan  |
|         pot         |  0.0  |  nan  |
|        animal       |  nan  |  nan  |
|       bicycle       |  nan  |  nan  |
|         lake        |  nan  |  nan  |
|      dishwasher     |  nan  |  nan  |
|        screen       | 88.12 | 88.92 |
|       blanket       | 37.69 | 38.47 |
|      sculpture      |  0.0  |  nan  |
|         hood        |  nan  |  nan  |
|        sconce       | 49.15 | 84.03 |
|         vase        | 47.45 |  51.8 |
|    traffic light    |  nan  |  nan  |
|         tray        |  0.0  |  0.0  |
|        ashcan       |  0.0  |  0.0  |
|         fan         |  3.86 |  4.53 |
|         pier        |  nan  |  nan  |
|      crt screen     |  0.0  |  nan  |
|        plate        |  0.0  |  nan  |
|       monitor       |  0.0  |  0.0  |
|    bulletin board   |  0.0  |  nan  |
|        shower       |  nan  |  nan  |
|       radiator      |  68.4 | 71.64 |
|        glass        |  0.0  |  0.0  |
|        clock        |  6.43 |  7.6  |
|         flag        |  0.0  |  0.0  |
+---------------------+-------+-------+
Summary:

+-------+------+-------+
|  aAcc | mIoU |  mAcc |
+-------+------+-------+
| 78.84 | 34.5 | 53.86 |
+-------+------+-------+
