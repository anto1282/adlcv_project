Loaded dependency [python3/3.11.4]: gcc/12.3.0-binutils-2.40
Loaded dependency [python3/3.11.4]: sqlite3/3.42.0
Loaded module: python3/3.11.4

Loading python3/3.11.4
  Loading requirement: gcc/12.3.0-binutils-2.40 sqlite3/3.42.0
Loaded module: cuda/11.3
/dtu/blackhole/0e/154958/miniconda3/envs/ldm/lib/python3.8/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
2025-04-30 16:47:46,354 - mmseg - INFO - Multi-processing start method is `None`
2025-04-30 16:47:46,379 - mmseg - INFO - OpenCV num_threads is `1
2025-04-30 16:47:46,379 - mmseg - INFO - OMP num threads is 1
2025-04-30 16:47:46,407 - mmseg - INFO - Loaded 851 images
/dtu/blackhole/0e/154958/miniconda3/envs/ldm/lib/python3.8/site-packages/torch/utils/data/dataloader.py:487: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/dtu/blackhole/0e/154958/miniconda3/envs/ldm/lib/python3.8/site-packages/mmseg/models/losses/cross_entropy_loss.py:235: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.
  warnings.warn(
segmentation/test.py:313: UserWarning: SyncBN is only supported with DDP. To be compatible with DP, we convert SyncBN to BN. Please use dist_train.sh which can avoid this error.
  warnings.warn(
/dtu/blackhole/0e/154958/miniconda3/envs/ldm/lib/python3.8/site-packages/torch/utils/data/dataloader.py:487: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Traceback (most recent call last):
  File "segmentation/test.py", line 369, in <module>
    main()
  File "segmentation/test.py", line 322, in main
    results = single_gpu_test(
  File "/dtu/blackhole/0e/154958/miniconda3/envs/ldm/lib/python3.8/site-packages/mmseg/apis/test.py", line 89, in single_gpu_test
    for batch_indices, data in zip(loader_indices, data_loader):
  File "/dtu/blackhole/0e/154958/miniconda3/envs/ldm/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 530, in __next__
    data = self._next_data()
  File "/dtu/blackhole/0e/154958/miniconda3/envs/ldm/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 1204, in _next_data
    return self._process_data(data)
  File "/dtu/blackhole/0e/154958/miniconda3/envs/ldm/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 1250, in _process_data
    data.reraise()
  File "/dtu/blackhole/0e/154958/miniconda3/envs/ldm/lib/python3.8/site-packages/torch/_utils.py", line 457, in reraise
    raise exception
IndexError: Caught IndexError in DataLoader worker process 7.
Original Traceback (most recent call last):
  File "/dtu/blackhole/0e/154958/miniconda3/envs/ldm/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py", line 287, in _worker_loop
    data = fetcher.fetch(index)
  File "/dtu/blackhole/0e/154958/miniconda3/envs/ldm/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 49, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/dtu/blackhole/0e/154958/miniconda3/envs/ldm/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 49, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/dtu/blackhole/0e/154958/miniconda3/envs/ldm/lib/python3.8/site-packages/mmseg/datasets/custom.py", line 213, in __getitem__
    return self.prepare_test_img(idx)
  File "/dtu/blackhole/0e/154958/miniconda3/envs/ldm/lib/python3.8/site-packages/mmseg/datasets/custom.py", line 248, in prepare_test_img
    return self.pipeline(results)
  File "/dtu/blackhole/0e/154958/miniconda3/envs/ldm/lib/python3.8/site-packages/mmseg/datasets/pipelines/compose.py", line 41, in __call__
    data = t(data)
  File "/dtu/blackhole/0e/154958/miniconda3/envs/ldm/lib/python3.8/site-packages/mmseg/datasets/pipelines/test_time_aug.py", line 128, in __call__
    data = self.transforms(_results)
  File "/dtu/blackhole/0e/154958/miniconda3/envs/ldm/lib/python3.8/site-packages/mmseg/datasets/pipelines/compose.py", line 41, in __call__
    data = t(data)
  File "/zhome/b6/d/154958/ADLCV_Project/VPD/segmentation/datasets/augments.py", line 48, in __call__
    chosen_type = random.choice(list(gt_bbox_masks.keys()))
  File "/dtu/blackhole/0e/154958/miniconda3/envs/ldm/lib/python3.8/random.py", line 290, in choice
    raise IndexError('Cannot choose from an empty sequence') from None
IndexError: Cannot choose from an empty sequence

