âœ… Set input_type to scribble
Filtered dataset: 163 / 851 images kept.
LatentDiffusion: Running in eps-prediction mode
DiffusionWrapper has 859.52 M params.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 4, 32, 32) = 4096 dimensions.
making attention of type 'vanilla' with 512 in_channels
Restored from /work3/s203557/checkpoints/v1-5-pruned-emaonly.ckpt with 0 missing and 199 unexpected keys
Unexpected Keys: ['model_ema.decay', 'model_ema.num_updates', 'cond_stage_model.transformer.text_model.embeddings.position_ids', 'cond_stage_model.transformer.text_model.embeddings.token_embedding.weight', 'cond_stage_model.transformer.text_model.embeddings.position_embedding.weight', 'cond_stage_model.transformer.text_model.encoder.layers.0.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.0.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.0.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.0.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.0.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.0.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.0.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.0.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.0.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.0.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.0.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.0.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.0.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.0.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.0.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.0.layer_norm2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.1.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.1.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.1.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.1.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.1.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.1.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.1.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.1.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.1.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.1.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.1.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.1.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.1.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.1.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.1.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.1.layer_norm2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.2.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.2.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.2.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.2.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.2.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.2.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.2.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.2.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.2.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.2.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.2.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.2.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.2.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.2.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.2.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.2.layer_norm2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.3.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.3.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.3.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.3.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.3.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.3.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.3.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.3.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.3.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.3.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.3.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.3.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.3.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.3.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.3.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.3.layer_norm2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.4.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.4.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.4.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.4.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.4.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.4.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.4.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.4.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.4.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.4.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.4.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.4.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.4.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.4.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.4.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.4.layer_norm2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.5.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.5.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.5.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.5.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.5.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.5.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.5.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.5.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.5.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.5.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.5.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.5.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.5.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.5.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.5.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.5.layer_norm2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.6.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.6.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.6.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.6.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.6.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.6.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.6.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.6.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.6.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.6.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.6.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.6.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.6.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.6.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.6.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.6.layer_norm2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.7.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.7.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.7.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.7.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.7.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.7.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.7.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.7.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.7.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.7.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.7.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.7.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.7.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.7.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.7.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.7.layer_norm2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.8.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.8.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.8.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.8.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.8.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.8.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.8.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.8.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.8.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.8.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.8.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.8.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.8.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.8.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.8.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.8.layer_norm2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.9.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.9.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.9.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.9.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.9.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.9.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.9.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.9.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.9.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.9.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.9.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.9.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.9.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.9.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.9.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.9.layer_norm2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.10.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.10.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.10.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.10.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.10.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.10.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.10.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.10.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.10.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.10.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.10.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.10.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.10.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.10.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.10.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.10.layer_norm2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.11.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.11.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.11.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.11.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.11.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.11.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.11.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.11.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.11.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.11.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.11.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.11.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.11.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.11.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.11.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.11.layer_norm2.bias', 'cond_stage_model.transformer.text_model.final_layer_norm.weight', 'cond_stage_model.transformer.text_model.final_layer_norm.bias']
load checkpoint from local path: /work3/s203557/experiments/control_net_vpd/iter_12000.pth
The model and loaded state dict do not match exactly

unexpected key in source state_dict: sd_model.lvlb_weights

[                                                  ] 0/163, elapsed: 0s, ETA:[                                 ] 1/163, 0.2 task/s, elapsed: 7s, ETA:  1076s[                                 ] 2/163, 0.3 task/s, elapsed: 7s, ETA:   549s[                                 ] 3/163, 0.4 task/s, elapsed: 7s, ETA:   372s[                                 ] 4/163, 0.6 task/s, elapsed: 7s, ETA:   285s[>                                ] 5/163, 0.7 task/s, elapsed: 7s, ETA:   232s[>                                ] 6/163, 0.8 task/s, elapsed: 8s, ETA:   197s[>                                ] 7/163, 0.9 task/s, elapsed: 8s, ETA:   172s[>                                ] 8/163, 1.0 task/s, elapsed: 8s, ETA:   153s[>                                ] 9/163, 1.1 task/s, elapsed: 8s, ETA:   138s[>                               ] 10/163, 1.2 task/s, elapsed: 8s, ETA:   126s[>>                              ] 11/163, 1.3 task/s, elapsed: 8s, ETA:   117s[>>                              ] 12/163, 1.4 task/s, elapsed: 9s, ETA:   109s[>>                              ] 13/163, 1.5 task/s, elapsed: 9s, ETA:   102s[>>                              ] 14/163, 1.6 task/s, elapsed: 9s, ETA:    96s[>>                              ] 15/163, 1.6 task/s, elapsed: 9s, ETA:    91s[>>>                             ] 16/163, 1.7 task/s, elapsed: 9s, ETA:    86s[>>>                            ] 17/163, 1.8 task/s, elapsed: 10s, ETA:    82s[>>>                            ] 18/163, 1.9 task/s, elapsed: 10s, ETA:    78s[>>>                            ] 19/163, 1.9 task/s, elapsed: 10s, ETA:    75s[>>>                            ] 20/163, 2.0 task/s, elapsed: 10s, ETA:    72s[>>>                            ] 21/163, 2.1 task/s, elapsed: 10s, ETA:    69s[>>>>                           ] 22/163, 2.1 task/s, elapsed: 10s, ETA:    66s[>>>>                           ] 23/163, 2.2 task/s, elapsed: 11s, ETA:    64s[>>>>                           ] 24/163, 2.2 task/s, elapsed: 11s, ETA:    62s[>>>>                           ] 25/163, 2.3 task/s, elapsed: 11s, ETA:    60s[>>>>                           ] 26/163, 2.4 task/s, elapsed: 11s, ETA:    58s[>>>>>                          ] 27/163, 2.4 task/s, elapsed: 11s, ETA:    57s[>>>>>                          ] 28/163, 2.5 task/s, elapsed: 11s, ETA:    55s[>>>>>                          ] 29/163, 2.5 task/s, elapsed: 12s, ETA:    54s[>>>>>                          ] 30/163, 2.5 task/s, elapsed: 12s, ETA:    52s[>>>>>                          ] 31/163, 2.6 task/s, elapsed: 12s, ETA:    51s[>>>>>>                         ] 32/163, 2.6 task/s, elapsed: 12s, ETA:    50s[>>>>>>                         ] 33/163, 2.7 task/s, elapsed: 12s, ETA:    49s[>>>>>>                         ] 34/163, 2.7 task/s, elapsed: 13s, ETA:    47s[>>>>>>                         ] 35/163, 2.8 task/s, elapsed: 13s, ETA:    46s[>>>>>>                         ] 36/163, 2.8 task/s, elapsed: 13s, ETA:    45s[>>>>>>>                        ] 37/163, 2.8 task/s, elapsed: 13s, ETA:    44s[>>>>>>>                        ] 38/163, 2.9 task/s, elapsed: 13s, ETA:    43s[>>>>>>>                        ] 39/163, 2.9 task/s, elapsed: 13s, ETA:    43s[>>>>>>>                        ] 40/163, 2.9 task/s, elapsed: 14s, ETA:    42s[>>>>>>>                        ] 41/163, 3.0 task/s, elapsed: 14s, ETA:    41s[>>>>>>>                        ] 42/163, 3.0 task/s, elapsed: 14s, ETA:    40s[>>>>>>>>                       ] 43/163, 3.1 task/s, elapsed: 14s, ETA:    39s[>>>>>>>>                       ] 44/163, 3.1 task/s, elapsed: 14s, ETA:    39s[>>>>>>>>                       ] 45/163, 3.1 task/s, elapsed: 14s, ETA:    38s[>>>>>>>>                       ] 46/163, 3.1 task/s, elapsed: 15s, ETA:    37s[>>>>>>>>                       ] 47/163, 3.2 task/s, elapsed: 15s, ETA:    37s[>>>>>>>>>                      ] 48/163, 3.2 task/s, elapsed: 15s, ETA:    36s[>>>>>>>>>                      ] 49/163, 3.2 task/s, elapsed: 15s, ETA:    35s[>>>>>>>>>                      ] 50/163, 3.3 task/s, elapsed: 15s, ETA:    35s[>>>>>>>>>                      ] 51/163, 3.3 task/s, elapsed: 15s, ETA:    34s[>>>>>>>>>                      ] 52/163, 3.3 task/s, elapsed: 16s, ETA:    33s[>>>>>>>>>>                     ] 53/163, 3.3 task/s, elapsed: 16s, ETA:    33s[>>>>>>>>>>                     ] 54/163, 3.4 task/s, elapsed: 16s, ETA:    32s[>>>>>>>>>>                     ] 55/163, 3.4 task/s, elapsed: 16s, ETA:    32s[>>>>>>>>>>                     ] 56/163, 3.4 task/s, elapsed: 16s, ETA:    31s[>>>>>>>>>>                     ] 57/163, 3.4 task/s, elapsed: 17s, ETA:    31s[>>>>>>>>>>>                    ] 58/163, 3.5 task/s, elapsed: 17s, ETA:    30s[>>>>>>>>>>>                    ] 59/163, 3.5 task/s, elapsed: 17s, ETA:    30s[>>>>>>>>>>>                    ] 60/163, 3.5 task/s, elapsed: 17s, ETA:    29s[>>>>>>>>>>>                    ] 61/163, 3.5 task/s, elapsed: 17s, ETA:    29s[>>>>>>>>>>>                    ] 62/163, 3.6 task/s, elapsed: 17s, ETA:    28s[>>>>>>>>>>>                    ] 63/163, 3.6 task/s, elapsed: 18s, ETA:    28s[>>>>>>>>>>>>                   ] 64/163, 3.6 task/s, elapsed: 18s, ETA:    27s[>>>>>>>>>>>>                   ] 65/163, 3.6 task/s, elapsed: 18s, ETA:    27s[>>>>>>>>>>>>                   ] 66/163, 3.7 task/s, elapsed: 18s, ETA:    26s[>>>>>>>>>>>>                   ] 67/163, 3.7 task/s, elapsed: 18s, ETA:    26s[>>>>>>>>>>>>                   ] 68/163, 3.7 task/s, elapsed: 18s, ETA:    26s[>>>>>>>>>>>>>                  ] 69/163, 3.7 task/s, elapsed: 19s, ETA:    25s[>>>>>>>>>>>>>                  ] 70/163, 3.7 task/s, elapsed: 19s, ETA:    25s[>>>>>>>>>>>>>                  ] 71/163, 3.8 task/s, elapsed: 19s, ETA:    24s[>>>>>>>>>>>>>                  ] 72/163, 3.8 task/s, elapsed: 19s, ETA:    24s[>>>>>>>>>>>>>                  ] 73/163, 3.8 task/s, elapsed: 19s, ETA:    24s[>>>>>>>>>>>>>>                 ] 74/163, 3.8 task/s, elapsed: 19s, ETA:    23s[>>>>>>>>>>>>>>                 ] 75/163, 3.8 task/s, elapsed: 20s, ETA:    23s[>>>>>>>>>>>>>>                 ] 76/163, 3.8 task/s, elapsed: 20s, ETA:    23s[>>>>>>>>>>>>>>                 ] 77/163, 3.9 task/s, elapsed: 20s, ETA:    22s[>>>>>>>>>>>>>>                 ] 78/163, 3.9 task/s, elapsed: 20s, ETA:    22s[>>>>>>>>>>>>>>>                ] 79/163, 3.9 task/s, elapsed: 20s, ETA:    22s[>>>>>>>>>>>>>>>                ] 80/163, 3.9 task/s, elapsed: 20s, ETA:    21s[>>>>>>>>>>>>>>>                ] 81/163, 3.9 task/s, elapsed: 21s, ETA:    21s[>>>>>>>>>>>>>>>                ] 82/163, 3.9 task/s, elapsed: 21s, ETA:    21s[>>>>>>>>>>>>>>>                ] 83/163, 4.0 task/s, elapsed: 21s, ETA:    20s[>>>>>>>>>>>>>>>                ] 84/163, 4.0 task/s, elapsed: 21s, ETA:    20s[>>>>>>>>>>>>>>>>               ] 85/163, 4.0 task/s, elapsed: 21s, ETA:    20s[>>>>>>>>>>>>>>>>               ] 86/163, 4.0 task/s, elapsed: 21s, ETA:    19s[>>>>>>>>>>>>>>>>               ] 87/163, 4.0 task/s, elapsed: 22s, ETA:    19s[>>>>>>>>>>>>>>>>               ] 88/163, 4.0 task/s, elapsed: 22s, ETA:    19s[>>>>>>>>>>>>>>>>               ] 89/163, 4.1 task/s, elapsed: 22s, ETA:    18s[>>>>>>>>>>>>>>>>>              ] 90/163, 4.1 task/s, elapsed: 22s, ETA:    18s[>>>>>>>>>>>>>>>>>              ] 91/163, 4.1 task/s, elapsed: 22s, ETA:    18s[>>>>>>>>>>>>>>>>>              ] 92/163, 4.1 task/s, elapsed: 23s, ETA:    17s[>>>>>>>>>>>>>>>>>              ] 93/163, 4.1 task/s, elapsed: 23s, ETA:    17s[>>>>>>>>>>>>>>>>>              ] 94/163, 4.1 task/s, elapsed: 23s, ETA:    17s[>>>>>>>>>>>>>>>>>>             ] 95/163, 4.1 task/s, elapsed: 23s, ETA:    17s[>>>>>>>>>>>>>>>>>>             ] 96/163, 4.1 task/s, elapsed: 23s, ETA:    16s[>>>>>>>>>>>>>>>>>>             ] 97/163, 4.1 task/s, elapsed: 23s, ETA:    16s[>>>>>>>>>>>>>>>>>>             ] 98/163, 4.2 task/s, elapsed: 24s, ETA:    16s[>>>>>>>>>>>>>>>>>>             ] 99/163, 4.2 task/s, elapsed: 24s, ETA:    15s[>>>>>>>>>>>>>>>>>>            ] 100/163, 4.2 task/s, elapsed: 24s, ETA:    15s[>>>>>>>>>>>>>>>>>>            ] 101/163, 4.2 task/s, elapsed: 24s, ETA:    15s[>>>>>>>>>>>>>>>>>>            ] 102/163, 4.1 task/s, elapsed: 25s, ETA:    15s[>>>>>>>>>>>>>>>>>>            ] 103/163, 4.2 task/s, elapsed: 25s, ETA:    14s[>>>>>>>>>>>>>>>>>>>           ] 104/163, 4.2 task/s, elapsed: 25s, ETA:    14s[>>>>>>>>>>>>>>>>>>>           ] 105/163, 4.2 task/s, elapsed: 25s, ETA:    14s[>>>>>>>>>>>>>>>>>>>           ] 106/163, 4.2 task/s, elapsed: 25s, ETA:    14s[>>>>>>>>>>>>>>>>>>>           ] 107/163, 4.2 task/s, elapsed: 25s, ETA:    13s[>>>>>>>>>>>>>>>>>>>           ] 108/163, 4.2 task/s, elapsed: 26s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>          ] 109/163, 4.2 task/s, elapsed: 26s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>          ] 110/163, 4.2 task/s, elapsed: 26s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>          ] 111/163, 4.2 task/s, elapsed: 26s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>          ] 112/163, 4.2 task/s, elapsed: 26s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>          ] 113/163, 4.3 task/s, elapsed: 27s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>          ] 114/163, 4.3 task/s, elapsed: 27s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>         ] 115/163, 4.3 task/s, elapsed: 27s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>         ] 116/163, 4.3 task/s, elapsed: 27s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>         ] 117/163, 4.3 task/s, elapsed: 27s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>         ] 118/163, 4.3 task/s, elapsed: 27s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>         ] 119/163, 4.3 task/s, elapsed: 28s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>        ] 120/163, 4.3 task/s, elapsed: 28s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>        ] 121/163, 4.3 task/s, elapsed: 28s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>        ] 122/163, 4.3 task/s, elapsed: 28s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>        ] 123/163, 4.3 task/s, elapsed: 28s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>        ] 124/163, 4.3 task/s, elapsed: 29s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>       ] 125/163, 4.4 task/s, elapsed: 29s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>       ] 126/163, 4.4 task/s, elapsed: 29s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>       ] 127/163, 4.4 task/s, elapsed: 29s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>       ] 128/163, 4.4 task/s, elapsed: 29s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>       ] 129/163, 4.4 task/s, elapsed: 29s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>       ] 130/163, 4.4 task/s, elapsed: 30s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 131/163, 4.4 task/s, elapsed: 30s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 132/163, 4.4 task/s, elapsed: 30s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 133/163, 4.4 task/s, elapsed: 30s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 134/163, 4.4 task/s, elapsed: 30s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 135/163, 4.4 task/s, elapsed: 31s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 136/163, 4.4 task/s, elapsed: 31s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 137/163, 4.4 task/s, elapsed: 31s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 138/163, 4.4 task/s, elapsed: 31s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 139/163, 4.5 task/s, elapsed: 31s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 140/163, 4.5 task/s, elapsed: 31s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 141/163, 4.5 task/s, elapsed: 32s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 142/163, 4.5 task/s, elapsed: 32s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 143/163, 4.5 task/s, elapsed: 32s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 144/163, 4.5 task/s, elapsed: 32s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 145/163, 4.5 task/s, elapsed: 32s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 146/163, 4.5 task/s, elapsed: 32s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 147/163, 4.5 task/s, elapsed: 33s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 148/163, 4.5 task/s, elapsed: 33s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 149/163, 4.5 task/s, elapsed: 33s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 150/163, 4.5 task/s, elapsed: 33s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 151/163, 4.6 task/s, elapsed: 33s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 152/163, 4.6 task/s, elapsed: 33s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 153/163, 4.6 task/s, elapsed: 33s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 154/163, 4.6 task/s, elapsed: 34s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 155/163, 4.6 task/s, elapsed: 34s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 156/163, 4.6 task/s, elapsed: 34s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 157/163, 4.6 task/s, elapsed: 34s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 158/163, 4.6 task/s, elapsed: 34s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 159/163, 4.6 task/s, elapsed: 35s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 160/163, 4.6 task/s, elapsed: 35s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 161/163, 4.6 task/s, elapsed: 35s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 162/163, 4.6 task/s, elapsed: 35s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 163/163, 4.6 task/s, elapsed: 35s, ETA:     0sper class results:

+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        | 80.91 | 90.72 |
|       building      | 74.01 | 81.82 |
|         sky         | 90.49 | 96.57 |
|        floor        | 86.01 | 93.41 |
|         tree        | 15.34 |  25.2 |
|       ceiling       | 86.86 | 95.01 |
|         road        | 92.99 | 97.89 |
|         bed         | 90.45 | 97.38 |
|      windowpane     | 75.33 | 87.86 |
|        grass        |  0.0  |  0.0  |
|       cabinet       | 55.45 | 68.18 |
|       sidewalk      | 72.57 | 74.58 |
|        person       | 84.46 | 92.59 |
|        earth        | 20.12 | 63.48 |
|         door        | 63.32 | 74.59 |
|        table        | 67.38 | 81.12 |
|       mountain      | 51.86 | 57.33 |
|        plant        | 62.23 | 76.34 |
|       curtain       |  74.0 | 80.89 |
|        chair        | 68.28 | 80.88 |
|         car         | 60.92 | 63.39 |
|        water        |  0.0  |  0.0  |
|       painting      | 72.38 | 86.63 |
|         sofa        | 67.58 | 75.33 |
|        shelf        | 52.24 | 68.01 |
|        house        |  nan  |  nan  |
|         sea         |  nan  |  nan  |
|        mirror       | 83.09 | 91.58 |
|         rug         | 63.45 | 70.11 |
|        field        |  nan  |  nan  |
|       armchair      | 62.94 | 84.65 |
|         seat        | 59.36 | 61.98 |
|        fence        |  4.83 |  8.18 |
|         desk        | 56.32 | 83.76 |
|         rock        |  nan  |  nan  |
|       wardrobe      | 64.82 |  82.8 |
|         lamp        | 70.54 | 82.99 |
|       bathtub       |  92.8 | 99.51 |
|       railing       | 51.85 | 70.16 |
|       cushion       | 59.32 | 75.17 |
|         base        | 22.47 | 48.76 |
|         box         | 34.12 | 40.14 |
|        column       | 76.77 | 79.65 |
|      signboard      | 19.83 | 30.68 |
|   chest of drawers  | 48.41 | 79.87 |
|       counter       | 41.79 | 59.26 |
|         sand        | 80.32 | 81.21 |
|         sink        | 65.87 | 74.42 |
|      skyscraper     |  nan  |  nan  |
|      fireplace      | 63.35 | 92.12 |
|     refrigerator    | 67.44 | 69.16 |
|      grandstand     |  nan  |  nan  |
|         path        |  nan  |  nan  |
|        stairs       |  0.0  |  0.0  |
|        runway       | 94.01 | 99.58 |
|         case        |  0.0  |  0.0  |
|      pool table     | 97.31 | 99.48 |
|        pillow       | 57.15 |  61.9 |
|     screen door     |  0.0  |  0.0  |
|       stairway      |  2.18 |  2.19 |
|        river        |  nan  |  nan  |
|        bridge       |  nan  |  nan  |
|       bookcase      |  42.1 |  62.9 |
|        blind        | 74.29 | 76.02 |
|     coffee table    |  58.9 |  70.8 |
|        toilet       | 90.32 | 95.52 |
|        flower       | 60.01 | 73.23 |
|         book        | 34.59 |  67.7 |
|         hill        |  0.0  |  nan  |
|        bench        |  0.0  |  0.0  |
|      countertop     | 42.85 | 61.88 |
|        stove        | 53.54 | 96.71 |
|         palm        |  nan  |  nan  |
|    kitchen island   |  0.0  |  nan  |
|       computer      | 74.93 | 86.87 |
|     swivel chair    | 55.23 |  72.4 |
|         boat        |  nan  |  nan  |
|         bar         | 68.14 | 70.58 |
|    arcade machine   |  nan  |  nan  |
|        hovel        |  nan  |  nan  |
|         bus         |  nan  |  nan  |
|        towel        | 60.93 | 72.72 |
|        light        | 61.12 | 77.38 |
|        truck        |  8.23 | 10.35 |
|        tower        | 63.15 | 64.06 |
|      chandelier     | 72.59 | 84.73 |
|        awning       |  0.0  |  0.0  |
|     streetlight     |  2.12 |  2.13 |
|        booth        |  nan  |  nan  |
| television receiver | 48.26 | 58.93 |
|       airplane      | 71.24 | 93.64 |
|      dirt track     |  nan  |  nan  |
|       apparel       | 48.23 | 55.94 |
|         pole        | 18.33 | 74.92 |
|         land        |  nan  |  nan  |
|      bannister      |  0.0  |  nan  |
|      escalator      |  0.0  |  nan  |
|       ottoman       | 67.55 | 72.77 |
|        bottle       | 26.51 | 43.85 |
|        buffet       |  0.0  |  0.0  |
|        poster       | 22.97 | 38.65 |
|        stage        | 52.53 | 97.65 |
|         van         |  0.0  |  0.0  |
|         ship        |  nan  |  nan  |
|       fountain      |  0.0  |  nan  |
|    conveyer belt    | 91.81 | 99.55 |
|        canopy       |  0.0  |  nan  |
|        washer       |  nan  |  nan  |
|      plaything      | 18.83 | 55.46 |
|    swimming pool    |  nan  |  nan  |
|        stool        | 32.31 |  39.5 |
|        barrel       |  60.6 |  60.6 |
|        basket       |  42.1 | 56.33 |
|      waterfall      |  nan  |  nan  |
|         tent        |  nan  |  nan  |
|         bag         | 14.67 | 18.27 |
|       minibike      | 87.76 | 97.21 |
|        cradle       | 90.35 | 99.94 |
|         oven        |  0.0  |  0.0  |
|         ball        | 56.67 |  74.0 |
|         food        | 33.24 | 38.72 |
|         step        |  4.19 |  5.77 |
|         tank        |  0.0  |  0.0  |
|      trade name     |  0.0  |  0.0  |
|      microwave      | 66.55 |  79.0 |
|         pot         | 56.21 | 64.69 |
|        animal       |  nan  |  nan  |
|       bicycle       | 34.18 | 44.87 |
|         lake        |  nan  |  nan  |
|      dishwasher     |  0.0  |  nan  |
|        screen       | 42.59 | 42.73 |
|       blanket       | 15.85 | 16.75 |
|      sculpture      |  0.0  |  0.0  |
|         hood        |  0.0  |  0.0  |
|        sconce       | 47.73 | 60.74 |
|         vase        | 27.24 | 52.47 |
|    traffic light    |  0.0  |  0.0  |
|         tray        |  3.09 |  8.05 |
|        ashcan       | 19.18 | 33.01 |
|         fan         | 71.36 | 76.56 |
|         pier        |  nan  |  nan  |
|      crt screen     |  2.3  |  4.8  |
|        plate        |  52.3 | 70.85 |
|       monitor       |  0.0  |  0.0  |
|    bulletin board   | 48.33 | 83.87 |
|        shower       |  0.0  |  0.0  |
|       radiator      | 29.61 | 40.27 |
|        glass        | 15.14 | 16.46 |
|        clock        | 35.15 | 48.24 |
|         flag        | 45.06 | 55.12 |
+---------------------+-------+-------+
Summary:

+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 83.18 | 43.43 | 56.48 |
+-------+-------+-------+
