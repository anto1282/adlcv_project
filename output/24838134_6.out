âœ… Set input_type to scribble
Filtered dataset: 72 / 851 images kept.
LatentDiffusion: Running in eps-prediction mode
DiffusionWrapper has 859.52 M params.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 4, 32, 32) = 4096 dimensions.
making attention of type 'vanilla' with 512 in_channels
Restored from /work3/s203557/checkpoints/v1-5-pruned-emaonly.ckpt with 0 missing and 199 unexpected keys
Unexpected Keys: ['model_ema.decay', 'model_ema.num_updates', 'cond_stage_model.transformer.text_model.embeddings.position_ids', 'cond_stage_model.transformer.text_model.embeddings.token_embedding.weight', 'cond_stage_model.transformer.text_model.embeddings.position_embedding.weight', 'cond_stage_model.transformer.text_model.encoder.layers.0.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.0.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.0.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.0.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.0.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.0.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.0.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.0.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.0.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.0.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.0.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.0.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.0.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.0.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.0.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.0.layer_norm2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.1.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.1.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.1.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.1.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.1.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.1.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.1.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.1.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.1.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.1.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.1.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.1.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.1.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.1.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.1.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.1.layer_norm2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.2.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.2.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.2.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.2.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.2.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.2.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.2.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.2.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.2.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.2.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.2.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.2.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.2.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.2.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.2.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.2.layer_norm2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.3.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.3.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.3.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.3.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.3.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.3.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.3.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.3.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.3.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.3.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.3.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.3.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.3.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.3.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.3.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.3.layer_norm2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.4.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.4.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.4.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.4.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.4.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.4.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.4.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.4.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.4.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.4.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.4.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.4.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.4.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.4.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.4.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.4.layer_norm2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.5.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.5.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.5.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.5.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.5.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.5.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.5.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.5.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.5.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.5.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.5.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.5.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.5.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.5.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.5.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.5.layer_norm2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.6.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.6.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.6.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.6.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.6.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.6.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.6.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.6.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.6.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.6.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.6.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.6.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.6.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.6.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.6.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.6.layer_norm2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.7.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.7.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.7.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.7.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.7.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.7.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.7.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.7.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.7.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.7.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.7.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.7.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.7.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.7.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.7.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.7.layer_norm2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.8.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.8.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.8.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.8.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.8.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.8.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.8.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.8.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.8.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.8.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.8.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.8.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.8.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.8.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.8.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.8.layer_norm2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.9.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.9.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.9.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.9.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.9.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.9.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.9.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.9.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.9.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.9.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.9.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.9.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.9.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.9.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.9.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.9.layer_norm2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.10.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.10.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.10.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.10.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.10.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.10.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.10.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.10.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.10.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.10.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.10.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.10.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.10.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.10.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.10.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.10.layer_norm2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.11.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.11.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.11.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.11.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.11.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.11.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.11.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.11.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.11.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.11.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.11.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.11.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.11.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.11.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.11.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.11.layer_norm2.bias', 'cond_stage_model.transformer.text_model.final_layer_norm.weight', 'cond_stage_model.transformer.text_model.final_layer_norm.bias']
load checkpoint from local path: /work3/s203557/experiments/control_net_vpd/iter_12000.pth
The model and loaded state dict do not match exactly

unexpected key in source state_dict: sd_model.lvlb_weights

[                                                  ] 0/72, elapsed: 0s, ETA:[                                  ] 1/72, 0.3 task/s, elapsed: 3s, ETA:   248s[                                  ] 2/72, 0.5 task/s, elapsed: 4s, ETA:   128s[>                                 ] 3/72, 0.8 task/s, elapsed: 4s, ETA:    89s[>                                 ] 4/72, 1.0 task/s, elapsed: 4s, ETA:    68s[>>                                ] 5/72, 1.2 task/s, elapsed: 4s, ETA:    56s[>>                                ] 6/72, 1.4 task/s, elapsed: 4s, ETA:    48s[>>>                               ] 7/72, 1.5 task/s, elapsed: 5s, ETA:    42s[>>>                               ] 8/72, 1.7 task/s, elapsed: 5s, ETA:    38s[>>>>                              ] 9/72, 1.8 task/s, elapsed: 5s, ETA:    34s[>>>>                             ] 10/72, 2.0 task/s, elapsed: 5s, ETA:    31s[>>>>>                            ] 11/72, 2.1 task/s, elapsed: 5s, ETA:    29s[>>>>>                            ] 12/72, 2.2 task/s, elapsed: 5s, ETA:    27s[>>>>>                            ] 13/72, 2.4 task/s, elapsed: 6s, ETA:    25s[>>>>>>                           ] 14/72, 2.5 task/s, elapsed: 6s, ETA:    24s[>>>>>>                           ] 15/72, 2.6 task/s, elapsed: 6s, ETA:    22s[>>>>>>>                          ] 16/72, 2.7 task/s, elapsed: 6s, ETA:    21s[>>>>>>>                          ] 17/72, 2.7 task/s, elapsed: 6s, ETA:    20s[>>>>>>>>                         ] 18/72, 2.8 task/s, elapsed: 6s, ETA:    19s[>>>>>>>>                         ] 19/72, 2.9 task/s, elapsed: 7s, ETA:    18s[>>>>>>>>>                        ] 20/72, 3.0 task/s, elapsed: 7s, ETA:    17s[>>>>>>>>>                        ] 21/72, 3.1 task/s, elapsed: 7s, ETA:    17s[>>>>>>>>>>                       ] 22/72, 3.1 task/s, elapsed: 7s, ETA:    16s[>>>>>>>>>>                       ] 23/72, 3.2 task/s, elapsed: 7s, ETA:    15s[>>>>>>>>>>>                      ] 24/72, 3.3 task/s, elapsed: 7s, ETA:    15s[>>>>>>>>>>>                      ] 25/72, 3.3 task/s, elapsed: 8s, ETA:    14s[>>>>>>>>>>>                      ] 26/72, 3.4 task/s, elapsed: 8s, ETA:    14s[>>>>>>>>>>>>                     ] 27/72, 3.4 task/s, elapsed: 8s, ETA:    13s[>>>>>>>>>>>>                     ] 28/72, 3.5 task/s, elapsed: 8s, ETA:    13s[>>>>>>>>>>>>>                    ] 29/72, 3.6 task/s, elapsed: 8s, ETA:    12s[>>>>>>>>>>>>>                    ] 30/72, 3.6 task/s, elapsed: 8s, ETA:    12s[>>>>>>>>>>>>>>                   ] 31/72, 3.7 task/s, elapsed: 8s, ETA:    11s[>>>>>>>>>>>>>>                   ] 32/72, 3.7 task/s, elapsed: 9s, ETA:    11s[>>>>>>>>>>>>>>>                  ] 33/72, 3.7 task/s, elapsed: 9s, ETA:    10s[>>>>>>>>>>>>>>>                  ] 34/72, 3.8 task/s, elapsed: 9s, ETA:    10s[>>>>>>>>>>>>>>>>                 ] 35/72, 3.8 task/s, elapsed: 9s, ETA:    10s[>>>>>>>>>>>>>>>>                 ] 36/72, 3.8 task/s, elapsed: 9s, ETA:     9s[>>>>>>>>>>>>>>>>                ] 37/72, 3.9 task/s, elapsed: 10s, ETA:     9s[>>>>>>>>>>>>>>>>                ] 38/72, 3.9 task/s, elapsed: 10s, ETA:     9s[>>>>>>>>>>>>>>>>>               ] 39/72, 4.0 task/s, elapsed: 10s, ETA:     8s[>>>>>>>>>>>>>>>>>               ] 40/72, 4.0 task/s, elapsed: 10s, ETA:     8s[>>>>>>>>>>>>>>>>>>              ] 41/72, 4.0 task/s, elapsed: 10s, ETA:     8s[>>>>>>>>>>>>>>>>>>              ] 42/72, 4.1 task/s, elapsed: 10s, ETA:     7s[>>>>>>>>>>>>>>>>>>>             ] 43/72, 4.1 task/s, elapsed: 10s, ETA:     7s[>>>>>>>>>>>>>>>>>>>             ] 44/72, 4.1 task/s, elapsed: 11s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>            ] 45/72, 4.2 task/s, elapsed: 11s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>            ] 46/72, 4.2 task/s, elapsed: 11s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>            ] 47/72, 4.2 task/s, elapsed: 11s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>           ] 48/72, 4.2 task/s, elapsed: 11s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>           ] 49/72, 4.3 task/s, elapsed: 11s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>          ] 50/72, 4.3 task/s, elapsed: 12s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>          ] 51/72, 4.3 task/s, elapsed: 12s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>         ] 52/72, 4.3 task/s, elapsed: 12s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>         ] 53/72, 4.4 task/s, elapsed: 12s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>        ] 54/72, 4.4 task/s, elapsed: 12s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>        ] 55/72, 4.4 task/s, elapsed: 12s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>        ] 56/72, 4.4 task/s, elapsed: 13s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>       ] 57/72, 4.5 task/s, elapsed: 13s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>       ] 58/72, 4.5 task/s, elapsed: 13s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>      ] 59/72, 4.5 task/s, elapsed: 13s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>      ] 60/72, 4.5 task/s, elapsed: 13s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>     ] 61/72, 4.5 task/s, elapsed: 13s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>     ] 62/72, 4.6 task/s, elapsed: 14s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 63/72, 4.6 task/s, elapsed: 14s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 64/72, 4.6 task/s, elapsed: 14s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 65/72, 4.6 task/s, elapsed: 14s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 66/72, 4.6 task/s, elapsed: 14s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 67/72, 4.6 task/s, elapsed: 14s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 68/72, 4.6 task/s, elapsed: 15s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 69/72, 4.7 task/s, elapsed: 15s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 70/72, 4.7 task/s, elapsed: 15s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 71/72, 4.7 task/s, elapsed: 15s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 72/72, 4.7 task/s, elapsed: 15s, ETA:     0sper class results:

+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        |  78.2 | 88.19 |
|       building      | 92.24 | 96.72 |
|         sky         | 83.71 | 87.82 |
|        floor        | 83.92 | 94.11 |
|         tree        | 70.93 | 82.48 |
|       ceiling       | 86.32 | 91.23 |
|         road        | 76.67 | 77.72 |
|         bed         | 90.16 | 97.73 |
|      windowpane     | 67.78 | 87.95 |
|        grass        | 67.47 | 88.32 |
|       cabinet       | 42.93 | 49.98 |
|       sidewalk      |  68.9 | 86.95 |
|        person       | 82.67 | 93.29 |
|        earth        | 14.47 | 15.54 |
|         door        | 70.03 | 78.77 |
|        table        | 53.97 |  75.2 |
|       mountain      |  nan  |  nan  |
|        plant        | 47.54 | 66.43 |
|       curtain       | 83.15 | 98.53 |
|        chair        | 52.25 | 56.45 |
|         car         | 89.73 | 94.32 |
|        water        | 82.04 | 86.35 |
|       painting      | 67.25 | 92.12 |
|         sofa        | 14.17 | 26.94 |
|        shelf        |  55.1 | 78.68 |
|        house        |  nan  |  nan  |
|         sea         | 56.09 | 98.18 |
|        mirror       | 47.67 | 75.67 |
|         rug         | 28.23 | 28.74 |
|        field        |  nan  |  nan  |
|       armchair      | 70.39 | 80.95 |
|         seat        | 31.18 | 83.06 |
|        fence        | 19.18 | 28.56 |
|         desk        | 51.53 | 83.32 |
|         rock        |  0.0  |  0.0  |
|       wardrobe      | 75.21 | 83.38 |
|         lamp        |  76.8 | 84.99 |
|       bathtub       |  nan  |  nan  |
|       railing       | 68.22 | 78.09 |
|       cushion       | 32.56 | 43.13 |
|         base        | 20.73 | 71.08 |
|         box         |  40.6 | 53.61 |
|        column       |  0.0  |  0.0  |
|      signboard      | 30.52 | 41.49 |
|   chest of drawers  | 15.76 | 99.58 |
|       counter       | 40.33 | 42.27 |
|         sand        |  nan  |  nan  |
|         sink        | 59.19 | 68.01 |
|      skyscraper     |  nan  |  nan  |
|      fireplace      |  0.0  |  nan  |
|     refrigerator    | 58.66 | 59.17 |
|      grandstand     |  0.0  |  nan  |
|         path        | 88.76 | 91.18 |
|        stairs       |  0.0  |  0.0  |
|        runway       |  nan  |  nan  |
|         case        |  6.96 | 82.98 |
|      pool table     |  nan  |  nan  |
|        pillow       |  44.9 | 45.04 |
|     screen door     |  nan  |  nan  |
|       stairway      |  0.0  |  0.0  |
|        river        |  0.0  |  nan  |
|        bridge       |  0.0  |  nan  |
|       bookcase      |  nan  |  nan  |
|        blind        |  5.18 |  5.18 |
|     coffee table    |  35.3 | 35.94 |
|        toilet       |  nan  |  nan  |
|        flower       | 44.09 | 59.07 |
|         book        |  12.4 | 16.64 |
|         hill        |  nan  |  nan  |
|        bench        | 48.54 | 50.14 |
|      countertop     | 12.93 | 12.95 |
|        stove        | 89.57 |  95.6 |
|         palm        |  0.0  |  0.0  |
|    kitchen island   |  0.0  |  nan  |
|       computer      |  0.0  |  nan  |
|     swivel chair    |  68.6 | 86.76 |
|         boat        |  0.06 |  1.42 |
|         bar         |  0.0  |  nan  |
|    arcade machine   |  nan  |  nan  |
|        hovel        |  nan  |  nan  |
|         bus         | 89.96 |  95.7 |
|        towel        |  0.0  |  0.0  |
|        light        | 66.22 | 70.32 |
|        truck        |  0.0  |  0.0  |
|        tower        |  nan  |  nan  |
|      chandelier     |  nan  |  nan  |
|        awning       |  7.46 |  7.51 |
|     streetlight     | 39.08 | 55.03 |
|        booth        |  nan  |  nan  |
| television receiver | 28.99 | 38.74 |
|       airplane      |  nan  |  nan  |
|      dirt track     |  nan  |  nan  |
|       apparel       | 10.53 | 11.18 |
|         pole        | 56.31 | 72.76 |
|         land        |  nan  |  nan  |
|      bannister      |  0.0  |  nan  |
|      escalator      |  nan  |  nan  |
|       ottoman       |  0.0  |  0.0  |
|        bottle       | 20.82 | 43.71 |
|        buffet       |  nan  |  nan  |
|        poster       | 91.69 | 99.03 |
|        stage        |  nan  |  nan  |
|         van         | 70.62 |  93.7 |
|         ship        |  nan  |  nan  |
|       fountain      |  0.0  |  nan  |
|    conveyer belt    | 95.94 | 96.07 |
|        canopy       |  0.0  |  nan  |
|        washer       |  0.0  |  0.0  |
|      plaything      |  7.75 |  58.7 |
|    swimming pool    |  nan  |  nan  |
|        stool        |  0.0  |  nan  |
|        barrel       |  nan  |  nan  |
|        basket       | 43.95 | 70.38 |
|      waterfall      |  nan  |  nan  |
|         tent        |  nan  |  nan  |
|         bag         | 17.83 | 18.78 |
|       minibike      | 82.27 | 90.28 |
|        cradle       |  nan  |  nan  |
|         oven        |  0.0  |  nan  |
|         ball        |  39.4 | 39.51 |
|         food        | 25.31 | 29.26 |
|         step        | 13.34 | 13.99 |
|         tank        |  0.0  |  0.0  |
|      trade name     | 62.37 | 70.19 |
|      microwave      |  69.1 | 71.85 |
|         pot         | 77.77 |  83.5 |
|        animal       |  nan  |  nan  |
|       bicycle       | 55.59 | 76.33 |
|         lake        |  nan  |  nan  |
|      dishwasher     |  nan  |  nan  |
|        screen       |  nan  |  nan  |
|       blanket       |  0.0  |  nan  |
|      sculpture      |  0.0  |  nan  |
|         hood        |  0.0  |  0.0  |
|        sconce       | 21.72 | 28.35 |
|         vase        | 48.55 | 75.54 |
|    traffic light    | 36.79 | 48.58 |
|         tray        |  1.72 |  8.15 |
|        ashcan       | 15.76 | 34.46 |
|         fan         | 55.82 | 61.31 |
|         pier        |  0.0  |  0.0  |
|      crt screen     | 71.73 | 76.27 |
|        plate        | 62.43 | 67.79 |
|       monitor       |  0.0  |  0.0  |
|    bulletin board   | 60.69 | 69.25 |
|        shower       |  nan  |  nan  |
|       radiator      |  0.0  |  0.0  |
|        glass        | 11.68 | 12.67 |
|        clock        | 20.71 | 53.16 |
|         flag        | 17.06 | 23.25 |
+---------------------+-------+-------+
Summary:

+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 83.02 | 37.92 | 54.35 |
+-------+-------+-------+
