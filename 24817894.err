Loaded dependency [python3/3.11.4]: gcc/12.3.0-binutils-2.40
Loaded dependency [python3/3.11.4]: sqlite3/3.42.0
Loaded module: python3/3.11.4

Loading python3/3.11.4
  Loading requirement: gcc/12.3.0-binutils-2.40 sqlite3/3.42.0
Loaded module: cuda/11.3
/dtu/blackhole/0e/154958/miniconda3/envs/ldm/lib/python3.8/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
2025-04-27 21:27:32,236 - mmseg - INFO - Multi-processing start method is `None`
2025-04-27 21:27:32,299 - mmseg - INFO - OpenCV num_threads is `1
2025-04-27 21:27:32,299 - mmseg - INFO - OMP num threads is 1
2025-04-27 21:27:32,474 - mmseg - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.8.19 | packaged by conda-forge | (default, Mar 20 2024, 12:47:35) [GCC 12.3.0]
CUDA available: True
GPU 0: NVIDIA A100-PCIE-40GB
CUDA_HOME: /appl/cuda/11.3.0
NVCC: Cuda compilation tools, release 11.3, V11.3.58
GCC: gcc (GCC) 12.3.0
PyTorch: 1.11.0+cu113
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.5.2 (Git Hash a9302535553c73243c632ad3c4c80beec3d19a1e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.11.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

TorchVision: 0.12.0+cu113
OpenCV: 4.6.0
MMCV: 1.5.0
MMCV Compiler: GCC 7.3
MMCV CUDA Compiler: 11.3
MMSegmentation: 0.29.0+ec74f67
------------------------------------------------------------

2025-04-27 21:27:32,474 - mmseg - INFO - Distributed training: False
2025-04-27 21:27:34,544 - mmseg - INFO - Config:
norm_cfg = dict(type='SyncBN', requires_grad=True)
model = dict(
    type='VPDSeg',
    pretrained='open-mmlab://resnet50_v1c',
    backbone=dict(
        type='ResNetV1c',
        depth=50,
        num_stages=4,
        out_indices=(0, 1, 2, 3),
        dilations=(1, 1, 1, 1),
        strides=(1, 2, 2, 2),
        norm_cfg=dict(type='SyncBN', requires_grad=True),
        norm_eval=False,
        style='pytorch',
        contract_dilation=True),
    neck=dict(
        type='FPN',
        in_channels=[320, 790, 1430, 1280],
        out_channels=256,
        num_outs=4),
    decode_head=dict(
        type='FPNHead',
        in_channels=[256, 256, 256, 256],
        in_index=[0, 1, 2, 3],
        feature_strides=[4, 8, 16, 32],
        channels=256,
        dropout_ratio=0.1,
        num_classes=150,
        norm_cfg=dict(type='SyncBN', requires_grad=True),
        align_corners=False,
        loss_decode=dict(
            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0)),
    train_cfg=dict(),
    test_cfg=dict(mode='slide', crop_size=(512, 512), stride=(341, 341)),
    sd_path='/work3/s203557/checkpoints/v1-5-pruned-emaonly.ckpt',
    sd_config=
    '/zhome/b6/d/154958/ADLCV_Project/VPD/segmentation/v1-inference.yaml',
    max_boxes=6)
dataset_type = 'ADE20KDataset'
data_root = '/work3/s203520/advanced_computer_vision/filtered_dataset'
IMG_MEAN = [127.5, 127.5, 127.5]
IMG_VAR = [127.5, 127.5, 127.5]
img_norm_cfg = dict(
    mean=[127.5, 127.5, 127.5], std=[127.5, 127.5, 127.5], to_rgb=True)
crop_size = (512, 512)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations', reduce_zero_label=True),
    dict(
        type='LoadPerClassMasksFromFolder',
        mask_root=
        '/work3/s203520/advanced_computer_vision/filtered_dataset/prompt_masks',
        types=['box', 'scribble', 'dot'],
        suffix='.npy',
        random_select=True),
    dict(type='ResizeWithBBox', img_scale=(2048, 512), ratio_range=(0.5, 2.0)),
    dict(type='RandomCropWithBBox', crop_size=(512, 512), cat_max_ratio=0.75),
    dict(type='RandomFlipWithBBox', prob=0.5),
    dict(type='PhotoMetricDistortion'),
    dict(
        type='Normalize',
        mean=[127.5, 127.5, 127.5],
        std=[127.5, 127.5, 127.5],
        to_rgb=True),
    dict(
        type='PadToSizeWithBBox', size=(512, 512), pad_val=0, seg_pad_val=255),
    dict(type='DefaultFormatBundle'),
    dict(
        type='Collect',
        keys=['img', 'gt_semantic_seg', 'gt_bbox_masks'],
        meta_keys=('filename', 'ori_shape', 'img_shape', 'pad_shape',
                   'scale_factor', 'input_type'))
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(512, 512),
        flip=False,
        transforms=[
            dict(type='ResizeWithBBox', keep_ratio=False),
            dict(type='RandomFlipWithBBox'),
            dict(
                type='Normalize',
                mean=[127.5, 127.5, 127.5],
                std=[127.5, 127.5, 127.5],
                to_rgb=True),
            dict(
                type='LoadPerClassMasksFromFolder',
                mask_root=
                '/work3/s203520/advanced_computer_vision/filtered_dataset/prompt_masks',
                suffix='.npy',
                types=['box', 'scribble', 'dot'],
                random_select=True),
            dict(type='ImageToTensor', keys=['img']),
            dict(
                type='Collect',
                keys=['img', 'gt_bbox_masks'],
                meta_keys=('filename', 'ori_shape', 'img_shape', 'pad_shape',
                           'scale_factor', 'input_type'))
        ])
]
data = dict(
    samples_per_gpu=1,
    workers_per_gpu=8,
    train=dict(
        type='ADE20KDataset',
        data_root='/work3/s203520/advanced_computer_vision/filtered_dataset',
        img_dir='images/training',
        ann_dir='annotations/training',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations', reduce_zero_label=True),
            dict(
                type='LoadPerClassMasksFromFolder',
                mask_root=
                '/work3/s203520/advanced_computer_vision/filtered_dataset/prompt_masks',
                types=['box', 'scribble', 'dot'],
                suffix='.npy',
                random_select=True),
            dict(
                type='ResizeWithBBox',
                img_scale=(2048, 512),
                ratio_range=(0.5, 2.0)),
            dict(
                type='RandomCropWithBBox',
                crop_size=(512, 512),
                cat_max_ratio=0.75),
            dict(type='RandomFlipWithBBox', prob=0.5),
            dict(type='PhotoMetricDistortion'),
            dict(
                type='Normalize',
                mean=[127.5, 127.5, 127.5],
                std=[127.5, 127.5, 127.5],
                to_rgb=True),
            dict(
                type='PadToSizeWithBBox',
                size=(512, 512),
                pad_val=0,
                seg_pad_val=255),
            dict(type='DefaultFormatBundle'),
            dict(
                type='Collect',
                keys=['img', 'gt_semantic_seg', 'gt_bbox_masks'],
                meta_keys=('filename', 'ori_shape', 'img_shape', 'pad_shape',
                           'scale_factor', 'input_type'))
        ]),
    val=dict(
        type='ADE20KDataset',
        data_root='/work3/s203520/advanced_computer_vision/filtered_dataset',
        img_dir='images/validation',
        ann_dir='annotations/validation',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(512, 512),
                flip=False,
                transforms=[
                    dict(type='ResizeWithBBox', keep_ratio=False),
                    dict(type='RandomFlipWithBBox'),
                    dict(
                        type='Normalize',
                        mean=[127.5, 127.5, 127.5],
                        std=[127.5, 127.5, 127.5],
                        to_rgb=True),
                    dict(
                        type='LoadPerClassMasksFromFolder',
                        mask_root=
                        '/work3/s203520/advanced_computer_vision/filtered_dataset/prompt_masks',
                        suffix='.npy',
                        types=['box', 'scribble', 'dot'],
                        random_select=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(
                        type='Collect',
                        keys=['img', 'gt_bbox_masks'],
                        meta_keys=('filename', 'ori_shape', 'img_shape',
                                   'pad_shape', 'scale_factor', 'input_type'))
                ])
        ]),
    test=dict(
        type='ADE20KDataset',
        data_root='/work3/s203520/advanced_computer_vision/filtered_dataset',
        img_dir='images/validation',
        ann_dir='annotations/validation',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(512, 512),
                flip=False,
                transforms=[
                    dict(type='ResizeWithBBox', keep_ratio=False),
                    dict(type='RandomFlipWithBBox'),
                    dict(
                        type='Normalize',
                        mean=[127.5, 127.5, 127.5],
                        std=[127.5, 127.5, 127.5],
                        to_rgb=True),
                    dict(
                        type='LoadPerClassMasksFromFolder',
                        mask_root=
                        '/work3/s203520/advanced_computer_vision/filtered_dataset/prompt_masks',
                        suffix='.npy',
                        types=['box', 'scribble', 'dot'],
                        random_select=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(
                        type='Collect',
                        keys=['img', 'gt_bbox_masks'],
                        meta_keys=('filename', 'ori_shape', 'img_shape',
                                   'pad_shape', 'scale_factor', 'input_type'))
                ])
        ]))
log_config = dict(
    interval=50, hooks=[dict(type='TextLoggerHook', by_epoch=False)])
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = '/work3/s203557/checkpoints/vpd.chkpt'
resume_from = None
workflow = [('train', 1)]
cudnn_benchmark = True
find_unused_parameters = True
optimizer = dict(
    type='AdamW',
    lr=8e-05,
    weight_decay=0.001,
    paramwise_cfg=dict(
        custom_keys=dict(
            trainable_unet=dict(lr_mult=0.1), encoder_vq=dict(lr_mult=0.0))))
optimizer_config = dict()
lr_config = dict(
    policy='poly',
    power=1,
    min_lr=0.0,
    by_epoch=False,
    warmup='linear',
    warmup_iters=1500,
    warmup_ratio=1e-06)
runner = dict(type='IterBasedRunner', max_iters=40000)
checkpoint_config = dict(by_epoch=False, interval=4000)
evaluation = dict(interval=4000, metric='mIoU')
custom_imports = dict(
    imports=['segmentation.hooks.visualize_hook'], allow_failed_imports=False)
work_dir = '/work3/s203557/experiments/control_net_vpd/'
fp16 = dict(loss_scale=512.0)
custom_hooks = [
    dict(
        type='TrainVisualizeHook',
        interval=4000,
        num_samples=2,
        save_dir='vis')
]
gpu_ids = [0]
auto_resume = False

2025-04-27 21:27:34,544 - mmseg - INFO - Set random seed to 379426044, deterministic: False
/dtu/blackhole/0e/154958/miniconda3/envs/ldm/lib/python3.8/site-packages/mmseg/models/losses/cross_entropy_loss.py:235: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.
  warnings.warn(
2025-04-27 21:27:46,580 - mmseg - INFO - initialize FPN with init_cfg {'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}
2025-04-27 21:27:46,601 - mmseg - INFO - initialize FPNHead with init_cfg {'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
segmentation/train.py:251: UserWarning: SyncBN is only supported with DDP. To be compatible with DP, we convert SyncBN to BN. Please use dist_train.sh which can avoid this error.
  warnings.warn(
2025-04-27 21:27:47,415 - mmseg - INFO - VPDSeg(
  (encoder_vq): AutoencoderKL(
    (encoder): Encoder(
      (conv_in): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (down): ModuleList(
        (0): Module(
          (block): ModuleList(
            (0): ResnetBlock(
              (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)
              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
            (1): ResnetBlock(
              (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)
              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (attn): ModuleList()
          (downsample): Downsample(
            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2))
          )
        )
        (1): Module(
          (block): ModuleList(
            (0): ResnetBlock(
              (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)
              (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (nin_shortcut): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): ResnetBlock(
              (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (attn): ModuleList()
          (downsample): Downsample(
            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))
          )
        )
        (2): Module(
          (block): ModuleList(
            (0): ResnetBlock(
              (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)
              (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (nin_shortcut): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): ResnetBlock(
              (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)
              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (attn): ModuleList()
          (downsample): Downsample(
            (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2))
          )
        )
        (3): Module(
          (block): ModuleList(
            (0): ResnetBlock(
              (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)
              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
            (1): ResnetBlock(
              (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)
              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (attn): ModuleList()
        )
      )
      (mid): Module(
        (block_1): ResnetBlock(
          (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)
          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (attn_1): AttnBlock(
          (norm): GroupNorm(32, 512, eps=1e-06, affine=True)
          (q): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (k): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (v): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (proj_out): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
        )
        (block_2): ResnetBlock(
          (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)
          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (norm_out): GroupNorm(32, 512, eps=1e-06, affine=True)
      (conv_out): Conv2d(512, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (loss): Identity()
    (quant_conv): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1))
    (post_quant_conv): Conv2d(4, 4, kernel_size=(1, 1), stride=(1, 1))
  )
  (unet): UNetWrapper(
    (unet): DiffusionWrapper(
      (diffusion_model): UNetModel(
        (time_embed): Sequential(
          (0): Linear(in_features=320, out_features=1280, bias=True)
          (1): SiLU()
          (2): Linear(in_features=1280, out_features=1280, bias=True)
        )
        (input_blocks): ModuleList(
          (0): TimestepEmbedSequential(
            (0): Conv2d(4, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (1): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=320, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Identity()
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 320, eps=1e-06, affine=True)
              (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=320, out_features=320, bias=False)
                    (to_v): Linear(in_features=320, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=320, out_features=2560, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=1280, out_features=320, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=768, out_features=320, bias=False)
                    (to_v): Linear(in_features=768, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (2): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=320, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Identity()
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 320, eps=1e-06, affine=True)
              (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=320, out_features=320, bias=False)
                    (to_v): Linear(in_features=320, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=320, out_features=2560, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=1280, out_features=320, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=768, out_features=320, bias=False)
                    (to_v): Linear(in_features=768, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (3): TimestepEmbedSequential(
            (0): Downsample(
              (op): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
            )
          )
          (4): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(320, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=640, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(320, 640, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 640, eps=1e-06, affine=True)
              (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=640, out_features=640, bias=False)
                    (to_v): Linear(in_features=640, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=640, out_features=5120, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=2560, out_features=640, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=768, out_features=640, bias=False)
                    (to_v): Linear(in_features=768, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (5): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=640, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Identity()
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 640, eps=1e-06, affine=True)
              (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=640, out_features=640, bias=False)
                    (to_v): Linear(in_features=640, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=640, out_features=5120, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=2560, out_features=640, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=768, out_features=640, bias=False)
                    (to_v): Linear(in_features=768, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (6): TimestepEmbedSequential(
            (0): Downsample(
              (op): Conv2d(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
            )
          )
          (7): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(640, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(640, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)
              (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_v): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=1280, out_features=10240, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=5120, out_features=1280, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=768, out_features=1280, bias=False)
                    (to_v): Linear(in_features=768, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (8): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Identity()
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)
              (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_v): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=1280, out_features=10240, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=5120, out_features=1280, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=768, out_features=1280, bias=False)
                    (to_v): Linear(in_features=768, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (9): TimestepEmbedSequential(
            (0): Downsample(
              (op): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
            )
          )
          (10): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Identity()
            )
          )
          (11): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Identity()
            )
          )
        )
        (middle_block): TimestepEmbedSequential(
          (0): ResBlock(
            (in_layers): Sequential(
              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
              (1): SiLU()
              (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
            (h_upd): Identity()
            (x_upd): Identity()
            (emb_layers): Sequential(
              (0): SiLU()
              (1): Linear(in_features=1280, out_features=1280, bias=True)
            )
            (out_layers): Sequential(
              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
              (1): SiLU()
              (2): Dropout(p=0, inplace=False)
              (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
            (skip_connection): Identity()
          )
          (1): SpatialTransformer(
            (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)
            (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
            (transformer_blocks): ModuleList(
              (0): BasicTransformerBlock(
                (attn1): CrossAttention(
                  (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                  (to_k): Linear(in_features=1280, out_features=1280, bias=False)
                  (to_v): Linear(in_features=1280, out_features=1280, bias=False)
                  (to_out): Sequential(
                    (0): Linear(in_features=1280, out_features=1280, bias=True)
                    (1): Dropout(p=0.0, inplace=False)
                  )
                )
                (ff): FeedForward(
                  (net): Sequential(
                    (0): GEGLU(
                      (proj): Linear(in_features=1280, out_features=10240, bias=True)
                    )
                    (1): Dropout(p=0.0, inplace=False)
                    (2): Linear(in_features=5120, out_features=1280, bias=True)
                  )
                )
                (attn2): CrossAttention(
                  (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                  (to_k): Linear(in_features=768, out_features=1280, bias=False)
                  (to_v): Linear(in_features=768, out_features=1280, bias=False)
                  (to_out): Sequential(
                    (0): Linear(in_features=1280, out_features=1280, bias=True)
                    (1): Dropout(p=0.0, inplace=False)
                  )
                )
                (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
              )
            )
            (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
          )
          (2): ResBlock(
            (in_layers): Sequential(
              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
              (1): SiLU()
              (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
            (h_upd): Identity()
            (x_upd): Identity()
            (emb_layers): Sequential(
              (0): SiLU()
              (1): Linear(in_features=1280, out_features=1280, bias=True)
            )
            (out_layers): Sequential(
              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
              (1): SiLU()
              (2): Dropout(p=0, inplace=False)
              (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
            (skip_connection): Identity()
          )
        )
        (output_blocks): ModuleList(
          (0): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (1): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (2): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): Upsample(
              (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (3): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)
              (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_v): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=1280, out_features=10240, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=5120, out_features=1280, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=768, out_features=1280, bias=False)
                    (to_v): Linear(in_features=768, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (4): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)
              (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_v): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=1280, out_features=10240, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=5120, out_features=1280, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=768, out_features=1280, bias=False)
                    (to_v): Linear(in_features=768, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (5): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 1920, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(1920, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(1920, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)
              (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_v): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=1280, out_features=10240, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=5120, out_features=1280, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=768, out_features=1280, bias=False)
                    (to_v): Linear(in_features=768, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
            (2): Upsample(
              (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (6): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 1920, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(1920, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=640, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(1920, 640, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 640, eps=1e-06, affine=True)
              (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=640, out_features=640, bias=False)
                    (to_v): Linear(in_features=640, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=640, out_features=5120, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=2560, out_features=640, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=768, out_features=640, bias=False)
                    (to_v): Linear(in_features=768, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (7): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(1280, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=640, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 640, eps=1e-06, affine=True)
              (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=640, out_features=640, bias=False)
                    (to_v): Linear(in_features=640, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=640, out_features=5120, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=2560, out_features=640, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=768, out_features=640, bias=False)
                    (to_v): Linear(in_features=768, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (8): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 960, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(960, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=640, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(960, 640, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 640, eps=1e-06, affine=True)
              (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=640, out_features=640, bias=False)
                    (to_v): Linear(in_features=640, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=640, out_features=5120, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=2560, out_features=640, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=768, out_features=640, bias=False)
                    (to_v): Linear(in_features=768, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
            )
            (2): Upsample(
              (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (9): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 960, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(960, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=320, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 320, eps=1e-06, affine=True)
              (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=320, out_features=320, bias=False)
                    (to_v): Linear(in_features=320, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=320, out_features=2560, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=1280, out_features=320, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=768, out_features=320, bias=False)
                    (to_v): Linear(in_features=768, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (10): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=320, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 320, eps=1e-06, affine=True)
              (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=320, out_features=320, bias=False)
                    (to_v): Linear(in_features=320, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=320, out_features=2560, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=1280, out_features=320, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=768, out_features=320, bias=False)
                    (to_v): Linear(in_features=768, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (11): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=320, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 320, eps=1e-06, affine=True)
              (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=320, out_features=320, bias=False)
                    (to_v): Linear(in_features=320, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=320, out_features=2560, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=1280, out_features=320, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=768, out_features=320, bias=False)
                    (to_v): Linear(in_features=768, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
            )
          )
        )
        (out): Sequential(
          (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
          (1): SiLU()
          (2): Conv2d(320, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
    )
    (trainable_unet): DiffusionWrapper(
      (diffusion_model): UNetModel(
        (time_embed): Sequential(
          (0): Linear(in_features=320, out_features=1280, bias=True)
          (1): SiLU()
          (2): Linear(in_features=1280, out_features=1280, bias=True)
        )
        (input_blocks): ModuleList(
          (0): TimestepEmbedSequential(
            (0): Conv2d(4, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (1): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=320, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Identity()
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 320, eps=1e-06, affine=True)
              (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=320, out_features=320, bias=False)
                    (to_v): Linear(in_features=320, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=320, out_features=2560, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=1280, out_features=320, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=768, out_features=320, bias=False)
                    (to_v): Linear(in_features=768, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (2): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=320, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Identity()
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 320, eps=1e-06, affine=True)
              (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=320, out_features=320, bias=False)
                    (to_v): Linear(in_features=320, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=320, out_features=2560, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=1280, out_features=320, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=768, out_features=320, bias=False)
                    (to_v): Linear(in_features=768, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (3): TimestepEmbedSequential(
            (0): Downsample(
              (op): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
            )
          )
          (4): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(320, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=640, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(320, 640, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 640, eps=1e-06, affine=True)
              (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=640, out_features=640, bias=False)
                    (to_v): Linear(in_features=640, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=640, out_features=5120, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=2560, out_features=640, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=768, out_features=640, bias=False)
                    (to_v): Linear(in_features=768, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (5): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=640, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Identity()
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 640, eps=1e-06, affine=True)
              (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=640, out_features=640, bias=False)
                    (to_v): Linear(in_features=640, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=640, out_features=5120, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=2560, out_features=640, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=768, out_features=640, bias=False)
                    (to_v): Linear(in_features=768, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (6): TimestepEmbedSequential(
            (0): Downsample(
              (op): Conv2d(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
            )
          )
          (7): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(640, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(640, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)
              (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_v): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=1280, out_features=10240, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=5120, out_features=1280, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=768, out_features=1280, bias=False)
                    (to_v): Linear(in_features=768, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (8): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Identity()
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)
              (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_v): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=1280, out_features=10240, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=5120, out_features=1280, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=768, out_features=1280, bias=False)
                    (to_v): Linear(in_features=768, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (9): TimestepEmbedSequential(
            (0): Downsample(
              (op): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
            )
          )
          (10): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Identity()
            )
          )
          (11): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Identity()
            )
          )
        )
        (middle_block): TimestepEmbedSequential(
          (0): ResBlock(
            (in_layers): Sequential(
              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
              (1): SiLU()
              (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
            (h_upd): Identity()
            (x_upd): Identity()
            (emb_layers): Sequential(
              (0): SiLU()
              (1): Linear(in_features=1280, out_features=1280, bias=True)
            )
            (out_layers): Sequential(
              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
              (1): SiLU()
              (2): Dropout(p=0, inplace=False)
              (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
            (skip_connection): Identity()
          )
          (1): SpatialTransformer(
            (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)
            (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
            (transformer_blocks): ModuleList(
              (0): BasicTransformerBlock(
                (attn1): CrossAttention(
                  (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                  (to_k): Linear(in_features=1280, out_features=1280, bias=False)
                  (to_v): Linear(in_features=1280, out_features=1280, bias=False)
                  (to_out): Sequential(
                    (0): Linear(in_features=1280, out_features=1280, bias=True)
                    (1): Dropout(p=0.0, inplace=False)
                  )
                )
                (ff): FeedForward(
                  (net): Sequential(
                    (0): GEGLU(
                      (proj): Linear(in_features=1280, out_features=10240, bias=True)
                    )
                    (1): Dropout(p=0.0, inplace=False)
                    (2): Linear(in_features=5120, out_features=1280, bias=True)
                  )
                )
                (attn2): CrossAttention(
                  (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                  (to_k): Linear(in_features=768, out_features=1280, bias=False)
                  (to_v): Linear(in_features=768, out_features=1280, bias=False)
                  (to_out): Sequential(
                    (0): Linear(in_features=1280, out_features=1280, bias=True)
                    (1): Dropout(p=0.0, inplace=False)
                  )
                )
                (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
              )
            )
            (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
          )
          (2): ResBlock(
            (in_layers): Sequential(
              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
              (1): SiLU()
              (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
            (h_upd): Identity()
            (x_upd): Identity()
            (emb_layers): Sequential(
              (0): SiLU()
              (1): Linear(in_features=1280, out_features=1280, bias=True)
            )
            (out_layers): Sequential(
              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
              (1): SiLU()
              (2): Dropout(p=0, inplace=False)
              (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
            (skip_connection): Identity()
          )
        )
        (output_blocks): ModuleList(
          (0): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (1): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (2): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): Upsample(
              (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (3): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)
              (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_v): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=1280, out_features=10240, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=5120, out_features=1280, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=768, out_features=1280, bias=False)
                    (to_v): Linear(in_features=768, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (4): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)
              (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_v): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=1280, out_features=10240, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=5120, out_features=1280, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=768, out_features=1280, bias=False)
                    (to_v): Linear(in_features=768, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (5): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 1920, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(1920, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(1920, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)
              (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_v): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=1280, out_features=10240, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=5120, out_features=1280, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=768, out_features=1280, bias=False)
                    (to_v): Linear(in_features=768, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
            (2): Upsample(
              (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (6): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 1920, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(1920, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=640, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(1920, 640, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 640, eps=1e-06, affine=True)
              (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=640, out_features=640, bias=False)
                    (to_v): Linear(in_features=640, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=640, out_features=5120, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=2560, out_features=640, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=768, out_features=640, bias=False)
                    (to_v): Linear(in_features=768, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (7): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(1280, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=640, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 640, eps=1e-06, affine=True)
              (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=640, out_features=640, bias=False)
                    (to_v): Linear(in_features=640, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=640, out_features=5120, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=2560, out_features=640, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=768, out_features=640, bias=False)
                    (to_v): Linear(in_features=768, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (8): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 960, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(960, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=640, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(960, 640, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 640, eps=1e-06, affine=True)
              (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=640, out_features=640, bias=False)
                    (to_v): Linear(in_features=640, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=640, out_features=5120, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=2560, out_features=640, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=768, out_features=640, bias=False)
                    (to_v): Linear(in_features=768, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
            )
            (2): Upsample(
              (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (9): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 960, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(960, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=320, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 320, eps=1e-06, affine=True)
              (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=320, out_features=320, bias=False)
                    (to_v): Linear(in_features=320, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=320, out_features=2560, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=1280, out_features=320, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=768, out_features=320, bias=False)
                    (to_v): Linear(in_features=768, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (10): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=320, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 320, eps=1e-06, affine=True)
              (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=320, out_features=320, bias=False)
                    (to_v): Linear(in_features=320, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=320, out_features=2560, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=1280, out_features=320, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=768, out_features=320, bias=False)
                    (to_v): Linear(in_features=768, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (11): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=320, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 320, eps=1e-06, affine=True)
              (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=320, out_features=320, bias=False)
                    (to_v): Linear(in_features=320, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=320, out_features=2560, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=1280, out_features=320, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=768, out_features=320, bias=False)
                    (to_v): Linear(in_features=768, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
            )
          )
        )
        (out): Sequential(
          (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
          (1): SiLU()
          (2): Conv2d(320, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
    )
    (zero_convs): ModuleList(
      (0): ZeroConv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
      (1): ZeroConv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
      (2): ZeroConv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
      (3): ZeroConv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
      (4): ZeroConv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
      (5): ZeroConv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (box_encoder): EncoderControlNet(
    (box_cnn): Sequential(
      (0): Conv2d(1, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (3): ReLU(inplace=True)
    )
    (scribble_cnn): Sequential(
      (0): Conv2d(1, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (3): ReLU(inplace=True)
    )
    (dot_cnn): Sequential(
      (0): Conv2d(1, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (3): ReLU(inplace=True)
    )
    (out64): Sequential(
      (0): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
    )
    (out32): Sequential(
      (0): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
    )
    (out16): Sequential(
      (0): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
    )
    (conv64): Sequential(
      (0): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (1): ReLU(inplace=True)
    )
    (conv32): Sequential(
      (0): Conv2d(320, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (1): ReLU(inplace=True)
    )
    (conv16): Sequential(
      (0): Conv2d(640, 1280, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (1): ReLU(inplace=True)
    )
  )
  (sd_model): LatentDiffusion(
    (model): None
    (first_stage_model): None
  )
  (text_adapter): TextAdapter(
    (fc): Sequential(
      (0): Linear(in_features=768, out_features=768, bias=True)
      (1): GELU()
      (2): Linear(in_features=768, out_features=768, bias=True)
    )
  )
  (neck): FPN(
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(320, 256, kernel_size=(1, 1), stride=(1, 1))
      )
      (1): ConvModule(
        (conv): Conv2d(790, 256, kernel_size=(1, 1), stride=(1, 1))
      )
      (2): ConvModule(
        (conv): Conv2d(1430, 256, kernel_size=(1, 1), stride=(1, 1))
      )
      (3): ConvModule(
        (conv): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (1): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (2): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (3): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
  )
  init_cfg={'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}
  (decode_head): FPNHead(
    input_transform=multiple_select, ignore_index=255, align_corners=False
    (loss_decode): CrossEntropyLoss(avg_non_ignore=False)
    (conv_seg): Conv2d(256, 150, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (scale_heads): ModuleList(
      (0): Sequential(
        (0): ConvModule(
          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (1): Sequential(
        (0): ConvModule(
          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): Upsample()
      )
      (2): Sequential(
        (0): ConvModule(
          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): Upsample()
        (2): ConvModule(
          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): Upsample()
      )
      (3): Sequential(
        (0): ConvModule(
          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): Upsample()
        (2): ConvModule(
          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): Upsample()
        (4): ConvModule(
          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (5): Upsample()
      )
    )
  )
  init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
)
2025-04-27 21:27:47,646 - mmseg - INFO - Loaded 7725 images
/dtu/blackhole/0e/154958/miniconda3/envs/ldm/lib/python3.8/site-packages/torch/utils/data/dataloader.py:487: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
2025-04-27 21:27:57,221 - mmseg - INFO - Loaded 851 images
2025-04-27 21:27:57,223 - mmseg - INFO - load checkpoint from local path: /work3/s203557/checkpoints/vpd.chkpt
2025-04-27 21:28:00,300 - mmseg - WARNING - The model and loaded state dict do not match exactly

unexpected key in source state_dict: sd_model.lvlb_weights

missing keys in source state_dict: encoder_vq.encoder.conv_in.weight, encoder_vq.encoder.conv_in.bias, encoder_vq.encoder.down.0.block.0.norm1.weight, encoder_vq.encoder.down.0.block.0.norm1.bias, encoder_vq.encoder.down.0.block.0.conv1.weight, encoder_vq.encoder.down.0.block.0.conv1.bias, encoder_vq.encoder.down.0.block.0.norm2.weight, encoder_vq.encoder.down.0.block.0.norm2.bias, encoder_vq.encoder.down.0.block.0.conv2.weight, encoder_vq.encoder.down.0.block.0.conv2.bias, encoder_vq.encoder.down.0.block.1.norm1.weight, encoder_vq.encoder.down.0.block.1.norm1.bias, encoder_vq.encoder.down.0.block.1.conv1.weight, encoder_vq.encoder.down.0.block.1.conv1.bias, encoder_vq.encoder.down.0.block.1.norm2.weight, encoder_vq.encoder.down.0.block.1.norm2.bias, encoder_vq.encoder.down.0.block.1.conv2.weight, encoder_vq.encoder.down.0.block.1.conv2.bias, encoder_vq.encoder.down.0.downsample.conv.weight, encoder_vq.encoder.down.0.downsample.conv.bias, encoder_vq.encoder.down.1.block.0.norm1.weight, encoder_vq.encoder.down.1.block.0.norm1.bias, encoder_vq.encoder.down.1.block.0.conv1.weight, encoder_vq.encoder.down.1.block.0.conv1.bias, encoder_vq.encoder.down.1.block.0.norm2.weight, encoder_vq.encoder.down.1.block.0.norm2.bias, encoder_vq.encoder.down.1.block.0.conv2.weight, encoder_vq.encoder.down.1.block.0.conv2.bias, encoder_vq.encoder.down.1.block.0.nin_shortcut.weight, encoder_vq.encoder.down.1.block.0.nin_shortcut.bias, encoder_vq.encoder.down.1.block.1.norm1.weight, encoder_vq.encoder.down.1.block.1.norm1.bias, encoder_vq.encoder.down.1.block.1.conv1.weight, encoder_vq.encoder.down.1.block.1.conv1.bias, encoder_vq.encoder.down.1.block.1.norm2.weight, encoder_vq.encoder.down.1.block.1.norm2.bias, encoder_vq.encoder.down.1.block.1.conv2.weight, encoder_vq.encoder.down.1.block.1.conv2.bias, encoder_vq.encoder.down.1.downsample.conv.weight, encoder_vq.encoder.down.1.downsample.conv.bias, encoder_vq.encoder.down.2.block.0.norm1.weight, encoder_vq.encoder.down.2.block.0.norm1.bias, encoder_vq.encoder.down.2.block.0.conv1.weight, encoder_vq.encoder.down.2.block.0.conv1.bias, encoder_vq.encoder.down.2.block.0.norm2.weight, encoder_vq.encoder.down.2.block.0.norm2.bias, encoder_vq.encoder.down.2.block.0.conv2.weight, encoder_vq.encoder.down.2.block.0.conv2.bias, encoder_vq.encoder.down.2.block.0.nin_shortcut.weight, encoder_vq.encoder.down.2.block.0.nin_shortcut.bias, encoder_vq.encoder.down.2.block.1.norm1.weight, encoder_vq.encoder.down.2.block.1.norm1.bias, encoder_vq.encoder.down.2.block.1.conv1.weight, encoder_vq.encoder.down.2.block.1.conv1.bias, encoder_vq.encoder.down.2.block.1.norm2.weight, encoder_vq.encoder.down.2.block.1.norm2.bias, encoder_vq.encoder.down.2.block.1.conv2.weight, encoder_vq.encoder.down.2.block.1.conv2.bias, encoder_vq.encoder.down.2.downsample.conv.weight, encoder_vq.encoder.down.2.downsample.conv.bias, encoder_vq.encoder.down.3.block.0.norm1.weight, encoder_vq.encoder.down.3.block.0.norm1.bias, encoder_vq.encoder.down.3.block.0.conv1.weight, encoder_vq.encoder.down.3.block.0.conv1.bias, encoder_vq.encoder.down.3.block.0.norm2.weight, encoder_vq.encoder.down.3.block.0.norm2.bias, encoder_vq.encoder.down.3.block.0.conv2.weight, encoder_vq.encoder.down.3.block.0.conv2.bias, encoder_vq.encoder.down.3.block.1.norm1.weight, encoder_vq.encoder.down.3.block.1.norm1.bias, encoder_vq.encoder.down.3.block.1.conv1.weight, encoder_vq.encoder.down.3.block.1.conv1.bias, encoder_vq.encoder.down.3.block.1.norm2.weight, encoder_vq.encoder.down.3.block.1.norm2.bias, encoder_vq.encoder.down.3.block.1.conv2.weight, encoder_vq.encoder.down.3.block.1.conv2.bias, encoder_vq.encoder.mid.block_1.norm1.weight, encoder_vq.encoder.mid.block_1.norm1.bias, encoder_vq.encoder.mid.block_1.conv1.weight, encoder_vq.encoder.mid.block_1.conv1.bias, encoder_vq.encoder.mid.block_1.norm2.weight, encoder_vq.encoder.mid.block_1.norm2.bias, encoder_vq.encoder.mid.block_1.conv2.weight, encoder_vq.encoder.mid.block_1.conv2.bias, encoder_vq.encoder.mid.attn_1.norm.weight, encoder_vq.encoder.mid.attn_1.norm.bias, encoder_vq.encoder.mid.attn_1.q.weight, encoder_vq.encoder.mid.attn_1.q.bias, encoder_vq.encoder.mid.attn_1.k.weight, encoder_vq.encoder.mid.attn_1.k.bias, encoder_vq.encoder.mid.attn_1.v.weight, encoder_vq.encoder.mid.attn_1.v.bias, encoder_vq.encoder.mid.attn_1.proj_out.weight, encoder_vq.encoder.mid.attn_1.proj_out.bias, encoder_vq.encoder.mid.block_2.norm1.weight, encoder_vq.encoder.mid.block_2.norm1.bias, encoder_vq.encoder.mid.block_2.conv1.weight, encoder_vq.encoder.mid.block_2.conv1.bias, encoder_vq.encoder.mid.block_2.norm2.weight, encoder_vq.encoder.mid.block_2.norm2.bias, encoder_vq.encoder.mid.block_2.conv2.weight, encoder_vq.encoder.mid.block_2.conv2.bias, encoder_vq.encoder.norm_out.weight, encoder_vq.encoder.norm_out.bias, encoder_vq.encoder.conv_out.weight, encoder_vq.encoder.conv_out.bias, encoder_vq.quant_conv.weight, encoder_vq.quant_conv.bias, encoder_vq.post_quant_conv.weight, encoder_vq.post_quant_conv.bias, unet.trainable_unet.diffusion_model.time_embed.0.weight, unet.trainable_unet.diffusion_model.time_embed.0.bias, unet.trainable_unet.diffusion_model.time_embed.2.weight, unet.trainable_unet.diffusion_model.time_embed.2.bias, unet.trainable_unet.diffusion_model.input_blocks.0.0.weight, unet.trainable_unet.diffusion_model.input_blocks.0.0.bias, unet.trainable_unet.diffusion_model.input_blocks.1.0.in_layers.0.weight, unet.trainable_unet.diffusion_model.input_blocks.1.0.in_layers.0.bias, unet.trainable_unet.diffusion_model.input_blocks.1.0.in_layers.2.weight, unet.trainable_unet.diffusion_model.input_blocks.1.0.in_layers.2.bias, unet.trainable_unet.diffusion_model.input_blocks.1.0.emb_layers.1.weight, unet.trainable_unet.diffusion_model.input_blocks.1.0.emb_layers.1.bias, unet.trainable_unet.diffusion_model.input_blocks.1.0.out_layers.0.weight, unet.trainable_unet.diffusion_model.input_blocks.1.0.out_layers.0.bias, unet.trainable_unet.diffusion_model.input_blocks.1.0.out_layers.3.weight, unet.trainable_unet.diffusion_model.input_blocks.1.0.out_layers.3.bias, unet.trainable_unet.diffusion_model.input_blocks.1.1.norm.weight, unet.trainable_unet.diffusion_model.input_blocks.1.1.norm.bias, unet.trainable_unet.diffusion_model.input_blocks.1.1.proj_in.weight, unet.trainable_unet.diffusion_model.input_blocks.1.1.proj_in.bias, unet.trainable_unet.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_q.weight, unet.trainable_unet.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_k.weight, unet.trainable_unet.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_v.weight, unet.trainable_unet.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_out.0.weight, unet.trainable_unet.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_out.0.bias, unet.trainable_unet.diffusion_model.input_blocks.1.1.transformer_blocks.0.ff.net.0.proj.weight, unet.trainable_unet.diffusion_model.input_blocks.1.1.transformer_blocks.0.ff.net.0.proj.bias, unet.trainable_unet.diffusion_model.input_blocks.1.1.transformer_blocks.0.ff.net.2.weight, unet.trainable_unet.diffusion_model.input_blocks.1.1.transformer_blocks.0.ff.net.2.bias, unet.trainable_unet.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_q.weight, unet.trainable_unet.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_k.weight, unet.trainable_unet.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_v.weight, unet.trainable_unet.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_out.0.weight, unet.trainable_unet.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_out.0.bias, unet.trainable_unet.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm1.weight, unet.trainable_unet.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm1.bias, unet.trainable_unet.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm2.weight, unet.trainable_unet.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm2.bias, unet.trainable_unet.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm3.weight, unet.trainable_unet.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm3.bias, unet.trainable_unet.diffusion_model.input_blocks.1.1.proj_out.weight, unet.trainable_unet.diffusion_model.input_blocks.1.1.proj_out.bias, unet.trainable_unet.diffusion_model.input_blocks.2.0.in_layers.0.weight, unet.trainable_unet.diffusion_model.input_blocks.2.0.in_layers.0.bias, unet.trainable_unet.diffusion_model.input_blocks.2.0.in_layers.2.weight, unet.trainable_unet.diffusion_model.input_blocks.2.0.in_layers.2.bias, unet.trainable_unet.diffusion_model.input_blocks.2.0.emb_layers.1.weight, unet.trainable_unet.diffusion_model.input_blocks.2.0.emb_layers.1.bias, unet.trainable_unet.diffusion_model.input_blocks.2.0.out_layers.0.weight, unet.trainable_unet.diffusion_model.input_blocks.2.0.out_layers.0.bias, unet.trainable_unet.diffusion_model.input_blocks.2.0.out_layers.3.weight, unet.trainable_unet.diffusion_model.input_blocks.2.0.out_layers.3.bias, unet.trainable_unet.diffusion_model.input_blocks.2.1.norm.weight, unet.trainable_unet.diffusion_model.input_blocks.2.1.norm.bias, unet.trainable_unet.diffusion_model.input_blocks.2.1.proj_in.weight, unet.trainable_unet.diffusion_model.input_blocks.2.1.proj_in.bias, unet.trainable_unet.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_q.weight, unet.trainable_unet.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_k.weight, unet.trainable_unet.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_v.weight, unet.trainable_unet.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_out.0.weight, unet.trainable_unet.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_out.0.bias, unet.trainable_unet.diffusion_model.input_blocks.2.1.transformer_blocks.0.ff.net.0.proj.weight, unet.trainable_unet.diffusion_model.input_blocks.2.1.transformer_blocks.0.ff.net.0.proj.bias, unet.trainable_unet.diffusion_model.input_blocks.2.1.transformer_blocks.0.ff.net.2.weight, unet.trainable_unet.diffusion_model.input_blocks.2.1.transformer_blocks.0.ff.net.2.bias, unet.trainable_unet.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_q.weight, unet.trainable_unet.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_k.weight, unet.trainable_unet.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_v.weight, unet.trainable_unet.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_out.0.weight, unet.trainable_unet.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_out.0.bias, unet.trainable_unet.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm1.weight, unet.trainable_unet.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm1.bias, unet.trainable_unet.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm2.weight, unet.trainable_unet.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm2.bias, unet.trainable_unet.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm3.weight, unet.trainable_unet.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm3.bias, unet.trainable_unet.diffusion_model.input_blocks.2.1.proj_out.weight, unet.trainable_unet.diffusion_model.input_blocks.2.1.proj_out.bias, unet.trainable_unet.diffusion_model.input_blocks.3.0.op.weight, unet.trainable_unet.diffusion_model.input_blocks.3.0.op.bias, unet.trainable_unet.diffusion_model.input_blocks.4.0.in_layers.0.weight, unet.trainable_unet.diffusion_model.input_blocks.4.0.in_layers.0.bias, unet.trainable_unet.diffusion_model.input_blocks.4.0.in_layers.2.weight, unet.trainable_unet.diffusion_model.input_blocks.4.0.in_layers.2.bias, unet.trainable_unet.diffusion_model.input_blocks.4.0.emb_layers.1.weight, unet.trainable_unet.diffusion_model.input_blocks.4.0.emb_layers.1.bias, unet.trainable_unet.diffusion_model.input_blocks.4.0.out_layers.0.weight, unet.trainable_unet.diffusion_model.input_blocks.4.0.out_layers.0.bias, unet.trainable_unet.diffusion_model.input_blocks.4.0.out_layers.3.weight, unet.trainable_unet.diffusion_model.input_blocks.4.0.out_layers.3.bias, unet.trainable_unet.diffusion_model.input_blocks.4.0.skip_connection.weight, unet.trainable_unet.diffusion_model.input_blocks.4.0.skip_connection.bias, unet.trainable_unet.diffusion_model.input_blocks.4.1.norm.weight, unet.trainable_unet.diffusion_model.input_blocks.4.1.norm.bias, unet.trainable_unet.diffusion_model.input_blocks.4.1.proj_in.weight, unet.trainable_unet.diffusion_model.input_blocks.4.1.proj_in.bias, unet.trainable_unet.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_q.weight, unet.trainable_unet.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_k.weight, unet.trainable_unet.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_v.weight, unet.trainable_unet.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_out.0.weight, unet.trainable_unet.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_out.0.bias, unet.trainable_unet.diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.0.proj.weight, unet.trainable_unet.diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.0.proj.bias, unet.trainable_unet.diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.2.weight, unet.trainable_unet.diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.2.bias, unet.trainable_unet.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_q.weight, unet.trainable_unet.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_k.weight, unet.trainable_unet.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_v.weight, unet.trainable_unet.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_out.0.weight, unet.trainable_unet.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_out.0.bias, unet.trainable_unet.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm1.weight, unet.trainable_unet.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm1.bias, unet.trainable_unet.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm2.weight, unet.trainable_unet.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm2.bias, unet.trainable_unet.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm3.weight, unet.trainable_unet.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm3.bias, unet.trainable_unet.diffusion_model.input_blocks.4.1.proj_out.weight, unet.trainable_unet.diffusion_model.input_blocks.4.1.proj_out.bias, unet.trainable_unet.diffusion_model.input_blocks.5.0.in_layers.0.weight, unet.trainable_unet.diffusion_model.input_blocks.5.0.in_layers.0.bias, unet.trainable_unet.diffusion_model.input_blocks.5.0.in_layers.2.weight, unet.trainable_unet.diffusion_model.input_blocks.5.0.in_layers.2.bias, unet.trainable_unet.diffusion_model.input_blocks.5.0.emb_layers.1.weight, unet.trainable_unet.diffusion_model.input_blocks.5.0.emb_layers.1.bias, unet.trainable_unet.diffusion_model.input_blocks.5.0.out_layers.0.weight, unet.trainable_unet.diffusion_model.input_blocks.5.0.out_layers.0.bias, unet.trainable_unet.diffusion_model.input_blocks.5.0.out_layers.3.weight, unet.trainable_unet.diffusion_model.input_blocks.5.0.out_layers.3.bias, unet.trainable_unet.diffusion_model.input_blocks.5.1.norm.weight, unet.trainable_unet.diffusion_model.input_blocks.5.1.norm.bias, unet.trainable_unet.diffusion_model.input_blocks.5.1.proj_in.weight, unet.trainable_unet.diffusion_model.input_blocks.5.1.proj_in.bias, unet.trainable_unet.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_q.weight, unet.trainable_unet.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_k.weight, unet.trainable_unet.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_v.weight, unet.trainable_unet.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_out.0.weight, unet.trainable_unet.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_out.0.bias, unet.trainable_unet.diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.0.proj.weight, unet.trainable_unet.diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.0.proj.bias, unet.trainable_unet.diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.2.weight, unet.trainable_unet.diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.2.bias, unet.trainable_unet.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_q.weight, unet.trainable_unet.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_k.weight, unet.trainable_unet.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_v.weight, unet.trainable_unet.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_out.0.weight, unet.trainable_unet.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_out.0.bias, unet.trainable_unet.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm1.weight, unet.trainable_unet.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm1.bias, unet.trainable_unet.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm2.weight, unet.trainable_unet.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm2.bias, unet.trainable_unet.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm3.weight, unet.trainable_unet.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm3.bias, unet.trainable_unet.diffusion_model.input_blocks.5.1.proj_out.weight, unet.trainable_unet.diffusion_model.input_blocks.5.1.proj_out.bias, unet.trainable_unet.diffusion_model.input_blocks.6.0.op.weight, unet.trainable_unet.diffusion_model.input_blocks.6.0.op.bias, unet.trainable_unet.diffusion_model.input_blocks.7.0.in_layers.0.weight, unet.trainable_unet.diffusion_model.input_blocks.7.0.in_layers.0.bias, unet.trainable_unet.diffusion_model.input_blocks.7.0.in_layers.2.weight, unet.trainable_unet.diffusion_model.input_blocks.7.0.in_layers.2.bias, unet.trainable_unet.diffusion_model.input_blocks.7.0.emb_layers.1.weight, unet.trainable_unet.diffusion_model.input_blocks.7.0.emb_layers.1.bias, unet.trainable_unet.diffusion_model.input_blocks.7.0.out_layers.0.weight, unet.trainable_unet.diffusion_model.input_blocks.7.0.out_layers.0.bias, unet.trainable_unet.diffusion_model.input_blocks.7.0.out_layers.3.weight, unet.trainable_unet.diffusion_model.input_blocks.7.0.out_layers.3.bias, unet.trainable_unet.diffusion_model.input_blocks.7.0.skip_connection.weight, unet.trainable_unet.diffusion_model.input_blocks.7.0.skip_connection.bias, unet.trainable_unet.diffusion_model.input_blocks.7.1.norm.weight, unet.trainable_unet.diffusion_model.input_blocks.7.1.norm.bias, unet.trainable_unet.diffusion_model.input_blocks.7.1.proj_in.weight, unet.trainable_unet.diffusion_model.input_blocks.7.1.proj_in.bias, unet.trainable_unet.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_q.weight, unet.trainable_unet.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_k.weight, unet.trainable_unet.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_v.weight, unet.trainable_unet.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_out.0.weight, unet.trainable_unet.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_out.0.bias, unet.trainable_unet.diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.0.proj.weight, unet.trainable_unet.diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.0.proj.bias, unet.trainable_unet.diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.2.weight, unet.trainable_unet.diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.2.bias, unet.trainable_unet.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_q.weight, unet.trainable_unet.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_k.weight, unet.trainable_unet.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_v.weight, unet.trainable_unet.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_out.0.weight, unet.trainable_unet.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_out.0.bias, unet.trainable_unet.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm1.weight, unet.trainable_unet.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm1.bias, unet.trainable_unet.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm2.weight, unet.trainable_unet.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm2.bias, unet.trainable_unet.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm3.weight, unet.trainable_unet.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm3.bias, unet.trainable_unet.diffusion_model.input_blocks.7.1.proj_out.weight, unet.trainable_unet.diffusion_model.input_blocks.7.1.proj_out.bias, unet.trainable_unet.diffusion_model.input_blocks.8.0.in_layers.0.weight, unet.trainable_unet.diffusion_model.input_blocks.8.0.in_layers.0.bias, unet.trainable_unet.diffusion_model.input_blocks.8.0.in_layers.2.weight, unet.trainable_unet.diffusion_model.input_blocks.8.0.in_layers.2.bias, unet.trainable_unet.diffusion_model.input_blocks.8.0.emb_layers.1.weight, unet.trainable_unet.diffusion_model.input_blocks.8.0.emb_layers.1.bias, unet.trainable_unet.diffusion_model.input_blocks.8.0.out_layers.0.weight, unet.trainable_unet.diffusion_model.input_blocks.8.0.out_layers.0.bias, unet.trainable_unet.diffusion_model.input_blocks.8.0.out_layers.3.weight, unet.trainable_unet.diffusion_model.input_blocks.8.0.out_layers.3.bias, unet.trainable_unet.diffusion_model.input_blocks.8.1.norm.weight, unet.trainable_unet.diffusion_model.input_blocks.8.1.norm.bias, unet.trainable_unet.diffusion_model.input_blocks.8.1.proj_in.weight, unet.trainable_unet.diffusion_model.input_blocks.8.1.proj_in.bias, unet.trainable_unet.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_q.weight, unet.trainable_unet.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_k.weight, unet.trainable_unet.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_v.weight, unet.trainable_unet.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_out.0.weight, unet.trainable_unet.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_out.0.bias, unet.trainable_unet.diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.0.proj.weight, unet.trainable_unet.diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.0.proj.bias, unet.trainable_unet.diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.2.weight, unet.trainable_unet.diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.2.bias, unet.trainable_unet.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_q.weight, unet.trainable_unet.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_k.weight, unet.trainable_unet.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_v.weight, unet.trainable_unet.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_out.0.weight, unet.trainable_unet.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_out.0.bias, unet.trainable_unet.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm1.weight, unet.trainable_unet.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm1.bias, unet.trainable_unet.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm2.weight, unet.trainable_unet.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm2.bias, unet.trainable_unet.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm3.weight, unet.trainable_unet.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm3.bias, unet.trainable_unet.diffusion_model.input_blocks.8.1.proj_out.weight, unet.trainable_unet.diffusion_model.input_blocks.8.1.proj_out.bias, unet.trainable_unet.diffusion_model.input_blocks.9.0.op.weight, unet.trainable_unet.diffusion_model.input_blocks.9.0.op.bias, unet.trainable_unet.diffusion_model.input_blocks.10.0.in_layers.0.weight, unet.trainable_unet.diffusion_model.input_blocks.10.0.in_layers.0.bias, unet.trainable_unet.diffusion_model.input_blocks.10.0.in_layers.2.weight, unet.trainable_unet.diffusion_model.input_blocks.10.0.in_layers.2.bias, unet.trainable_unet.diffusion_model.input_blocks.10.0.emb_layers.1.weight, unet.trainable_unet.diffusion_model.input_blocks.10.0.emb_layers.1.bias, unet.trainable_unet.diffusion_model.input_blocks.10.0.out_layers.0.weight, unet.trainable_unet.diffusion_model.input_blocks.10.0.out_layers.0.bias, unet.trainable_unet.diffusion_model.input_blocks.10.0.out_layers.3.weight, unet.trainable_unet.diffusion_model.input_blocks.10.0.out_layers.3.bias, unet.trainable_unet.diffusion_model.input_blocks.11.0.in_layers.0.weight, unet.trainable_unet.diffusion_model.input_blocks.11.0.in_layers.0.bias, unet.trainable_unet.diffusion_model.input_blocks.11.0.in_layers.2.weight, unet.trainable_unet.diffusion_model.input_blocks.11.0.in_layers.2.bias, unet.trainable_unet.diffusion_model.input_blocks.11.0.emb_layers.1.weight, unet.trainable_unet.diffusion_model.input_blocks.11.0.emb_layers.1.bias, unet.trainable_unet.diffusion_model.input_blocks.11.0.out_layers.0.weight, unet.trainable_unet.diffusion_model.input_blocks.11.0.out_layers.0.bias, unet.trainable_unet.diffusion_model.input_blocks.11.0.out_layers.3.weight, unet.trainable_unet.diffusion_model.input_blocks.11.0.out_layers.3.bias, unet.trainable_unet.diffusion_model.middle_block.0.in_layers.0.weight, unet.trainable_unet.diffusion_model.middle_block.0.in_layers.0.bias, unet.trainable_unet.diffusion_model.middle_block.0.in_layers.2.weight, unet.trainable_unet.diffusion_model.middle_block.0.in_layers.2.bias, unet.trainable_unet.diffusion_model.middle_block.0.emb_layers.1.weight, unet.trainable_unet.diffusion_model.middle_block.0.emb_layers.1.bias, unet.trainable_unet.diffusion_model.middle_block.0.out_layers.0.weight, unet.trainable_unet.diffusion_model.middle_block.0.out_layers.0.bias, unet.trainable_unet.diffusion_model.middle_block.0.out_layers.3.weight, unet.trainable_unet.diffusion_model.middle_block.0.out_layers.3.bias, unet.trainable_unet.diffusion_model.middle_block.1.norm.weight, unet.trainable_unet.diffusion_model.middle_block.1.norm.bias, unet.trainable_unet.diffusion_model.middle_block.1.proj_in.weight, unet.trainable_unet.diffusion_model.middle_block.1.proj_in.bias, unet.trainable_unet.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_q.weight, unet.trainable_unet.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_k.weight, unet.trainable_unet.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_v.weight, unet.trainable_unet.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_out.0.weight, unet.trainable_unet.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_out.0.bias, unet.trainable_unet.diffusion_model.middle_block.1.transformer_blocks.0.ff.net.0.proj.weight, unet.trainable_unet.diffusion_model.middle_block.1.transformer_blocks.0.ff.net.0.proj.bias, unet.trainable_unet.diffusion_model.middle_block.1.transformer_blocks.0.ff.net.2.weight, unet.trainable_unet.diffusion_model.middle_block.1.transformer_blocks.0.ff.net.2.bias, unet.trainable_unet.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_q.weight, unet.trainable_unet.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_k.weight, unet.trainable_unet.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_v.weight, unet.trainable_unet.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_out.0.weight, unet.trainable_unet.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_out.0.bias, unet.trainable_unet.diffusion_model.middle_block.1.transformer_blocks.0.norm1.weight, unet.trainable_unet.diffusion_model.middle_block.1.transformer_blocks.0.norm1.bias, unet.trainable_unet.diffusion_model.middle_block.1.transformer_blocks.0.norm2.weight, unet.trainable_unet.diffusion_model.middle_block.1.transformer_blocks.0.norm2.bias, unet.trainable_unet.diffusion_model.middle_block.1.transformer_blocks.0.norm3.weight, unet.trainable_unet.diffusion_model.middle_block.1.transformer_blocks.0.norm3.bias, unet.trainable_unet.diffusion_model.middle_block.1.proj_out.weight, unet.trainable_unet.diffusion_model.middle_block.1.proj_out.bias, unet.trainable_unet.diffusion_model.middle_block.2.in_layers.0.weight, unet.trainable_unet.diffusion_model.middle_block.2.in_layers.0.bias, unet.trainable_unet.diffusion_model.middle_block.2.in_layers.2.weight, unet.trainable_unet.diffusion_model.middle_block.2.in_layers.2.bias, unet.trainable_unet.diffusion_model.middle_block.2.emb_layers.1.weight, unet.trainable_unet.diffusion_model.middle_block.2.emb_layers.1.bias, unet.trainable_unet.diffusion_model.middle_block.2.out_layers.0.weight, unet.trainable_unet.diffusion_model.middle_block.2.out_layers.0.bias, unet.trainable_unet.diffusion_model.middle_block.2.out_layers.3.weight, unet.trainable_unet.diffusion_model.middle_block.2.out_layers.3.bias, unet.trainable_unet.diffusion_model.output_blocks.0.0.in_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.0.0.in_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.0.0.in_layers.2.weight, unet.trainable_unet.diffusion_model.output_blocks.0.0.in_layers.2.bias, unet.trainable_unet.diffusion_model.output_blocks.0.0.emb_layers.1.weight, unet.trainable_unet.diffusion_model.output_blocks.0.0.emb_layers.1.bias, unet.trainable_unet.diffusion_model.output_blocks.0.0.out_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.0.0.out_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.0.0.out_layers.3.weight, unet.trainable_unet.diffusion_model.output_blocks.0.0.out_layers.3.bias, unet.trainable_unet.diffusion_model.output_blocks.0.0.skip_connection.weight, unet.trainable_unet.diffusion_model.output_blocks.0.0.skip_connection.bias, unet.trainable_unet.diffusion_model.output_blocks.1.0.in_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.1.0.in_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.1.0.in_layers.2.weight, unet.trainable_unet.diffusion_model.output_blocks.1.0.in_layers.2.bias, unet.trainable_unet.diffusion_model.output_blocks.1.0.emb_layers.1.weight, unet.trainable_unet.diffusion_model.output_blocks.1.0.emb_layers.1.bias, unet.trainable_unet.diffusion_model.output_blocks.1.0.out_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.1.0.out_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.1.0.out_layers.3.weight, unet.trainable_unet.diffusion_model.output_blocks.1.0.out_layers.3.bias, unet.trainable_unet.diffusion_model.output_blocks.1.0.skip_connection.weight, unet.trainable_unet.diffusion_model.output_blocks.1.0.skip_connection.bias, unet.trainable_unet.diffusion_model.output_blocks.2.0.in_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.2.0.in_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.2.0.in_layers.2.weight, unet.trainable_unet.diffusion_model.output_blocks.2.0.in_layers.2.bias, unet.trainable_unet.diffusion_model.output_blocks.2.0.emb_layers.1.weight, unet.trainable_unet.diffusion_model.output_blocks.2.0.emb_layers.1.bias, unet.trainable_unet.diffusion_model.output_blocks.2.0.out_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.2.0.out_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.2.0.out_layers.3.weight, unet.trainable_unet.diffusion_model.output_blocks.2.0.out_layers.3.bias, unet.trainable_unet.diffusion_model.output_blocks.2.0.skip_connection.weight, unet.trainable_unet.diffusion_model.output_blocks.2.0.skip_connection.bias, unet.trainable_unet.diffusion_model.output_blocks.2.1.conv.weight, unet.trainable_unet.diffusion_model.output_blocks.2.1.conv.bias, unet.trainable_unet.diffusion_model.output_blocks.3.0.in_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.3.0.in_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.3.0.in_layers.2.weight, unet.trainable_unet.diffusion_model.output_blocks.3.0.in_layers.2.bias, unet.trainable_unet.diffusion_model.output_blocks.3.0.emb_layers.1.weight, unet.trainable_unet.diffusion_model.output_blocks.3.0.emb_layers.1.bias, unet.trainable_unet.diffusion_model.output_blocks.3.0.out_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.3.0.out_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.3.0.out_layers.3.weight, unet.trainable_unet.diffusion_model.output_blocks.3.0.out_layers.3.bias, unet.trainable_unet.diffusion_model.output_blocks.3.0.skip_connection.weight, unet.trainable_unet.diffusion_model.output_blocks.3.0.skip_connection.bias, unet.trainable_unet.diffusion_model.output_blocks.3.1.norm.weight, unet.trainable_unet.diffusion_model.output_blocks.3.1.norm.bias, unet.trainable_unet.diffusion_model.output_blocks.3.1.proj_in.weight, unet.trainable_unet.diffusion_model.output_blocks.3.1.proj_in.bias, unet.trainable_unet.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_q.weight, unet.trainable_unet.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_k.weight, unet.trainable_unet.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_v.weight, unet.trainable_unet.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_out.0.weight, unet.trainable_unet.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_out.0.bias, unet.trainable_unet.diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.0.proj.weight, unet.trainable_unet.diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.0.proj.bias, unet.trainable_unet.diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.2.weight, unet.trainable_unet.diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.2.bias, unet.trainable_unet.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_q.weight, unet.trainable_unet.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_k.weight, unet.trainable_unet.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_v.weight, unet.trainable_unet.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_out.0.weight, unet.trainable_unet.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_out.0.bias, unet.trainable_unet.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm1.weight, unet.trainable_unet.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm1.bias, unet.trainable_unet.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm2.weight, unet.trainable_unet.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm2.bias, unet.trainable_unet.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm3.weight, unet.trainable_unet.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm3.bias, unet.trainable_unet.diffusion_model.output_blocks.3.1.proj_out.weight, unet.trainable_unet.diffusion_model.output_blocks.3.1.proj_out.bias, unet.trainable_unet.diffusion_model.output_blocks.4.0.in_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.4.0.in_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.4.0.in_layers.2.weight, unet.trainable_unet.diffusion_model.output_blocks.4.0.in_layers.2.bias, unet.trainable_unet.diffusion_model.output_blocks.4.0.emb_layers.1.weight, unet.trainable_unet.diffusion_model.output_blocks.4.0.emb_layers.1.bias, unet.trainable_unet.diffusion_model.output_blocks.4.0.out_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.4.0.out_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.4.0.out_layers.3.weight, unet.trainable_unet.diffusion_model.output_blocks.4.0.out_layers.3.bias, unet.trainable_unet.diffusion_model.output_blocks.4.0.skip_connection.weight, unet.trainable_unet.diffusion_model.output_blocks.4.0.skip_connection.bias, unet.trainable_unet.diffusion_model.output_blocks.4.1.norm.weight, unet.trainable_unet.diffusion_model.output_blocks.4.1.norm.bias, unet.trainable_unet.diffusion_model.output_blocks.4.1.proj_in.weight, unet.trainable_unet.diffusion_model.output_blocks.4.1.proj_in.bias, unet.trainable_unet.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_q.weight, unet.trainable_unet.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_k.weight, unet.trainable_unet.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_v.weight, unet.trainable_unet.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_out.0.weight, unet.trainable_unet.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_out.0.bias, unet.trainable_unet.diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.0.proj.weight, unet.trainable_unet.diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.0.proj.bias, unet.trainable_unet.diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.2.weight, unet.trainable_unet.diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.2.bias, unet.trainable_unet.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_q.weight, unet.trainable_unet.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_k.weight, unet.trainable_unet.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_v.weight, unet.trainable_unet.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_out.0.weight, unet.trainable_unet.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_out.0.bias, unet.trainable_unet.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm1.weight, unet.trainable_unet.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm1.bias, unet.trainable_unet.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm2.weight, unet.trainable_unet.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm2.bias, unet.trainable_unet.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm3.weight, unet.trainable_unet.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm3.bias, unet.trainable_unet.diffusion_model.output_blocks.4.1.proj_out.weight, unet.trainable_unet.diffusion_model.output_blocks.4.1.proj_out.bias, unet.trainable_unet.diffusion_model.output_blocks.5.0.in_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.5.0.in_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.5.0.in_layers.2.weight, unet.trainable_unet.diffusion_model.output_blocks.5.0.in_layers.2.bias, unet.trainable_unet.diffusion_model.output_blocks.5.0.emb_layers.1.weight, unet.trainable_unet.diffusion_model.output_blocks.5.0.emb_layers.1.bias, unet.trainable_unet.diffusion_model.output_blocks.5.0.out_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.5.0.out_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.5.0.out_layers.3.weight, unet.trainable_unet.diffusion_model.output_blocks.5.0.out_layers.3.bias, unet.trainable_unet.diffusion_model.output_blocks.5.0.skip_connection.weight, unet.trainable_unet.diffusion_model.output_blocks.5.0.skip_connection.bias, unet.trainable_unet.diffusion_model.output_blocks.5.1.norm.weight, unet.trainable_unet.diffusion_model.output_blocks.5.1.norm.bias, unet.trainable_unet.diffusion_model.output_blocks.5.1.proj_in.weight, unet.trainable_unet.diffusion_model.output_blocks.5.1.proj_in.bias, unet.trainable_unet.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_q.weight, unet.trainable_unet.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_k.weight, unet.trainable_unet.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_v.weight, unet.trainable_unet.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_out.0.weight, unet.trainable_unet.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_out.0.bias, unet.trainable_unet.diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.0.proj.weight, unet.trainable_unet.diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.0.proj.bias, unet.trainable_unet.diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.2.weight, unet.trainable_unet.diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.2.bias, unet.trainable_unet.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_q.weight, unet.trainable_unet.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_k.weight, unet.trainable_unet.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_v.weight, unet.trainable_unet.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_out.0.weight, unet.trainable_unet.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_out.0.bias, unet.trainable_unet.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm1.weight, unet.trainable_unet.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm1.bias, unet.trainable_unet.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm2.weight, unet.trainable_unet.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm2.bias, unet.trainable_unet.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm3.weight, unet.trainable_unet.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm3.bias, unet.trainable_unet.diffusion_model.output_blocks.5.1.proj_out.weight, unet.trainable_unet.diffusion_model.output_blocks.5.1.proj_out.bias, unet.trainable_unet.diffusion_model.output_blocks.5.2.conv.weight, unet.trainable_unet.diffusion_model.output_blocks.5.2.conv.bias, unet.trainable_unet.diffusion_model.output_blocks.6.0.in_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.6.0.in_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.6.0.in_layers.2.weight, unet.trainable_unet.diffusion_model.output_blocks.6.0.in_layers.2.bias, unet.trainable_unet.diffusion_model.output_blocks.6.0.emb_layers.1.weight, unet.trainable_unet.diffusion_model.output_blocks.6.0.emb_layers.1.bias, unet.trainable_unet.diffusion_model.output_blocks.6.0.out_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.6.0.out_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.6.0.out_layers.3.weight, unet.trainable_unet.diffusion_model.output_blocks.6.0.out_layers.3.bias, unet.trainable_unet.diffusion_model.output_blocks.6.0.skip_connection.weight, unet.trainable_unet.diffusion_model.output_blocks.6.0.skip_connection.bias, unet.trainable_unet.diffusion_model.output_blocks.6.1.norm.weight, unet.trainable_unet.diffusion_model.output_blocks.6.1.norm.bias, unet.trainable_unet.diffusion_model.output_blocks.6.1.proj_in.weight, unet.trainable_unet.diffusion_model.output_blocks.6.1.proj_in.bias, unet.trainable_unet.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_q.weight, unet.trainable_unet.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_k.weight, unet.trainable_unet.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_v.weight, unet.trainable_unet.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_out.0.weight, unet.trainable_unet.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_out.0.bias, unet.trainable_unet.diffusion_model.output_blocks.6.1.transformer_blocks.0.ff.net.0.proj.weight, unet.trainable_unet.diffusion_model.output_blocks.6.1.transformer_blocks.0.ff.net.0.proj.bias, unet.trainable_unet.diffusion_model.output_blocks.6.1.transformer_blocks.0.ff.net.2.weight, unet.trainable_unet.diffusion_model.output_blocks.6.1.transformer_blocks.0.ff.net.2.bias, unet.trainable_unet.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_q.weight, unet.trainable_unet.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_k.weight, unet.trainable_unet.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_v.weight, unet.trainable_unet.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_out.0.weight, unet.trainable_unet.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_out.0.bias, unet.trainable_unet.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm1.weight, unet.trainable_unet.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm1.bias, unet.trainable_unet.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm2.weight, unet.trainable_unet.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm2.bias, unet.trainable_unet.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm3.weight, unet.trainable_unet.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm3.bias, unet.trainable_unet.diffusion_model.output_blocks.6.1.proj_out.weight, unet.trainable_unet.diffusion_model.output_blocks.6.1.proj_out.bias, unet.trainable_unet.diffusion_model.output_blocks.7.0.in_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.7.0.in_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.7.0.in_layers.2.weight, unet.trainable_unet.diffusion_model.output_blocks.7.0.in_layers.2.bias, unet.trainable_unet.diffusion_model.output_blocks.7.0.emb_layers.1.weight, unet.trainable_unet.diffusion_model.output_blocks.7.0.emb_layers.1.bias, unet.trainable_unet.diffusion_model.output_blocks.7.0.out_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.7.0.out_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.7.0.out_layers.3.weight, unet.trainable_unet.diffusion_model.output_blocks.7.0.out_layers.3.bias, unet.trainable_unet.diffusion_model.output_blocks.7.0.skip_connection.weight, unet.trainable_unet.diffusion_model.output_blocks.7.0.skip_connection.bias, unet.trainable_unet.diffusion_model.output_blocks.7.1.norm.weight, unet.trainable_unet.diffusion_model.output_blocks.7.1.norm.bias, unet.trainable_unet.diffusion_model.output_blocks.7.1.proj_in.weight, unet.trainable_unet.diffusion_model.output_blocks.7.1.proj_in.bias, unet.trainable_unet.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_q.weight, unet.trainable_unet.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_k.weight, unet.trainable_unet.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_v.weight, unet.trainable_unet.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_out.0.weight, unet.trainable_unet.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_out.0.bias, unet.trainable_unet.diffusion_model.output_blocks.7.1.transformer_blocks.0.ff.net.0.proj.weight, unet.trainable_unet.diffusion_model.output_blocks.7.1.transformer_blocks.0.ff.net.0.proj.bias, unet.trainable_unet.diffusion_model.output_blocks.7.1.transformer_blocks.0.ff.net.2.weight, unet.trainable_unet.diffusion_model.output_blocks.7.1.transformer_blocks.0.ff.net.2.bias, unet.trainable_unet.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_q.weight, unet.trainable_unet.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_k.weight, unet.trainable_unet.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_v.weight, unet.trainable_unet.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_out.0.weight, unet.trainable_unet.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_out.0.bias, unet.trainable_unet.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm1.weight, unet.trainable_unet.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm1.bias, unet.trainable_unet.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm2.weight, unet.trainable_unet.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm2.bias, unet.trainable_unet.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm3.weight, unet.trainable_unet.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm3.bias, unet.trainable_unet.diffusion_model.output_blocks.7.1.proj_out.weight, unet.trainable_unet.diffusion_model.output_blocks.7.1.proj_out.bias, unet.trainable_unet.diffusion_model.output_blocks.8.0.in_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.8.0.in_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.8.0.in_layers.2.weight, unet.trainable_unet.diffusion_model.output_blocks.8.0.in_layers.2.bias, unet.trainable_unet.diffusion_model.output_blocks.8.0.emb_layers.1.weight, unet.trainable_unet.diffusion_model.output_blocks.8.0.emb_layers.1.bias, unet.trainable_unet.diffusion_model.output_blocks.8.0.out_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.8.0.out_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.8.0.out_layers.3.weight, unet.trainable_unet.diffusion_model.output_blocks.8.0.out_layers.3.bias, unet.trainable_unet.diffusion_model.output_blocks.8.0.skip_connection.weight, unet.trainable_unet.diffusion_model.output_blocks.8.0.skip_connection.bias, unet.trainable_unet.diffusion_model.output_blocks.8.1.norm.weight, unet.trainable_unet.diffusion_model.output_blocks.8.1.norm.bias, unet.trainable_unet.diffusion_model.output_blocks.8.1.proj_in.weight, unet.trainable_unet.diffusion_model.output_blocks.8.1.proj_in.bias, unet.trainable_unet.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_q.weight, unet.trainable_unet.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_k.weight, unet.trainable_unet.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_v.weight, unet.trainable_unet.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_out.0.weight, unet.trainable_unet.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_out.0.bias, unet.trainable_unet.diffusion_model.output_blocks.8.1.transformer_blocks.0.ff.net.0.proj.weight, unet.trainable_unet.diffusion_model.output_blocks.8.1.transformer_blocks.0.ff.net.0.proj.bias, unet.trainable_unet.diffusion_model.output_blocks.8.1.transformer_blocks.0.ff.net.2.weight, unet.trainable_unet.diffusion_model.output_blocks.8.1.transformer_blocks.0.ff.net.2.bias, unet.trainable_unet.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_q.weight, unet.trainable_unet.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_k.weight, unet.trainable_unet.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_v.weight, unet.trainable_unet.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_out.0.weight, unet.trainable_unet.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_out.0.bias, unet.trainable_unet.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm1.weight, unet.trainable_unet.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm1.bias, unet.trainable_unet.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm2.weight, unet.trainable_unet.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm2.bias, unet.trainable_unet.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm3.weight, unet.trainable_unet.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm3.bias, unet.trainable_unet.diffusion_model.output_blocks.8.1.proj_out.weight, unet.trainable_unet.diffusion_model.output_blocks.8.1.proj_out.bias, unet.trainable_unet.diffusion_model.output_blocks.8.2.conv.weight, unet.trainable_unet.diffusion_model.output_blocks.8.2.conv.bias, unet.trainable_unet.diffusion_model.output_blocks.9.0.in_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.9.0.in_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.9.0.in_layers.2.weight, unet.trainable_unet.diffusion_model.output_blocks.9.0.in_layers.2.bias, unet.trainable_unet.diffusion_model.output_blocks.9.0.emb_layers.1.weight, unet.trainable_unet.diffusion_model.output_blocks.9.0.emb_layers.1.bias, unet.trainable_unet.diffusion_model.output_blocks.9.0.out_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.9.0.out_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.9.0.out_layers.3.weight, unet.trainable_unet.diffusion_model.output_blocks.9.0.out_layers.3.bias, unet.trainable_unet.diffusion_model.output_blocks.9.0.skip_connection.weight, unet.trainable_unet.diffusion_model.output_blocks.9.0.skip_connection.bias, unet.trainable_unet.diffusion_model.output_blocks.9.1.norm.weight, unet.trainable_unet.diffusion_model.output_blocks.9.1.norm.bias, unet.trainable_unet.diffusion_model.output_blocks.9.1.proj_in.weight, unet.trainable_unet.diffusion_model.output_blocks.9.1.proj_in.bias, unet.trainable_unet.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_q.weight, unet.trainable_unet.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_k.weight, unet.trainable_unet.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_v.weight, unet.trainable_unet.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_out.0.weight, unet.trainable_unet.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_out.0.bias, unet.trainable_unet.diffusion_model.output_blocks.9.1.transformer_blocks.0.ff.net.0.proj.weight, unet.trainable_unet.diffusion_model.output_blocks.9.1.transformer_blocks.0.ff.net.0.proj.bias, unet.trainable_unet.diffusion_model.output_blocks.9.1.transformer_blocks.0.ff.net.2.weight, unet.trainable_unet.diffusion_model.output_blocks.9.1.transformer_blocks.0.ff.net.2.bias, unet.trainable_unet.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_q.weight, unet.trainable_unet.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_k.weight, unet.trainable_unet.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_v.weight, unet.trainable_unet.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_out.0.weight, unet.trainable_unet.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_out.0.bias, unet.trainable_unet.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm1.weight, unet.trainable_unet.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm1.bias, unet.trainable_unet.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm2.weight, unet.trainable_unet.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm2.bias, unet.trainable_unet.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm3.weight, unet.trainable_unet.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm3.bias, unet.trainable_unet.diffusion_model.output_blocks.9.1.proj_out.weight, unet.trainable_unet.diffusion_model.output_blocks.9.1.proj_out.bias, unet.trainable_unet.diffusion_model.output_blocks.10.0.in_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.10.0.in_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.10.0.in_layers.2.weight, unet.trainable_unet.diffusion_model.output_blocks.10.0.in_layers.2.bias, unet.trainable_unet.diffusion_model.output_blocks.10.0.emb_layers.1.weight, unet.trainable_unet.diffusion_model.output_blocks.10.0.emb_layers.1.bias, unet.trainable_unet.diffusion_model.output_blocks.10.0.out_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.10.0.out_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.10.0.out_layers.3.weight, unet.trainable_unet.diffusion_model.output_blocks.10.0.out_layers.3.bias, unet.trainable_unet.diffusion_model.output_blocks.10.0.skip_connection.weight, unet.trainable_unet.diffusion_model.output_blocks.10.0.skip_connection.bias, unet.trainable_unet.diffusion_model.output_blocks.10.1.norm.weight, unet.trainable_unet.diffusion_model.output_blocks.10.1.norm.bias, unet.trainable_unet.diffusion_model.output_blocks.10.1.proj_in.weight, unet.trainable_unet.diffusion_model.output_blocks.10.1.proj_in.bias, unet.trainable_unet.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_q.weight, unet.trainable_unet.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_k.weight, unet.trainable_unet.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_v.weight, unet.trainable_unet.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_out.0.weight, unet.trainable_unet.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_out.0.bias, unet.trainable_unet.diffusion_model.output_blocks.10.1.transformer_blocks.0.ff.net.0.proj.weight, unet.trainable_unet.diffusion_model.output_blocks.10.1.transformer_blocks.0.ff.net.0.proj.bias, unet.trainable_unet.diffusion_model.output_blocks.10.1.transformer_blocks.0.ff.net.2.weight, unet.trainable_unet.diffusion_model.output_blocks.10.1.transformer_blocks.0.ff.net.2.bias, unet.trainable_unet.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_q.weight, unet.trainable_unet.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_k.weight, unet.trainable_unet.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_v.weight, unet.trainable_unet.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_out.0.weight, unet.trainable_unet.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_out.0.bias, unet.trainable_unet.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm1.weight, unet.trainable_unet.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm1.bias, unet.trainable_unet.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm2.weight, unet.trainable_unet.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm2.bias, unet.trainable_unet.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm3.weight, unet.trainable_unet.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm3.bias, unet.trainable_unet.diffusion_model.output_blocks.10.1.proj_out.weight, unet.trainable_unet.diffusion_model.output_blocks.10.1.proj_out.bias, unet.trainable_unet.diffusion_model.output_blocks.11.0.in_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.11.0.in_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.11.0.in_layers.2.weight, unet.trainable_unet.diffusion_model.output_blocks.11.0.in_layers.2.bias, unet.trainable_unet.diffusion_model.output_blocks.11.0.emb_layers.1.weight, unet.trainable_unet.diffusion_model.output_blocks.11.0.emb_layers.1.bias, unet.trainable_unet.diffusion_model.output_blocks.11.0.out_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.11.0.out_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.11.0.out_layers.3.weight, unet.trainable_unet.diffusion_model.output_blocks.11.0.out_layers.3.bias, unet.trainable_unet.diffusion_model.output_blocks.11.0.skip_connection.weight, unet.trainable_unet.diffusion_model.output_blocks.11.0.skip_connection.bias, unet.trainable_unet.diffusion_model.output_blocks.11.1.norm.weight, unet.trainable_unet.diffusion_model.output_blocks.11.1.norm.bias, unet.trainable_unet.diffusion_model.output_blocks.11.1.proj_in.weight, unet.trainable_unet.diffusion_model.output_blocks.11.1.proj_in.bias, unet.trainable_unet.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_q.weight, unet.trainable_unet.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_k.weight, unet.trainable_unet.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_v.weight, unet.trainable_unet.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_out.0.weight, unet.trainable_unet.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_out.0.bias, unet.trainable_unet.diffusion_model.output_blocks.11.1.transformer_blocks.0.ff.net.0.proj.weight, unet.trainable_unet.diffusion_model.output_blocks.11.1.transformer_blocks.0.ff.net.0.proj.bias, unet.trainable_unet.diffusion_model.output_blocks.11.1.transformer_blocks.0.ff.net.2.weight, unet.trainable_unet.diffusion_model.output_blocks.11.1.transformer_blocks.0.ff.net.2.bias, unet.trainable_unet.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_q.weight, unet.trainable_unet.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_k.weight, unet.trainable_unet.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_v.weight, unet.trainable_unet.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_out.0.weight, unet.trainable_unet.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_out.0.bias, unet.trainable_unet.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm1.weight, unet.trainable_unet.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm1.bias, unet.trainable_unet.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm2.weight, unet.trainable_unet.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm2.bias, unet.trainable_unet.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm3.weight, unet.trainable_unet.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm3.bias, unet.trainable_unet.diffusion_model.output_blocks.11.1.proj_out.weight, unet.trainable_unet.diffusion_model.output_blocks.11.1.proj_out.bias, unet.trainable_unet.diffusion_model.out.0.weight, unet.trainable_unet.diffusion_model.out.0.bias, unet.trainable_unet.diffusion_model.out.2.weight, unet.trainable_unet.diffusion_model.out.2.bias, unet.zero_convs.0.weight, unet.zero_convs.0.bias, unet.zero_convs.1.weight, unet.zero_convs.1.bias, unet.zero_convs.2.weight, unet.zero_convs.2.bias, unet.zero_convs.3.weight, unet.zero_convs.3.bias, unet.zero_convs.4.weight, unet.zero_convs.4.bias, unet.zero_convs.5.weight, unet.zero_convs.5.bias, box_encoder.box_cnn.0.weight, box_encoder.box_cnn.0.bias, box_encoder.box_cnn.2.weight, box_encoder.box_cnn.2.bias, box_encoder.scribble_cnn.0.weight, box_encoder.scribble_cnn.0.bias, box_encoder.scribble_cnn.2.weight, box_encoder.scribble_cnn.2.bias, box_encoder.dot_cnn.0.weight, box_encoder.dot_cnn.0.bias, box_encoder.dot_cnn.2.weight, box_encoder.dot_cnn.2.bias, box_encoder.out64.0.weight, box_encoder.out64.0.bias, box_encoder.out32.0.weight, box_encoder.out32.0.bias, box_encoder.out16.0.weight, box_encoder.out16.0.bias, box_encoder.conv64.0.weight, box_encoder.conv64.0.bias, box_encoder.conv32.0.weight, box_encoder.conv32.0.bias, box_encoder.conv16.0.weight, box_encoder.conv16.0.bias

2025-04-27 21:28:00,314 - mmseg - INFO - Start running, host: s203557@n-62-12-21, work_dir: /work3/s203557/experiments/control_net_vpd
2025-04-27 21:28:00,315 - mmseg - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(NORMAL      ) TrainVisualizeHook                 
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(NORMAL      ) TrainVisualizeHook                 
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
2025-04-27 21:28:00,315 - mmseg - INFO - workflow: [('train', 1)], max: 40000 iters
2025-04-27 21:28:00,315 - mmseg - INFO - Checkpoints will be saved to /work3/s203557/experiments/control_net_vpd by HardDiskBackend.
2025-04-27 21:28:38,355 - mmseg - INFO - Iter [50/40000]	lr: 2.610e-06, eta: 8:14:48, time: 0.743, data_time: 0.439, memory: 24195, decode.loss_ce: 1.0907, decode.acc_seg: 74.9106, loss: 1.0907
2025-04-27 21:29:03,874 - mmseg - INFO - Iter [100/40000]	lr: 5.267e-06, eta: 6:56:47, time: 0.510, data_time: 0.381, memory: 24195, decode.loss_ce: 0.9493, decode.acc_seg: 75.8925, loss: 0.9493
2025-04-27 21:29:29,946 - mmseg - INFO - Iter [150/40000]	lr: 7.917e-06, eta: 6:32:57, time: 0.521, data_time: 0.394, memory: 24195, decode.loss_ce: 0.9112, decode.acc_seg: 78.1275, loss: 0.9112
2025-04-27 21:29:54,385 - mmseg - INFO - Iter [200/40000]	lr: 1.056e-05, eta: 6:15:24, time: 0.489, data_time: 0.364, memory: 24195, decode.loss_ce: 0.9363, decode.acc_seg: 78.3938, loss: 0.9363
2025-04-27 21:30:21,803 - mmseg - INFO - Iter [250/40000]	lr: 1.320e-05, eta: 6:12:36, time: 0.548, data_time: 0.420, memory: 24195, decode.loss_ce: 0.7648, decode.acc_seg: 79.1546, loss: 0.7648
2025-04-27 21:30:46,094 - mmseg - INFO - Iter [300/40000]	lr: 1.583e-05, eta: 6:03:41, time: 0.486, data_time: 0.360, memory: 24195, decode.loss_ce: 0.7939, decode.acc_seg: 78.8000, loss: 0.7939
2025-04-27 21:31:10,358 - mmseg - INFO - Iter [350/40000]	lr: 1.845e-05, eta: 5:57:08, time: 0.485, data_time: 0.359, memory: 24195, decode.loss_ce: 0.8767, decode.acc_seg: 79.5813, loss: 0.8767
2025-04-27 21:31:34,628 - mmseg - INFO - Iter [400/40000]	lr: 2.107e-05, eta: 5:52:09, time: 0.485, data_time: 0.360, memory: 24195, decode.loss_ce: 0.9291, decode.acc_seg: 79.5046, loss: 0.9291
2025-04-27 21:32:01,829 - mmseg - INFO - Iter [450/40000]	lr: 2.368e-05, eta: 5:52:28, time: 0.544, data_time: 0.415, memory: 24195, decode.loss_ce: 0.6747, decode.acc_seg: 82.2127, loss: 0.6747
2025-04-27 21:32:28,698 - mmseg - INFO - Iter [500/40000]	lr: 2.628e-05, eta: 5:52:12, time: 0.537, data_time: 0.412, memory: 24195, decode.loss_ce: 0.6293, decode.acc_seg: 83.2126, loss: 0.6293
2025-04-27 21:32:53,006 - mmseg - INFO - Iter [550/40000]	lr: 2.888e-05, eta: 5:48:50, time: 0.486, data_time: 0.361, memory: 24195, decode.loss_ce: 0.6397, decode.acc_seg: 81.6110, loss: 0.6397
2025-04-27 21:33:17,273 - mmseg - INFO - Iter [600/40000]	lr: 3.147e-05, eta: 5:45:55, time: 0.485, data_time: 0.358, memory: 24195, decode.loss_ce: 0.4478, decode.acc_seg: 85.9056, loss: 0.4478
2025-04-27 21:33:44,394 - mmseg - INFO - Iter [650/40000]	lr: 3.405e-05, eta: 5:46:16, time: 0.542, data_time: 0.417, memory: 24195, decode.loss_ce: 0.7124, decode.acc_seg: 80.5510, loss: 0.7124
2025-04-27 21:34:08,567 - mmseg - INFO - Iter [700/40000]	lr: 3.663e-05, eta: 5:43:44, time: 0.483, data_time: 0.357, memory: 24195, decode.loss_ce: 0.8678, decode.acc_seg: 79.3429, loss: 0.8678
2025-04-27 21:34:32,787 - mmseg - INFO - Iter [750/40000]	lr: 3.920e-05, eta: 5:41:32, time: 0.484, data_time: 0.359, memory: 24195, decode.loss_ce: 1.0143, decode.acc_seg: 77.7322, loss: 1.0143
2025-04-27 21:34:57,032 - mmseg - INFO - Iter [800/40000]	lr: 4.176e-05, eta: 5:39:35, time: 0.485, data_time: 0.359, memory: 24195, decode.loss_ce: 0.8111, decode.acc_seg: 79.4124, loss: 0.8111
2025-04-27 21:35:24,266 - mmseg - INFO - Iter [850/40000]	lr: 4.432e-05, eta: 5:40:06, time: 0.545, data_time: 0.417, memory: 24195, decode.loss_ce: 0.5515, decode.acc_seg: 83.5142, loss: 0.5515
2025-04-27 21:35:48,414 - mmseg - INFO - Iter [900/40000]	lr: 4.687e-05, eta: 5:38:17, time: 0.483, data_time: 0.357, memory: 24195, decode.loss_ce: 0.6491, decode.acc_seg: 83.7908, loss: 0.6491
2025-04-27 21:36:12,765 - mmseg - INFO - Iter [950/40000]	lr: 4.941e-05, eta: 5:36:45, time: 0.487, data_time: 0.360, memory: 24195, decode.loss_ce: 0.4714, decode.acc_seg: 85.5258, loss: 0.4714
2025-04-27 21:36:37,232 - mmseg - INFO - Exp name: vpd_config.py
2025-04-27 21:36:37,232 - mmseg - INFO - Iter [1000/40000]	lr: 5.195e-05, eta: 5:35:25, time: 0.489, data_time: 0.363, memory: 24195, decode.loss_ce: 0.9004, decode.acc_seg: 78.8944, loss: 0.9004
2025-04-27 21:37:04,621 - mmseg - INFO - Iter [1050/40000]	lr: 5.448e-05, eta: 5:35:58, time: 0.548, data_time: 0.420, memory: 24195, decode.loss_ce: 0.6664, decode.acc_seg: 82.9270, loss: 0.6664
2025-04-27 21:37:31,469 - mmseg - INFO - Iter [1100/40000]	lr: 5.700e-05, eta: 5:36:06, time: 0.537, data_time: 0.411, memory: 24195, decode.loss_ce: 0.8123, decode.acc_seg: 82.6261, loss: 0.8123
2025-04-27 21:37:55,634 - mmseg - INFO - Iter [1150/40000]	lr: 5.952e-05, eta: 5:34:41, time: 0.483, data_time: 0.356, memory: 24195, decode.loss_ce: 0.7348, decode.acc_seg: 80.1280, loss: 0.7348
2025-04-27 21:38:19,973 - mmseg - INFO - Iter [1200/40000]	lr: 6.203e-05, eta: 5:33:26, time: 0.487, data_time: 0.360, memory: 24195, decode.loss_ce: 0.7159, decode.acc_seg: 81.9276, loss: 0.7159
2025-04-27 21:38:47,250 - mmseg - INFO - Iter [1250/40000]	lr: 6.453e-05, eta: 5:33:47, time: 0.546, data_time: 0.419, memory: 24195, decode.loss_ce: 0.6352, decode.acc_seg: 82.4779, loss: 0.6352
2025-04-27 21:39:14,269 - mmseg - INFO - Iter [1300/40000]	lr: 6.703e-05, eta: 5:33:56, time: 0.540, data_time: 0.414, memory: 24195, decode.loss_ce: 0.6635, decode.acc_seg: 83.6395, loss: 0.6635
2025-04-27 21:39:38,603 - mmseg - INFO - Iter [1350/40000]	lr: 6.952e-05, eta: 5:32:46, time: 0.487, data_time: 0.362, memory: 24195, decode.loss_ce: 0.4998, decode.acc_seg: 85.6214, loss: 0.4998
2025-04-27 21:40:02,768 - mmseg - INFO - Iter [1400/40000]	lr: 7.200e-05, eta: 5:31:34, time: 0.483, data_time: 0.358, memory: 24195, decode.loss_ce: 0.4857, decode.acc_seg: 86.0870, loss: 0.4857
2025-04-27 21:40:30,007 - mmseg - INFO - Iter [1450/40000]	lr: 7.448e-05, eta: 5:31:47, time: 0.545, data_time: 0.418, memory: 24195, decode.loss_ce: 0.4708, decode.acc_seg: 86.2219, loss: 0.4708
2025-04-27 21:40:54,212 - mmseg - INFO - Iter [1500/40000]	lr: 7.695e-05, eta: 5:30:40, time: 0.484, data_time: 0.358, memory: 24195, decode.loss_ce: 0.8002, decode.acc_seg: 79.4515, loss: 0.8002
2025-04-27 21:41:18,467 - mmseg - INFO - Iter [1550/40000]	lr: 7.690e-05, eta: 5:29:37, time: 0.485, data_time: 0.359, memory: 24195, decode.loss_ce: 0.6082, decode.acc_seg: 83.2997, loss: 0.6082
2025-04-27 21:41:42,648 - mmseg - INFO - Iter [1600/40000]	lr: 7.680e-05, eta: 5:28:34, time: 0.484, data_time: 0.358, memory: 24195, decode.loss_ce: 0.6577, decode.acc_seg: 83.1550, loss: 0.6577
2025-04-27 21:42:09,880 - mmseg - INFO - Iter [1650/40000]	lr: 7.670e-05, eta: 5:28:45, time: 0.545, data_time: 0.417, memory: 24195, decode.loss_ce: 0.4429, decode.acc_seg: 85.7822, loss: 0.4429
2025-04-27 21:42:36,980 - mmseg - INFO - Iter [1700/40000]	lr: 7.660e-05, eta: 5:28:50, time: 0.542, data_time: 0.416, memory: 24195, decode.loss_ce: 0.4496, decode.acc_seg: 86.3630, loss: 0.4496
2025-04-27 21:43:01,268 - mmseg - INFO - Iter [1750/40000]	lr: 7.650e-05, eta: 5:27:52, time: 0.486, data_time: 0.359, memory: 24195, decode.loss_ce: 0.5037, decode.acc_seg: 85.1897, loss: 0.5037
2025-04-27 21:43:28,026 - mmseg - INFO - Iter [1800/40000]	lr: 7.640e-05, eta: 5:27:49, time: 0.535, data_time: 0.409, memory: 24195, decode.loss_ce: 0.4492, decode.acc_seg: 87.8279, loss: 0.4492
2025-04-27 21:43:55,533 - mmseg - INFO - Iter [1850/40000]	lr: 7.630e-05, eta: 5:27:59, time: 0.550, data_time: 0.424, memory: 24195, decode.loss_ce: 0.5682, decode.acc_seg: 83.9656, loss: 0.5682
2025-04-27 21:44:19,825 - mmseg - INFO - Iter [1900/40000]	lr: 7.620e-05, eta: 5:27:03, time: 0.486, data_time: 0.359, memory: 24195, decode.loss_ce: 0.8152, decode.acc_seg: 81.8201, loss: 0.8152
2025-04-27 21:44:44,308 - mmseg - INFO - Iter [1950/40000]	lr: 7.610e-05, eta: 5:26:13, time: 0.490, data_time: 0.364, memory: 24195, decode.loss_ce: 0.5310, decode.acc_seg: 86.5184, loss: 0.5310
2025-04-27 21:45:10,281 - mmseg - INFO - Exp name: vpd_config.py
2025-04-27 21:45:10,282 - mmseg - INFO - Iter [2000/40000]	lr: 7.600e-05, eta: 5:25:52, time: 0.519, data_time: 0.394, memory: 24195, decode.loss_ce: 0.5611, decode.acc_seg: 84.0581, loss: 0.5611
2025-04-27 21:45:42,224 - mmseg - INFO - Iter [2050/40000]	lr: 7.590e-05, eta: 5:27:21, time: 0.639, data_time: 0.513, memory: 24195, decode.loss_ce: 0.6978, decode.acc_seg: 83.6197, loss: 0.6978
2025-04-27 21:46:08,044 - mmseg - INFO - Iter [2100/40000]	lr: 7.580e-05, eta: 5:26:54, time: 0.516, data_time: 0.389, memory: 24195, decode.loss_ce: 0.6163, decode.acc_seg: 82.2906, loss: 0.6163
2025-04-27 21:46:32,497 - mmseg - INFO - Iter [2150/40000]	lr: 7.570e-05, eta: 5:26:03, time: 0.489, data_time: 0.361, memory: 24195, decode.loss_ce: 0.4321, decode.acc_seg: 86.4609, loss: 0.4321
2025-04-27 21:46:56,941 - mmseg - INFO - Iter [2200/40000]	lr: 7.560e-05, eta: 5:25:13, time: 0.489, data_time: 0.363, memory: 24195, decode.loss_ce: 0.5394, decode.acc_seg: 85.2803, loss: 0.5394
2025-04-27 21:47:24,321 - mmseg - INFO - Iter [2250/40000]	lr: 7.550e-05, eta: 5:25:14, time: 0.548, data_time: 0.420, memory: 24195, decode.loss_ce: 0.5473, decode.acc_seg: 85.8375, loss: 0.5473
2025-04-27 21:47:48,652 - mmseg - INFO - Iter [2300/40000]	lr: 7.540e-05, eta: 5:24:23, time: 0.487, data_time: 0.359, memory: 24195, decode.loss_ce: 0.8201, decode.acc_seg: 79.8869, loss: 0.8201
2025-04-27 21:48:13,011 - mmseg - INFO - Iter [2350/40000]	lr: 7.530e-05, eta: 5:23:34, time: 0.487, data_time: 0.362, memory: 24195, decode.loss_ce: 0.6886, decode.acc_seg: 83.0680, loss: 0.6886
2025-04-27 21:48:37,527 - mmseg - INFO - Iter [2400/40000]	lr: 7.520e-05, eta: 5:22:48, time: 0.490, data_time: 0.365, memory: 24195, decode.loss_ce: 0.6250, decode.acc_seg: 84.0412, loss: 0.6250
2025-04-27 21:49:04,986 - mmseg - INFO - Iter [2450/40000]	lr: 7.510e-05, eta: 5:22:49, time: 0.549, data_time: 0.421, memory: 24195, decode.loss_ce: 0.7474, decode.acc_seg: 83.4508, loss: 0.7474
2025-04-27 21:49:29,371 - mmseg - INFO - Iter [2500/40000]	lr: 7.500e-05, eta: 5:22:02, time: 0.488, data_time: 0.362, memory: 24195, decode.loss_ce: 0.4199, decode.acc_seg: 87.3400, loss: 0.4199
2025-04-27 21:49:56,346 - mmseg - INFO - Iter [2550/40000]	lr: 7.490e-05, eta: 5:21:54, time: 0.539, data_time: 0.413, memory: 24195, decode.loss_ce: 0.7611, decode.acc_seg: 82.8435, loss: 0.7611
2025-04-27 21:50:20,802 - mmseg - INFO - Iter [2600/40000]	lr: 7.480e-05, eta: 5:21:09, time: 0.489, data_time: 0.364, memory: 24195, decode.loss_ce: 0.6321, decode.acc_seg: 85.0490, loss: 0.6321
2025-04-27 21:50:50,905 - mmseg - INFO - Iter [2650/40000]	lr: 7.470e-05, eta: 5:21:44, time: 0.602, data_time: 0.475, memory: 24195, decode.loss_ce: 0.6641, decode.acc_seg: 82.3528, loss: 0.6641
2025-04-27 21:51:15,453 - mmseg - INFO - Iter [2700/40000]	lr: 7.460e-05, eta: 5:21:01, time: 0.491, data_time: 0.365, memory: 24195, decode.loss_ce: 0.5533, decode.acc_seg: 84.7526, loss: 0.5533
2025-04-27 21:51:39,847 - mmseg - INFO - Iter [2750/40000]	lr: 7.450e-05, eta: 5:20:16, time: 0.488, data_time: 0.361, memory: 24195, decode.loss_ce: 0.3474, decode.acc_seg: 89.0792, loss: 0.3474
2025-04-27 21:52:04,009 - mmseg - INFO - Iter [2800/40000]	lr: 7.440e-05, eta: 5:19:28, time: 0.483, data_time: 0.358, memory: 24195, decode.loss_ce: 0.4957, decode.acc_seg: 86.8918, loss: 0.4957
2025-04-27 21:52:31,343 - mmseg - INFO - Iter [2850/40000]	lr: 7.430e-05, eta: 5:19:23, time: 0.547, data_time: 0.419, memory: 24195, decode.loss_ce: 0.6229, decode.acc_seg: 83.9547, loss: 0.6229
2025-04-27 21:52:55,698 - mmseg - INFO - Iter [2900/40000]	lr: 7.420e-05, eta: 5:18:39, time: 0.487, data_time: 0.362, memory: 24195, decode.loss_ce: 0.4031, decode.acc_seg: 88.4302, loss: 0.4031
2025-04-27 21:53:20,078 - mmseg - INFO - Iter [2950/40000]	lr: 7.410e-05, eta: 5:17:55, time: 0.488, data_time: 0.363, memory: 24195, decode.loss_ce: 0.4320, decode.acc_seg: 87.7453, loss: 0.4320
2025-04-27 21:53:44,583 - mmseg - INFO - Exp name: vpd_config.py
2025-04-27 21:53:44,584 - mmseg - INFO - Iter [3000/40000]	lr: 7.400e-05, eta: 5:17:14, time: 0.490, data_time: 0.364, memory: 24195, decode.loss_ce: 0.4152, decode.acc_seg: 89.2459, loss: 0.4152
2025-04-27 21:54:12,243 - mmseg - INFO - Iter [3050/40000]	lr: 7.390e-05, eta: 5:17:12, time: 0.553, data_time: 0.427, memory: 24195, decode.loss_ce: 0.5351, decode.acc_seg: 84.2664, loss: 0.5351
2025-04-27 21:54:37,265 - mmseg - INFO - Iter [3100/40000]	lr: 7.380e-05, eta: 5:16:38, time: 0.500, data_time: 0.377, memory: 24195, decode.loss_ce: 0.4626, decode.acc_seg: 87.0110, loss: 0.4626
2025-04-27 21:55:02,361 - mmseg - INFO - Iter [3150/40000]	lr: 7.370e-05, eta: 5:16:04, time: 0.502, data_time: 0.377, memory: 24195, decode.loss_ce: 0.4240, decode.acc_seg: 87.1070, loss: 0.4240
2025-04-27 21:55:27,237 - mmseg - INFO - Iter [3200/40000]	lr: 7.360e-05, eta: 5:15:29, time: 0.498, data_time: 0.374, memory: 24195, decode.loss_ce: 0.3707, decode.acc_seg: 87.1561, loss: 0.3707
2025-04-27 21:55:55,952 - mmseg - INFO - Iter [3250/40000]	lr: 7.350e-05, eta: 5:15:37, time: 0.574, data_time: 0.449, memory: 24195, decode.loss_ce: 0.4716, decode.acc_seg: 86.2087, loss: 0.4716
2025-04-27 21:56:20,479 - mmseg - INFO - Iter [3300/40000]	lr: 7.340e-05, eta: 5:14:57, time: 0.491, data_time: 0.366, memory: 24195, decode.loss_ce: 0.4756, decode.acc_seg: 86.6492, loss: 0.4756
2025-04-27 21:56:44,936 - mmseg - INFO - Iter [3350/40000]	lr: 7.330e-05, eta: 5:14:18, time: 0.489, data_time: 0.364, memory: 24195, decode.loss_ce: 0.4443, decode.acc_seg: 85.8270, loss: 0.4443
2025-04-27 21:57:09,404 - mmseg - INFO - Iter [3400/40000]	lr: 7.320e-05, eta: 5:13:38, time: 0.489, data_time: 0.366, memory: 24195, decode.loss_ce: 0.5593, decode.acc_seg: 84.8923, loss: 0.5593
2025-04-27 21:57:37,016 - mmseg - INFO - Iter [3450/40000]	lr: 7.310e-05, eta: 5:13:33, time: 0.552, data_time: 0.426, memory: 24195, decode.loss_ce: 0.6275, decode.acc_seg: 83.4969, loss: 0.6275
2025-04-27 21:58:01,632 - mmseg - INFO - Iter [3500/40000]	lr: 7.300e-05, eta: 5:12:55, time: 0.492, data_time: 0.366, memory: 24195, decode.loss_ce: 0.5354, decode.acc_seg: 86.8832, loss: 0.5354
2025-04-27 21:58:26,174 - mmseg - INFO - Iter [3550/40000]	lr: 7.290e-05, eta: 5:12:17, time: 0.491, data_time: 0.362, memory: 24195, decode.loss_ce: 0.5657, decode.acc_seg: 85.1245, loss: 0.5657
2025-04-27 21:58:50,605 - mmseg - INFO - Iter [3600/40000]	lr: 7.280e-05, eta: 5:11:39, time: 0.489, data_time: 0.361, memory: 24195, decode.loss_ce: 0.4485, decode.acc_seg: 88.1424, loss: 0.4485
2025-04-27 21:59:18,055 - mmseg - INFO - Iter [3650/40000]	lr: 7.270e-05, eta: 5:11:31, time: 0.549, data_time: 0.421, memory: 24195, decode.loss_ce: 0.5180, decode.acc_seg: 87.2150, loss: 0.5180
2025-04-27 21:59:42,469 - mmseg - INFO - Iter [3700/40000]	lr: 7.260e-05, eta: 5:10:52, time: 0.488, data_time: 0.363, memory: 24195, decode.loss_ce: 0.5308, decode.acc_seg: 87.0157, loss: 0.5308
2025-04-27 22:00:06,889 - mmseg - INFO - Iter [3750/40000]	lr: 7.250e-05, eta: 5:10:14, time: 0.488, data_time: 0.365, memory: 24195, decode.loss_ce: 0.5972, decode.acc_seg: 85.7886, loss: 0.5972
2025-04-27 22:00:31,366 - mmseg - INFO - Iter [3800/40000]	lr: 7.240e-05, eta: 5:09:37, time: 0.490, data_time: 0.365, memory: 24195, decode.loss_ce: 0.6571, decode.acc_seg: 83.1609, loss: 0.6571
2025-04-27 22:00:58,836 - mmseg - INFO - Iter [3850/40000]	lr: 7.230e-05, eta: 5:09:29, time: 0.549, data_time: 0.422, memory: 24195, decode.loss_ce: 0.7622, decode.acc_seg: 82.3363, loss: 0.7622
2025-04-27 22:01:23,278 - mmseg - INFO - Iter [3900/40000]	lr: 7.220e-05, eta: 5:08:51, time: 0.489, data_time: 0.365, memory: 24195, decode.loss_ce: 0.5316, decode.acc_seg: 87.0214, loss: 0.5316
2025-04-27 22:01:47,751 - mmseg - INFO - Iter [3950/40000]	lr: 7.210e-05, eta: 5:08:15, time: 0.489, data_time: 0.363, memory: 24195, decode.loss_ce: 0.6325, decode.acc_seg: 83.7130, loss: 0.6325
2025-04-27 22:02:12,303 - mmseg - INFO - Saving checkpoint at 4000 iterations
2025-04-27 22:02:25,197 - mmseg - INFO - Exp name: vpd_config.py
2025-04-27 22:02:25,197 - mmseg - INFO - Iter [4000/40000]	lr: 7.200e-05, eta: 5:09:35, time: 0.749, data_time: 0.366, memory: 24195, decode.loss_ce: 0.6022, decode.acc_seg: 85.2568, loss: 0.6022
Traceback (most recent call last):
  File "segmentation/train.py", line 287, in <module>
    main()
  File "segmentation/train.py", line 276, in main
    train_segmentor(
  File "/dtu/blackhole/0e/154958/miniconda3/envs/ldm/lib/python3.8/site-packages/mmseg/apis/train.py", line 194, in train_segmentor
    runner.run(data_loaders, cfg.workflow)
  File "/dtu/blackhole/0e/154958/miniconda3/envs/ldm/lib/python3.8/site-packages/mmcv/runner/iter_based_runner.py", line 134, in run
    iter_runner(iter_loaders[i], **kwargs)
  File "/dtu/blackhole/0e/154958/miniconda3/envs/ldm/lib/python3.8/site-packages/mmcv/runner/iter_based_runner.py", line 67, in train
    self.call_hook('after_train_iter')
  File "/dtu/blackhole/0e/154958/miniconda3/envs/ldm/lib/python3.8/site-packages/mmcv/runner/base_runner.py", line 309, in call_hook
    getattr(hook, fn_name)(self)
  File "/dtu/blackhole/0e/154958/miniconda3/envs/ldm/lib/python3.8/site-packages/mmcv/runner/hooks/evaluation.py", line 262, in after_train_iter
    self._do_evaluate(runner)
  File "/dtu/blackhole/0e/154958/miniconda3/envs/ldm/lib/python3.8/site-packages/mmseg/core/evaluation/eval_hooks.py", line 51, in _do_evaluate
    results = single_gpu_test(
  File "/dtu/blackhole/0e/154958/miniconda3/envs/ldm/lib/python3.8/site-packages/mmseg/apis/test.py", line 91, in single_gpu_test
    result = model(return_loss=False, **data)
  File "/dtu/blackhole/0e/154958/miniconda3/envs/ldm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/dtu/blackhole/0e/154958/miniconda3/envs/ldm/lib/python3.8/site-packages/mmcv/parallel/data_parallel.py", line 50, in forward
    return super().forward(*inputs, **kwargs)
  File "/dtu/blackhole/0e/154958/miniconda3/envs/ldm/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py", line 166, in forward
    return self.module(*inputs[0], **kwargs[0])
  File "/dtu/blackhole/0e/154958/miniconda3/envs/ldm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/dtu/blackhole/0e/154958/miniconda3/envs/ldm/lib/python3.8/site-packages/mmcv/runner/fp16_utils.py", line 110, in new_func
    return old_func(*args, **kwargs)
  File "/dtu/blackhole/0e/154958/miniconda3/envs/ldm/lib/python3.8/site-packages/mmseg/models/segmentors/base.py", line 110, in forward
    return self.forward_test(img, img_metas, **kwargs)
  File "/dtu/blackhole/0e/154958/miniconda3/envs/ldm/lib/python3.8/site-packages/mmseg/models/segmentors/base.py", line 92, in forward_test
    return self.simple_test(imgs[0], img_metas[0], **kwargs)
  File "/zhome/b6/d/154958/ADLCV_Project/VPD/segmentation/models/vpd_seg.py", line 383, in simple_test
    seg_logit = self.inference(img, img_meta, gt_bbox_masks=gt_bbox_masks,rescale= rescale)
  File "/zhome/b6/d/154958/ADLCV_Project/VPD/segmentation/models/vpd_seg.py", line 361, in inference
    seg_logits = self.whole_inference(img, img_meta, gt_bbox_masks=gt_bbox_masks, rescale=rescale)
  File "/zhome/b6/d/154958/ADLCV_Project/VPD/segmentation/models/vpd_seg.py", line 321, in whole_inference
    seg_logit = self.encode_decode(img, img_meta,gt_bbox_masks=gt_bbox_masks)
  File "/zhome/b6/d/154958/ADLCV_Project/VPD/segmentation/models/vpd_seg.py", line 261, in encode_decode
    x = self.extract_feat(img,img_metas, gt_bbox_masks=gt_bbox_masks)
  File "/zhome/b6/d/154958/ADLCV_Project/VPD/segmentation/models/vpd_seg.py", line 116, in extract_feat
    if masks.dim() == 3:
AttributeError: 'list' object has no attribute 'dim'
