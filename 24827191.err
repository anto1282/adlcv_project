Loaded dependency [python3/3.11.4]: gcc/12.3.0-binutils-2.40
Loaded dependency [python3/3.11.4]: sqlite3/3.42.0
Loaded module: python3/3.11.4

Loading python3/3.11.4
  Loading requirement: gcc/12.3.0-binutils-2.40 sqlite3/3.42.0
Loaded module: cuda/11.3
/dtu/blackhole/0e/154958/miniconda3/envs/ldm/lib/python3.8/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
2025-04-29 11:00:09,654 - mmseg - INFO - Multi-processing start method is `None`
2025-04-29 11:00:09,717 - mmseg - INFO - OpenCV num_threads is `1
2025-04-29 11:00:09,717 - mmseg - INFO - OMP num threads is 1
2025-04-29 11:00:09,832 - mmseg - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.8.19 | packaged by conda-forge | (default, Mar 20 2024, 12:47:35) [GCC 12.3.0]
CUDA available: True
GPU 0: NVIDIA A100 80GB PCIe
CUDA_HOME: /appl/cuda/11.3.0
NVCC: Cuda compilation tools, release 11.3, V11.3.58
GCC: gcc (GCC) 12.3.0
PyTorch: 1.11.0+cu113
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.5.2 (Git Hash a9302535553c73243c632ad3c4c80beec3d19a1e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.11.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

TorchVision: 0.12.0+cu113
OpenCV: 4.6.0
MMCV: 1.5.0
MMCV Compiler: GCC 7.3
MMCV CUDA Compiler: 11.3
MMSegmentation: 0.29.0+c1cbb58
------------------------------------------------------------

2025-04-29 11:00:09,832 - mmseg - INFO - Distributed training: False
2025-04-29 11:00:11,001 - mmseg - INFO - Config:
norm_cfg = dict(type='SyncBN', requires_grad=True)
model = dict(
    type='VPDSeg',
    pretrained='open-mmlab://resnet50_v1c',
    backbone=dict(
        type='ResNetV1c',
        depth=50,
        num_stages=4,
        out_indices=(0, 1, 2, 3),
        dilations=(1, 1, 1, 1),
        strides=(1, 2, 2, 2),
        norm_cfg=dict(type='SyncBN', requires_grad=True),
        norm_eval=False,
        style='pytorch',
        contract_dilation=True),
    neck=dict(
        type='FPN',
        in_channels=[320, 790, 1430, 1280],
        out_channels=256,
        num_outs=4),
    decode_head=dict(
        type='FPNHead',
        in_channels=[256, 256, 256, 256],
        in_index=[0, 1, 2, 3],
        feature_strides=[4, 8, 16, 32],
        channels=256,
        dropout_ratio=0.1,
        num_classes=150,
        norm_cfg=dict(type='SyncBN', requires_grad=True),
        align_corners=False,
        loss_decode=dict(
            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0)),
    train_cfg=dict(),
    test_cfg=dict(mode='slide', crop_size=(512, 512), stride=(341, 341)),
    sd_path='/work3/s203557/checkpoints/v1-5-pruned-emaonly.ckpt',
    sd_config=
    '/zhome/b6/d/154958/ADLCV_Project/VPD/segmentation/v1-inference.yaml',
    max_boxes=6)
dataset_type = 'ADE20KDataset'
data_root = '/work3/s203520/advanced_computer_vision/filtered_dataset'
IMG_MEAN = [127.5, 127.5, 127.5]
IMG_VAR = [127.5, 127.5, 127.5]
img_norm_cfg = dict(
    mean=[127.5, 127.5, 127.5], std=[127.5, 127.5, 127.5], to_rgb=True)
crop_size = (512, 512)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations', reduce_zero_label=True),
    dict(
        type='LoadPerClassMasksFromFolder',
        mask_root=
        '/work3/s203520/advanced_computer_vision/filtered_dataset/prompt_masks',
        types=['box', 'scribble', 'dot'],
        suffix='.npy',
        random_select=True),
    dict(type='ResizeWithBBox', img_scale=(2048, 512), ratio_range=(0.5, 2.0)),
    dict(type='RandomCropWithBBox', crop_size=(512, 512), cat_max_ratio=0.75),
    dict(type='RandomFlipWithBBox', prob=0.5),
    dict(type='PhotoMetricDistortion'),
    dict(
        type='Normalize',
        mean=[127.5, 127.5, 127.5],
        std=[127.5, 127.5, 127.5],
        to_rgb=True),
    dict(
        type='PadToSizeWithBBox', size=(512, 512), pad_val=0, seg_pad_val=255),
    dict(type='DefaultFormatBundle'),
    dict(
        type='Collect',
        keys=['img', 'gt_semantic_seg', 'gt_bbox_masks'],
        meta_keys=('filename', 'ori_shape', 'img_shape', 'pad_shape',
                   'scale_factor', 'input_type'))
]
val_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(512, 512),
        flip=False,
        transforms=[
            dict(
                type='LoadPerClassMasksFromFolder',
                mask_root=
                '/work3/s203520/advanced_computer_vision/filtered_dataset/prompt_masks',
                suffix='.npy',
                types=['box', 'scribble', 'dot'],
                random_select=True),
            dict(type='ResizeWithBBox', keep_ratio=False),
            dict(type='RandomFlipWithBBox', prob=0.0),
            dict(
                type='Normalize',
                mean=[127.5, 127.5, 127.5],
                std=[127.5, 127.5, 127.5],
                to_rgb=True),
            dict(type='ImageToTensor', keys=['img']),
            dict(
                type='Collect',
                keys=['img', 'gt_bbox_masks'],
                meta_keys=('filename', 'ori_shape', 'img_shape', 'pad_shape',
                           'scale_factor', 'input_type'))
        ])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(512, 512),
        flip=False,
        transforms=[
            dict(
                type='LoadPerClassMasksFromFolder',
                mask_root=
                '/work3/s203520/advanced_computer_vision/filtered_dataset/prompt_masks',
                suffix='.npy',
                types=['box'],
                random_select=True),
            dict(type='ResizeWithBBox', keep_ratio=False),
            dict(type='RandomFlipWithBBox', prob=0.0),
            dict(
                type='Normalize',
                mean=[127.5, 127.5, 127.5],
                std=[127.5, 127.5, 127.5],
                to_rgb=True),
            dict(type='ImageToTensor', keys=['img']),
            dict(
                type='Collect',
                keys=['img', 'gt_bbox_masks'],
                meta_keys=('filename', 'ori_shape', 'img_shape', 'pad_shape',
                           'scale_factor', 'input_type'))
        ])
]
data = dict(
    samples_per_gpu=4,
    workers_per_gpu=8,
    train=dict(
        type='ADE20KDataset',
        data_root='/work3/s203520/advanced_computer_vision/filtered_dataset',
        img_dir='images/training',
        ann_dir='annotations/training',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations', reduce_zero_label=True),
            dict(
                type='LoadPerClassMasksFromFolder',
                mask_root=
                '/work3/s203520/advanced_computer_vision/filtered_dataset/prompt_masks',
                types=['box', 'scribble', 'dot'],
                suffix='.npy',
                random_select=True),
            dict(
                type='ResizeWithBBox',
                img_scale=(2048, 512),
                ratio_range=(0.5, 2.0)),
            dict(
                type='RandomCropWithBBox',
                crop_size=(512, 512),
                cat_max_ratio=0.75),
            dict(type='RandomFlipWithBBox', prob=0.5),
            dict(type='PhotoMetricDistortion'),
            dict(
                type='Normalize',
                mean=[127.5, 127.5, 127.5],
                std=[127.5, 127.5, 127.5],
                to_rgb=True),
            dict(
                type='PadToSizeWithBBox',
                size=(512, 512),
                pad_val=0,
                seg_pad_val=255),
            dict(type='DefaultFormatBundle'),
            dict(
                type='Collect',
                keys=['img', 'gt_semantic_seg', 'gt_bbox_masks'],
                meta_keys=('filename', 'ori_shape', 'img_shape', 'pad_shape',
                           'scale_factor', 'input_type'))
        ]),
    val=dict(
        type='ADE20KDataset',
        data_root='/work3/s203520/advanced_computer_vision/filtered_dataset',
        img_dir='images/validation',
        ann_dir='annotations/validation',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(512, 512),
                flip=False,
                transforms=[
                    dict(
                        type='LoadPerClassMasksFromFolder',
                        mask_root=
                        '/work3/s203520/advanced_computer_vision/filtered_dataset/prompt_masks',
                        suffix='.npy',
                        types=['box', 'scribble', 'dot'],
                        random_select=True),
                    dict(type='ResizeWithBBox', keep_ratio=False),
                    dict(type='RandomFlipWithBBox', prob=0.0),
                    dict(
                        type='Normalize',
                        mean=[127.5, 127.5, 127.5],
                        std=[127.5, 127.5, 127.5],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(
                        type='Collect',
                        keys=['img', 'gt_bbox_masks'],
                        meta_keys=('filename', 'ori_shape', 'img_shape',
                                   'pad_shape', 'scale_factor', 'input_type'))
                ])
        ]),
    test=dict(
        type='CustomDatasetWithClassFilter',
        class_filter=[42],
        data_root='/work3/s203520/advanced_computer_vision/filtered_dataset',
        img_dir='images/validation/box',
        ann_dir='annotations/validation/box',
        json_path=
        '/zhome/b6/d/154958/ADLCV_Project/VPD/segmentation/datasets/validation_class_info.json',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(512, 512),
                flip=False,
                transforms=[
                    dict(
                        type='LoadPerClassMasksFromFolder',
                        mask_root=
                        '/work3/s203520/advanced_computer_vision/filtered_dataset/prompt_masks',
                        suffix='.npy',
                        types=['box'],
                        random_select=True),
                    dict(type='ResizeWithBBox', keep_ratio=False),
                    dict(type='RandomFlipWithBBox', prob=0.0),
                    dict(
                        type='Normalize',
                        mean=[127.5, 127.5, 127.5],
                        std=[127.5, 127.5, 127.5],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(
                        type='Collect',
                        keys=['img', 'gt_bbox_masks'],
                        meta_keys=('filename', 'ori_shape', 'img_shape',
                                   'pad_shape', 'scale_factor', 'input_type'))
                ])
        ]))
log_config = dict(
    interval=50, hooks=[dict(type='TextLoggerHook', by_epoch=False)])
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = '/work3/s203557/experiments/control_net_vpd/iter_4000.pth'
resume_from = None
workflow = [('train', 1)]
cudnn_benchmark = True
find_unused_parameters = True
optimizer = dict(
    type='AdamW',
    lr=8e-05,
    weight_decay=0.001,
    paramwise_cfg=dict(
        custom_keys=dict(
            trainable_unet=dict(lr_mult=0.1), encoder_vq=dict(lr_mult=0.0))))
optimizer_config = dict()
lr_config = dict(
    policy='poly',
    power=1,
    min_lr=0.0,
    by_epoch=False,
    warmup='linear',
    warmup_iters=1500,
    warmup_ratio=1e-06)
runner = dict(type='IterBasedRunner', max_iters=20000)
checkpoint_config = dict(by_epoch=False, interval=2000)
evaluation = dict(interval=2000, metric='mIoU')
custom_imports = dict(
    imports=['segmentation.hooks.visualize_hook'], allow_failed_imports=False)
work_dir = '/work3/s203557/experiments/control_net_vpd/'
fp16 = dict(loss_scale=512.0)
custom_hooks = [
    dict(
        type='TrainVisualizeHook',
        interval=4000,
        num_samples=2,
        save_dir='vis')
]
gpu_ids = [0]
auto_resume = False

2025-04-29 11:00:11,002 - mmseg - INFO - Set random seed to 975502434, deterministic: False
/dtu/blackhole/0e/154958/miniconda3/envs/ldm/lib/python3.8/site-packages/mmseg/models/losses/cross_entropy_loss.py:235: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.
  warnings.warn(
2025-04-29 11:00:21,245 - mmseg - INFO - initialize FPN with init_cfg {'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}
2025-04-29 11:00:21,263 - mmseg - INFO - initialize FPNHead with init_cfg {'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
segmentation/train.py:251: UserWarning: SyncBN is only supported with DDP. To be compatible with DP, we convert SyncBN to BN. Please use dist_train.sh which can avoid this error.
  warnings.warn(
2025-04-29 11:00:22,011 - mmseg - INFO - VPDSeg(
  (encoder_vq): AutoencoderKL(
    (encoder): Encoder(
      (conv_in): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (down): ModuleList(
        (0): Module(
          (block): ModuleList(
            (0): ResnetBlock(
              (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)
              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
            (1): ResnetBlock(
              (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)
              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (attn): ModuleList()
          (downsample): Downsample(
            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2))
          )
        )
        (1): Module(
          (block): ModuleList(
            (0): ResnetBlock(
              (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)
              (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (nin_shortcut): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): ResnetBlock(
              (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (attn): ModuleList()
          (downsample): Downsample(
            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))
          )
        )
        (2): Module(
          (block): ModuleList(
            (0): ResnetBlock(
              (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)
              (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (nin_shortcut): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): ResnetBlock(
              (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)
              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (attn): ModuleList()
          (downsample): Downsample(
            (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2))
          )
        )
        (3): Module(
          (block): ModuleList(
            (0): ResnetBlock(
              (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)
              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
            (1): ResnetBlock(
              (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)
              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (attn): ModuleList()
        )
      )
      (mid): Module(
        (block_1): ResnetBlock(
          (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)
          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (attn_1): AttnBlock(
          (norm): GroupNorm(32, 512, eps=1e-06, affine=True)
          (q): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (k): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (v): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (proj_out): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
        )
        (block_2): ResnetBlock(
          (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)
          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (norm_out): GroupNorm(32, 512, eps=1e-06, affine=True)
      (conv_out): Conv2d(512, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (loss): Identity()
    (quant_conv): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1))
    (post_quant_conv): Conv2d(4, 4, kernel_size=(1, 1), stride=(1, 1))
  )
  (unet): UNetWrapper(
    (unet): DiffusionWrapper(
      (diffusion_model): UNetModel(
        (time_embed): Sequential(
          (0): Linear(in_features=320, out_features=1280, bias=True)
          (1): SiLU()
          (2): Linear(in_features=1280, out_features=1280, bias=True)
        )
        (input_blocks): ModuleList(
          (0): TimestepEmbedSequential(
            (0): Conv2d(4, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (1): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=320, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Identity()
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 320, eps=1e-06, affine=True)
              (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=320, out_features=320, bias=False)
                    (to_v): Linear(in_features=320, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=320, out_features=2560, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=1280, out_features=320, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=768, out_features=320, bias=False)
                    (to_v): Linear(in_features=768, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (2): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=320, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Identity()
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 320, eps=1e-06, affine=True)
              (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=320, out_features=320, bias=False)
                    (to_v): Linear(in_features=320, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=320, out_features=2560, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=1280, out_features=320, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=768, out_features=320, bias=False)
                    (to_v): Linear(in_features=768, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (3): TimestepEmbedSequential(
            (0): Downsample(
              (op): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
            )
          )
          (4): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(320, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=640, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(320, 640, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 640, eps=1e-06, affine=True)
              (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=640, out_features=640, bias=False)
                    (to_v): Linear(in_features=640, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=640, out_features=5120, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=2560, out_features=640, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=768, out_features=640, bias=False)
                    (to_v): Linear(in_features=768, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (5): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=640, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Identity()
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 640, eps=1e-06, affine=True)
              (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=640, out_features=640, bias=False)
                    (to_v): Linear(in_features=640, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=640, out_features=5120, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=2560, out_features=640, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=768, out_features=640, bias=False)
                    (to_v): Linear(in_features=768, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (6): TimestepEmbedSequential(
            (0): Downsample(
              (op): Conv2d(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
            )
          )
          (7): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(640, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(640, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)
              (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_v): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=1280, out_features=10240, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=5120, out_features=1280, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=768, out_features=1280, bias=False)
                    (to_v): Linear(in_features=768, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (8): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Identity()
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)
              (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_v): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=1280, out_features=10240, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=5120, out_features=1280, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=768, out_features=1280, bias=False)
                    (to_v): Linear(in_features=768, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (9): TimestepEmbedSequential(
            (0): Downsample(
              (op): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
            )
          )
          (10): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Identity()
            )
          )
          (11): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Identity()
            )
          )
        )
        (middle_block): TimestepEmbedSequential(
          (0): ResBlock(
            (in_layers): Sequential(
              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
              (1): SiLU()
              (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
            (h_upd): Identity()
            (x_upd): Identity()
            (emb_layers): Sequential(
              (0): SiLU()
              (1): Linear(in_features=1280, out_features=1280, bias=True)
            )
            (out_layers): Sequential(
              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
              (1): SiLU()
              (2): Dropout(p=0, inplace=False)
              (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
            (skip_connection): Identity()
          )
          (1): SpatialTransformer(
            (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)
            (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
            (transformer_blocks): ModuleList(
              (0): BasicTransformerBlock(
                (attn1): CrossAttention(
                  (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                  (to_k): Linear(in_features=1280, out_features=1280, bias=False)
                  (to_v): Linear(in_features=1280, out_features=1280, bias=False)
                  (to_out): Sequential(
                    (0): Linear(in_features=1280, out_features=1280, bias=True)
                    (1): Dropout(p=0.0, inplace=False)
                  )
                )
                (ff): FeedForward(
                  (net): Sequential(
                    (0): GEGLU(
                      (proj): Linear(in_features=1280, out_features=10240, bias=True)
                    )
                    (1): Dropout(p=0.0, inplace=False)
                    (2): Linear(in_features=5120, out_features=1280, bias=True)
                  )
                )
                (attn2): CrossAttention(
                  (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                  (to_k): Linear(in_features=768, out_features=1280, bias=False)
                  (to_v): Linear(in_features=768, out_features=1280, bias=False)
                  (to_out): Sequential(
                    (0): Linear(in_features=1280, out_features=1280, bias=True)
                    (1): Dropout(p=0.0, inplace=False)
                  )
                )
                (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
              )
            )
            (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
          )
          (2): ResBlock(
            (in_layers): Sequential(
              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
              (1): SiLU()
              (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
            (h_upd): Identity()
            (x_upd): Identity()
            (emb_layers): Sequential(
              (0): SiLU()
              (1): Linear(in_features=1280, out_features=1280, bias=True)
            )
            (out_layers): Sequential(
              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
              (1): SiLU()
              (2): Dropout(p=0, inplace=False)
              (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
            (skip_connection): Identity()
          )
        )
        (output_blocks): ModuleList(
          (0): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (1): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (2): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): Upsample(
              (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (3): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)
              (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_v): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=1280, out_features=10240, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=5120, out_features=1280, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=768, out_features=1280, bias=False)
                    (to_v): Linear(in_features=768, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (4): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)
              (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_v): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=1280, out_features=10240, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=5120, out_features=1280, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=768, out_features=1280, bias=False)
                    (to_v): Linear(in_features=768, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (5): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 1920, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(1920, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(1920, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)
              (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_v): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=1280, out_features=10240, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=5120, out_features=1280, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=768, out_features=1280, bias=False)
                    (to_v): Linear(in_features=768, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
            (2): Upsample(
              (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (6): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 1920, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(1920, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=640, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(1920, 640, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 640, eps=1e-06, affine=True)
              (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=640, out_features=640, bias=False)
                    (to_v): Linear(in_features=640, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=640, out_features=5120, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=2560, out_features=640, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=768, out_features=640, bias=False)
                    (to_v): Linear(in_features=768, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (7): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(1280, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=640, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 640, eps=1e-06, affine=True)
              (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=640, out_features=640, bias=False)
                    (to_v): Linear(in_features=640, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=640, out_features=5120, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=2560, out_features=640, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=768, out_features=640, bias=False)
                    (to_v): Linear(in_features=768, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (8): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 960, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(960, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=640, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(960, 640, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 640, eps=1e-06, affine=True)
              (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=640, out_features=640, bias=False)
                    (to_v): Linear(in_features=640, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=640, out_features=5120, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=2560, out_features=640, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=768, out_features=640, bias=False)
                    (to_v): Linear(in_features=768, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
            )
            (2): Upsample(
              (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (9): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 960, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(960, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=320, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 320, eps=1e-06, affine=True)
              (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=320, out_features=320, bias=False)
                    (to_v): Linear(in_features=320, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=320, out_features=2560, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=1280, out_features=320, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=768, out_features=320, bias=False)
                    (to_v): Linear(in_features=768, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (10): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=320, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 320, eps=1e-06, affine=True)
              (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=320, out_features=320, bias=False)
                    (to_v): Linear(in_features=320, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=320, out_features=2560, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=1280, out_features=320, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=768, out_features=320, bias=False)
                    (to_v): Linear(in_features=768, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (11): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=320, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 320, eps=1e-06, affine=True)
              (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=320, out_features=320, bias=False)
                    (to_v): Linear(in_features=320, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=320, out_features=2560, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=1280, out_features=320, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=768, out_features=320, bias=False)
                    (to_v): Linear(in_features=768, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
            )
          )
        )
        (out): Sequential(
          (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
          (1): SiLU()
          (2): Conv2d(320, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
    )
    (trainable_unet): DiffusionWrapper(
      (diffusion_model): UNetModel(
        (time_embed): Sequential(
          (0): Linear(in_features=320, out_features=1280, bias=True)
          (1): SiLU()
          (2): Linear(in_features=1280, out_features=1280, bias=True)
        )
        (input_blocks): ModuleList(
          (0): TimestepEmbedSequential(
            (0): Conv2d(4, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (1): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=320, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Identity()
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 320, eps=1e-06, affine=True)
              (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=320, out_features=320, bias=False)
                    (to_v): Linear(in_features=320, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=320, out_features=2560, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=1280, out_features=320, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=768, out_features=320, bias=False)
                    (to_v): Linear(in_features=768, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (2): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=320, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Identity()
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 320, eps=1e-06, affine=True)
              (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=320, out_features=320, bias=False)
                    (to_v): Linear(in_features=320, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=320, out_features=2560, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=1280, out_features=320, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=768, out_features=320, bias=False)
                    (to_v): Linear(in_features=768, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (3): TimestepEmbedSequential(
            (0): Downsample(
              (op): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
            )
          )
          (4): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(320, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=640, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(320, 640, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 640, eps=1e-06, affine=True)
              (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=640, out_features=640, bias=False)
                    (to_v): Linear(in_features=640, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=640, out_features=5120, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=2560, out_features=640, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=768, out_features=640, bias=False)
                    (to_v): Linear(in_features=768, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (5): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=640, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Identity()
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 640, eps=1e-06, affine=True)
              (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=640, out_features=640, bias=False)
                    (to_v): Linear(in_features=640, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=640, out_features=5120, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=2560, out_features=640, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=768, out_features=640, bias=False)
                    (to_v): Linear(in_features=768, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (6): TimestepEmbedSequential(
            (0): Downsample(
              (op): Conv2d(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
            )
          )
          (7): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(640, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(640, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)
              (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_v): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=1280, out_features=10240, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=5120, out_features=1280, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=768, out_features=1280, bias=False)
                    (to_v): Linear(in_features=768, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (8): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Identity()
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)
              (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_v): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=1280, out_features=10240, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=5120, out_features=1280, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=768, out_features=1280, bias=False)
                    (to_v): Linear(in_features=768, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (9): TimestepEmbedSequential(
            (0): Downsample(
              (op): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
            )
          )
          (10): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Identity()
            )
          )
          (11): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Identity()
            )
          )
        )
        (middle_block): TimestepEmbedSequential(
          (0): ResBlock(
            (in_layers): Sequential(
              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
              (1): SiLU()
              (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
            (h_upd): Identity()
            (x_upd): Identity()
            (emb_layers): Sequential(
              (0): SiLU()
              (1): Linear(in_features=1280, out_features=1280, bias=True)
            )
            (out_layers): Sequential(
              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
              (1): SiLU()
              (2): Dropout(p=0, inplace=False)
              (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
            (skip_connection): Identity()
          )
          (1): SpatialTransformer(
            (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)
            (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
            (transformer_blocks): ModuleList(
              (0): BasicTransformerBlock(
                (attn1): CrossAttention(
                  (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                  (to_k): Linear(in_features=1280, out_features=1280, bias=False)
                  (to_v): Linear(in_features=1280, out_features=1280, bias=False)
                  (to_out): Sequential(
                    (0): Linear(in_features=1280, out_features=1280, bias=True)
                    (1): Dropout(p=0.0, inplace=False)
                  )
                )
                (ff): FeedForward(
                  (net): Sequential(
                    (0): GEGLU(
                      (proj): Linear(in_features=1280, out_features=10240, bias=True)
                    )
                    (1): Dropout(p=0.0, inplace=False)
                    (2): Linear(in_features=5120, out_features=1280, bias=True)
                  )
                )
                (attn2): CrossAttention(
                  (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                  (to_k): Linear(in_features=768, out_features=1280, bias=False)
                  (to_v): Linear(in_features=768, out_features=1280, bias=False)
                  (to_out): Sequential(
                    (0): Linear(in_features=1280, out_features=1280, bias=True)
                    (1): Dropout(p=0.0, inplace=False)
                  )
                )
                (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
              )
            )
            (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
          )
          (2): ResBlock(
            (in_layers): Sequential(
              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
              (1): SiLU()
              (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
            (h_upd): Identity()
            (x_upd): Identity()
            (emb_layers): Sequential(
              (0): SiLU()
              (1): Linear(in_features=1280, out_features=1280, bias=True)
            )
            (out_layers): Sequential(
              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
              (1): SiLU()
              (2): Dropout(p=0, inplace=False)
              (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
            (skip_connection): Identity()
          )
        )
        (output_blocks): ModuleList(
          (0): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (1): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (2): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): Upsample(
              (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (3): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)
              (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_v): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=1280, out_features=10240, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=5120, out_features=1280, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=768, out_features=1280, bias=False)
                    (to_v): Linear(in_features=768, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (4): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)
              (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_v): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=1280, out_features=10240, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=5120, out_features=1280, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=768, out_features=1280, bias=False)
                    (to_v): Linear(in_features=768, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (5): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 1920, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(1920, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(1920, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)
              (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_v): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=1280, out_features=10240, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=5120, out_features=1280, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=768, out_features=1280, bias=False)
                    (to_v): Linear(in_features=768, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
            (2): Upsample(
              (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (6): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 1920, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(1920, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=640, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(1920, 640, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 640, eps=1e-06, affine=True)
              (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=640, out_features=640, bias=False)
                    (to_v): Linear(in_features=640, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=640, out_features=5120, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=2560, out_features=640, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=768, out_features=640, bias=False)
                    (to_v): Linear(in_features=768, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (7): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(1280, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=640, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 640, eps=1e-06, affine=True)
              (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=640, out_features=640, bias=False)
                    (to_v): Linear(in_features=640, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=640, out_features=5120, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=2560, out_features=640, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=768, out_features=640, bias=False)
                    (to_v): Linear(in_features=768, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (8): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 960, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(960, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=640, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(960, 640, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 640, eps=1e-06, affine=True)
              (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=640, out_features=640, bias=False)
                    (to_v): Linear(in_features=640, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=640, out_features=5120, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=2560, out_features=640, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=768, out_features=640, bias=False)
                    (to_v): Linear(in_features=768, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
            )
            (2): Upsample(
              (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (9): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 960, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(960, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=320, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 320, eps=1e-06, affine=True)
              (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=320, out_features=320, bias=False)
                    (to_v): Linear(in_features=320, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=320, out_features=2560, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=1280, out_features=320, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=768, out_features=320, bias=False)
                    (to_v): Linear(in_features=768, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (10): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=320, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 320, eps=1e-06, affine=True)
              (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=320, out_features=320, bias=False)
                    (to_v): Linear(in_features=320, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=320, out_features=2560, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=1280, out_features=320, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=768, out_features=320, bias=False)
                    (to_v): Linear(in_features=768, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (11): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=320, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 320, eps=1e-06, affine=True)
              (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=320, out_features=320, bias=False)
                    (to_v): Linear(in_features=320, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=320, out_features=2560, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=1280, out_features=320, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=768, out_features=320, bias=False)
                    (to_v): Linear(in_features=768, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
            )
          )
        )
        (out): Sequential(
          (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
          (1): SiLU()
          (2): Conv2d(320, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
    )
    (zero_convs): ModuleList(
      (0): ZeroConv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
      (1): ZeroConv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
      (2): ZeroConv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
      (3): ZeroConv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
      (4): ZeroConv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
      (5): ZeroConv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (box_encoder): EncoderControlNet(
    (box_cnn): Sequential(
      (0): Conv2d(1, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (3): ReLU(inplace=True)
    )
    (scribble_cnn): Sequential(
      (0): Conv2d(1, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (3): ReLU(inplace=True)
    )
    (dot_cnn): Sequential(
      (0): Conv2d(1, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (3): ReLU(inplace=True)
    )
    (out64): Sequential(
      (0): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
    )
    (out32): Sequential(
      (0): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
    )
    (out16): Sequential(
      (0): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
    )
    (conv64): Sequential(
      (0): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (1): ReLU(inplace=True)
    )
    (conv32): Sequential(
      (0): Conv2d(320, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (1): ReLU(inplace=True)
    )
    (conv16): Sequential(
      (0): Conv2d(640, 1280, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (1): ReLU(inplace=True)
    )
  )
  (sd_model): LatentDiffusion(
    (model): None
    (first_stage_model): None
  )
  (text_adapter): TextAdapter(
    (fc): Sequential(
      (0): Linear(in_features=768, out_features=768, bias=True)
      (1): GELU()
      (2): Linear(in_features=768, out_features=768, bias=True)
    )
  )
  (neck): FPN(
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(320, 256, kernel_size=(1, 1), stride=(1, 1))
      )
      (1): ConvModule(
        (conv): Conv2d(790, 256, kernel_size=(1, 1), stride=(1, 1))
      )
      (2): ConvModule(
        (conv): Conv2d(1430, 256, kernel_size=(1, 1), stride=(1, 1))
      )
      (3): ConvModule(
        (conv): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (1): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (2): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (3): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
  )
  init_cfg={'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}
  (decode_head): FPNHead(
    input_transform=multiple_select, ignore_index=255, align_corners=False
    (loss_decode): CrossEntropyLoss(avg_non_ignore=False)
    (conv_seg): Conv2d(256, 150, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (scale_heads): ModuleList(
      (0): Sequential(
        (0): ConvModule(
          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (1): Sequential(
        (0): ConvModule(
          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): Upsample()
      )
      (2): Sequential(
        (0): ConvModule(
          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): Upsample()
        (2): ConvModule(
          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): Upsample()
      )
      (3): Sequential(
        (0): ConvModule(
          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): Upsample()
        (2): ConvModule(
          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): Upsample()
        (4): ConvModule(
          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (5): Upsample()
      )
    )
  )
  init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
)
2025-04-29 11:00:22,321 - mmseg - INFO - Loaded 7725 images
/dtu/blackhole/0e/154958/miniconda3/envs/ldm/lib/python3.8/site-packages/torch/utils/data/dataloader.py:487: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
2025-04-29 11:00:28,989 - mmseg - INFO - Loaded 851 images
2025-04-29 11:00:28,991 - mmseg - INFO - load checkpoint from local path: /work3/s203557/experiments/control_net_vpd/iter_4000.pth
2025-04-29 11:00:33,379 - mmseg - WARNING - The model and loaded state dict do not match exactly

unexpected key in source state_dict: sd_model.lvlb_weights

2025-04-29 11:00:33,413 - mmseg - INFO - Start running, host: s203557@n-62-18-12, work_dir: /work3/s203557/experiments/control_net_vpd
2025-04-29 11:00:33,413 - mmseg - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(NORMAL      ) TrainVisualizeHook                 
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(NORMAL      ) TrainVisualizeHook                 
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
2025-04-29 11:00:33,414 - mmseg - INFO - workflow: [('train', 1)], max: 20000 iters
2025-04-29 11:00:33,414 - mmseg - INFO - Checkpoints will be saved to /work3/s203557/experiments/control_net_vpd by HardDiskBackend.
2025-04-29 11:03:20,546 - mmseg - INFO - Iter [50/20000]	lr: 2.607e-06, eta: 18:25:41, time: 3.325, data_time: 2.245, memory: 75916, decode.loss_ce: 0.1503, decode.acc_seg: 93.8418, loss: 0.1503
2025-04-29 11:05:11,033 - mmseg - INFO - Iter [100/20000]	lr: 5.254e-06, eta: 15:17:54, time: 2.210, data_time: 1.918, memory: 75916, decode.loss_ce: 0.1603, decode.acc_seg: 93.7100, loss: 0.1603
2025-04-29 11:07:01,128 - mmseg - INFO - Iter [150/20000]	lr: 7.888e-06, eta: 14:13:13, time: 2.202, data_time: 1.912, memory: 75916, decode.loss_ce: 0.1710, decode.acc_seg: 93.1594, loss: 0.1710
2025-04-29 11:08:49,269 - mmseg - INFO - Iter [200/20000]	lr: 1.051e-05, eta: 13:36:44, time: 2.163, data_time: 1.874, memory: 75916, decode.loss_ce: 0.1621, decode.acc_seg: 93.5035, loss: 0.1621
2025-04-29 11:10:53,771 - mmseg - INFO - Iter [250/20000]	lr: 1.311e-05, eta: 13:35:39, time: 2.490, data_time: 2.201, memory: 75916, decode.loss_ce: 0.1537, decode.acc_seg: 93.9307, loss: 0.1537
2025-04-29 11:12:42,019 - mmseg - INFO - Iter [300/20000]	lr: 1.571e-05, eta: 13:16:28, time: 2.165, data_time: 1.876, memory: 75916, decode.loss_ce: 0.1704, decode.acc_seg: 93.1244, loss: 0.1704
2025-04-29 11:14:30,561 - mmseg - INFO - Iter [350/20000]	lr: 1.829e-05, eta: 13:02:31, time: 2.171, data_time: 1.882, memory: 75916, decode.loss_ce: 0.1631, decode.acc_seg: 93.5044, loss: 0.1631
2025-04-29 11:16:20,541 - mmseg - INFO - Iter [400/20000]	lr: 2.086e-05, eta: 12:52:46, time: 2.200, data_time: 1.911, memory: 75916, decode.loss_ce: 0.1696, decode.acc_seg: 93.2233, loss: 0.1696
2025-04-29 11:18:25,045 - mmseg - INFO - Iter [450/20000]	lr: 2.341e-05, eta: 12:55:18, time: 2.490, data_time: 2.201, memory: 75916, decode.loss_ce: 0.1609, decode.acc_seg: 93.7258, loss: 0.1609
2025-04-29 11:20:13,842 - mmseg - INFO - Iter [500/20000]	lr: 2.595e-05, eta: 12:46:42, time: 2.176, data_time: 1.887, memory: 75916, decode.loss_ce: 0.1508, decode.acc_seg: 93.8538, loss: 0.1508
2025-04-29 11:22:02,721 - mmseg - INFO - Iter [550/20000]	lr: 2.848e-05, eta: 12:39:23, time: 2.178, data_time: 1.889, memory: 75916, decode.loss_ce: 0.1615, decode.acc_seg: 93.7265, loss: 0.1615
2025-04-29 11:23:51,321 - mmseg - INFO - Iter [600/20000]	lr: 3.099e-05, eta: 12:32:50, time: 2.172, data_time: 1.883, memory: 75916, decode.loss_ce: 0.1567, decode.acc_seg: 93.8208, loss: 0.1567
2025-04-29 11:25:55,748 - mmseg - INFO - Iter [650/20000]	lr: 3.349e-05, eta: 12:34:52, time: 2.489, data_time: 2.200, memory: 75916, decode.loss_ce: 0.1721, decode.acc_seg: 93.1869, loss: 0.1721
2025-04-29 11:27:44,825 - mmseg - INFO - Iter [700/20000]	lr: 3.598e-05, eta: 12:29:16, time: 2.182, data_time: 1.893, memory: 75916, decode.loss_ce: 0.1797, decode.acc_seg: 92.7302, loss: 0.1797
2025-04-29 11:29:34,683 - mmseg - INFO - Iter [750/20000]	lr: 3.845e-05, eta: 12:24:30, time: 2.197, data_time: 1.908, memory: 75916, decode.loss_ce: 0.1747, decode.acc_seg: 93.3803, loss: 0.1747
2025-04-29 11:31:24,504 - mmseg - INFO - Iter [800/20000]	lr: 4.091e-05, eta: 12:20:05, time: 2.196, data_time: 1.907, memory: 75916, decode.loss_ce: 0.1497, decode.acc_seg: 94.1714, loss: 0.1497
2025-04-29 11:33:36,723 - mmseg - INFO - Iter [850/20000]	lr: 4.336e-05, eta: 12:24:23, time: 2.644, data_time: 2.352, memory: 75916, decode.loss_ce: 0.1720, decode.acc_seg: 93.1817, loss: 0.1720
2025-04-29 11:35:29,352 - mmseg - INFO - Iter [900/20000]	lr: 4.579e-05, eta: 12:21:02, time: 2.253, data_time: 1.962, memory: 75916, decode.loss_ce: 0.1793, decode.acc_seg: 93.0076, loss: 0.1793
2025-04-29 11:37:19,070 - mmseg - INFO - Iter [950/20000]	lr: 4.821e-05, eta: 12:16:51, time: 2.194, data_time: 1.906, memory: 75916, decode.loss_ce: 0.1630, decode.acc_seg: 93.7535, loss: 0.1630
2025-04-29 11:39:08,839 - mmseg - INFO - Exp name: vpd_config.py
2025-04-29 11:39:08,840 - mmseg - INFO - Iter [1000/20000]	lr: 5.062e-05, eta: 12:12:56, time: 2.195, data_time: 1.907, memory: 75916, decode.loss_ce: 0.1496, decode.acc_seg: 94.0850, loss: 0.1496
2025-04-29 11:41:14,473 - mmseg - INFO - Iter [1050/20000]	lr: 5.301e-05, eta: 12:13:59, time: 2.513, data_time: 2.224, memory: 75916, decode.loss_ce: 0.1679, decode.acc_seg: 93.3105, loss: 0.1679
2025-04-29 11:43:04,033 - mmseg - INFO - Iter [1100/20000]	lr: 5.539e-05, eta: 12:10:09, time: 2.191, data_time: 1.902, memory: 75916, decode.loss_ce: 0.1646, decode.acc_seg: 93.3526, loss: 0.1646
2025-04-29 11:44:54,084 - mmseg - INFO - Iter [1150/20000]	lr: 5.776e-05, eta: 12:06:37, time: 2.201, data_time: 1.912, memory: 75916, decode.loss_ce: 0.1685, decode.acc_seg: 93.2800, loss: 0.1685
2025-04-29 11:46:43,387 - mmseg - INFO - Iter [1200/20000]	lr: 6.011e-05, eta: 12:03:02, time: 2.186, data_time: 1.897, memory: 75916, decode.loss_ce: 0.1738, decode.acc_seg: 93.4081, loss: 0.1738
2025-04-29 11:48:49,951 - mmseg - INFO - Iter [1250/20000]	lr: 6.245e-05, eta: 12:03:55, time: 2.531, data_time: 2.242, memory: 75916, decode.loss_ce: 0.2107, decode.acc_seg: 92.5823, loss: 0.2107
2025-04-29 11:50:43,412 - mmseg - INFO - Iter [1300/20000]	lr: 6.478e-05, eta: 12:01:25, time: 2.269, data_time: 1.980, memory: 75916, decode.loss_ce: 0.1711, decode.acc_seg: 92.8583, loss: 0.1711
2025-04-29 11:52:34,452 - mmseg - INFO - Iter [1350/20000]	lr: 6.709e-05, eta: 11:58:24, time: 2.221, data_time: 1.931, memory: 75916, decode.loss_ce: 0.1534, decode.acc_seg: 93.9725, loss: 0.1534
2025-04-29 11:54:24,867 - mmseg - INFO - Iter [1400/20000]	lr: 6.939e-05, eta: 11:55:20, time: 2.208, data_time: 1.919, memory: 75916, decode.loss_ce: 0.1783, decode.acc_seg: 92.7154, loss: 0.1783
2025-04-29 11:56:31,392 - mmseg - INFO - Iter [1450/20000]	lr: 7.168e-05, eta: 11:55:47, time: 2.531, data_time: 2.241, memory: 75916, decode.loss_ce: 0.1684, decode.acc_seg: 93.1787, loss: 0.1684
2025-04-29 11:58:21,821 - mmseg - INFO - Iter [1500/20000]	lr: 7.395e-05, eta: 11:52:46, time: 2.209, data_time: 1.920, memory: 75916, decode.loss_ce: 0.1554, decode.acc_seg: 93.9254, loss: 0.1554
2025-04-29 12:00:14,534 - mmseg - INFO - Iter [1550/20000]	lr: 7.380e-05, eta: 11:50:16, time: 2.254, data_time: 1.965, memory: 75916, decode.loss_ce: 0.1597, decode.acc_seg: 93.6552, loss: 0.1597
2025-04-29 12:02:05,000 - mmseg - INFO - Iter [1600/20000]	lr: 7.360e-05, eta: 11:47:23, time: 2.209, data_time: 1.920, memory: 75916, decode.loss_ce: 0.1643, decode.acc_seg: 93.3381, loss: 0.1643
2025-04-29 12:04:10,159 - mmseg - INFO - Iter [1650/20000]	lr: 7.340e-05, eta: 11:47:17, time: 2.503, data_time: 2.214, memory: 75916, decode.loss_ce: 0.1712, decode.acc_seg: 93.0097, loss: 0.1712
2025-04-29 12:05:59,247 - mmseg - INFO - Iter [1700/20000]	lr: 7.320e-05, eta: 11:44:11, time: 2.182, data_time: 1.893, memory: 75916, decode.loss_ce: 0.1529, decode.acc_seg: 93.7633, loss: 0.1529
2025-04-29 12:07:47,909 - mmseg - INFO - Iter [1750/20000]	lr: 7.300e-05, eta: 11:41:04, time: 2.173, data_time: 1.884, memory: 75916, decode.loss_ce: 0.1735, decode.acc_seg: 93.0394, loss: 0.1735
2025-04-29 12:09:41,667 - mmseg - INFO - Iter [1800/20000]	lr: 7.280e-05, eta: 11:38:54, time: 2.275, data_time: 1.983, memory: 75916, decode.loss_ce: 0.1845, decode.acc_seg: 92.8866, loss: 0.1845
2025-04-29 12:11:55,767 - mmseg - INFO - Iter [1850/20000]	lr: 7.260e-05, eta: 11:40:04, time: 2.682, data_time: 2.387, memory: 75916, decode.loss_ce: 0.1799, decode.acc_seg: 92.9938, loss: 0.1799
2025-04-29 12:13:44,889 - mmseg - INFO - Iter [1900/20000]	lr: 7.240e-05, eta: 11:37:06, time: 2.182, data_time: 1.893, memory: 75916, decode.loss_ce: 0.1942, decode.acc_seg: 92.3240, loss: 0.1942
2025-04-29 12:15:42,697 - mmseg - INFO - Iter [1950/20000]	lr: 7.220e-05, eta: 11:35:31, time: 2.356, data_time: 2.067, memory: 75916, decode.loss_ce: 0.1914, decode.acc_seg: 92.8768, loss: 0.1914
2025-04-29 12:17:31,086 - mmseg - INFO - Saving checkpoint at 2000 iterations
2025-04-29 12:17:40,804 - mmseg - INFO - Exp name: vpd_config.py
2025-04-29 12:17:40,804 - mmseg - INFO - Iter [2000/20000]	lr: 7.200e-05, eta: 11:33:58, time: 2.362, data_time: 1.879, memory: 75916, decode.loss_ce: 0.1889, decode.acc_seg: 92.7795, loss: 0.1889
2025-04-29 12:19:21,039 - mmseg - INFO - per class results:
2025-04-29 12:19:21,046 - mmseg - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        |  79.8 | 89.94 |
|       building      | 84.69 | 93.47 |
|         sky         | 93.62 | 97.09 |
|        floor        | 82.52 | 89.88 |
|         tree        | 73.92 | 85.55 |
|       ceiling       |  86.8 | 94.71 |
|         road        | 86.17 |  91.8 |
|         bed         | 91.19 |  97.1 |
|      windowpane     | 67.46 |  83.9 |
|        grass        | 72.23 | 81.81 |
|       cabinet       |  58.6 | 72.26 |
|       sidewalk      |  69.1 | 85.13 |
|        person       | 81.21 | 91.51 |
|        earth        | 35.36 | 55.87 |
|         door        | 58.36 | 71.22 |
|        table        | 64.92 | 81.71 |
|       mountain      | 45.54 | 64.37 |
|        plant        | 53.17 | 61.57 |
|       curtain       | 72.86 | 83.32 |
|        chair        | 64.44 | 75.86 |
|         car         | 83.18 | 90.61 |
|        water        | 51.32 | 84.49 |
|       painting      | 75.22 | 89.24 |
|         sofa        | 72.29 |  83.4 |
|        shelf        | 49.76 | 67.59 |
|        house        |  38.3 | 67.59 |
|         sea         | 68.47 | 89.14 |
|        mirror       | 82.29 | 90.63 |
|         rug         | 65.98 | 78.45 |
|        field        | 32.92 | 62.74 |
|       armchair      | 52.81 | 75.84 |
|         seat        |  54.9 | 84.88 |
|        fence        | 27.37 |  41.6 |
|         desk        | 46.47 | 72.98 |
|         rock        | 47.52 | 61.87 |
|       wardrobe      | 55.53 | 74.64 |
|         lamp        | 68.24 | 79.03 |
|       bathtub       | 92.64 | 94.93 |
|       railing       | 44.64 | 62.54 |
|       cushion       | 62.09 | 74.28 |
|         base        | 31.04 | 55.77 |
|         box         | 32.02 | 38.81 |
|        column       | 52.77 | 58.48 |
|      signboard      | 29.72 |  38.6 |
|   chest of drawers  | 50.27 | 69.58 |
|       counter       | 45.21 | 58.41 |
|         sand        | 77.16 | 90.29 |
|         sink        | 67.75 | 72.17 |
|      skyscraper     | 48.18 | 97.72 |
|      fireplace      |  66.9 |  92.2 |
|     refrigerator    | 61.69 | 66.02 |
|      grandstand     | 44.93 | 84.27 |
|         path        | 34.54 | 40.71 |
|        stairs       | 34.25 | 41.89 |
|        runway       | 92.93 | 99.95 |
|         case        | 43.04 | 74.17 |
|      pool table     | 92.63 | 96.02 |
|        pillow       | 56.92 | 65.35 |
|     screen door     | 81.63 | 84.85 |
|       stairway      | 34.35 | 45.69 |
|        river        |  27.1 | 30.92 |
|        bridge       | 66.21 | 84.84 |
|       bookcase      | 46.42 | 64.59 |
|        blind        | 58.67 | 60.46 |
|     coffee table    |  60.2 | 71.98 |
|        toilet       | 87.05 | 90.84 |
|        flower       |  50.3 | 60.74 |
|         book        | 45.72 | 59.69 |
|         hill        | 16.68 | 23.42 |
|        bench        | 43.02 | 47.18 |
|      countertop     | 58.36 | 77.56 |
|        stove        | 80.62 | 95.83 |
|         palm        | 56.29 | 74.24 |
|    kitchen island   | 36.14 | 55.68 |
|       computer      | 69.47 | 82.18 |
|     swivel chair    | 63.06 | 86.59 |
|         boat        | 18.68 |  21.7 |
|         bar         | 42.15 | 48.58 |
|    arcade machine   | 80.29 | 93.33 |
|        hovel        |  3.19 |  4.46 |
|         bus         | 81.05 | 90.44 |
|        towel        | 63.97 | 77.43 |
|        light        | 53.99 |  59.8 |
|        truck        | 29.54 | 32.54 |
|        tower        | 39.36 | 61.72 |
|      chandelier     | 71.64 |  85.7 |
|        awning       | 17.76 |  19.0 |
|     streetlight     | 25.56 | 31.51 |
|        booth        | 30.44 | 36.38 |
| television receiver |  63.6 | 72.83 |
|       airplane      | 26.82 | 27.84 |
|      dirt track     |  7.07 | 20.14 |
|       apparel       | 31.41 | 35.91 |
|         pole        | 39.85 | 50.63 |
|         land        |  3.52 |  4.24 |
|      bannister      | 16.91 | 22.89 |
|      escalator      | 35.84 | 44.21 |
|       ottoman       | 53.05 | 76.34 |
|        bottle       | 27.01 | 43.67 |
|        buffet       | 38.56 | 48.64 |
|        poster       | 44.81 | 56.73 |
|        stage        | 45.06 | 64.75 |
|         van         | 38.07 | 51.32 |
|         ship        | 13.38 |  95.5 |
|       fountain      | 30.38 | 31.35 |
|    conveyer belt    | 88.97 | 97.92 |
|        canopy       | 36.07 | 44.66 |
|        washer       | 36.86 | 36.89 |
|      plaything      | 29.21 | 60.65 |
|    swimming pool    | 61.03 | 65.34 |
|        stool        | 41.69 | 69.49 |
|        barrel       | 70.77 | 70.77 |
|        basket       |  39.4 |  48.2 |
|      waterfall      | 92.24 | 97.33 |
|         tent        |  0.0  |  nan  |
|         bag         | 15.94 | 18.53 |
|       minibike      | 74.03 |  86.0 |
|        cradle       | 82.05 | 98.62 |
|         oven        | 50.31 | 76.33 |
|         ball        | 50.79 | 60.36 |
|         food        | 48.67 | 63.63 |
|         step        | 19.13 | 22.49 |
|         tank        | 88.59 | 91.95 |
|      trade name     | 26.38 | 29.28 |
|      microwave      |  71.4 | 80.91 |
|         pot         | 54.91 |  62.7 |
|        animal       | 74.09 |  76.5 |
|       bicycle       | 57.75 | 72.95 |
|         lake        |  0.0  |  0.0  |
|      dishwasher     | 79.53 | 91.94 |
|        screen       | 64.17 | 80.52 |
|       blanket       | 37.12 | 39.14 |
|      sculpture      | 76.16 | 86.14 |
|         hood        | 28.99 | 34.31 |
|        sconce       | 44.48 |  52.3 |
|         vase        | 32.29 | 48.99 |
|    traffic light    | 31.13 | 40.75 |
|         tray        | 15.69 | 23.62 |
|        ashcan       | 34.71 | 43.63 |
|         fan         |  60.1 | 69.38 |
|         pier        | 30.97 | 47.03 |
|      crt screen     | 32.69 | 42.97 |
|        plate        | 60.39 | 81.04 |
|       monitor       | 69.44 | 78.16 |
|    bulletin board   | 53.07 | 75.92 |
|        shower       |  11.4 | 15.28 |
|       radiator      | 53.22 | 61.06 |
|        glass        | 12.61 | 13.43 |
|        clock        | 44.92 | 53.02 |
|         flag        | 44.35 |  51.2 |
+---------------------+-------+-------+
2025-04-29 12:19:21,046 - mmseg - INFO - Summary:
2025-04-29 12:19:21,046 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 84.18 | 51.59 | 64.32 |
+-------+-------+-------+
2025-04-29 12:19:21,047 - mmseg - INFO - Exp name: vpd_config.py
2025-04-29 12:19:21,047 - mmseg - INFO - Iter(val) [851]	aAcc: 0.8418, mIoU: 0.5159, mAcc: 0.6432, IoU.wall: 0.7980, IoU.building: 0.8469, IoU.sky: 0.9362, IoU.floor: 0.8252, IoU.tree: 0.7392, IoU.ceiling: 0.8680, IoU.road: 0.8617, IoU.bed : 0.9119, IoU.windowpane: 0.6746, IoU.grass: 0.7223, IoU.cabinet: 0.5860, IoU.sidewalk: 0.6910, IoU.person: 0.8121, IoU.earth: 0.3536, IoU.door: 0.5836, IoU.table: 0.6492, IoU.mountain: 0.4554, IoU.plant: 0.5317, IoU.curtain: 0.7286, IoU.chair: 0.6444, IoU.car: 0.8318, IoU.water: 0.5132, IoU.painting: 0.7522, IoU.sofa: 0.7229, IoU.shelf: 0.4976, IoU.house: 0.3830, IoU.sea: 0.6847, IoU.mirror: 0.8229, IoU.rug: 0.6598, IoU.field: 0.3292, IoU.armchair: 0.5281, IoU.seat: 0.5490, IoU.fence: 0.2737, IoU.desk: 0.4647, IoU.rock: 0.4752, IoU.wardrobe: 0.5553, IoU.lamp: 0.6824, IoU.bathtub: 0.9264, IoU.railing: 0.4464, IoU.cushion: 0.6209, IoU.base: 0.3104, IoU.box: 0.3202, IoU.column: 0.5277, IoU.signboard: 0.2972, IoU.chest of drawers: 0.5027, IoU.counter: 0.4521, IoU.sand: 0.7716, IoU.sink: 0.6775, IoU.skyscraper: 0.4818, IoU.fireplace: 0.6690, IoU.refrigerator: 0.6169, IoU.grandstand: 0.4493, IoU.path: 0.3454, IoU.stairs: 0.3425, IoU.runway: 0.9293, IoU.case: 0.4304, IoU.pool table: 0.9263, IoU.pillow: 0.5692, IoU.screen door: 0.8163, IoU.stairway: 0.3435, IoU.river: 0.2710, IoU.bridge: 0.6621, IoU.bookcase: 0.4642, IoU.blind: 0.5867, IoU.coffee table: 0.6020, IoU.toilet: 0.8705, IoU.flower: 0.5030, IoU.book: 0.4572, IoU.hill: 0.1668, IoU.bench: 0.4302, IoU.countertop: 0.5836, IoU.stove: 0.8062, IoU.palm: 0.5629, IoU.kitchen island: 0.3614, IoU.computer: 0.6947, IoU.swivel chair: 0.6306, IoU.boat: 0.1868, IoU.bar: 0.4215, IoU.arcade machine: 0.8029, IoU.hovel: 0.0319, IoU.bus: 0.8105, IoU.towel: 0.6397, IoU.light: 0.5399, IoU.truck: 0.2954, IoU.tower: 0.3936, IoU.chandelier: 0.7164, IoU.awning: 0.1776, IoU.streetlight: 0.2556, IoU.booth: 0.3044, IoU.television receiver: 0.6360, IoU.airplane: 0.2682, IoU.dirt track: 0.0707, IoU.apparel: 0.3141, IoU.pole: 0.3985, IoU.land: 0.0352, IoU.bannister: 0.1691, IoU.escalator: 0.3584, IoU.ottoman: 0.5305, IoU.bottle: 0.2701, IoU.buffet: 0.3856, IoU.poster: 0.4481, IoU.stage: 0.4506, IoU.van: 0.3807, IoU.ship: 0.1338, IoU.fountain: 0.3038, IoU.conveyer belt: 0.8897, IoU.canopy: 0.3607, IoU.washer: 0.3686, IoU.plaything: 0.2921, IoU.swimming pool: 0.6103, IoU.stool: 0.4169, IoU.barrel: 0.7077, IoU.basket: 0.3940, IoU.waterfall: 0.9224, IoU.tent: 0.0000, IoU.bag: 0.1594, IoU.minibike: 0.7403, IoU.cradle: 0.8205, IoU.oven: 0.5031, IoU.ball: 0.5079, IoU.food: 0.4867, IoU.step: 0.1913, IoU.tank: 0.8859, IoU.trade name: 0.2638, IoU.microwave: 0.7140, IoU.pot: 0.5491, IoU.animal: 0.7409, IoU.bicycle: 0.5775, IoU.lake: 0.0000, IoU.dishwasher: 0.7953, IoU.screen: 0.6417, IoU.blanket: 0.3712, IoU.sculpture: 0.7616, IoU.hood: 0.2899, IoU.sconce: 0.4448, IoU.vase: 0.3229, IoU.traffic light: 0.3113, IoU.tray: 0.1569, IoU.ashcan: 0.3471, IoU.fan: 0.6010, IoU.pier: 0.3097, IoU.crt screen: 0.3269, IoU.plate: 0.6039, IoU.monitor: 0.6944, IoU.bulletin board: 0.5307, IoU.shower: 0.1140, IoU.radiator: 0.5322, IoU.glass: 0.1261, IoU.clock: 0.4492, IoU.flag: 0.4435, Acc.wall: 0.8994, Acc.building: 0.9347, Acc.sky: 0.9709, Acc.floor: 0.8988, Acc.tree: 0.8555, Acc.ceiling: 0.9471, Acc.road: 0.9180, Acc.bed : 0.9710, Acc.windowpane: 0.8390, Acc.grass: 0.8181, Acc.cabinet: 0.7226, Acc.sidewalk: 0.8513, Acc.person: 0.9151, Acc.earth: 0.5587, Acc.door: 0.7122, Acc.table: 0.8171, Acc.mountain: 0.6437, Acc.plant: 0.6157, Acc.curtain: 0.8332, Acc.chair: 0.7586, Acc.car: 0.9061, Acc.water: 0.8449, Acc.painting: 0.8924, Acc.sofa: 0.8340, Acc.shelf: 0.6759, Acc.house: 0.6759, Acc.sea: 0.8914, Acc.mirror: 0.9063, Acc.rug: 0.7845, Acc.field: 0.6274, Acc.armchair: 0.7584, Acc.seat: 0.8488, Acc.fence: 0.4160, Acc.desk: 0.7298, Acc.rock: 0.6187, Acc.wardrobe: 0.7464, Acc.lamp: 0.7903, Acc.bathtub: 0.9493, Acc.railing: 0.6254, Acc.cushion: 0.7428, Acc.base: 0.5577, Acc.box: 0.3881, Acc.column: 0.5848, Acc.signboard: 0.3860, Acc.chest of drawers: 0.6958, Acc.counter: 0.5841, Acc.sand: 0.9029, Acc.sink: 0.7217, Acc.skyscraper: 0.9772, Acc.fireplace: 0.9220, Acc.refrigerator: 0.6602, Acc.grandstand: 0.8427, Acc.path: 0.4071, Acc.stairs: 0.4189, Acc.runway: 0.9995, Acc.case: 0.7417, Acc.pool table: 0.9602, Acc.pillow: 0.6535, Acc.screen door: 0.8485, Acc.stairway: 0.4569, Acc.river: 0.3092, Acc.bridge: 0.8484, Acc.bookcase: 0.6459, Acc.blind: 0.6046, Acc.coffee table: 0.7198, Acc.toilet: 0.9084, Acc.flower: 0.6074, Acc.book: 0.5969, Acc.hill: 0.2342, Acc.bench: 0.4718, Acc.countertop: 0.7756, Acc.stove: 0.9583, Acc.palm: 0.7424, Acc.kitchen island: 0.5568, Acc.computer: 0.8218, Acc.swivel chair: 0.8659, Acc.boat: 0.2170, Acc.bar: 0.4858, Acc.arcade machine: 0.9333, Acc.hovel: 0.0446, Acc.bus: 0.9044, Acc.towel: 0.7743, Acc.light: 0.5980, Acc.truck: 0.3254, Acc.tower: 0.6172, Acc.chandelier: 0.8570, Acc.awning: 0.1900, Acc.streetlight: 0.3151, Acc.booth: 0.3638, Acc.television receiver: 0.7283, Acc.airplane: 0.2784, Acc.dirt track: 0.2014, Acc.apparel: 0.3591, Acc.pole: 0.5063, Acc.land: 0.0424, Acc.bannister: 0.2289, Acc.escalator: 0.4421, Acc.ottoman: 0.7634, Acc.bottle: 0.4367, Acc.buffet: 0.4864, Acc.poster: 0.5673, Acc.stage: 0.6475, Acc.van: 0.5132, Acc.ship: 0.9550, Acc.fountain: 0.3135, Acc.conveyer belt: 0.9792, Acc.canopy: 0.4466, Acc.washer: 0.3689, Acc.plaything: 0.6065, Acc.swimming pool: 0.6534, Acc.stool: 0.6949, Acc.barrel: 0.7077, Acc.basket: 0.4820, Acc.waterfall: 0.9733, Acc.tent: nan, Acc.bag: 0.1853, Acc.minibike: 0.8600, Acc.cradle: 0.9862, Acc.oven: 0.7633, Acc.ball: 0.6036, Acc.food: 0.6363, Acc.step: 0.2249, Acc.tank: 0.9195, Acc.trade name: 0.2928, Acc.microwave: 0.8091, Acc.pot: 0.6270, Acc.animal: 0.7650, Acc.bicycle: 0.7295, Acc.lake: 0.0000, Acc.dishwasher: 0.9194, Acc.screen: 0.8052, Acc.blanket: 0.3914, Acc.sculpture: 0.8614, Acc.hood: 0.3431, Acc.sconce: 0.5230, Acc.vase: 0.4899, Acc.traffic light: 0.4075, Acc.tray: 0.2362, Acc.ashcan: 0.4363, Acc.fan: 0.6938, Acc.pier: 0.4703, Acc.crt screen: 0.4297, Acc.plate: 0.8104, Acc.monitor: 0.7816, Acc.bulletin board: 0.7592, Acc.shower: 0.1528, Acc.radiator: 0.6106, Acc.glass: 0.1343, Acc.clock: 0.5302, Acc.flag: 0.5120
2025-04-29 12:20:41,261 - mmseg - INFO - Iter [2050/20000]	lr: 7.180e-05, eta: 11:41:30, time: 3.609, data_time: 3.317, memory: 75916, decode.loss_ce: 0.1715, decode.acc_seg: 93.5259, loss: 0.1715
2025-04-29 12:22:33,605 - mmseg - INFO - Iter [2100/20000]	lr: 7.160e-05, eta: 11:38:51, time: 2.247, data_time: 1.957, memory: 75916, decode.loss_ce: 0.2156, decode.acc_seg: 92.1737, loss: 0.2156
2025-04-29 12:24:22,356 - mmseg - INFO - Iter [2150/20000]	lr: 7.140e-05, eta: 11:35:44, time: 2.175, data_time: 1.886, memory: 75916, decode.loss_ce: 0.1719, decode.acc_seg: 93.0216, loss: 0.1719
2025-04-29 12:26:10,752 - mmseg - INFO - Iter [2200/20000]	lr: 7.120e-05, eta: 11:32:38, time: 2.168, data_time: 1.879, memory: 75916, decode.loss_ce: 0.1627, decode.acc_seg: 93.4153, loss: 0.1627
2025-04-29 12:28:08,594 - mmseg - INFO - Iter [2250/20000]	lr: 7.100e-05, eta: 11:30:50, time: 2.357, data_time: 2.065, memory: 75916, decode.loss_ce: 0.1827, decode.acc_seg: 92.7106, loss: 0.1827
2025-04-29 12:30:11,187 - mmseg - INFO - Iter [2300/20000]	lr: 7.080e-05, eta: 11:29:38, time: 2.452, data_time: 2.159, memory: 75916, decode.loss_ce: 0.1591, decode.acc_seg: 93.7028, loss: 0.1591
2025-04-29 12:32:01,092 - mmseg - INFO - Iter [2350/20000]	lr: 7.060e-05, eta: 11:26:49, time: 2.198, data_time: 1.909, memory: 75916, decode.loss_ce: 0.1570, decode.acc_seg: 93.8816, loss: 0.1570
2025-04-29 12:33:50,037 - mmseg - INFO - Iter [2400/20000]	lr: 7.040e-05, eta: 11:23:55, time: 2.179, data_time: 1.890, memory: 75916, decode.loss_ce: 0.1659, decode.acc_seg: 93.3750, loss: 0.1659
2025-04-29 12:35:47,887 - mmseg - INFO - Iter [2450/20000]	lr: 7.020e-05, eta: 11:22:08, time: 2.357, data_time: 2.068, memory: 75916, decode.loss_ce: 0.1565, decode.acc_seg: 93.7478, loss: 0.1565
2025-04-29 12:37:39,859 - mmseg - INFO - Iter [2500/20000]	lr: 7.000e-05, eta: 11:19:39, time: 2.239, data_time: 1.950, memory: 75916, decode.loss_ce: 0.1694, decode.acc_seg: 93.2377, loss: 0.1694
2025-04-29 12:39:27,341 - mmseg - INFO - Iter [2550/20000]	lr: 6.980e-05, eta: 11:16:40, time: 2.150, data_time: 1.860, memory: 75916, decode.loss_ce: 0.1550, decode.acc_seg: 93.8768, loss: 0.1550
2025-04-29 12:41:14,981 - mmseg - INFO - Iter [2600/20000]	lr: 6.960e-05, eta: 11:13:46, time: 2.153, data_time: 1.863, memory: 75916, decode.loss_ce: 0.1789, decode.acc_seg: 92.6289, loss: 0.1789
2025-04-29 12:43:08,287 - mmseg - INFO - Iter [2650/20000]	lr: 6.940e-05, eta: 11:11:31, time: 2.266, data_time: 1.976, memory: 75916, decode.loss_ce: 0.1722, decode.acc_seg: 93.0492, loss: 0.1722
2025-04-29 12:45:04,500 - mmseg - INFO - Iter [2700/20000]	lr: 6.920e-05, eta: 11:09:35, time: 2.324, data_time: 2.035, memory: 75916, decode.loss_ce: 0.1873, decode.acc_seg: 92.9704, loss: 0.1873
2025-04-29 12:46:52,203 - mmseg - INFO - Iter [2750/20000]	lr: 6.900e-05, eta: 11:06:46, time: 2.154, data_time: 1.865, memory: 75916, decode.loss_ce: 0.1783, decode.acc_seg: 92.8671, loss: 0.1783
2025-04-29 12:48:41,136 - mmseg - INFO - Iter [2800/20000]	lr: 6.880e-05, eta: 11:04:07, time: 2.179, data_time: 1.890, memory: 75916, decode.loss_ce: 0.1650, decode.acc_seg: 93.5074, loss: 0.1650
2025-04-29 12:50:05,800 - mmseg - INFO - Iter [2850/20000]	lr: 6.860e-05, eta: 10:59:04, time: 1.693, data_time: 1.404, memory: 75916, decode.loss_ce: 0.1797, decode.acc_seg: 93.0902, loss: 0.1797
2025-04-29 12:52:08,444 - mmseg - INFO - Iter [2900/20000]	lr: 6.840e-05, eta: 10:57:52, time: 2.453, data_time: 2.163, memory: 75916, decode.loss_ce: 0.1734, decode.acc_seg: 93.0539, loss: 0.1734
2025-04-29 12:53:58,445 - mmseg - INFO - Iter [2950/20000]	lr: 6.820e-05, eta: 10:55:25, time: 2.200, data_time: 1.910, memory: 75916, decode.loss_ce: 0.1712, decode.acc_seg: 93.1300, loss: 0.1712
2025-04-29 12:55:49,886 - mmseg - INFO - Exp name: vpd_config.py
2025-04-29 12:55:49,886 - mmseg - INFO - Iter [3000/20000]	lr: 6.800e-05, eta: 10:53:08, time: 2.229, data_time: 1.939, memory: 75916, decode.loss_ce: 0.1620, decode.acc_seg: 93.6089, loss: 0.1620
2025-04-29 12:57:34,427 - mmseg - INFO - Iter [3050/20000]	lr: 6.780e-05, eta: 10:50:13, time: 2.091, data_time: 1.802, memory: 75916, decode.loss_ce: 0.1670, decode.acc_seg: 93.2000, loss: 0.1670
2025-04-29 12:59:35,662 - mmseg - INFO - Iter [3100/20000]	lr: 6.760e-05, eta: 10:48:51, time: 2.425, data_time: 2.134, memory: 75916, decode.loss_ce: 0.1550, decode.acc_seg: 93.6146, loss: 0.1550
2025-04-29 13:01:15,096 - mmseg - INFO - Iter [3150/20000]	lr: 6.740e-05, eta: 10:45:32, time: 1.989, data_time: 1.698, memory: 75916, decode.loss_ce: 0.1525, decode.acc_seg: 93.8537, loss: 0.1525
2025-04-29 13:03:07,623 - mmseg - INFO - Iter [3200/20000]	lr: 6.720e-05, eta: 10:43:24, time: 2.251, data_time: 1.960, memory: 75916, decode.loss_ce: 0.1627, decode.acc_seg: 93.4727, loss: 0.1627
2025-04-29 13:05:00,622 - mmseg - INFO - Iter [3250/20000]	lr: 6.700e-05, eta: 10:41:20, time: 2.260, data_time: 1.970, memory: 75916, decode.loss_ce: 0.1610, decode.acc_seg: 93.4627, loss: 0.1610
2025-04-29 13:06:53,836 - mmseg - INFO - Iter [3300/20000]	lr: 6.680e-05, eta: 10:39:17, time: 2.264, data_time: 1.975, memory: 75916, decode.loss_ce: 0.1487, decode.acc_seg: 94.0807, loss: 0.1487
2025-04-29 13:08:46,790 - mmseg - INFO - Iter [3350/20000]	lr: 6.660e-05, eta: 10:37:12, time: 2.259, data_time: 1.970, memory: 75916, decode.loss_ce: 0.1603, decode.acc_seg: 93.2730, loss: 0.1603
2025-04-29 13:10:38,510 - mmseg - INFO - Iter [3400/20000]	lr: 6.640e-05, eta: 10:35:02, time: 2.234, data_time: 1.945, memory: 75916, decode.loss_ce: 0.1834, decode.acc_seg: 92.8289, loss: 0.1834
2025-04-29 13:12:32,617 - mmseg - INFO - Iter [3450/20000]	lr: 6.620e-05, eta: 10:33:05, time: 2.282, data_time: 1.993, memory: 75916, decode.loss_ce: 0.1853, decode.acc_seg: 92.9450, loss: 0.1853
2025-04-29 13:14:25,401 - mmseg - INFO - Iter [3500/20000]	lr: 6.600e-05, eta: 10:31:00, time: 2.256, data_time: 1.966, memory: 75916, decode.loss_ce: 0.1642, decode.acc_seg: 93.8079, loss: 0.1642
2025-04-29 13:16:18,174 - mmseg - INFO - Iter [3550/20000]	lr: 6.580e-05, eta: 10:28:57, time: 2.255, data_time: 1.966, memory: 75916, decode.loss_ce: 0.1763, decode.acc_seg: 93.0539, loss: 0.1763
2025-04-29 13:18:11,710 - mmseg - INFO - Iter [3600/20000]	lr: 6.560e-05, eta: 10:26:57, time: 2.271, data_time: 1.981, memory: 75916, decode.loss_ce: 0.1758, decode.acc_seg: 93.2793, loss: 0.1758
2025-04-29 13:20:02,691 - mmseg - INFO - Iter [3650/20000]	lr: 6.540e-05, eta: 10:24:45, time: 2.220, data_time: 1.930, memory: 75916, decode.loss_ce: 0.1687, decode.acc_seg: 93.1867, loss: 0.1687
2025-04-29 13:21:53,878 - mmseg - INFO - Iter [3700/20000]	lr: 6.520e-05, eta: 10:22:35, time: 2.224, data_time: 1.933, memory: 75916, decode.loss_ce: 0.1650, decode.acc_seg: 93.5463, loss: 0.1650
2025-04-29 13:23:41,161 - mmseg - INFO - Iter [3750/20000]	lr: 6.500e-05, eta: 10:20:09, time: 2.146, data_time: 1.856, memory: 75916, decode.loss_ce: 0.1700, decode.acc_seg: 93.4833, loss: 0.1700
2025-04-29 13:25:30,655 - mmseg - INFO - Iter [3800/20000]	lr: 6.480e-05, eta: 10:17:53, time: 2.190, data_time: 1.900, memory: 75916, decode.loss_ce: 0.1635, decode.acc_seg: 93.5076, loss: 0.1635
2025-04-29 13:27:26,945 - mmseg - INFO - Iter [3850/20000]	lr: 6.460e-05, eta: 10:16:07, time: 2.326, data_time: 2.036, memory: 75916, decode.loss_ce: 0.1665, decode.acc_seg: 93.3726, loss: 0.1665
2025-04-29 13:29:16,587 - mmseg - INFO - Iter [3900/20000]	lr: 6.440e-05, eta: 10:13:53, time: 2.193, data_time: 1.903, memory: 75916, decode.loss_ce: 0.1699, decode.acc_seg: 93.1870, loss: 0.1699
2025-04-29 13:31:05,196 - mmseg - INFO - Iter [3950/20000]	lr: 6.420e-05, eta: 10:11:35, time: 2.172, data_time: 1.882, memory: 75916, decode.loss_ce: 0.1593, decode.acc_seg: 93.4717, loss: 0.1593
2025-04-29 13:33:04,317 - mmseg - INFO - Saving checkpoint at 4000 iterations
2025-04-29 13:33:13,793 - mmseg - INFO - Exp name: vpd_config.py
2025-04-29 13:33:13,802 - mmseg - INFO - Iter [4000/20000]	lr: 6.400e-05, eta: 10:10:38, time: 2.572, data_time: 2.092, memory: 75916, decode.loss_ce: 0.1517, decode.acc_seg: 93.9821, loss: 0.1517
2025-04-29 13:34:45,893 - mmseg - INFO - per class results:
2025-04-29 13:34:45,899 - mmseg - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        | 79.85 | 89.97 |
|       building      | 84.66 | 92.49 |
|         sky         | 93.63 | 96.72 |
|        floor        | 82.23 | 90.32 |
|         tree        | 73.99 | 88.64 |
|       ceiling       | 86.81 | 94.57 |
|         road        | 86.35 | 91.43 |
|         bed         | 91.23 | 97.57 |
|      windowpane     | 67.59 | 83.43 |
|        grass        | 73.77 | 84.14 |
|       cabinet       | 58.62 | 72.47 |
|       sidewalk      | 69.06 |  84.5 |
|        person       | 81.19 | 92.43 |
|        earth        | 32.36 | 56.98 |
|         door        | 59.16 | 72.88 |
|        table        | 65.59 | 80.23 |
|       mountain      | 37.83 | 51.44 |
|        plant        | 51.85 | 60.07 |
|       curtain       | 73.39 |  83.0 |
|        chair        | 64.62 | 74.92 |
|         car         | 83.07 |  91.2 |
|        water        | 51.68 | 85.68 |
|       painting      | 75.05 | 89.93 |
|         sofa        | 73.58 | 84.56 |
|        shelf        | 50.39 | 68.45 |
|        house        | 36.87 | 67.95 |
|         sea         | 70.46 | 88.01 |
|        mirror       | 81.89 | 92.22 |
|         rug         | 65.75 |  78.6 |
|        field        | 32.78 | 55.04 |
|       armchair      | 53.56 | 74.74 |
|         seat        | 56.07 | 84.78 |
|        fence        | 26.48 | 42.78 |
|         desk        | 46.83 | 73.57 |
|         rock        | 47.64 | 62.13 |
|       wardrobe      | 55.09 | 74.34 |
|         lamp        | 67.75 | 79.05 |
|       bathtub       | 92.61 | 95.14 |
|       railing       | 45.35 | 61.53 |
|       cushion       | 60.75 | 76.66 |
|         base        | 28.74 | 54.26 |
|         box         | 30.37 | 34.75 |
|        column       | 53.33 | 60.21 |
|      signboard      | 31.34 | 43.21 |
|   chest of drawers  | 48.38 | 69.52 |
|       counter       | 44.75 | 56.52 |
|         sand        | 48.44 | 52.03 |
|         sink        | 67.84 | 72.28 |
|      skyscraper     | 48.93 | 96.33 |
|      fireplace      | 66.73 | 92.57 |
|     refrigerator    | 68.47 | 77.48 |
|      grandstand     | 47.37 | 83.67 |
|         path        | 36.77 | 44.25 |
|        stairs       | 34.06 | 43.31 |
|        runway       | 93.77 | 99.46 |
|         case        | 42.35 | 68.18 |
|      pool table     |  93.0 | 95.77 |
|        pillow       | 55.32 | 61.77 |
|     screen door     | 81.73 | 85.56 |
|       stairway      | 33.85 | 41.66 |
|        river        | 26.77 | 30.22 |
|        bridge       | 65.46 | 84.91 |
|       bookcase      | 43.05 |  56.5 |
|        blind        |  59.4 |  62.3 |
|     coffee table    | 59.73 | 73.79 |
|        toilet       | 86.63 | 91.07 |
|        flower       | 50.39 |  60.8 |
|         book        | 41.17 | 66.38 |
|         hill        | 17.36 | 25.05 |
|        bench        | 44.24 |  51.3 |
|      countertop     | 56.29 |  80.0 |
|        stove        | 81.81 | 94.87 |
|         palm        |  55.3 | 72.67 |
|    kitchen island   | 42.11 | 69.16 |
|       computer      | 69.67 | 81.17 |
|     swivel chair    | 61.08 | 85.99 |
|         boat        | 18.57 | 21.06 |
|         bar         | 42.81 | 50.83 |
|    arcade machine   | 79.71 | 95.17 |
|        hovel        |  0.51 |  0.69 |
|         bus         | 79.63 | 91.34 |
|        towel        | 61.91 | 72.38 |
|        light        | 54.11 |  59.8 |
|        truck        | 27.71 | 30.82 |
|        tower        | 35.48 | 55.21 |
|      chandelier     | 71.72 | 88.43 |
|        awning       | 20.84 | 23.44 |
|     streetlight     | 26.84 | 34.65 |
|        booth        | 32.63 | 37.47 |
| television receiver | 61.18 | 70.88 |
|       airplane      | 27.98 |  30.0 |
|      dirt track     | 10.76 | 27.02 |
|       apparel       | 31.91 | 34.85 |
|         pole        | 37.02 | 44.86 |
|         land        |  3.31 |  4.1  |
|      bannister      | 16.42 | 22.69 |
|      escalator      | 35.09 | 42.48 |
|       ottoman       | 54.61 | 77.96 |
|        bottle       | 26.88 | 46.83 |
|        buffet       | 38.86 | 47.67 |
|        poster       | 46.53 | 54.58 |
|        stage        | 35.95 | 47.72 |
|         van         | 36.96 | 48.68 |
|         ship        | 13.49 | 95.85 |
|       fountain      | 31.88 |  33.3 |
|    conveyer belt    | 91.19 | 97.42 |
|        canopy       | 36.49 | 45.43 |
|        washer       | 37.38 | 37.41 |
|      plaything      | 28.48 | 52.36 |
|    swimming pool    | 62.03 | 70.48 |
|        stool        | 44.71 | 64.49 |
|        barrel       |  5.46 |  5.46 |
|        basket       | 36.87 | 46.85 |
|      waterfall      | 92.41 |  97.5 |
|         tent        |  0.0  |  nan  |
|         bag         | 15.25 | 17.21 |
|       minibike      | 74.86 | 86.77 |
|        cradle       | 83.72 | 98.87 |
|         oven        |  48.8 | 74.98 |
|         ball        | 52.71 | 66.71 |
|         food        | 42.29 | 47.87 |
|         step        | 19.38 | 23.05 |
|         tank        | 90.16 | 93.45 |
|      trade name     | 30.58 |  35.6 |
|      microwave      | 71.78 | 83.51 |
|         pot         | 54.37 | 60.43 |
|        animal       |  75.7 | 79.81 |
|       bicycle       |  57.1 | 75.59 |
|         lake        |  0.0  |  0.0  |
|      dishwasher     |  76.3 | 92.28 |
|        screen       | 67.74 | 84.22 |
|       blanket       | 35.35 | 37.17 |
|      sculpture      | 73.69 | 82.34 |
|         hood        | 46.53 | 57.25 |
|        sconce       | 47.54 | 58.87 |
|         vase        | 32.29 | 52.45 |
|    traffic light    | 31.36 | 43.64 |
|         tray        | 17.08 |  31.5 |
|        ashcan       | 32.71 | 43.46 |
|         fan         |  62.0 | 71.93 |
|         pier        | 34.52 |  48.9 |
|      crt screen     | 31.13 | 35.52 |
|        plate        | 60.32 | 77.71 |
|       monitor       | 69.12 | 80.75 |
|    bulletin board   | 57.35 | 68.77 |
|        shower       |  5.42 |  5.74 |
|       radiator      | 55.41 | 66.88 |
|        glass        | 15.52 | 17.44 |
|        clock        | 42.67 | 54.61 |
|         flag        | 46.36 | 54.66 |
+---------------------+-------+-------+
2025-04-29 13:34:45,899 - mmseg - INFO - Summary:
2025-04-29 13:34:45,899 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 84.06 | 51.05 | 63.77 |
+-------+-------+-------+
2025-04-29 13:34:45,900 - mmseg - INFO - Exp name: vpd_config.py
2025-04-29 13:34:45,900 - mmseg - INFO - Iter(val) [851]	aAcc: 0.8406, mIoU: 0.5105, mAcc: 0.6377, IoU.wall: 0.7985, IoU.building: 0.8466, IoU.sky: 0.9363, IoU.floor: 0.8223, IoU.tree: 0.7399, IoU.ceiling: 0.8681, IoU.road: 0.8635, IoU.bed : 0.9123, IoU.windowpane: 0.6759, IoU.grass: 0.7377, IoU.cabinet: 0.5862, IoU.sidewalk: 0.6906, IoU.person: 0.8119, IoU.earth: 0.3236, IoU.door: 0.5916, IoU.table: 0.6559, IoU.mountain: 0.3783, IoU.plant: 0.5185, IoU.curtain: 0.7339, IoU.chair: 0.6462, IoU.car: 0.8307, IoU.water: 0.5168, IoU.painting: 0.7505, IoU.sofa: 0.7358, IoU.shelf: 0.5039, IoU.house: 0.3687, IoU.sea: 0.7046, IoU.mirror: 0.8189, IoU.rug: 0.6575, IoU.field: 0.3278, IoU.armchair: 0.5356, IoU.seat: 0.5607, IoU.fence: 0.2648, IoU.desk: 0.4683, IoU.rock: 0.4764, IoU.wardrobe: 0.5509, IoU.lamp: 0.6775, IoU.bathtub: 0.9261, IoU.railing: 0.4535, IoU.cushion: 0.6075, IoU.base: 0.2874, IoU.box: 0.3037, IoU.column: 0.5333, IoU.signboard: 0.3134, IoU.chest of drawers: 0.4838, IoU.counter: 0.4475, IoU.sand: 0.4844, IoU.sink: 0.6784, IoU.skyscraper: 0.4893, IoU.fireplace: 0.6673, IoU.refrigerator: 0.6847, IoU.grandstand: 0.4737, IoU.path: 0.3677, IoU.stairs: 0.3406, IoU.runway: 0.9377, IoU.case: 0.4235, IoU.pool table: 0.9300, IoU.pillow: 0.5532, IoU.screen door: 0.8173, IoU.stairway: 0.3385, IoU.river: 0.2677, IoU.bridge: 0.6546, IoU.bookcase: 0.4305, IoU.blind: 0.5940, IoU.coffee table: 0.5973, IoU.toilet: 0.8663, IoU.flower: 0.5039, IoU.book: 0.4117, IoU.hill: 0.1736, IoU.bench: 0.4424, IoU.countertop: 0.5629, IoU.stove: 0.8181, IoU.palm: 0.5530, IoU.kitchen island: 0.4211, IoU.computer: 0.6967, IoU.swivel chair: 0.6108, IoU.boat: 0.1857, IoU.bar: 0.4281, IoU.arcade machine: 0.7971, IoU.hovel: 0.0051, IoU.bus: 0.7963, IoU.towel: 0.6191, IoU.light: 0.5411, IoU.truck: 0.2771, IoU.tower: 0.3548, IoU.chandelier: 0.7172, IoU.awning: 0.2084, IoU.streetlight: 0.2684, IoU.booth: 0.3263, IoU.television receiver: 0.6118, IoU.airplane: 0.2798, IoU.dirt track: 0.1076, IoU.apparel: 0.3191, IoU.pole: 0.3702, IoU.land: 0.0331, IoU.bannister: 0.1642, IoU.escalator: 0.3509, IoU.ottoman: 0.5461, IoU.bottle: 0.2688, IoU.buffet: 0.3886, IoU.poster: 0.4653, IoU.stage: 0.3595, IoU.van: 0.3696, IoU.ship: 0.1349, IoU.fountain: 0.3188, IoU.conveyer belt: 0.9119, IoU.canopy: 0.3649, IoU.washer: 0.3738, IoU.plaything: 0.2848, IoU.swimming pool: 0.6203, IoU.stool: 0.4471, IoU.barrel: 0.0546, IoU.basket: 0.3687, IoU.waterfall: 0.9241, IoU.tent: 0.0000, IoU.bag: 0.1525, IoU.minibike: 0.7486, IoU.cradle: 0.8372, IoU.oven: 0.4880, IoU.ball: 0.5271, IoU.food: 0.4229, IoU.step: 0.1938, IoU.tank: 0.9016, IoU.trade name: 0.3058, IoU.microwave: 0.7178, IoU.pot: 0.5437, IoU.animal: 0.7570, IoU.bicycle: 0.5710, IoU.lake: 0.0000, IoU.dishwasher: 0.7630, IoU.screen: 0.6774, IoU.blanket: 0.3535, IoU.sculpture: 0.7369, IoU.hood: 0.4653, IoU.sconce: 0.4754, IoU.vase: 0.3229, IoU.traffic light: 0.3136, IoU.tray: 0.1708, IoU.ashcan: 0.3271, IoU.fan: 0.6200, IoU.pier: 0.3452, IoU.crt screen: 0.3113, IoU.plate: 0.6032, IoU.monitor: 0.6912, IoU.bulletin board: 0.5735, IoU.shower: 0.0542, IoU.radiator: 0.5541, IoU.glass: 0.1552, IoU.clock: 0.4267, IoU.flag: 0.4636, Acc.wall: 0.8997, Acc.building: 0.9249, Acc.sky: 0.9672, Acc.floor: 0.9032, Acc.tree: 0.8864, Acc.ceiling: 0.9457, Acc.road: 0.9143, Acc.bed : 0.9757, Acc.windowpane: 0.8343, Acc.grass: 0.8414, Acc.cabinet: 0.7247, Acc.sidewalk: 0.8450, Acc.person: 0.9243, Acc.earth: 0.5698, Acc.door: 0.7288, Acc.table: 0.8023, Acc.mountain: 0.5144, Acc.plant: 0.6007, Acc.curtain: 0.8300, Acc.chair: 0.7492, Acc.car: 0.9120, Acc.water: 0.8568, Acc.painting: 0.8993, Acc.sofa: 0.8456, Acc.shelf: 0.6845, Acc.house: 0.6795, Acc.sea: 0.8801, Acc.mirror: 0.9222, Acc.rug: 0.7860, Acc.field: 0.5504, Acc.armchair: 0.7474, Acc.seat: 0.8478, Acc.fence: 0.4278, Acc.desk: 0.7357, Acc.rock: 0.6213, Acc.wardrobe: 0.7434, Acc.lamp: 0.7905, Acc.bathtub: 0.9514, Acc.railing: 0.6153, Acc.cushion: 0.7666, Acc.base: 0.5426, Acc.box: 0.3475, Acc.column: 0.6021, Acc.signboard: 0.4321, Acc.chest of drawers: 0.6952, Acc.counter: 0.5652, Acc.sand: 0.5203, Acc.sink: 0.7228, Acc.skyscraper: 0.9633, Acc.fireplace: 0.9257, Acc.refrigerator: 0.7748, Acc.grandstand: 0.8367, Acc.path: 0.4425, Acc.stairs: 0.4331, Acc.runway: 0.9946, Acc.case: 0.6818, Acc.pool table: 0.9577, Acc.pillow: 0.6177, Acc.screen door: 0.8556, Acc.stairway: 0.4166, Acc.river: 0.3022, Acc.bridge: 0.8491, Acc.bookcase: 0.5650, Acc.blind: 0.6230, Acc.coffee table: 0.7379, Acc.toilet: 0.9107, Acc.flower: 0.6080, Acc.book: 0.6638, Acc.hill: 0.2505, Acc.bench: 0.5130, Acc.countertop: 0.8000, Acc.stove: 0.9487, Acc.palm: 0.7267, Acc.kitchen island: 0.6916, Acc.computer: 0.8117, Acc.swivel chair: 0.8599, Acc.boat: 0.2106, Acc.bar: 0.5083, Acc.arcade machine: 0.9517, Acc.hovel: 0.0069, Acc.bus: 0.9134, Acc.towel: 0.7238, Acc.light: 0.5980, Acc.truck: 0.3082, Acc.tower: 0.5521, Acc.chandelier: 0.8843, Acc.awning: 0.2344, Acc.streetlight: 0.3465, Acc.booth: 0.3747, Acc.television receiver: 0.7088, Acc.airplane: 0.3000, Acc.dirt track: 0.2702, Acc.apparel: 0.3485, Acc.pole: 0.4486, Acc.land: 0.0410, Acc.bannister: 0.2269, Acc.escalator: 0.4248, Acc.ottoman: 0.7796, Acc.bottle: 0.4683, Acc.buffet: 0.4767, Acc.poster: 0.5458, Acc.stage: 0.4772, Acc.van: 0.4868, Acc.ship: 0.9585, Acc.fountain: 0.3330, Acc.conveyer belt: 0.9742, Acc.canopy: 0.4543, Acc.washer: 0.3741, Acc.plaything: 0.5236, Acc.swimming pool: 0.7048, Acc.stool: 0.6449, Acc.barrel: 0.0546, Acc.basket: 0.4685, Acc.waterfall: 0.9750, Acc.tent: nan, Acc.bag: 0.1721, Acc.minibike: 0.8677, Acc.cradle: 0.9887, Acc.oven: 0.7498, Acc.ball: 0.6671, Acc.food: 0.4787, Acc.step: 0.2305, Acc.tank: 0.9345, Acc.trade name: 0.3560, Acc.microwave: 0.8351, Acc.pot: 0.6043, Acc.animal: 0.7981, Acc.bicycle: 0.7559, Acc.lake: 0.0000, Acc.dishwasher: 0.9228, Acc.screen: 0.8422, Acc.blanket: 0.3717, Acc.sculpture: 0.8234, Acc.hood: 0.5725, Acc.sconce: 0.5887, Acc.vase: 0.5245, Acc.traffic light: 0.4364, Acc.tray: 0.3150, Acc.ashcan: 0.4346, Acc.fan: 0.7193, Acc.pier: 0.4890, Acc.crt screen: 0.3552, Acc.plate: 0.7771, Acc.monitor: 0.8075, Acc.bulletin board: 0.6877, Acc.shower: 0.0574, Acc.radiator: 0.6688, Acc.glass: 0.1744, Acc.clock: 0.5461, Acc.flag: 0.5466
2025-04-29 13:36:55,074 - mmseg - INFO - Iter [4050/20000]	lr: 6.380e-05, eta: 10:15:44, time: 4.425, data_time: 3.723, memory: 75916, decode.loss_ce: 0.1742, decode.acc_seg: 93.4138, loss: 0.1742
2025-04-29 13:38:44,369 - mmseg - INFO - Iter [4100/20000]	lr: 6.360e-05, eta: 10:13:22, time: 2.186, data_time: 1.895, memory: 75916, decode.loss_ce: 0.1488, decode.acc_seg: 94.0343, loss: 0.1488
2025-04-29 13:40:33,941 - mmseg - INFO - Iter [4150/20000]	lr: 6.340e-05, eta: 10:11:03, time: 2.191, data_time: 1.900, memory: 75916, decode.loss_ce: 0.1907, decode.acc_seg: 92.7088, loss: 0.1907
2025-04-29 13:42:21,840 - mmseg - INFO - Iter [4200/20000]	lr: 6.320e-05, eta: 10:08:38, time: 2.158, data_time: 1.868, memory: 75916, decode.loss_ce: 0.1749, decode.acc_seg: 93.3712, loss: 0.1749
2025-04-29 13:44:28,997 - mmseg - INFO - Iter [4250/20000]	lr: 6.300e-05, eta: 10:07:26, time: 2.543, data_time: 2.252, memory: 75916, decode.loss_ce: 0.1839, decode.acc_seg: 93.0628, loss: 0.1839
2025-04-29 13:46:13,051 - mmseg - INFO - Iter [4300/20000]	lr: 6.280e-05, eta: 10:04:48, time: 2.081, data_time: 1.790, memory: 75916, decode.loss_ce: 0.1866, decode.acc_seg: 92.6090, loss: 0.1866
2025-04-29 13:48:02,794 - mmseg - INFO - Iter [4350/20000]	lr: 6.260e-05, eta: 10:02:31, time: 2.195, data_time: 1.904, memory: 75916, decode.loss_ce: 0.1787, decode.acc_seg: 93.0557, loss: 0.1787
2025-04-29 13:49:39,875 - mmseg - INFO - Iter [4400/20000]	lr: 6.240e-05, eta: 9:59:30, time: 1.942, data_time: 1.650, memory: 75916, decode.loss_ce: 0.1466, decode.acc_seg: 94.1813, loss: 0.1466
2025-04-29 13:51:35,876 - mmseg - INFO - Iter [4450/20000]	lr: 6.220e-05, eta: 9:57:37, time: 2.320, data_time: 2.031, memory: 75916, decode.loss_ce: 0.1570, decode.acc_seg: 93.7685, loss: 0.1570
2025-04-29 13:53:32,326 - mmseg - INFO - Iter [4500/20000]	lr: 6.200e-05, eta: 9:55:46, time: 2.329, data_time: 2.039, memory: 75916, decode.loss_ce: 0.1741, decode.acc_seg: 92.9210, loss: 0.1741
2025-04-29 13:55:16,035 - mmseg - INFO - Iter [4550/20000]	lr: 6.180e-05, eta: 9:53:11, time: 2.074, data_time: 1.784, memory: 75916, decode.loss_ce: 0.1573, decode.acc_seg: 93.5521, loss: 0.1573
2025-04-29 13:57:04,117 - mmseg - INFO - Iter [4600/20000]	lr: 6.160e-05, eta: 9:50:52, time: 2.162, data_time: 1.872, memory: 75916, decode.loss_ce: 0.1617, decode.acc_seg: 93.3926, loss: 0.1617
2025-04-29 13:59:01,938 - mmseg - INFO - Iter [4650/20000]	lr: 6.140e-05, eta: 9:49:06, time: 2.356, data_time: 2.067, memory: 75916, decode.loss_ce: 0.1538, decode.acc_seg: 93.4384, loss: 0.1538
2025-04-29 14:00:59,473 - mmseg - INFO - Iter [4700/20000]	lr: 6.120e-05, eta: 9:47:19, time: 2.351, data_time: 2.060, memory: 75916, decode.loss_ce: 0.1668, decode.acc_seg: 93.2980, loss: 0.1668
2025-04-29 14:02:50,781 - mmseg - INFO - Iter [4750/20000]	lr: 6.100e-05, eta: 9:45:11, time: 2.226, data_time: 1.937, memory: 75916, decode.loss_ce: 0.1615, decode.acc_seg: 93.5826, loss: 0.1615
2025-04-29 14:04:40,928 - mmseg - INFO - Iter [4800/20000]	lr: 6.080e-05, eta: 9:43:00, time: 2.203, data_time: 1.912, memory: 75916, decode.loss_ce: 0.1526, decode.acc_seg: 93.8248, loss: 0.1526
2025-04-29 14:06:38,691 - mmseg - INFO - Iter [4850/20000]	lr: 6.060e-05, eta: 9:41:14, time: 2.355, data_time: 2.065, memory: 75916, decode.loss_ce: 0.1456, decode.acc_seg: 93.9719, loss: 0.1456
2025-04-29 14:08:38,195 - mmseg - INFO - Iter [4900/20000]	lr: 6.040e-05, eta: 9:39:32, time: 2.390, data_time: 2.101, memory: 75916, decode.loss_ce: 0.1678, decode.acc_seg: 93.2650, loss: 0.1678
2025-04-29 14:10:26,516 - mmseg - INFO - Iter [4950/20000]	lr: 6.020e-05, eta: 9:37:16, time: 2.166, data_time: 1.877, memory: 75916, decode.loss_ce: 0.1743, decode.acc_seg: 92.9982, loss: 0.1743
2025-04-29 14:12:09,865 - mmseg - INFO - Exp name: vpd_config.py
2025-04-29 14:12:09,866 - mmseg - INFO - Iter [5000/20000]	lr: 6.000e-05, eta: 9:34:46, time: 2.067, data_time: 1.777, memory: 75916, decode.loss_ce: 0.1713, decode.acc_seg: 92.9804, loss: 0.1713
2025-04-29 14:14:02,004 - mmseg - INFO - Iter [5050/20000]	lr: 5.980e-05, eta: 9:32:43, time: 2.243, data_time: 1.954, memory: 75916, decode.loss_ce: 0.1511, decode.acc_seg: 94.0924, loss: 0.1511
2025-04-29 14:16:02,261 - mmseg - INFO - Iter [5100/20000]	lr: 5.960e-05, eta: 9:31:04, time: 2.405, data_time: 2.116, memory: 75916, decode.loss_ce: 0.1701, decode.acc_seg: 93.3173, loss: 0.1701
2025-04-29 14:17:24,218 - mmseg - INFO - Iter [5150/20000]	lr: 5.940e-05, eta: 9:27:33, time: 1.639, data_time: 1.349, memory: 75916, decode.loss_ce: 0.1497, decode.acc_seg: 93.7988, loss: 0.1497
2025-04-29 14:19:13,194 - mmseg - INFO - Iter [5200/20000]	lr: 5.920e-05, eta: 9:25:22, time: 2.180, data_time: 1.890, memory: 75916, decode.loss_ce: 0.1615, decode.acc_seg: 93.9176, loss: 0.1615
2025-04-29 14:21:05,147 - mmseg - INFO - Iter [5250/20000]	lr: 5.900e-05, eta: 9:23:20, time: 2.239, data_time: 1.949, memory: 75916, decode.loss_ce: 0.1801, decode.acc_seg: 92.9244, loss: 0.1801
2025-04-29 14:23:06,388 - mmseg - INFO - Iter [5300/20000]	lr: 5.880e-05, eta: 9:21:44, time: 2.425, data_time: 2.135, memory: 75916, decode.loss_ce: 0.1742, decode.acc_seg: 93.1162, loss: 0.1742
2025-04-29 14:24:50,055 - mmseg - INFO - Iter [5350/20000]	lr: 5.860e-05, eta: 9:19:20, time: 2.073, data_time: 1.783, memory: 75916, decode.loss_ce: 0.1750, decode.acc_seg: 92.7960, loss: 0.1750
2025-04-29 14:26:40,515 - mmseg - INFO - Iter [5400/20000]	lr: 5.840e-05, eta: 9:17:14, time: 2.209, data_time: 1.919, memory: 75916, decode.loss_ce: 0.1606, decode.acc_seg: 93.7396, loss: 0.1606
2025-04-29 14:28:29,615 - mmseg - INFO - Iter [5450/20000]	lr: 5.820e-05, eta: 9:15:05, time: 2.182, data_time: 1.892, memory: 75916, decode.loss_ce: 0.1643, decode.acc_seg: 93.5287, loss: 0.1643
2025-04-29 14:30:33,720 - mmseg - INFO - Iter [5500/20000]	lr: 5.800e-05, eta: 9:13:36, time: 2.482, data_time: 2.193, memory: 75916, decode.loss_ce: 0.1722, decode.acc_seg: 93.0778, loss: 0.1722
2025-04-29 14:32:22,952 - mmseg - INFO - Iter [5550/20000]	lr: 5.780e-05, eta: 9:11:28, time: 2.185, data_time: 1.895, memory: 75916, decode.loss_ce: 0.1544, decode.acc_seg: 93.7641, loss: 0.1544
2025-04-29 14:34:13,388 - mmseg - INFO - Iter [5600/20000]	lr: 5.760e-05, eta: 9:09:23, time: 2.209, data_time: 1.918, memory: 75916, decode.loss_ce: 0.1615, decode.acc_seg: 93.4435, loss: 0.1615
2025-04-29 14:36:01,889 - mmseg - INFO - Iter [5650/20000]	lr: 5.740e-05, eta: 9:07:13, time: 2.170, data_time: 1.880, memory: 75916, decode.loss_ce: 0.1613, decode.acc_seg: 93.2883, loss: 0.1613
2025-04-29 14:38:07,070 - mmseg - INFO - Iter [5700/20000]	lr: 5.720e-05, eta: 9:05:46, time: 2.504, data_time: 2.214, memory: 75916, decode.loss_ce: 0.2085, decode.acc_seg: 91.8672, loss: 0.2085
2025-04-29 14:39:52,843 - mmseg - INFO - Iter [5750/20000]	lr: 5.700e-05, eta: 9:03:30, time: 2.116, data_time: 1.825, memory: 75916, decode.loss_ce: 0.1589, decode.acc_seg: 93.2572, loss: 0.1589
2025-04-29 14:41:41,501 - mmseg - INFO - Iter [5800/20000]	lr: 5.680e-05, eta: 9:01:21, time: 2.173, data_time: 1.884, memory: 75916, decode.loss_ce: 0.1628, decode.acc_seg: 93.2947, loss: 0.1628
2025-04-29 14:43:30,876 - mmseg - INFO - Iter [5850/20000]	lr: 5.660e-05, eta: 8:59:15, time: 2.187, data_time: 1.898, memory: 75916, decode.loss_ce: 0.1644, decode.acc_seg: 93.6348, loss: 0.1644
2025-04-29 14:45:36,022 - mmseg - INFO - Iter [5900/20000]	lr: 5.640e-05, eta: 8:57:46, time: 2.503, data_time: 2.213, memory: 75916, decode.loss_ce: 0.1649, decode.acc_seg: 93.5342, loss: 0.1649
2025-04-29 14:47:24,186 - mmseg - INFO - Iter [5950/20000]	lr: 5.620e-05, eta: 8:55:37, time: 2.163, data_time: 1.873, memory: 75916, decode.loss_ce: 0.1795, decode.acc_seg: 92.9982, loss: 0.1795
2025-04-29 14:49:13,211 - mmseg - INFO - Saving checkpoint at 6000 iterations
2025-04-29 14:49:22,468 - mmseg - INFO - Exp name: vpd_config.py
2025-04-29 14:49:22,476 - mmseg - INFO - Iter [6000/20000]	lr: 5.600e-05, eta: 8:53:52, time: 2.366, data_time: 1.891, memory: 75916, decode.loss_ce: 0.1652, decode.acc_seg: 93.6318, loss: 0.1652
2025-04-29 14:50:54,266 - mmseg - INFO - per class results:
2025-04-29 14:50:54,273 - mmseg - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        | 79.83 | 89.93 |
|       building      | 85.93 | 93.75 |
|         sky         | 93.63 | 96.67 |
|        floor        | 82.42 | 89.49 |
|         tree        | 74.13 | 89.15 |
|       ceiling       | 86.99 | 95.24 |
|         road        | 86.11 |  91.3 |
|         bed         | 91.06 | 97.31 |
|      windowpane     | 67.38 | 83.98 |
|        grass        | 75.46 | 87.29 |
|       cabinet       | 57.62 | 74.21 |
|       sidewalk      | 69.53 |  86.4 |
|        person       | 81.08 | 92.36 |
|        earth        | 32.76 | 56.23 |
|         door        | 59.33 | 73.79 |
|        table        | 65.26 | 80.45 |
|       mountain      | 33.73 | 45.88 |
|        plant        | 51.11 | 58.73 |
|       curtain       |  72.9 | 82.34 |
|        chair        | 64.64 | 75.16 |
|         car         | 83.17 | 91.67 |
|        water        | 51.98 | 84.62 |
|       painting      | 75.02 |  88.7 |
|         sofa        |  71.7 | 83.11 |
|        shelf        | 50.44 | 66.59 |
|        house        |  44.9 | 64.76 |
|         sea         | 70.17 | 89.04 |
|        mirror       | 81.55 |  93.3 |
|         rug         | 65.73 | 78.44 |
|        field        | 34.67 | 53.64 |
|       armchair      | 52.56 | 77.96 |
|         seat        | 54.66 | 86.02 |
|        fence        | 26.51 | 44.34 |
|         desk        | 47.43 | 71.22 |
|         rock        | 47.42 | 62.65 |
|       wardrobe      | 55.64 | 75.18 |
|         lamp        | 68.25 | 78.67 |
|       bathtub       |  92.4 | 96.17 |
|       railing       | 44.36 | 60.28 |
|       cushion       | 61.52 | 73.31 |
|         base        | 29.16 | 55.97 |
|         box         | 31.87 | 38.58 |
|        column       | 53.54 | 59.99 |
|      signboard      | 30.13 | 39.56 |
|   chest of drawers  | 48.94 | 69.38 |
|       counter       | 46.71 | 64.19 |
|         sand        | 71.59 | 79.36 |
|         sink        | 66.96 | 71.71 |
|      skyscraper     | 47.35 | 91.69 |
|      fireplace      | 67.78 | 92.05 |
|     refrigerator    | 61.02 |  67.2 |
|      grandstand     |  45.9 | 84.68 |
|         path        | 32.52 | 36.86 |
|        stairs       | 34.58 | 40.22 |
|        runway       | 93.83 |  99.7 |
|         case        | 43.39 | 70.13 |
|      pool table     | 92.65 | 96.03 |
|        pillow       | 56.93 | 64.45 |
|     screen door     | 81.86 | 84.88 |
|       stairway      | 33.44 |  45.9 |
|        river        | 26.29 | 29.46 |
|        bridge       | 72.86 | 83.36 |
|       bookcase      | 43.09 | 54.25 |
|        blind        | 59.12 | 61.04 |
|     coffee table    | 59.95 | 71.69 |
|        toilet       | 87.16 | 90.75 |
|        flower       | 50.68 | 62.56 |
|         book        | 41.78 | 65.62 |
|         hill        | 17.04 | 24.18 |
|        bench        | 35.89 | 40.99 |
|      countertop     |  57.0 | 81.92 |
|        stove        |  77.8 | 96.05 |
|         palm        |  56.2 | 72.91 |
|    kitchen island   | 40.72 | 66.38 |
|       computer      | 68.83 | 82.06 |
|     swivel chair    | 63.05 | 87.85 |
|         boat        | 17.45 | 19.16 |
|         bar         | 40.09 |  44.0 |
|    arcade machine   |  79.9 | 93.69 |
|        hovel        |  4.47 |  6.63 |
|         bus         | 77.65 | 85.58 |
|        towel        | 62.02 | 74.94 |
|        light        | 54.21 |  59.9 |
|        truck        | 28.21 | 31.39 |
|        tower        | 37.59 | 58.46 |
|      chandelier     | 72.03 | 87.89 |
|        awning       | 21.38 | 23.38 |
|     streetlight     | 25.42 | 31.43 |
|        booth        | 23.35 | 28.46 |
| television receiver | 55.97 | 63.85 |
|       airplane      | 28.88 | 31.19 |
|      dirt track     | 10.01 | 35.13 |
|       apparel       | 25.39 | 27.38 |
|         pole        | 37.11 | 44.19 |
|         land        |  3.23 |  3.91 |
|      bannister      | 17.34 | 23.48 |
|      escalator      | 30.29 | 35.48 |
|       ottoman       | 52.73 | 79.19 |
|        bottle       | 26.54 | 44.86 |
|        buffet       | 31.06 |  37.1 |
|        poster       | 42.56 | 58.39 |
|        stage        | 34.68 | 47.33 |
|         van         | 35.73 |  49.2 |
|         ship        |  12.9 | 96.47 |
|       fountain      | 33.07 | 35.07 |
|    conveyer belt    | 72.26 | 99.07 |
|        canopy       | 38.22 | 44.33 |
|        washer       |  35.6 | 35.62 |
|      plaything      | 27.88 | 51.53 |
|    swimming pool    | 60.52 | 69.62 |
|        stool        | 49.16 | 67.09 |
|        barrel       |  1.5  |  1.5  |
|        basket       | 38.61 | 47.35 |
|      waterfall      | 92.58 | 97.71 |
|         tent        |  0.0  |  nan  |
|         bag         |  16.8 | 20.32 |
|       minibike      | 74.54 | 86.16 |
|        cradle       | 82.54 | 99.06 |
|         oven        | 50.78 | 71.72 |
|         ball        | 53.25 | 68.51 |
|         food        | 43.66 | 51.58 |
|         step        | 21.16 | 25.06 |
|         tank        | 90.55 | 92.74 |
|      trade name     | 31.09 |  36.1 |
|      microwave      | 70.59 | 84.64 |
|         pot         | 56.22 | 63.58 |
|        animal       | 75.88 | 79.86 |
|       bicycle       | 58.41 | 74.77 |
|         lake        |  0.0  |  0.0  |
|      dishwasher     | 79.46 | 91.63 |
|        screen       | 57.53 | 87.81 |
|       blanket       | 33.04 | 34.05 |
|      sculpture      | 74.21 | 84.53 |
|         hood        |  45.6 | 55.29 |
|        sconce       | 45.54 | 54.62 |
|         vase        | 33.03 | 52.22 |
|    traffic light    | 31.69 | 43.85 |
|         tray        | 17.02 | 28.21 |
|        ashcan       | 35.54 |  48.8 |
|         fan         | 61.24 | 67.77 |
|         pier        | 27.12 | 50.02 |
|      crt screen     | 29.25 | 34.55 |
|        plate        | 61.34 | 79.05 |
|       monitor       | 73.86 | 90.53 |
|    bulletin board   |  59.2 |  70.2 |
|        shower       |  2.92 |  2.97 |
|       radiator      | 53.43 | 63.92 |
|        glass        | 14.47 | 15.81 |
|        clock        | 42.42 |  49.5 |
|         flag        | 43.96 |  49.4 |
+---------------------+-------+-------+
2025-04-29 14:50:54,273 - mmseg - INFO - Summary:
2025-04-29 14:50:54,273 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 84.23 | 50.69 | 63.51 |
+-------+-------+-------+
2025-04-29 14:50:54,274 - mmseg - INFO - Exp name: vpd_config.py
2025-04-29 14:50:54,274 - mmseg - INFO - Iter(val) [851]	aAcc: 0.8423, mIoU: 0.5069, mAcc: 0.6351, IoU.wall: 0.7983, IoU.building: 0.8593, IoU.sky: 0.9363, IoU.floor: 0.8242, IoU.tree: 0.7413, IoU.ceiling: 0.8699, IoU.road: 0.8611, IoU.bed : 0.9106, IoU.windowpane: 0.6738, IoU.grass: 0.7546, IoU.cabinet: 0.5762, IoU.sidewalk: 0.6953, IoU.person: 0.8108, IoU.earth: 0.3276, IoU.door: 0.5933, IoU.table: 0.6526, IoU.mountain: 0.3373, IoU.plant: 0.5111, IoU.curtain: 0.7290, IoU.chair: 0.6464, IoU.car: 0.8317, IoU.water: 0.5198, IoU.painting: 0.7502, IoU.sofa: 0.7170, IoU.shelf: 0.5044, IoU.house: 0.4490, IoU.sea: 0.7017, IoU.mirror: 0.8155, IoU.rug: 0.6573, IoU.field: 0.3467, IoU.armchair: 0.5256, IoU.seat: 0.5466, IoU.fence: 0.2651, IoU.desk: 0.4743, IoU.rock: 0.4742, IoU.wardrobe: 0.5564, IoU.lamp: 0.6825, IoU.bathtub: 0.9240, IoU.railing: 0.4436, IoU.cushion: 0.6152, IoU.base: 0.2916, IoU.box: 0.3187, IoU.column: 0.5354, IoU.signboard: 0.3013, IoU.chest of drawers: 0.4894, IoU.counter: 0.4671, IoU.sand: 0.7159, IoU.sink: 0.6696, IoU.skyscraper: 0.4735, IoU.fireplace: 0.6778, IoU.refrigerator: 0.6102, IoU.grandstand: 0.4590, IoU.path: 0.3252, IoU.stairs: 0.3458, IoU.runway: 0.9383, IoU.case: 0.4339, IoU.pool table: 0.9265, IoU.pillow: 0.5693, IoU.screen door: 0.8186, IoU.stairway: 0.3344, IoU.river: 0.2629, IoU.bridge: 0.7286, IoU.bookcase: 0.4309, IoU.blind: 0.5912, IoU.coffee table: 0.5995, IoU.toilet: 0.8716, IoU.flower: 0.5068, IoU.book: 0.4178, IoU.hill: 0.1704, IoU.bench: 0.3589, IoU.countertop: 0.5700, IoU.stove: 0.7780, IoU.palm: 0.5620, IoU.kitchen island: 0.4072, IoU.computer: 0.6883, IoU.swivel chair: 0.6305, IoU.boat: 0.1745, IoU.bar: 0.4009, IoU.arcade machine: 0.7990, IoU.hovel: 0.0447, IoU.bus: 0.7765, IoU.towel: 0.6202, IoU.light: 0.5421, IoU.truck: 0.2821, IoU.tower: 0.3759, IoU.chandelier: 0.7203, IoU.awning: 0.2138, IoU.streetlight: 0.2542, IoU.booth: 0.2335, IoU.television receiver: 0.5597, IoU.airplane: 0.2888, IoU.dirt track: 0.1001, IoU.apparel: 0.2539, IoU.pole: 0.3711, IoU.land: 0.0323, IoU.bannister: 0.1734, IoU.escalator: 0.3029, IoU.ottoman: 0.5273, IoU.bottle: 0.2654, IoU.buffet: 0.3106, IoU.poster: 0.4256, IoU.stage: 0.3468, IoU.van: 0.3573, IoU.ship: 0.1290, IoU.fountain: 0.3307, IoU.conveyer belt: 0.7226, IoU.canopy: 0.3822, IoU.washer: 0.3560, IoU.plaything: 0.2788, IoU.swimming pool: 0.6052, IoU.stool: 0.4916, IoU.barrel: 0.0150, IoU.basket: 0.3861, IoU.waterfall: 0.9258, IoU.tent: 0.0000, IoU.bag: 0.1680, IoU.minibike: 0.7454, IoU.cradle: 0.8254, IoU.oven: 0.5078, IoU.ball: 0.5325, IoU.food: 0.4366, IoU.step: 0.2116, IoU.tank: 0.9055, IoU.trade name: 0.3109, IoU.microwave: 0.7059, IoU.pot: 0.5622, IoU.animal: 0.7588, IoU.bicycle: 0.5841, IoU.lake: 0.0000, IoU.dishwasher: 0.7946, IoU.screen: 0.5753, IoU.blanket: 0.3304, IoU.sculpture: 0.7421, IoU.hood: 0.4560, IoU.sconce: 0.4554, IoU.vase: 0.3303, IoU.traffic light: 0.3169, IoU.tray: 0.1702, IoU.ashcan: 0.3554, IoU.fan: 0.6124, IoU.pier: 0.2712, IoU.crt screen: 0.2925, IoU.plate: 0.6134, IoU.monitor: 0.7386, IoU.bulletin board: 0.5920, IoU.shower: 0.0292, IoU.radiator: 0.5343, IoU.glass: 0.1447, IoU.clock: 0.4242, IoU.flag: 0.4396, Acc.wall: 0.8993, Acc.building: 0.9375, Acc.sky: 0.9667, Acc.floor: 0.8949, Acc.tree: 0.8915, Acc.ceiling: 0.9524, Acc.road: 0.9130, Acc.bed : 0.9731, Acc.windowpane: 0.8398, Acc.grass: 0.8729, Acc.cabinet: 0.7421, Acc.sidewalk: 0.8640, Acc.person: 0.9236, Acc.earth: 0.5623, Acc.door: 0.7379, Acc.table: 0.8045, Acc.mountain: 0.4588, Acc.plant: 0.5873, Acc.curtain: 0.8234, Acc.chair: 0.7516, Acc.car: 0.9167, Acc.water: 0.8462, Acc.painting: 0.8870, Acc.sofa: 0.8311, Acc.shelf: 0.6659, Acc.house: 0.6476, Acc.sea: 0.8904, Acc.mirror: 0.9330, Acc.rug: 0.7844, Acc.field: 0.5364, Acc.armchair: 0.7796, Acc.seat: 0.8602, Acc.fence: 0.4434, Acc.desk: 0.7122, Acc.rock: 0.6265, Acc.wardrobe: 0.7518, Acc.lamp: 0.7867, Acc.bathtub: 0.9617, Acc.railing: 0.6028, Acc.cushion: 0.7331, Acc.base: 0.5597, Acc.box: 0.3858, Acc.column: 0.5999, Acc.signboard: 0.3956, Acc.chest of drawers: 0.6938, Acc.counter: 0.6419, Acc.sand: 0.7936, Acc.sink: 0.7171, Acc.skyscraper: 0.9169, Acc.fireplace: 0.9205, Acc.refrigerator: 0.6720, Acc.grandstand: 0.8468, Acc.path: 0.3686, Acc.stairs: 0.4022, Acc.runway: 0.9970, Acc.case: 0.7013, Acc.pool table: 0.9603, Acc.pillow: 0.6445, Acc.screen door: 0.8488, Acc.stairway: 0.4590, Acc.river: 0.2946, Acc.bridge: 0.8336, Acc.bookcase: 0.5425, Acc.blind: 0.6104, Acc.coffee table: 0.7169, Acc.toilet: 0.9075, Acc.flower: 0.6256, Acc.book: 0.6562, Acc.hill: 0.2418, Acc.bench: 0.4099, Acc.countertop: 0.8192, Acc.stove: 0.9605, Acc.palm: 0.7291, Acc.kitchen island: 0.6638, Acc.computer: 0.8206, Acc.swivel chair: 0.8785, Acc.boat: 0.1916, Acc.bar: 0.4400, Acc.arcade machine: 0.9369, Acc.hovel: 0.0663, Acc.bus: 0.8558, Acc.towel: 0.7494, Acc.light: 0.5990, Acc.truck: 0.3139, Acc.tower: 0.5846, Acc.chandelier: 0.8789, Acc.awning: 0.2338, Acc.streetlight: 0.3143, Acc.booth: 0.2846, Acc.television receiver: 0.6385, Acc.airplane: 0.3119, Acc.dirt track: 0.3513, Acc.apparel: 0.2738, Acc.pole: 0.4419, Acc.land: 0.0391, Acc.bannister: 0.2348, Acc.escalator: 0.3548, Acc.ottoman: 0.7919, Acc.bottle: 0.4486, Acc.buffet: 0.3710, Acc.poster: 0.5839, Acc.stage: 0.4733, Acc.van: 0.4920, Acc.ship: 0.9647, Acc.fountain: 0.3507, Acc.conveyer belt: 0.9907, Acc.canopy: 0.4433, Acc.washer: 0.3562, Acc.plaything: 0.5153, Acc.swimming pool: 0.6962, Acc.stool: 0.6709, Acc.barrel: 0.0150, Acc.basket: 0.4735, Acc.waterfall: 0.9771, Acc.tent: nan, Acc.bag: 0.2032, Acc.minibike: 0.8616, Acc.cradle: 0.9906, Acc.oven: 0.7172, Acc.ball: 0.6851, Acc.food: 0.5158, Acc.step: 0.2506, Acc.tank: 0.9274, Acc.trade name: 0.3610, Acc.microwave: 0.8464, Acc.pot: 0.6358, Acc.animal: 0.7986, Acc.bicycle: 0.7477, Acc.lake: 0.0000, Acc.dishwasher: 0.9163, Acc.screen: 0.8781, Acc.blanket: 0.3405, Acc.sculpture: 0.8453, Acc.hood: 0.5529, Acc.sconce: 0.5462, Acc.vase: 0.5222, Acc.traffic light: 0.4385, Acc.tray: 0.2821, Acc.ashcan: 0.4880, Acc.fan: 0.6777, Acc.pier: 0.5002, Acc.crt screen: 0.3455, Acc.plate: 0.7905, Acc.monitor: 0.9053, Acc.bulletin board: 0.7020, Acc.shower: 0.0297, Acc.radiator: 0.6392, Acc.glass: 0.1581, Acc.clock: 0.4950, Acc.flag: 0.4940
2025-04-29 14:52:15,737 - mmseg - INFO - Iter [6050/20000]	lr: 5.580e-05, eta: 8:54:13, time: 3.465, data_time: 3.172, memory: 75916, decode.loss_ce: 0.1719, decode.acc_seg: 93.1660, loss: 0.1719
2025-04-29 14:54:09,965 - mmseg - INFO - Iter [6100/20000]	lr: 5.560e-05, eta: 8:52:17, time: 2.285, data_time: 1.994, memory: 75916, decode.loss_ce: 0.1422, decode.acc_seg: 94.3645, loss: 0.1422
2025-04-29 14:56:03,153 - mmseg - INFO - Iter [6150/20000]	lr: 5.540e-05, eta: 8:50:18, time: 2.264, data_time: 1.972, memory: 75916, decode.loss_ce: 0.1752, decode.acc_seg: 93.2713, loss: 0.1752
2025-04-29 14:57:52,496 - mmseg - INFO - Iter [6200/20000]	lr: 5.520e-05, eta: 8:48:11, time: 2.187, data_time: 1.897, memory: 75916, decode.loss_ce: 0.1685, decode.acc_seg: 93.2968, loss: 0.1685
2025-04-29 14:59:48,979 - mmseg - INFO - Iter [6250/20000]	lr: 5.500e-05, eta: 8:46:20, time: 2.330, data_time: 2.039, memory: 75916, decode.loss_ce: 0.1805, decode.acc_seg: 92.6577, loss: 0.1805
2025-04-29 15:01:43,736 - mmseg - INFO - Iter [6300/20000]	lr: 5.480e-05, eta: 8:44:25, time: 2.295, data_time: 2.005, memory: 75916, decode.loss_ce: 0.1564, decode.acc_seg: 93.4829, loss: 0.1564
2025-04-29 15:03:38,043 - mmseg - INFO - Iter [6350/20000]	lr: 5.460e-05, eta: 8:42:29, time: 2.286, data_time: 1.995, memory: 75916, decode.loss_ce: 0.1605, decode.acc_seg: 93.6333, loss: 0.1605
2025-04-29 15:05:27,416 - mmseg - INFO - Iter [6400/20000]	lr: 5.440e-05, eta: 8:40:22, time: 2.187, data_time: 1.897, memory: 75916, decode.loss_ce: 0.1604, decode.acc_seg: 93.8653, loss: 0.1604
2025-04-29 15:07:25,443 - mmseg - INFO - Iter [6450/20000]	lr: 5.420e-05, eta: 8:38:34, time: 2.361, data_time: 2.071, memory: 75916, decode.loss_ce: 0.1595, decode.acc_seg: 93.8803, loss: 0.1595
2025-04-29 15:09:10,798 - mmseg - INFO - Iter [6500/20000]	lr: 5.400e-05, eta: 8:36:20, time: 2.107, data_time: 1.817, memory: 75916, decode.loss_ce: 0.1437, decode.acc_seg: 94.1855, loss: 0.1437
2025-04-29 15:11:12,824 - mmseg - INFO - Iter [6550/20000]	lr: 5.380e-05, eta: 8:34:40, time: 2.441, data_time: 2.150, memory: 75916, decode.loss_ce: 0.1696, decode.acc_seg: 93.1881, loss: 0.1696
2025-04-29 15:13:02,667 - mmseg - INFO - Iter [6600/20000]	lr: 5.360e-05, eta: 8:32:35, time: 2.197, data_time: 1.907, memory: 75916, decode.loss_ce: 0.1665, decode.acc_seg: 93.3985, loss: 0.1665
2025-04-29 15:14:52,720 - mmseg - INFO - Iter [6650/20000]	lr: 5.340e-05, eta: 8:30:31, time: 2.201, data_time: 1.912, memory: 75916, decode.loss_ce: 0.1626, decode.acc_seg: 93.2778, loss: 0.1626
2025-04-29 15:16:44,997 - mmseg - INFO - Iter [6700/20000]	lr: 5.320e-05, eta: 8:28:31, time: 2.246, data_time: 1.956, memory: 75916, decode.loss_ce: 0.1709, decode.acc_seg: 93.0133, loss: 0.1709
2025-04-29 15:18:49,658 - mmseg - INFO - Iter [6750/20000]	lr: 5.300e-05, eta: 8:26:56, time: 2.493, data_time: 2.203, memory: 75916, decode.loss_ce: 0.1590, decode.acc_seg: 93.5873, loss: 0.1590
2025-04-29 15:20:39,647 - mmseg - INFO - Iter [6800/20000]	lr: 5.280e-05, eta: 8:24:52, time: 2.200, data_time: 1.910, memory: 75916, decode.loss_ce: 0.1734, decode.acc_seg: 93.2670, loss: 0.1734
2025-04-29 15:22:30,197 - mmseg - INFO - Iter [6850/20000]	lr: 5.260e-05, eta: 8:22:49, time: 2.211, data_time: 1.922, memory: 75916, decode.loss_ce: 0.1585, decode.acc_seg: 93.4646, loss: 0.1585
2025-04-29 15:24:21,926 - mmseg - INFO - Iter [6900/20000]	lr: 5.240e-05, eta: 8:20:49, time: 2.235, data_time: 1.944, memory: 75916, decode.loss_ce: 0.1420, decode.acc_seg: 94.3430, loss: 0.1420
2025-04-29 15:26:29,070 - mmseg - INFO - Iter [6950/20000]	lr: 5.220e-05, eta: 8:19:18, time: 2.543, data_time: 2.253, memory: 75916, decode.loss_ce: 0.1682, decode.acc_seg: 93.6260, loss: 0.1682
2025-04-29 15:28:18,782 - mmseg - INFO - Exp name: vpd_config.py
2025-04-29 15:28:18,783 - mmseg - INFO - Iter [7000/20000]	lr: 5.200e-05, eta: 8:17:14, time: 2.194, data_time: 1.905, memory: 75916, decode.loss_ce: 0.1692, decode.acc_seg: 93.5242, loss: 0.1692
2025-04-29 15:30:07,914 - mmseg - INFO - Iter [7050/20000]	lr: 5.180e-05, eta: 8:15:08, time: 2.183, data_time: 1.893, memory: 75916, decode.loss_ce: 0.1615, decode.acc_seg: 93.7352, loss: 0.1615
2025-04-29 15:31:56,955 - mmseg - INFO - Iter [7100/20000]	lr: 5.160e-05, eta: 8:13:03, time: 2.181, data_time: 1.891, memory: 75916, decode.loss_ce: 0.1567, decode.acc_seg: 93.7975, loss: 0.1567
2025-04-29 15:33:58,956 - mmseg - INFO - Iter [7150/20000]	lr: 5.140e-05, eta: 8:11:22, time: 2.440, data_time: 2.150, memory: 75916, decode.loss_ce: 0.1647, decode.acc_seg: 93.0381, loss: 0.1647
2025-04-29 15:35:52,360 - mmseg - INFO - Iter [7200/20000]	lr: 5.120e-05, eta: 8:09:25, time: 2.268, data_time: 1.978, memory: 75916, decode.loss_ce: 0.1414, decode.acc_seg: 94.1170, loss: 0.1414
2025-04-29 15:37:46,833 - mmseg - INFO - Iter [7250/20000]	lr: 5.100e-05, eta: 8:07:30, time: 2.289, data_time: 1.999, memory: 75916, decode.loss_ce: 0.1591, decode.acc_seg: 93.6946, loss: 0.1591
2025-04-29 15:39:36,950 - mmseg - INFO - Iter [7300/20000]	lr: 5.080e-05, eta: 8:05:27, time: 2.202, data_time: 1.912, memory: 75916, decode.loss_ce: 0.1624, decode.acc_seg: 93.4901, loss: 0.1624
2025-04-29 15:41:34,652 - mmseg - INFO - Iter [7350/20000]	lr: 5.060e-05, eta: 8:03:38, time: 2.354, data_time: 2.064, memory: 75916, decode.loss_ce: 0.1665, decode.acc_seg: 93.5756, loss: 0.1665
2025-04-29 15:43:25,551 - mmseg - INFO - Iter [7400/20000]	lr: 5.040e-05, eta: 8:01:36, time: 2.218, data_time: 1.927, memory: 75916, decode.loss_ce: 0.1686, decode.acc_seg: 93.0351, loss: 0.1686
2025-04-29 15:45:25,521 - mmseg - INFO - Iter [7450/20000]	lr: 5.020e-05, eta: 7:59:51, time: 2.399, data_time: 2.109, memory: 75916, decode.loss_ce: 0.1655, decode.acc_seg: 93.4452, loss: 0.1655
2025-04-29 15:47:15,525 - mmseg - INFO - Iter [7500/20000]	lr: 5.000e-05, eta: 7:57:48, time: 2.200, data_time: 1.909, memory: 75916, decode.loss_ce: 0.2151, decode.acc_seg: 92.2753, loss: 0.2151
2025-04-29 15:49:14,790 - mmseg - INFO - Iter [7550/20000]	lr: 4.980e-05, eta: 7:56:01, time: 2.385, data_time: 2.094, memory: 75916, decode.loss_ce: 0.1871, decode.acc_seg: 92.6060, loss: 0.1871
2025-04-29 15:51:04,788 - mmseg - INFO - Iter [7600/20000]	lr: 4.960e-05, eta: 7:53:59, time: 2.200, data_time: 1.909, memory: 75916, decode.loss_ce: 0.1543, decode.acc_seg: 93.4546, loss: 0.1543
2025-04-29 15:52:58,230 - mmseg - INFO - Iter [7650/20000]	lr: 4.940e-05, eta: 7:52:02, time: 2.269, data_time: 1.978, memory: 75916, decode.loss_ce: 0.1829, decode.acc_seg: 93.1131, loss: 0.1829
2025-04-29 15:54:46,321 - mmseg - INFO - Iter [7700/20000]	lr: 4.920e-05, eta: 7:49:57, time: 2.162, data_time: 1.872, memory: 75916, decode.loss_ce: 0.1587, decode.acc_seg: 93.6661, loss: 0.1587
2025-04-29 15:56:36,707 - mmseg - INFO - Iter [7750/20000]	lr: 4.900e-05, eta: 7:47:56, time: 2.208, data_time: 1.916, memory: 75916, decode.loss_ce: 0.1799, decode.acc_seg: 93.2732, loss: 0.1799
2025-04-29 15:58:07,358 - mmseg - INFO - Iter [7800/20000]	lr: 4.880e-05, eta: 7:45:23, time: 1.813, data_time: 1.524, memory: 75916, decode.loss_ce: 0.1603, decode.acc_seg: 93.4310, loss: 0.1603
2025-04-29 16:00:03,652 - mmseg - INFO - Iter [7850/20000]	lr: 4.860e-05, eta: 7:43:32, time: 2.326, data_time: 2.036, memory: 75916, decode.loss_ce: 0.1634, decode.acc_seg: 93.4415, loss: 0.1634
2025-04-29 16:01:46,873 - mmseg - INFO - Iter [7900/20000]	lr: 4.840e-05, eta: 7:41:20, time: 2.064, data_time: 1.774, memory: 75916, decode.loss_ce: 0.1640, decode.acc_seg: 93.7132, loss: 0.1640
2025-04-29 16:03:36,263 - mmseg - INFO - Iter [7950/20000]	lr: 4.820e-05, eta: 7:39:18, time: 2.188, data_time: 1.897, memory: 75916, decode.loss_ce: 0.1751, decode.acc_seg: 93.0472, loss: 0.1751
2025-04-29 16:05:42,732 - mmseg - INFO - Saving checkpoint at 8000 iterations
2025-04-29 16:05:52,049 - mmseg - INFO - Exp name: vpd_config.py
2025-04-29 16:05:52,049 - mmseg - INFO - Iter [8000/20000]	lr: 4.800e-05, eta: 7:37:56, time: 2.716, data_time: 2.238, memory: 75916, decode.loss_ce: 0.1727, decode.acc_seg: 93.2885, loss: 0.1727
2025-04-29 16:07:23,936 - mmseg - INFO - per class results:
2025-04-29 16:07:23,943 - mmseg - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        | 79.89 | 90.66 |
|       building      | 85.35 | 92.91 |
|         sky         | 93.69 | 97.04 |
|        floor        | 82.24 | 89.87 |
|         tree        | 74.33 |  87.7 |
|       ceiling       | 86.73 | 93.92 |
|         road        | 85.82 | 91.75 |
|         bed         | 90.89 | 97.62 |
|      windowpane     | 67.37 | 84.76 |
|        grass        | 74.86 | 88.24 |
|       cabinet       | 57.87 | 72.09 |
|       sidewalk      | 68.41 | 83.74 |
|        person       | 81.04 | 93.05 |
|        earth        | 31.98 | 53.88 |
|         door        | 58.41 | 70.23 |
|        table        | 65.77 | 81.19 |
|       mountain      | 32.82 | 44.17 |
|        plant        | 51.03 | 58.37 |
|       curtain       | 72.97 |  82.8 |
|        chair        | 64.34 | 77.31 |
|         car         |  83.2 | 90.88 |
|        water        | 50.37 | 87.23 |
|       painting      | 76.17 | 87.73 |
|         sofa        | 72.35 |  84.4 |
|        shelf        | 50.71 | 67.41 |
|        house        | 39.16 | 67.15 |
|         sea         | 70.14 | 88.33 |
|        mirror       | 80.27 | 94.03 |
|         rug         | 65.63 | 78.11 |
|        field        | 35.65 | 54.86 |
|       armchair      | 52.17 | 73.63 |
|         seat        |  56.0 |  84.3 |
|        fence        | 26.89 | 41.97 |
|         desk        | 46.24 | 71.07 |
|         rock        | 47.97 | 62.63 |
|       wardrobe      |  55.3 | 74.32 |
|         lamp        | 68.08 | 79.56 |
|       bathtub       | 92.25 | 96.24 |
|       railing       | 43.89 | 60.56 |
|       cushion       | 62.02 | 73.49 |
|         base        | 28.04 | 54.67 |
|         box         |  30.5 | 36.83 |
|        column       | 52.48 | 59.25 |
|      signboard      |  31.2 | 41.29 |
|   chest of drawers  | 49.94 | 68.38 |
|       counter       | 43.89 | 54.93 |
|         sand        | 74.66 | 93.37 |
|         sink        | 67.12 | 71.77 |
|      skyscraper     | 48.21 | 94.59 |
|      fireplace      | 67.77 | 92.47 |
|     refrigerator    | 63.01 | 67.75 |
|      grandstand     | 45.37 |  85.0 |
|         path        |  35.8 |  42.1 |
|        stairs       | 34.33 | 40.81 |
|        runway       | 93.24 | 99.92 |
|         case        | 42.87 | 69.79 |
|      pool table     | 92.48 | 96.03 |
|        pillow       | 54.55 | 60.65 |
|     screen door     | 81.76 | 84.23 |
|       stairway      | 33.56 | 44.18 |
|        river        | 26.24 | 28.69 |
|        bridge       |  68.2 | 87.91 |
|       bookcase      | 45.06 | 56.72 |
|        blind        | 58.61 | 61.76 |
|     coffee table    | 59.74 | 73.49 |
|        toilet       | 86.87 | 91.12 |
|        flower       | 50.54 | 62.15 |
|         book        |  42.3 | 63.61 |
|         hill        | 17.17 | 23.99 |
|        bench        | 42.66 | 52.31 |
|      countertop     | 56.72 | 81.27 |
|        stove        | 76.52 | 96.62 |
|         palm        | 55.14 | 72.44 |
|    kitchen island   | 43.98 | 71.55 |
|       computer      | 69.07 | 81.53 |
|     swivel chair    | 58.63 | 76.98 |
|         boat        | 16.12 | 17.76 |
|         bar         | 44.93 | 54.67 |
|    arcade machine   | 79.28 | 92.56 |
|        hovel        |  3.04 |  4.56 |
|         bus         | 79.07 | 89.52 |
|        towel        | 61.03 | 72.99 |
|        light        | 53.97 | 59.34 |
|        truck        | 26.66 | 29.84 |
|        tower        | 40.36 | 63.31 |
|      chandelier     | 71.89 | 85.71 |
|        awning       | 16.37 | 17.17 |
|     streetlight     | 26.48 | 34.55 |
|        booth        | 25.39 | 30.67 |
| television receiver | 56.41 | 63.64 |
|       airplane      | 31.09 | 33.21 |
|      dirt track     | 10.11 | 27.25 |
|       apparel       | 32.45 | 37.33 |
|         pole        | 35.32 | 41.78 |
|         land        |  3.98 |  5.02 |
|      bannister      | 17.48 | 24.39 |
|      escalator      | 26.23 | 29.43 |
|       ottoman       | 52.23 |  71.3 |
|        bottle       | 26.61 | 43.74 |
|        buffet       | 39.19 | 47.96 |
|        poster       | 45.57 | 58.56 |
|        stage        | 40.81 | 56.37 |
|         van         | 36.47 | 49.56 |
|         ship        | 12.14 | 96.32 |
|       fountain      | 28.36 |  29.6 |
|    conveyer belt    | 75.16 |  98.4 |
|        canopy       |  36.1 |  44.7 |
|        washer       | 35.39 | 35.41 |
|      plaything      | 25.84 | 43.51 |
|    swimming pool    | 60.22 | 64.48 |
|        stool        | 41.76 | 69.47 |
|        barrel       | 21.09 | 21.09 |
|        basket       | 37.69 | 48.42 |
|      waterfall      | 92.57 | 97.71 |
|         tent        |  0.0  |  nan  |
|         bag         |  16.3 | 19.18 |
|       minibike      | 74.16 | 85.11 |
|        cradle       | 83.56 | 98.89 |
|         oven        | 48.98 | 62.63 |
|         ball        | 52.84 | 67.32 |
|         food        |  36.7 | 41.91 |
|         step        | 22.06 | 26.72 |
|         tank        | 85.03 | 86.33 |
|      trade name     | 28.12 | 31.35 |
|      microwave      | 73.06 | 81.85 |
|         pot         | 56.21 | 62.59 |
|        animal       | 75.42 | 78.56 |
|       bicycle       | 58.54 | 76.64 |
|         lake        |  0.0  |  0.0  |
|      dishwasher     | 77.94 | 92.29 |
|        screen       | 63.73 | 80.56 |
|       blanket       | 35.03 | 36.92 |
|      sculpture      | 71.73 | 84.59 |
|         hood        | 43.05 | 52.44 |
|        sconce       | 43.77 | 52.58 |
|         vase        | 33.45 | 46.99 |
|    traffic light    | 32.74 | 46.16 |
|         tray        | 17.31 | 29.69 |
|        ashcan       | 35.03 | 49.02 |
|         fan         | 64.64 | 72.58 |
|         pier        | 26.12 | 49.26 |
|      crt screen     | 30.36 | 42.45 |
|        plate        | 61.25 | 77.33 |
|       monitor       | 77.09 | 87.27 |
|    bulletin board   | 57.53 |  70.7 |
|        shower       |  4.3  |  4.42 |
|       radiator      | 53.76 | 64.45 |
|        glass        | 14.11 | 15.47 |
|        clock        |  42.3 | 51.64 |
|         flag        | 44.11 |  50.8 |
+---------------------+-------+-------+
2025-04-29 16:07:23,943 - mmseg - INFO - Summary:
2025-04-29 16:07:23,943 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 84.11 | 50.76 | 63.47 |
+-------+-------+-------+
2025-04-29 16:07:23,944 - mmseg - INFO - Exp name: vpd_config.py
2025-04-29 16:07:23,944 - mmseg - INFO - Iter(val) [851]	aAcc: 0.8411, mIoU: 0.5076, mAcc: 0.6347, IoU.wall: 0.7989, IoU.building: 0.8535, IoU.sky: 0.9369, IoU.floor: 0.8224, IoU.tree: 0.7433, IoU.ceiling: 0.8673, IoU.road: 0.8582, IoU.bed : 0.9089, IoU.windowpane: 0.6737, IoU.grass: 0.7486, IoU.cabinet: 0.5787, IoU.sidewalk: 0.6841, IoU.person: 0.8104, IoU.earth: 0.3198, IoU.door: 0.5841, IoU.table: 0.6577, IoU.mountain: 0.3282, IoU.plant: 0.5103, IoU.curtain: 0.7297, IoU.chair: 0.6434, IoU.car: 0.8320, IoU.water: 0.5037, IoU.painting: 0.7617, IoU.sofa: 0.7235, IoU.shelf: 0.5071, IoU.house: 0.3916, IoU.sea: 0.7014, IoU.mirror: 0.8027, IoU.rug: 0.6563, IoU.field: 0.3565, IoU.armchair: 0.5217, IoU.seat: 0.5600, IoU.fence: 0.2689, IoU.desk: 0.4624, IoU.rock: 0.4797, IoU.wardrobe: 0.5530, IoU.lamp: 0.6808, IoU.bathtub: 0.9225, IoU.railing: 0.4389, IoU.cushion: 0.6202, IoU.base: 0.2804, IoU.box: 0.3050, IoU.column: 0.5248, IoU.signboard: 0.3120, IoU.chest of drawers: 0.4994, IoU.counter: 0.4389, IoU.sand: 0.7466, IoU.sink: 0.6712, IoU.skyscraper: 0.4821, IoU.fireplace: 0.6777, IoU.refrigerator: 0.6301, IoU.grandstand: 0.4537, IoU.path: 0.3580, IoU.stairs: 0.3433, IoU.runway: 0.9324, IoU.case: 0.4287, IoU.pool table: 0.9248, IoU.pillow: 0.5455, IoU.screen door: 0.8176, IoU.stairway: 0.3356, IoU.river: 0.2624, IoU.bridge: 0.6820, IoU.bookcase: 0.4506, IoU.blind: 0.5861, IoU.coffee table: 0.5974, IoU.toilet: 0.8687, IoU.flower: 0.5054, IoU.book: 0.4230, IoU.hill: 0.1717, IoU.bench: 0.4266, IoU.countertop: 0.5672, IoU.stove: 0.7652, IoU.palm: 0.5514, IoU.kitchen island: 0.4398, IoU.computer: 0.6907, IoU.swivel chair: 0.5863, IoU.boat: 0.1612, IoU.bar: 0.4493, IoU.arcade machine: 0.7928, IoU.hovel: 0.0304, IoU.bus: 0.7907, IoU.towel: 0.6103, IoU.light: 0.5397, IoU.truck: 0.2666, IoU.tower: 0.4036, IoU.chandelier: 0.7189, IoU.awning: 0.1637, IoU.streetlight: 0.2648, IoU.booth: 0.2539, IoU.television receiver: 0.5641, IoU.airplane: 0.3109, IoU.dirt track: 0.1011, IoU.apparel: 0.3245, IoU.pole: 0.3532, IoU.land: 0.0398, IoU.bannister: 0.1748, IoU.escalator: 0.2623, IoU.ottoman: 0.5223, IoU.bottle: 0.2661, IoU.buffet: 0.3919, IoU.poster: 0.4557, IoU.stage: 0.4081, IoU.van: 0.3647, IoU.ship: 0.1214, IoU.fountain: 0.2836, IoU.conveyer belt: 0.7516, IoU.canopy: 0.3610, IoU.washer: 0.3539, IoU.plaything: 0.2584, IoU.swimming pool: 0.6022, IoU.stool: 0.4176, IoU.barrel: 0.2109, IoU.basket: 0.3769, IoU.waterfall: 0.9257, IoU.tent: 0.0000, IoU.bag: 0.1630, IoU.minibike: 0.7416, IoU.cradle: 0.8356, IoU.oven: 0.4898, IoU.ball: 0.5284, IoU.food: 0.3670, IoU.step: 0.2206, IoU.tank: 0.8503, IoU.trade name: 0.2812, IoU.microwave: 0.7306, IoU.pot: 0.5621, IoU.animal: 0.7542, IoU.bicycle: 0.5854, IoU.lake: 0.0000, IoU.dishwasher: 0.7794, IoU.screen: 0.6373, IoU.blanket: 0.3503, IoU.sculpture: 0.7173, IoU.hood: 0.4305, IoU.sconce: 0.4377, IoU.vase: 0.3345, IoU.traffic light: 0.3274, IoU.tray: 0.1731, IoU.ashcan: 0.3503, IoU.fan: 0.6464, IoU.pier: 0.2612, IoU.crt screen: 0.3036, IoU.plate: 0.6125, IoU.monitor: 0.7709, IoU.bulletin board: 0.5753, IoU.shower: 0.0430, IoU.radiator: 0.5376, IoU.glass: 0.1411, IoU.clock: 0.4230, IoU.flag: 0.4411, Acc.wall: 0.9066, Acc.building: 0.9291, Acc.sky: 0.9704, Acc.floor: 0.8987, Acc.tree: 0.8770, Acc.ceiling: 0.9392, Acc.road: 0.9175, Acc.bed : 0.9762, Acc.windowpane: 0.8476, Acc.grass: 0.8824, Acc.cabinet: 0.7209, Acc.sidewalk: 0.8374, Acc.person: 0.9305, Acc.earth: 0.5388, Acc.door: 0.7023, Acc.table: 0.8119, Acc.mountain: 0.4417, Acc.plant: 0.5837, Acc.curtain: 0.8280, Acc.chair: 0.7731, Acc.car: 0.9088, Acc.water: 0.8723, Acc.painting: 0.8773, Acc.sofa: 0.8440, Acc.shelf: 0.6741, Acc.house: 0.6715, Acc.sea: 0.8833, Acc.mirror: 0.9403, Acc.rug: 0.7811, Acc.field: 0.5486, Acc.armchair: 0.7363, Acc.seat: 0.8430, Acc.fence: 0.4197, Acc.desk: 0.7107, Acc.rock: 0.6263, Acc.wardrobe: 0.7432, Acc.lamp: 0.7956, Acc.bathtub: 0.9624, Acc.railing: 0.6056, Acc.cushion: 0.7349, Acc.base: 0.5467, Acc.box: 0.3683, Acc.column: 0.5925, Acc.signboard: 0.4129, Acc.chest of drawers: 0.6838, Acc.counter: 0.5493, Acc.sand: 0.9337, Acc.sink: 0.7177, Acc.skyscraper: 0.9459, Acc.fireplace: 0.9247, Acc.refrigerator: 0.6775, Acc.grandstand: 0.8500, Acc.path: 0.4210, Acc.stairs: 0.4081, Acc.runway: 0.9992, Acc.case: 0.6979, Acc.pool table: 0.9603, Acc.pillow: 0.6065, Acc.screen door: 0.8423, Acc.stairway: 0.4418, Acc.river: 0.2869, Acc.bridge: 0.8791, Acc.bookcase: 0.5672, Acc.blind: 0.6176, Acc.coffee table: 0.7349, Acc.toilet: 0.9112, Acc.flower: 0.6215, Acc.book: 0.6361, Acc.hill: 0.2399, Acc.bench: 0.5231, Acc.countertop: 0.8127, Acc.stove: 0.9662, Acc.palm: 0.7244, Acc.kitchen island: 0.7155, Acc.computer: 0.8153, Acc.swivel chair: 0.7698, Acc.boat: 0.1776, Acc.bar: 0.5467, Acc.arcade machine: 0.9256, Acc.hovel: 0.0456, Acc.bus: 0.8952, Acc.towel: 0.7299, Acc.light: 0.5934, Acc.truck: 0.2984, Acc.tower: 0.6331, Acc.chandelier: 0.8571, Acc.awning: 0.1717, Acc.streetlight: 0.3455, Acc.booth: 0.3067, Acc.television receiver: 0.6364, Acc.airplane: 0.3321, Acc.dirt track: 0.2725, Acc.apparel: 0.3733, Acc.pole: 0.4178, Acc.land: 0.0502, Acc.bannister: 0.2439, Acc.escalator: 0.2943, Acc.ottoman: 0.7130, Acc.bottle: 0.4374, Acc.buffet: 0.4796, Acc.poster: 0.5856, Acc.stage: 0.5637, Acc.van: 0.4956, Acc.ship: 0.9632, Acc.fountain: 0.2960, Acc.conveyer belt: 0.9840, Acc.canopy: 0.4470, Acc.washer: 0.3541, Acc.plaything: 0.4351, Acc.swimming pool: 0.6448, Acc.stool: 0.6947, Acc.barrel: 0.2109, Acc.basket: 0.4842, Acc.waterfall: 0.9771, Acc.tent: nan, Acc.bag: 0.1918, Acc.minibike: 0.8511, Acc.cradle: 0.9889, Acc.oven: 0.6263, Acc.ball: 0.6732, Acc.food: 0.4191, Acc.step: 0.2672, Acc.tank: 0.8633, Acc.trade name: 0.3135, Acc.microwave: 0.8185, Acc.pot: 0.6259, Acc.animal: 0.7856, Acc.bicycle: 0.7664, Acc.lake: 0.0000, Acc.dishwasher: 0.9229, Acc.screen: 0.8056, Acc.blanket: 0.3692, Acc.sculpture: 0.8459, Acc.hood: 0.5244, Acc.sconce: 0.5258, Acc.vase: 0.4699, Acc.traffic light: 0.4616, Acc.tray: 0.2969, Acc.ashcan: 0.4902, Acc.fan: 0.7258, Acc.pier: 0.4926, Acc.crt screen: 0.4245, Acc.plate: 0.7733, Acc.monitor: 0.8727, Acc.bulletin board: 0.7070, Acc.shower: 0.0442, Acc.radiator: 0.6445, Acc.glass: 0.1547, Acc.clock: 0.5164, Acc.flag: 0.5080
2025-04-29 16:09:36,220 - mmseg - INFO - Iter [8050/20000]	lr: 4.780e-05, eta: 7:38:44, time: 4.483, data_time: 3.763, memory: 75916, decode.loss_ce: 0.1778, decode.acc_seg: 93.6212, loss: 0.1778
2025-04-29 16:11:26,589 - mmseg - INFO - Iter [8100/20000]	lr: 4.760e-05, eta: 7:36:42, time: 2.207, data_time: 1.916, memory: 75916, decode.loss_ce: 0.1575, decode.acc_seg: 93.9380, loss: 0.1575
2025-04-29 16:13:17,094 - mmseg - INFO - Iter [8150/20000]	lr: 4.740e-05, eta: 7:34:40, time: 2.210, data_time: 1.920, memory: 75916, decode.loss_ce: 0.1675, decode.acc_seg: 93.4496, loss: 0.1675
2025-04-29 16:15:07,106 - mmseg - INFO - Iter [8200/20000]	lr: 4.720e-05, eta: 7:32:38, time: 2.200, data_time: 1.911, memory: 75916, decode.loss_ce: 0.1499, decode.acc_seg: 93.9630, loss: 0.1499
2025-04-29 16:17:13,644 - mmseg - INFO - Iter [8250/20000]	lr: 4.700e-05, eta: 7:30:59, time: 2.531, data_time: 2.241, memory: 75916, decode.loss_ce: 0.1550, decode.acc_seg: 93.7728, loss: 0.1550
2025-04-29 16:19:03,650 - mmseg - INFO - Iter [8300/20000]	lr: 4.680e-05, eta: 7:28:57, time: 2.200, data_time: 1.911, memory: 75916, decode.loss_ce: 0.1693, decode.acc_seg: 93.6445, loss: 0.1693
2025-04-29 16:20:54,070 - mmseg - INFO - Iter [8350/20000]	lr: 4.660e-05, eta: 7:26:55, time: 2.208, data_time: 1.916, memory: 75916, decode.loss_ce: 0.1874, decode.acc_seg: 92.6107, loss: 0.1874
2025-04-29 16:22:45,684 - mmseg - INFO - Iter [8400/20000]	lr: 4.640e-05, eta: 7:24:55, time: 2.232, data_time: 1.942, memory: 75916, decode.loss_ce: 0.1858, decode.acc_seg: 93.2116, loss: 0.1858
2025-04-29 16:24:52,406 - mmseg - INFO - Iter [8450/20000]	lr: 4.620e-05, eta: 7:23:16, time: 2.534, data_time: 2.243, memory: 75916, decode.loss_ce: 0.1513, decode.acc_seg: 93.8043, loss: 0.1513
2025-04-29 16:26:43,209 - mmseg - INFO - Iter [8500/20000]	lr: 4.600e-05, eta: 7:21:15, time: 2.216, data_time: 1.926, memory: 75916, decode.loss_ce: 0.1623, decode.acc_seg: 93.3825, loss: 0.1623
2025-04-29 16:28:32,944 - mmseg - INFO - Iter [8550/20000]	lr: 4.580e-05, eta: 7:19:13, time: 2.195, data_time: 1.904, memory: 75916, decode.loss_ce: 0.1840, decode.acc_seg: 92.5847, loss: 0.1840
2025-04-29 16:30:22,291 - mmseg - INFO - Iter [8600/20000]	lr: 4.560e-05, eta: 7:17:10, time: 2.187, data_time: 1.898, memory: 75916, decode.loss_ce: 0.1520, decode.acc_seg: 93.8663, loss: 0.1520
2025-04-29 16:32:24,617 - mmseg - INFO - Iter [8650/20000]	lr: 4.540e-05, eta: 7:15:25, time: 2.447, data_time: 2.157, memory: 75916, decode.loss_ce: 0.1575, decode.acc_seg: 93.5166, loss: 0.1575
2025-04-29 16:34:10,468 - mmseg - INFO - Iter [8700/20000]	lr: 4.520e-05, eta: 7:13:17, time: 2.117, data_time: 1.826, memory: 75916, decode.loss_ce: 0.1628, decode.acc_seg: 93.6794, loss: 0.1628
2025-04-29 16:35:59,636 - mmseg - INFO - Iter [8750/20000]	lr: 4.500e-05, eta: 7:11:15, time: 2.183, data_time: 1.894, memory: 75916, decode.loss_ce: 0.1926, decode.acc_seg: 92.6784, loss: 0.1926
2025-04-29 16:37:49,379 - mmseg - INFO - Iter [8800/20000]	lr: 4.480e-05, eta: 7:09:13, time: 2.195, data_time: 1.905, memory: 75916, decode.loss_ce: 0.1544, decode.acc_seg: 93.8845, loss: 0.1544
2025-04-29 16:39:55,416 - mmseg - INFO - Iter [8850/20000]	lr: 4.460e-05, eta: 7:07:32, time: 2.521, data_time: 2.232, memory: 75916, decode.loss_ce: 0.1625, decode.acc_seg: 93.4359, loss: 0.1625
2025-04-29 16:41:44,692 - mmseg - INFO - Iter [8900/20000]	lr: 4.440e-05, eta: 7:05:30, time: 2.186, data_time: 1.895, memory: 75916, decode.loss_ce: 0.1783, decode.acc_seg: 93.0380, loss: 0.1783
2025-04-29 16:43:31,060 - mmseg - INFO - Iter [8950/20000]	lr: 4.420e-05, eta: 7:03:24, time: 2.127, data_time: 1.837, memory: 75916, decode.loss_ce: 0.1781, decode.acc_seg: 92.8458, loss: 0.1781
2025-04-29 16:45:19,681 - mmseg - INFO - Exp name: vpd_config.py
2025-04-29 16:45:19,682 - mmseg - INFO - Iter [9000/20000]	lr: 4.400e-05, eta: 7:01:22, time: 2.172, data_time: 1.882, memory: 75916, decode.loss_ce: 0.1584, decode.acc_seg: 93.5662, loss: 0.1584
2025-04-29 16:47:22,251 - mmseg - INFO - Iter [9050/20000]	lr: 4.380e-05, eta: 6:59:36, time: 2.451, data_time: 2.162, memory: 75916, decode.loss_ce: 0.1799, decode.acc_seg: 93.0982, loss: 0.1799
2025-04-29 16:49:11,480 - mmseg - INFO - Iter [9100/20000]	lr: 4.360e-05, eta: 6:57:34, time: 2.185, data_time: 1.895, memory: 75916, decode.loss_ce: 0.1674, decode.acc_seg: 93.2906, loss: 0.1674
2025-04-29 16:50:59,779 - mmseg - INFO - Iter [9150/20000]	lr: 4.340e-05, eta: 6:55:31, time: 2.166, data_time: 1.876, memory: 75916, decode.loss_ce: 0.1757, decode.acc_seg: 92.9379, loss: 0.1757
2025-04-29 16:52:50,028 - mmseg - INFO - Iter [9200/20000]	lr: 4.320e-05, eta: 6:53:31, time: 2.205, data_time: 1.915, memory: 75916, decode.loss_ce: 0.1632, decode.acc_seg: 93.5099, loss: 0.1632
2025-04-29 16:54:54,642 - mmseg - INFO - Iter [9250/20000]	lr: 4.300e-05, eta: 6:51:47, time: 2.492, data_time: 2.201, memory: 75916, decode.loss_ce: 0.1485, decode.acc_seg: 94.0642, loss: 0.1485
2025-04-29 16:56:46,643 - mmseg - INFO - Iter [9300/20000]	lr: 4.280e-05, eta: 6:49:49, time: 2.240, data_time: 1.948, memory: 75916, decode.loss_ce: 0.1791, decode.acc_seg: 93.0058, loss: 0.1791
2025-04-29 16:58:36,156 - mmseg - INFO - Iter [9350/20000]	lr: 4.260e-05, eta: 6:47:48, time: 2.190, data_time: 1.901, memory: 75916, decode.loss_ce: 0.1544, decode.acc_seg: 93.8357, loss: 0.1544
2025-04-29 17:00:25,684 - mmseg - INFO - Iter [9400/20000]	lr: 4.240e-05, eta: 6:45:47, time: 2.191, data_time: 1.901, memory: 75916, decode.loss_ce: 0.1634, decode.acc_seg: 93.4236, loss: 0.1634
2025-04-29 17:02:26,336 - mmseg - INFO - Iter [9450/20000]	lr: 4.220e-05, eta: 6:43:59, time: 2.413, data_time: 2.123, memory: 75916, decode.loss_ce: 0.1634, decode.acc_seg: 93.2650, loss: 0.1634
2025-04-29 17:04:17,739 - mmseg - INFO - Iter [9500/20000]	lr: 4.200e-05, eta: 6:42:00, time: 2.228, data_time: 1.937, memory: 75916, decode.loss_ce: 0.1529, decode.acc_seg: 93.7512, loss: 0.1529
2025-04-29 17:06:08,041 - mmseg - INFO - Iter [9550/20000]	lr: 4.180e-05, eta: 6:40:00, time: 2.206, data_time: 1.915, memory: 75916, decode.loss_ce: 0.1803, decode.acc_seg: 92.8763, loss: 0.1803
2025-04-29 17:07:58,462 - mmseg - INFO - Iter [9600/20000]	lr: 4.160e-05, eta: 6:38:01, time: 2.208, data_time: 1.918, memory: 75916, decode.loss_ce: 0.1580, decode.acc_seg: 93.5676, loss: 0.1580
2025-04-29 17:09:59,851 - mmseg - INFO - Iter [9650/20000]	lr: 4.140e-05, eta: 6:36:13, time: 2.428, data_time: 2.137, memory: 75916, decode.loss_ce: 0.1673, decode.acc_seg: 93.4761, loss: 0.1673
2025-04-29 17:11:51,414 - mmseg - INFO - Iter [9700/20000]	lr: 4.120e-05, eta: 6:34:15, time: 2.231, data_time: 1.939, memory: 75916, decode.loss_ce: 0.2132, decode.acc_seg: 92.7404, loss: 0.2132
2025-04-29 17:13:44,916 - mmseg - INFO - Iter [9750/20000]	lr: 4.100e-05, eta: 6:32:18, time: 2.270, data_time: 1.979, memory: 75916, decode.loss_ce: 0.1609, decode.acc_seg: 93.8394, loss: 0.1609
2025-04-29 17:15:36,595 - mmseg - INFO - Iter [9800/20000]	lr: 4.080e-05, eta: 6:30:20, time: 2.234, data_time: 1.943, memory: 75916, decode.loss_ce: 0.1567, decode.acc_seg: 93.7161, loss: 0.1567
2025-04-29 17:17:42,869 - mmseg - INFO - Iter [9850/20000]	lr: 4.060e-05, eta: 6:28:37, time: 2.525, data_time: 2.235, memory: 75916, decode.loss_ce: 0.1636, decode.acc_seg: 93.4219, loss: 0.1636
2025-04-29 17:19:27,785 - mmseg - INFO - Iter [9900/20000]	lr: 4.040e-05, eta: 6:26:32, time: 2.098, data_time: 1.809, memory: 75916, decode.loss_ce: 0.1698, decode.acc_seg: 93.1088, loss: 0.1698
2025-04-29 17:21:14,485 - mmseg - INFO - Iter [9950/20000]	lr: 4.020e-05, eta: 6:24:29, time: 2.134, data_time: 1.843, memory: 75916, decode.loss_ce: 0.1628, decode.acc_seg: 93.2733, loss: 0.1628
2025-04-29 17:23:06,336 - mmseg - INFO - Saving checkpoint at 10000 iterations
2025-04-29 17:23:16,135 - mmseg - INFO - Exp name: vpd_config.py
2025-04-29 17:23:16,136 - mmseg - INFO - Iter [10000/20000]	lr: 4.000e-05, eta: 6:22:41, time: 2.433, data_time: 1.945, memory: 75916, decode.loss_ce: 0.1611, decode.acc_seg: 93.9401, loss: 0.1611
2025-04-29 17:24:49,061 - mmseg - INFO - per class results:
2025-04-29 17:24:49,068 - mmseg - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        | 79.84 | 89.94 |
|       building      | 85.21 | 92.97 |
|         sky         | 93.66 | 97.21 |
|        floor        | 82.28 | 90.13 |
|         tree        | 73.98 | 87.62 |
|       ceiling       | 86.71 | 94.61 |
|         road        | 85.84 | 92.14 |
|         bed         | 90.89 | 97.29 |
|      windowpane     | 67.29 | 84.01 |
|        grass        | 75.71 | 87.73 |
|       cabinet       | 58.14 | 73.98 |
|       sidewalk      | 68.82 | 84.04 |
|        person       | 81.34 | 91.55 |
|        earth        | 33.49 | 54.75 |
|         door        | 59.27 | 73.55 |
|        table        | 65.58 | 81.01 |
|       mountain      | 36.96 | 50.72 |
|        plant        | 50.55 | 57.93 |
|       curtain       | 72.81 | 83.76 |
|        chair        | 64.66 | 74.37 |
|         car         | 83.11 | 91.29 |
|        water        | 51.58 | 85.38 |
|       painting      |  74.3 | 88.99 |
|         sofa        | 71.63 | 83.28 |
|        shelf        | 49.17 | 62.31 |
|        house        | 39.32 | 66.95 |
|         sea         | 71.36 | 87.22 |
|        mirror       | 80.53 | 93.48 |
|         rug         | 66.17 | 79.58 |
|        field        | 34.28 | 50.82 |
|       armchair      | 52.65 | 78.17 |
|         seat        | 54.89 | 87.64 |
|        fence        | 26.98 | 43.56 |
|         desk        | 46.61 | 70.42 |
|         rock        | 47.81 | 62.48 |
|       wardrobe      | 56.43 |  74.2 |
|         lamp        | 68.09 | 80.87 |
|       bathtub       | 91.41 |  97.0 |
|       railing       |  44.7 | 64.36 |
|       cushion       | 61.06 | 72.54 |
|         base        | 27.08 | 59.49 |
|         box         | 31.38 | 39.48 |
|        column       | 53.58 | 62.66 |
|      signboard      | 31.84 | 41.75 |
|   chest of drawers  | 48.99 | 69.11 |
|       counter       | 45.87 | 59.25 |
|         sand        | 74.85 |  86.8 |
|         sink        | 67.35 | 70.71 |
|      skyscraper     | 47.02 | 89.95 |
|      fireplace      | 68.32 | 92.41 |
|     refrigerator    | 60.92 |  67.1 |
|      grandstand     | 48.11 | 83.87 |
|         path        | 35.67 | 42.58 |
|        stairs       | 34.19 | 40.88 |
|        runway       | 94.01 | 99.77 |
|         case        | 44.54 | 71.92 |
|      pool table     | 92.41 | 96.17 |
|        pillow       | 56.44 | 63.98 |
|     screen door     | 81.62 |  85.8 |
|       stairway      | 32.98 |  44.7 |
|        river        | 29.04 | 34.54 |
|        bridge       | 70.83 | 85.64 |
|       bookcase      | 42.37 | 57.96 |
|        blind        | 58.66 | 60.52 |
|     coffee table    | 60.43 | 72.03 |
|        toilet       | 87.04 | 91.52 |
|        flower       | 50.32 |  61.4 |
|         book        | 42.39 |  63.9 |
|         hill        | 16.81 | 24.47 |
|        bench        | 36.73 | 39.15 |
|      countertop     | 59.03 |  82.7 |
|        stove        | 77.07 | 94.48 |
|         palm        |  54.9 | 71.95 |
|    kitchen island   | 43.62 | 72.75 |
|       computer      | 69.17 | 82.79 |
|     swivel chair    | 62.21 | 86.04 |
|         boat        | 18.18 | 20.18 |
|         bar         | 42.79 | 49.26 |
|    arcade machine   | 80.93 | 94.16 |
|        hovel        |  2.93 |  4.27 |
|         bus         | 79.06 |  88.1 |
|        towel        | 58.75 | 73.36 |
|        light        | 57.62 | 66.61 |
|        truck        | 27.51 | 30.37 |
|        tower        | 41.81 | 66.32 |
|      chandelier     | 71.76 | 84.66 |
|        awning       | 20.31 | 21.98 |
|     streetlight     | 26.12 | 32.98 |
|        booth        | 25.03 | 28.65 |
| television receiver | 60.21 | 71.61 |
|       airplane      | 28.95 | 30.54 |
|      dirt track     | 11.03 | 31.46 |
|       apparel       |  32.4 | 37.28 |
|         pole        | 39.06 | 48.82 |
|         land        |  3.38 |  4.15 |
|      bannister      | 17.26 | 23.63 |
|      escalator      | 33.13 | 38.45 |
|       ottoman       | 52.81 | 77.09 |
|        bottle       |  26.5 | 43.42 |
|        buffet       | 38.96 | 48.04 |
|        poster       | 44.26 | 57.89 |
|        stage        | 36.33 |  50.4 |
|         van         | 35.62 | 47.94 |
|         ship        | 13.19 | 95.48 |
|       fountain      | 29.45 | 30.58 |
|    conveyer belt    |  89.7 | 97.41 |
|        canopy       | 34.88 | 44.37 |
|        washer       | 34.79 | 34.81 |
|      plaything      | 24.35 | 42.45 |
|    swimming pool    | 58.55 | 64.58 |
|        stool        | 50.86 | 61.29 |
|        barrel       |  5.35 |  5.35 |
|        basket       | 37.11 | 48.83 |
|      waterfall      | 92.64 | 97.81 |
|         tent        |  0.0  |  nan  |
|         bag         | 12.83 | 14.21 |
|       minibike      | 74.71 | 84.24 |
|        cradle       |  82.9 | 98.76 |
|         oven        | 50.15 | 73.18 |
|         ball        | 52.63 | 67.16 |
|         food        | 28.68 | 30.64 |
|         step        | 19.98 | 23.63 |
|         tank        | 87.39 | 88.82 |
|      trade name     | 32.14 | 37.45 |
|      microwave      | 71.54 | 83.53 |
|         pot         | 55.93 | 62.69 |
|        animal       | 75.33 | 78.41 |
|       bicycle       | 59.24 | 72.71 |
|         lake        |  0.0  |  0.0  |
|      dishwasher     | 78.39 | 92.18 |
|        screen       | 62.07 | 85.46 |
|       blanket       | 31.97 | 33.28 |
|      sculpture      | 73.99 | 87.97 |
|         hood        | 43.32 | 53.42 |
|        sconce       | 44.88 | 54.08 |
|         vase        | 32.31 | 52.42 |
|    traffic light    |  32.8 | 46.76 |
|         tray        | 16.69 | 25.88 |
|        ashcan       | 35.22 | 44.26 |
|         fan         | 59.01 | 64.54 |
|         pier        | 32.01 | 48.86 |
|      crt screen     | 30.28 | 36.94 |
|        plate        | 59.51 | 75.39 |
|       monitor       | 76.17 | 87.11 |
|    bulletin board   | 56.02 |  70.2 |
|        shower       |  9.58 | 10.08 |
|       radiator      | 53.48 | 64.08 |
|        glass        | 13.59 | 14.67 |
|        clock        | 42.41 | 50.86 |
|         flag        | 45.26 | 53.01 |
+---------------------+-------+-------+
2025-04-29 17:24:49,068 - mmseg - INFO - Summary:
2025-04-29 17:24:49,068 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 84.13 | 50.93 | 63.57 |
+-------+-------+-------+
2025-04-29 17:24:49,069 - mmseg - INFO - Exp name: vpd_config.py
2025-04-29 17:24:49,069 - mmseg - INFO - Iter(val) [851]	aAcc: 0.8413, mIoU: 0.5093, mAcc: 0.6357, IoU.wall: 0.7984, IoU.building: 0.8521, IoU.sky: 0.9366, IoU.floor: 0.8228, IoU.tree: 0.7398, IoU.ceiling: 0.8671, IoU.road: 0.8584, IoU.bed : 0.9089, IoU.windowpane: 0.6729, IoU.grass: 0.7571, IoU.cabinet: 0.5814, IoU.sidewalk: 0.6882, IoU.person: 0.8134, IoU.earth: 0.3349, IoU.door: 0.5927, IoU.table: 0.6558, IoU.mountain: 0.3696, IoU.plant: 0.5055, IoU.curtain: 0.7281, IoU.chair: 0.6466, IoU.car: 0.8311, IoU.water: 0.5158, IoU.painting: 0.7430, IoU.sofa: 0.7163, IoU.shelf: 0.4917, IoU.house: 0.3932, IoU.sea: 0.7136, IoU.mirror: 0.8053, IoU.rug: 0.6617, IoU.field: 0.3428, IoU.armchair: 0.5265, IoU.seat: 0.5489, IoU.fence: 0.2698, IoU.desk: 0.4661, IoU.rock: 0.4781, IoU.wardrobe: 0.5643, IoU.lamp: 0.6809, IoU.bathtub: 0.9141, IoU.railing: 0.4470, IoU.cushion: 0.6106, IoU.base: 0.2708, IoU.box: 0.3138, IoU.column: 0.5358, IoU.signboard: 0.3184, IoU.chest of drawers: 0.4899, IoU.counter: 0.4587, IoU.sand: 0.7485, IoU.sink: 0.6735, IoU.skyscraper: 0.4702, IoU.fireplace: 0.6832, IoU.refrigerator: 0.6092, IoU.grandstand: 0.4811, IoU.path: 0.3567, IoU.stairs: 0.3419, IoU.runway: 0.9401, IoU.case: 0.4454, IoU.pool table: 0.9241, IoU.pillow: 0.5644, IoU.screen door: 0.8162, IoU.stairway: 0.3298, IoU.river: 0.2904, IoU.bridge: 0.7083, IoU.bookcase: 0.4237, IoU.blind: 0.5866, IoU.coffee table: 0.6043, IoU.toilet: 0.8704, IoU.flower: 0.5032, IoU.book: 0.4239, IoU.hill: 0.1681, IoU.bench: 0.3673, IoU.countertop: 0.5903, IoU.stove: 0.7707, IoU.palm: 0.5490, IoU.kitchen island: 0.4362, IoU.computer: 0.6917, IoU.swivel chair: 0.6221, IoU.boat: 0.1818, IoU.bar: 0.4279, IoU.arcade machine: 0.8093, IoU.hovel: 0.0293, IoU.bus: 0.7906, IoU.towel: 0.5875, IoU.light: 0.5762, IoU.truck: 0.2751, IoU.tower: 0.4181, IoU.chandelier: 0.7176, IoU.awning: 0.2031, IoU.streetlight: 0.2612, IoU.booth: 0.2503, IoU.television receiver: 0.6021, IoU.airplane: 0.2895, IoU.dirt track: 0.1103, IoU.apparel: 0.3240, IoU.pole: 0.3906, IoU.land: 0.0338, IoU.bannister: 0.1726, IoU.escalator: 0.3313, IoU.ottoman: 0.5281, IoU.bottle: 0.2650, IoU.buffet: 0.3896, IoU.poster: 0.4426, IoU.stage: 0.3633, IoU.van: 0.3562, IoU.ship: 0.1319, IoU.fountain: 0.2945, IoU.conveyer belt: 0.8970, IoU.canopy: 0.3488, IoU.washer: 0.3479, IoU.plaything: 0.2435, IoU.swimming pool: 0.5855, IoU.stool: 0.5086, IoU.barrel: 0.0535, IoU.basket: 0.3711, IoU.waterfall: 0.9264, IoU.tent: 0.0000, IoU.bag: 0.1283, IoU.minibike: 0.7471, IoU.cradle: 0.8290, IoU.oven: 0.5015, IoU.ball: 0.5263, IoU.food: 0.2868, IoU.step: 0.1998, IoU.tank: 0.8739, IoU.trade name: 0.3214, IoU.microwave: 0.7154, IoU.pot: 0.5593, IoU.animal: 0.7533, IoU.bicycle: 0.5924, IoU.lake: 0.0000, IoU.dishwasher: 0.7839, IoU.screen: 0.6207, IoU.blanket: 0.3197, IoU.sculpture: 0.7399, IoU.hood: 0.4332, IoU.sconce: 0.4488, IoU.vase: 0.3231, IoU.traffic light: 0.3280, IoU.tray: 0.1669, IoU.ashcan: 0.3522, IoU.fan: 0.5901, IoU.pier: 0.3201, IoU.crt screen: 0.3028, IoU.plate: 0.5951, IoU.monitor: 0.7617, IoU.bulletin board: 0.5602, IoU.shower: 0.0958, IoU.radiator: 0.5348, IoU.glass: 0.1359, IoU.clock: 0.4241, IoU.flag: 0.4526, Acc.wall: 0.8994, Acc.building: 0.9297, Acc.sky: 0.9721, Acc.floor: 0.9013, Acc.tree: 0.8762, Acc.ceiling: 0.9461, Acc.road: 0.9214, Acc.bed : 0.9729, Acc.windowpane: 0.8401, Acc.grass: 0.8773, Acc.cabinet: 0.7398, Acc.sidewalk: 0.8404, Acc.person: 0.9155, Acc.earth: 0.5475, Acc.door: 0.7355, Acc.table: 0.8101, Acc.mountain: 0.5072, Acc.plant: 0.5793, Acc.curtain: 0.8376, Acc.chair: 0.7437, Acc.car: 0.9129, Acc.water: 0.8538, Acc.painting: 0.8899, Acc.sofa: 0.8328, Acc.shelf: 0.6231, Acc.house: 0.6695, Acc.sea: 0.8722, Acc.mirror: 0.9348, Acc.rug: 0.7958, Acc.field: 0.5082, Acc.armchair: 0.7817, Acc.seat: 0.8764, Acc.fence: 0.4356, Acc.desk: 0.7042, Acc.rock: 0.6248, Acc.wardrobe: 0.7420, Acc.lamp: 0.8087, Acc.bathtub: 0.9700, Acc.railing: 0.6436, Acc.cushion: 0.7254, Acc.base: 0.5949, Acc.box: 0.3948, Acc.column: 0.6266, Acc.signboard: 0.4175, Acc.chest of drawers: 0.6911, Acc.counter: 0.5925, Acc.sand: 0.8680, Acc.sink: 0.7071, Acc.skyscraper: 0.8995, Acc.fireplace: 0.9241, Acc.refrigerator: 0.6710, Acc.grandstand: 0.8387, Acc.path: 0.4258, Acc.stairs: 0.4088, Acc.runway: 0.9977, Acc.case: 0.7192, Acc.pool table: 0.9617, Acc.pillow: 0.6398, Acc.screen door: 0.8580, Acc.stairway: 0.4470, Acc.river: 0.3454, Acc.bridge: 0.8564, Acc.bookcase: 0.5796, Acc.blind: 0.6052, Acc.coffee table: 0.7203, Acc.toilet: 0.9152, Acc.flower: 0.6140, Acc.book: 0.6390, Acc.hill: 0.2447, Acc.bench: 0.3915, Acc.countertop: 0.8270, Acc.stove: 0.9448, Acc.palm: 0.7195, Acc.kitchen island: 0.7275, Acc.computer: 0.8279, Acc.swivel chair: 0.8604, Acc.boat: 0.2018, Acc.bar: 0.4926, Acc.arcade machine: 0.9416, Acc.hovel: 0.0427, Acc.bus: 0.8810, Acc.towel: 0.7336, Acc.light: 0.6661, Acc.truck: 0.3037, Acc.tower: 0.6632, Acc.chandelier: 0.8466, Acc.awning: 0.2198, Acc.streetlight: 0.3298, Acc.booth: 0.2865, Acc.television receiver: 0.7161, Acc.airplane: 0.3054, Acc.dirt track: 0.3146, Acc.apparel: 0.3728, Acc.pole: 0.4882, Acc.land: 0.0415, Acc.bannister: 0.2363, Acc.escalator: 0.3845, Acc.ottoman: 0.7709, Acc.bottle: 0.4342, Acc.buffet: 0.4804, Acc.poster: 0.5789, Acc.stage: 0.5040, Acc.van: 0.4794, Acc.ship: 0.9548, Acc.fountain: 0.3058, Acc.conveyer belt: 0.9741, Acc.canopy: 0.4437, Acc.washer: 0.3481, Acc.plaything: 0.4245, Acc.swimming pool: 0.6458, Acc.stool: 0.6129, Acc.barrel: 0.0535, Acc.basket: 0.4883, Acc.waterfall: 0.9781, Acc.tent: nan, Acc.bag: 0.1421, Acc.minibike: 0.8424, Acc.cradle: 0.9876, Acc.oven: 0.7318, Acc.ball: 0.6716, Acc.food: 0.3064, Acc.step: 0.2363, Acc.tank: 0.8882, Acc.trade name: 0.3745, Acc.microwave: 0.8353, Acc.pot: 0.6269, Acc.animal: 0.7841, Acc.bicycle: 0.7271, Acc.lake: 0.0000, Acc.dishwasher: 0.9218, Acc.screen: 0.8546, Acc.blanket: 0.3328, Acc.sculpture: 0.8797, Acc.hood: 0.5342, Acc.sconce: 0.5408, Acc.vase: 0.5242, Acc.traffic light: 0.4676, Acc.tray: 0.2588, Acc.ashcan: 0.4426, Acc.fan: 0.6454, Acc.pier: 0.4886, Acc.crt screen: 0.3694, Acc.plate: 0.7539, Acc.monitor: 0.8711, Acc.bulletin board: 0.7020, Acc.shower: 0.1008, Acc.radiator: 0.6408, Acc.glass: 0.1467, Acc.clock: 0.5086, Acc.flag: 0.5301
2025-04-29 17:26:05,277 - mmseg - INFO - Iter [10050/20000]	lr: 3.980e-05, eta: 6:21:40, time: 3.383, data_time: 3.090, memory: 75916, decode.loss_ce: 0.1669, decode.acc_seg: 93.6799, loss: 0.1669
2025-04-29 17:28:02,127 - mmseg - INFO - Iter [10100/20000]	lr: 3.960e-05, eta: 6:19:47, time: 2.337, data_time: 2.045, memory: 75916, decode.loss_ce: 0.1848, decode.acc_seg: 93.2826, loss: 0.1848
2025-04-29 17:29:57,410 - mmseg - INFO - Iter [10150/20000]	lr: 3.940e-05, eta: 6:17:52, time: 2.306, data_time: 2.015, memory: 75916, decode.loss_ce: 0.1814, decode.acc_seg: 93.0339, loss: 0.1814
2025-04-29 17:31:48,859 - mmseg - INFO - Iter [10200/20000]	lr: 3.920e-05, eta: 6:15:53, time: 2.229, data_time: 1.938, memory: 75916, decode.loss_ce: 0.1513, decode.acc_seg: 94.2313, loss: 0.1513
2025-04-29 17:33:42,891 - mmseg - INFO - Iter [10250/20000]	lr: 3.900e-05, eta: 6:13:57, time: 2.281, data_time: 1.990, memory: 75916, decode.loss_ce: 0.1594, decode.acc_seg: 93.5847, loss: 0.1594
2025-04-29 17:35:40,732 - mmseg - INFO - Iter [10300/20000]	lr: 3.880e-05, eta: 6:12:05, time: 2.357, data_time: 2.067, memory: 75916, decode.loss_ce: 0.1660, decode.acc_seg: 93.4262, loss: 0.1660
2025-04-29 17:37:32,908 - mmseg - INFO - Iter [10350/20000]	lr: 3.860e-05, eta: 6:10:07, time: 2.244, data_time: 1.951, memory: 75916, decode.loss_ce: 0.1751, decode.acc_seg: 92.9824, loss: 0.1751
2025-04-29 17:39:26,467 - mmseg - INFO - Iter [10400/20000]	lr: 3.840e-05, eta: 6:08:11, time: 2.271, data_time: 1.981, memory: 75916, decode.loss_ce: 0.1634, decode.acc_seg: 93.4332, loss: 0.1634
2025-04-29 17:41:19,254 - mmseg - INFO - Iter [10450/20000]	lr: 3.820e-05, eta: 6:06:14, time: 2.256, data_time: 1.965, memory: 75916, decode.loss_ce: 0.1765, decode.acc_seg: 93.0962, loss: 0.1765
2025-04-29 17:43:16,981 - mmseg - INFO - Iter [10500/20000]	lr: 3.800e-05, eta: 6:04:21, time: 2.355, data_time: 2.063, memory: 75916, decode.loss_ce: 0.1609, decode.acc_seg: 93.2827, loss: 0.1609
2025-04-29 17:45:06,710 - mmseg - INFO - Iter [10550/20000]	lr: 3.780e-05, eta: 6:02:21, time: 2.195, data_time: 1.905, memory: 75916, decode.loss_ce: 0.1481, decode.acc_seg: 94.1005, loss: 0.1481
2025-04-29 17:46:58,148 - mmseg - INFO - Iter [10600/20000]	lr: 3.760e-05, eta: 6:00:23, time: 2.229, data_time: 1.937, memory: 75916, decode.loss_ce: 0.1732, decode.acc_seg: 92.7860, loss: 0.1732
2025-04-29 17:48:55,157 - mmseg - INFO - Iter [10650/20000]	lr: 3.740e-05, eta: 5:58:30, time: 2.340, data_time: 2.048, memory: 75916, decode.loss_ce: 0.1619, decode.acc_seg: 93.6835, loss: 0.1619
2025-04-29 17:50:53,699 - mmseg - INFO - Iter [10700/20000]	lr: 3.720e-05, eta: 5:56:38, time: 2.371, data_time: 2.080, memory: 75916, decode.loss_ce: 0.1530, decode.acc_seg: 93.8230, loss: 0.1530
2025-04-29 17:52:42,499 - mmseg - INFO - Iter [10750/20000]	lr: 3.700e-05, eta: 5:54:37, time: 2.176, data_time: 1.885, memory: 75916, decode.loss_ce: 0.1801, decode.acc_seg: 93.7182, loss: 0.1801
2025-04-29 17:54:32,442 - mmseg - INFO - Iter [10800/20000]	lr: 3.680e-05, eta: 5:52:38, time: 2.199, data_time: 1.906, memory: 75916, decode.loss_ce: 0.1721, decode.acc_seg: 92.8828, loss: 0.1721
2025-04-29 17:56:24,245 - mmseg - INFO - Iter [10850/20000]	lr: 3.660e-05, eta: 5:50:40, time: 2.236, data_time: 1.946, memory: 75916, decode.loss_ce: 0.1664, decode.acc_seg: 93.6824, loss: 0.1664
2025-04-29 17:58:24,336 - mmseg - INFO - Iter [10900/20000]	lr: 3.640e-05, eta: 5:48:50, time: 2.402, data_time: 2.110, memory: 75916, decode.loss_ce: 0.1719, decode.acc_seg: 93.1799, loss: 0.1719
2025-04-29 18:00:12,323 - mmseg - INFO - Iter [10950/20000]	lr: 3.620e-05, eta: 5:46:49, time: 2.160, data_time: 1.870, memory: 75916, decode.loss_ce: 0.1507, decode.acc_seg: 93.9152, loss: 0.1507
2025-04-29 18:01:55,909 - mmseg - INFO - Exp name: vpd_config.py
2025-04-29 18:01:55,910 - mmseg - INFO - Iter [11000/20000]	lr: 3.600e-05, eta: 5:44:44, time: 2.072, data_time: 1.781, memory: 75916, decode.loss_ce: 0.1760, decode.acc_seg: 93.6675, loss: 0.1760
2025-04-29 18:03:46,027 - mmseg - INFO - Iter [11050/20000]	lr: 3.580e-05, eta: 5:42:46, time: 2.202, data_time: 1.911, memory: 75916, decode.loss_ce: 0.1673, decode.acc_seg: 93.2714, loss: 0.1673
2025-04-29 18:05:51,267 - mmseg - INFO - Iter [11100/20000]	lr: 3.560e-05, eta: 5:40:59, time: 2.505, data_time: 2.214, memory: 75916, decode.loss_ce: 0.1634, decode.acc_seg: 93.5302, loss: 0.1634
2025-04-29 18:07:40,565 - mmseg - INFO - Iter [11150/20000]	lr: 3.540e-05, eta: 5:39:00, time: 2.186, data_time: 1.895, memory: 75916, decode.loss_ce: 0.1537, decode.acc_seg: 94.0027, loss: 0.1537
2025-04-29 18:09:30,197 - mmseg - INFO - Iter [11200/20000]	lr: 3.520e-05, eta: 5:37:01, time: 2.193, data_time: 1.902, memory: 75916, decode.loss_ce: 0.1677, decode.acc_seg: 93.4877, loss: 0.1677
2025-04-29 18:10:55,815 - mmseg - INFO - Iter [11250/20000]	lr: 3.500e-05, eta: 5:34:43, time: 1.712, data_time: 1.422, memory: 75916, decode.loss_ce: 0.1690, decode.acc_seg: 93.1980, loss: 0.1690
2025-04-29 18:12:41,087 - mmseg - INFO - Iter [11300/20000]	lr: 3.480e-05, eta: 5:32:41, time: 2.105, data_time: 1.814, memory: 75916, decode.loss_ce: 0.1495, decode.acc_seg: 93.9046, loss: 0.1495
2025-04-29 18:14:17,098 - mmseg - INFO - Iter [11350/20000]	lr: 3.460e-05, eta: 5:30:32, time: 1.920, data_time: 1.630, memory: 75916, decode.loss_ce: 0.1636, decode.acc_seg: 93.2390, loss: 0.1636
2025-04-29 18:16:04,057 - mmseg - INFO - Iter [11400/20000]	lr: 3.440e-05, eta: 5:28:31, time: 2.139, data_time: 1.849, memory: 75916, decode.loss_ce: 0.1486, decode.acc_seg: 94.1078, loss: 0.1486
2025-04-29 18:17:41,202 - mmseg - INFO - Iter [11450/20000]	lr: 3.420e-05, eta: 5:26:24, time: 1.943, data_time: 1.651, memory: 75916, decode.loss_ce: 0.1596, decode.acc_seg: 93.5212, loss: 0.1596
2025-04-29 18:19:46,575 - mmseg - INFO - Iter [11500/20000]	lr: 3.400e-05, eta: 5:24:37, time: 2.507, data_time: 2.215, memory: 75916, decode.loss_ce: 0.1505, decode.acc_seg: 93.7595, loss: 0.1505
2025-04-29 18:21:30,298 - mmseg - INFO - Iter [11550/20000]	lr: 3.380e-05, eta: 5:22:35, time: 2.074, data_time: 1.785, memory: 75916, decode.loss_ce: 0.1653, decode.acc_seg: 93.6427, loss: 0.1653
2025-04-29 18:23:14,324 - mmseg - INFO - Iter [11600/20000]	lr: 3.360e-05, eta: 5:20:33, time: 2.080, data_time: 1.791, memory: 75916, decode.loss_ce: 0.1685, decode.acc_seg: 93.4781, loss: 0.1685
2025-04-29 18:25:02,993 - mmseg - INFO - Iter [11650/20000]	lr: 3.340e-05, eta: 5:18:34, time: 2.173, data_time: 1.884, memory: 75916, decode.loss_ce: 0.1554, decode.acc_seg: 93.9125, loss: 0.1554
2025-04-29 18:27:08,103 - mmseg - INFO - Iter [11700/20000]	lr: 3.320e-05, eta: 5:16:47, time: 2.502, data_time: 2.212, memory: 75916, decode.loss_ce: 0.1753, decode.acc_seg: 93.3244, loss: 0.1753
2025-04-29 18:28:56,563 - mmseg - INFO - Iter [11750/20000]	lr: 3.300e-05, eta: 5:14:48, time: 2.169, data_time: 1.879, memory: 75916, decode.loss_ce: 0.1753, decode.acc_seg: 93.2013, loss: 0.1753
2025-04-29 18:30:45,867 - mmseg - INFO - Iter [11800/20000]	lr: 3.280e-05, eta: 5:12:50, time: 2.186, data_time: 1.897, memory: 75916, decode.loss_ce: 0.2074, decode.acc_seg: 92.2398, loss: 0.2074
2025-04-29 18:32:35,143 - mmseg - INFO - Iter [11850/20000]	lr: 3.260e-05, eta: 5:10:52, time: 2.185, data_time: 1.895, memory: 75916, decode.loss_ce: 0.1460, decode.acc_seg: 94.0501, loss: 0.1460
2025-04-29 18:34:26,039 - mmseg - INFO - Iter [11900/20000]	lr: 3.240e-05, eta: 5:08:55, time: 2.218, data_time: 1.928, memory: 75916, decode.loss_ce: 0.1547, decode.acc_seg: 93.5479, loss: 0.1547
2025-04-29 18:36:14,976 - mmseg - INFO - Iter [11950/20000]	lr: 3.220e-05, eta: 5:06:57, time: 2.179, data_time: 1.887, memory: 75916, decode.loss_ce: 0.1638, decode.acc_seg: 93.5419, loss: 0.1638
2025-04-29 18:38:18,553 - mmseg - INFO - Saving checkpoint at 12000 iterations
2025-04-29 18:38:27,873 - mmseg - INFO - Exp name: vpd_config.py
2025-04-29 18:38:27,874 - mmseg - INFO - Iter [12000/20000]	lr: 3.200e-05, eta: 5:05:15, time: 2.658, data_time: 2.182, memory: 75916, decode.loss_ce: 0.1795, decode.acc_seg: 93.1397, loss: 0.1795
2025-04-29 18:39:59,426 - mmseg - INFO - per class results:
2025-04-29 18:39:59,433 - mmseg - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        | 79.81 | 89.56 |
|       building      | 85.78 | 94.09 |
|         sky         | 93.64 | 97.21 |
|        floor        | 82.26 | 90.15 |
|         tree        | 74.08 | 87.76 |
|       ceiling       | 86.87 |  95.0 |
|         road        |  85.9 | 92.15 |
|         bed         | 90.85 | 97.63 |
|      windowpane     | 67.31 | 83.55 |
|        grass        | 75.05 | 88.11 |
|       cabinet       | 58.21 | 73.49 |
|       sidewalk      | 68.47 | 83.27 |
|        person       | 81.28 | 92.26 |
|        earth        | 31.98 | 55.71 |
|         door        |  59.4 | 74.12 |
|        table        |  66.0 | 80.59 |
|       mountain      | 33.26 | 44.24 |
|        plant        | 50.57 | 57.78 |
|       curtain       | 73.29 | 82.99 |
|        chair        |  64.7 | 76.69 |
|         car         | 83.11 | 90.64 |
|        water        | 50.78 | 86.22 |
|       painting      | 76.65 | 87.98 |
|         sofa        |  72.6 | 83.23 |
|        shelf        | 49.65 | 65.41 |
|        house        |  46.3 | 65.29 |
|         sea         | 69.69 | 88.69 |
|        mirror       | 82.34 | 90.96 |
|         rug         | 65.61 | 78.13 |
|        field        | 34.13 | 50.69 |
|       armchair      | 52.04 | 74.32 |
|         seat        | 57.25 | 86.22 |
|        fence        | 26.93 | 41.94 |
|         desk        |  46.2 | 72.89 |
|         rock        | 48.26 | 64.63 |
|       wardrobe      |  56.0 | 75.54 |
|         lamp        | 68.23 | 81.52 |
|       bathtub       | 92.05 | 96.16 |
|       railing       | 45.22 | 61.21 |
|       cushion       | 62.19 | 73.78 |
|         base        | 26.74 | 53.97 |
|         box         | 31.94 | 40.16 |
|        column       | 53.85 | 61.31 |
|      signboard      |  31.3 | 41.55 |
|   chest of drawers  |  49.0 | 69.72 |
|       counter       |  44.1 | 59.56 |
|         sand        | 55.28 | 62.75 |
|         sink        | 67.24 | 72.68 |
|      skyscraper     | 48.12 | 94.18 |
|      fireplace      | 68.38 | 94.04 |
|     refrigerator    | 61.82 | 66.44 |
|      grandstand     |  47.0 | 83.87 |
|         path        | 32.62 | 37.93 |
|        stairs       | 34.75 |  40.7 |
|        runway       | 94.01 | 99.66 |
|         case        | 43.28 | 69.15 |
|      pool table     | 92.66 | 95.91 |
|        pillow       | 53.87 | 59.84 |
|     screen door     | 81.78 |  85.0 |
|       stairway      | 33.68 | 44.27 |
|        river        | 27.82 | 31.37 |
|        bridge       | 67.65 | 87.12 |
|       bookcase      | 43.19 | 59.78 |
|        blind        | 59.77 | 62.09 |
|     coffee table    | 59.81 | 72.71 |
|        toilet       | 86.71 | 91.48 |
|        flower       | 50.81 | 61.92 |
|         book        | 42.53 | 62.73 |
|         hill        | 17.48 | 25.18 |
|        bench        | 45.91 | 53.51 |
|      countertop     | 59.41 | 81.72 |
|        stove        |  79.6 | 93.55 |
|         palm        | 54.33 | 71.86 |
|    kitchen island   | 42.09 |  69.1 |
|       computer      | 68.61 | 81.93 |
|     swivel chair    | 60.52 | 78.88 |
|         boat        | 17.31 | 19.13 |
|         bar         |  41.2 |  47.9 |
|    arcade machine   | 79.92 | 95.02 |
|        hovel        |  3.64 |  5.25 |
|         bus         | 80.59 | 89.24 |
|        towel        | 59.64 | 75.06 |
|        light        |  55.4 | 62.61 |
|        truck        |  27.0 | 31.27 |
|        tower        | 38.39 |  60.1 |
|      chandelier     | 71.89 | 84.74 |
|        awning       | 19.89 |  21.5 |
|     streetlight     | 27.18 | 36.28 |
|        booth        | 26.02 |  27.9 |
| television receiver | 60.33 | 69.09 |
|       airplane      | 34.15 | 36.37 |
|      dirt track     |  9.63 | 34.26 |
|       apparel       |  32.3 |  36.0 |
|         pole        |  38.3 | 48.99 |
|         land        |  3.36 |  4.14 |
|      bannister      | 17.47 | 24.74 |
|      escalator      | 32.56 | 37.78 |
|       ottoman       | 54.12 | 78.82 |
|        bottle       | 26.49 | 43.15 |
|        buffet       | 39.03 | 48.61 |
|        poster       | 46.11 | 59.18 |
|        stage        | 42.92 |  63.0 |
|         van         | 36.82 | 49.01 |
|         ship        | 12.78 |  95.8 |
|       fountain      | 29.74 | 32.19 |
|    conveyer belt    | 87.79 | 97.31 |
|        canopy       | 38.73 | 45.68 |
|        washer       | 36.93 | 36.95 |
|      plaything      |  27.0 | 50.91 |
|    swimming pool    |  62.5 | 66.67 |
|        stool        |  45.3 | 63.78 |
|        barrel       |  59.1 |  59.1 |
|        basket       | 38.32 | 48.77 |
|      waterfall      |  92.5 | 97.86 |
|         tent        |  0.0  |  nan  |
|         bag         | 16.11 | 18.79 |
|       minibike      | 74.31 | 86.27 |
|        cradle       | 82.08 | 99.06 |
|         oven        | 47.77 | 75.33 |
|         ball        | 53.27 | 66.49 |
|         food        | 34.74 | 39.95 |
|         step        | 25.46 |  32.1 |
|         tank        | 80.94 | 84.51 |
|      trade name     | 30.15 | 34.65 |
|      microwave      | 71.46 | 83.17 |
|         pot         | 56.32 |  65.8 |
|        animal       | 75.08 | 78.26 |
|       bicycle       | 57.82 | 76.86 |
|         lake        |  0.0  |  0.0  |
|      dishwasher     | 77.25 | 92.26 |
|        screen       | 66.01 | 80.63 |
|       blanket       | 33.56 | 35.29 |
|      sculpture      | 74.13 | 84.23 |
|         hood        | 41.09 | 47.36 |
|        sconce       |  47.4 | 60.17 |
|         vase        | 33.63 | 50.72 |
|    traffic light    | 32.13 | 44.21 |
|         tray        | 17.29 | 28.48 |
|        ashcan       | 35.64 | 45.01 |
|         fan         |  63.3 | 70.46 |
|         pier        | 31.76 |  49.5 |
|      crt screen     | 31.43 | 42.27 |
|        plate        | 60.43 | 77.62 |
|       monitor       | 78.62 |  91.0 |
|    bulletin board   | 52.63 | 71.04 |
|        shower       |  8.64 |  8.83 |
|       radiator      | 54.74 | 64.16 |
|        glass        | 14.75 | 16.17 |
|        clock        | 44.04 | 53.49 |
|         flag        | 45.31 | 55.76 |
+---------------------+-------+-------+
2025-04-29 18:39:59,433 - mmseg - INFO - Summary:
2025-04-29 18:39:59,433 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 84.21 | 51.42 | 64.18 |
+-------+-------+-------+
2025-04-29 18:39:59,434 - mmseg - INFO - Exp name: vpd_config.py
2025-04-29 18:39:59,434 - mmseg - INFO - Iter(val) [851]	aAcc: 0.8421, mIoU: 0.5142, mAcc: 0.6418, IoU.wall: 0.7981, IoU.building: 0.8578, IoU.sky: 0.9364, IoU.floor: 0.8226, IoU.tree: 0.7408, IoU.ceiling: 0.8687, IoU.road: 0.8590, IoU.bed : 0.9085, IoU.windowpane: 0.6731, IoU.grass: 0.7505, IoU.cabinet: 0.5821, IoU.sidewalk: 0.6847, IoU.person: 0.8128, IoU.earth: 0.3198, IoU.door: 0.5940, IoU.table: 0.6600, IoU.mountain: 0.3326, IoU.plant: 0.5057, IoU.curtain: 0.7329, IoU.chair: 0.6470, IoU.car: 0.8311, IoU.water: 0.5078, IoU.painting: 0.7665, IoU.sofa: 0.7260, IoU.shelf: 0.4965, IoU.house: 0.4630, IoU.sea: 0.6969, IoU.mirror: 0.8234, IoU.rug: 0.6561, IoU.field: 0.3413, IoU.armchair: 0.5204, IoU.seat: 0.5725, IoU.fence: 0.2693, IoU.desk: 0.4620, IoU.rock: 0.4826, IoU.wardrobe: 0.5600, IoU.lamp: 0.6823, IoU.bathtub: 0.9205, IoU.railing: 0.4522, IoU.cushion: 0.6219, IoU.base: 0.2674, IoU.box: 0.3194, IoU.column: 0.5385, IoU.signboard: 0.3130, IoU.chest of drawers: 0.4900, IoU.counter: 0.4410, IoU.sand: 0.5528, IoU.sink: 0.6724, IoU.skyscraper: 0.4812, IoU.fireplace: 0.6838, IoU.refrigerator: 0.6182, IoU.grandstand: 0.4700, IoU.path: 0.3262, IoU.stairs: 0.3475, IoU.runway: 0.9401, IoU.case: 0.4328, IoU.pool table: 0.9266, IoU.pillow: 0.5387, IoU.screen door: 0.8178, IoU.stairway: 0.3368, IoU.river: 0.2782, IoU.bridge: 0.6765, IoU.bookcase: 0.4319, IoU.blind: 0.5977, IoU.coffee table: 0.5981, IoU.toilet: 0.8671, IoU.flower: 0.5081, IoU.book: 0.4253, IoU.hill: 0.1748, IoU.bench: 0.4591, IoU.countertop: 0.5941, IoU.stove: 0.7960, IoU.palm: 0.5433, IoU.kitchen island: 0.4209, IoU.computer: 0.6861, IoU.swivel chair: 0.6052, IoU.boat: 0.1731, IoU.bar: 0.4120, IoU.arcade machine: 0.7992, IoU.hovel: 0.0364, IoU.bus: 0.8059, IoU.towel: 0.5964, IoU.light: 0.5540, IoU.truck: 0.2700, IoU.tower: 0.3839, IoU.chandelier: 0.7189, IoU.awning: 0.1989, IoU.streetlight: 0.2718, IoU.booth: 0.2602, IoU.television receiver: 0.6033, IoU.airplane: 0.3415, IoU.dirt track: 0.0963, IoU.apparel: 0.3230, IoU.pole: 0.3830, IoU.land: 0.0336, IoU.bannister: 0.1747, IoU.escalator: 0.3256, IoU.ottoman: 0.5412, IoU.bottle: 0.2649, IoU.buffet: 0.3903, IoU.poster: 0.4611, IoU.stage: 0.4292, IoU.van: 0.3682, IoU.ship: 0.1278, IoU.fountain: 0.2974, IoU.conveyer belt: 0.8779, IoU.canopy: 0.3873, IoU.washer: 0.3693, IoU.plaything: 0.2700, IoU.swimming pool: 0.6250, IoU.stool: 0.4530, IoU.barrel: 0.5910, IoU.basket: 0.3832, IoU.waterfall: 0.9250, IoU.tent: 0.0000, IoU.bag: 0.1611, IoU.minibike: 0.7431, IoU.cradle: 0.8208, IoU.oven: 0.4777, IoU.ball: 0.5327, IoU.food: 0.3474, IoU.step: 0.2546, IoU.tank: 0.8094, IoU.trade name: 0.3015, IoU.microwave: 0.7146, IoU.pot: 0.5632, IoU.animal: 0.7508, IoU.bicycle: 0.5782, IoU.lake: 0.0000, IoU.dishwasher: 0.7725, IoU.screen: 0.6601, IoU.blanket: 0.3356, IoU.sculpture: 0.7413, IoU.hood: 0.4109, IoU.sconce: 0.4740, IoU.vase: 0.3363, IoU.traffic light: 0.3213, IoU.tray: 0.1729, IoU.ashcan: 0.3564, IoU.fan: 0.6330, IoU.pier: 0.3176, IoU.crt screen: 0.3143, IoU.plate: 0.6043, IoU.monitor: 0.7862, IoU.bulletin board: 0.5263, IoU.shower: 0.0864, IoU.radiator: 0.5474, IoU.glass: 0.1475, IoU.clock: 0.4404, IoU.flag: 0.4531, Acc.wall: 0.8956, Acc.building: 0.9409, Acc.sky: 0.9721, Acc.floor: 0.9015, Acc.tree: 0.8776, Acc.ceiling: 0.9500, Acc.road: 0.9215, Acc.bed : 0.9763, Acc.windowpane: 0.8355, Acc.grass: 0.8811, Acc.cabinet: 0.7349, Acc.sidewalk: 0.8327, Acc.person: 0.9226, Acc.earth: 0.5571, Acc.door: 0.7412, Acc.table: 0.8059, Acc.mountain: 0.4424, Acc.plant: 0.5778, Acc.curtain: 0.8299, Acc.chair: 0.7669, Acc.car: 0.9064, Acc.water: 0.8622, Acc.painting: 0.8798, Acc.sofa: 0.8323, Acc.shelf: 0.6541, Acc.house: 0.6529, Acc.sea: 0.8869, Acc.mirror: 0.9096, Acc.rug: 0.7813, Acc.field: 0.5069, Acc.armchair: 0.7432, Acc.seat: 0.8622, Acc.fence: 0.4194, Acc.desk: 0.7289, Acc.rock: 0.6463, Acc.wardrobe: 0.7554, Acc.lamp: 0.8152, Acc.bathtub: 0.9616, Acc.railing: 0.6121, Acc.cushion: 0.7378, Acc.base: 0.5397, Acc.box: 0.4016, Acc.column: 0.6131, Acc.signboard: 0.4155, Acc.chest of drawers: 0.6972, Acc.counter: 0.5956, Acc.sand: 0.6275, Acc.sink: 0.7268, Acc.skyscraper: 0.9418, Acc.fireplace: 0.9404, Acc.refrigerator: 0.6644, Acc.grandstand: 0.8387, Acc.path: 0.3793, Acc.stairs: 0.4070, Acc.runway: 0.9966, Acc.case: 0.6915, Acc.pool table: 0.9591, Acc.pillow: 0.5984, Acc.screen door: 0.8500, Acc.stairway: 0.4427, Acc.river: 0.3137, Acc.bridge: 0.8712, Acc.bookcase: 0.5978, Acc.blind: 0.6209, Acc.coffee table: 0.7271, Acc.toilet: 0.9148, Acc.flower: 0.6192, Acc.book: 0.6273, Acc.hill: 0.2518, Acc.bench: 0.5351, Acc.countertop: 0.8172, Acc.stove: 0.9355, Acc.palm: 0.7186, Acc.kitchen island: 0.6910, Acc.computer: 0.8193, Acc.swivel chair: 0.7888, Acc.boat: 0.1913, Acc.bar: 0.4790, Acc.arcade machine: 0.9502, Acc.hovel: 0.0525, Acc.bus: 0.8924, Acc.towel: 0.7506, Acc.light: 0.6261, Acc.truck: 0.3127, Acc.tower: 0.6010, Acc.chandelier: 0.8474, Acc.awning: 0.2150, Acc.streetlight: 0.3628, Acc.booth: 0.2790, Acc.television receiver: 0.6909, Acc.airplane: 0.3637, Acc.dirt track: 0.3426, Acc.apparel: 0.3600, Acc.pole: 0.4899, Acc.land: 0.0414, Acc.bannister: 0.2474, Acc.escalator: 0.3778, Acc.ottoman: 0.7882, Acc.bottle: 0.4315, Acc.buffet: 0.4861, Acc.poster: 0.5918, Acc.stage: 0.6300, Acc.van: 0.4901, Acc.ship: 0.9580, Acc.fountain: 0.3219, Acc.conveyer belt: 0.9731, Acc.canopy: 0.4568, Acc.washer: 0.3695, Acc.plaything: 0.5091, Acc.swimming pool: 0.6667, Acc.stool: 0.6378, Acc.barrel: 0.5910, Acc.basket: 0.4877, Acc.waterfall: 0.9786, Acc.tent: nan, Acc.bag: 0.1879, Acc.minibike: 0.8627, Acc.cradle: 0.9906, Acc.oven: 0.7533, Acc.ball: 0.6649, Acc.food: 0.3995, Acc.step: 0.3210, Acc.tank: 0.8451, Acc.trade name: 0.3465, Acc.microwave: 0.8317, Acc.pot: 0.6580, Acc.animal: 0.7826, Acc.bicycle: 0.7686, Acc.lake: 0.0000, Acc.dishwasher: 0.9226, Acc.screen: 0.8063, Acc.blanket: 0.3529, Acc.sculpture: 0.8423, Acc.hood: 0.4736, Acc.sconce: 0.6017, Acc.vase: 0.5072, Acc.traffic light: 0.4421, Acc.tray: 0.2848, Acc.ashcan: 0.4501, Acc.fan: 0.7046, Acc.pier: 0.4950, Acc.crt screen: 0.4227, Acc.plate: 0.7762, Acc.monitor: 0.9100, Acc.bulletin board: 0.7104, Acc.shower: 0.0883, Acc.radiator: 0.6416, Acc.glass: 0.1617, Acc.clock: 0.5349, Acc.flag: 0.5576
2025-04-29 18:42:07,747 - mmseg - INFO - Iter [12050/20000]	lr: 3.180e-05, eta: 5:04:30, time: 4.397, data_time: 3.699, memory: 75916, decode.loss_ce: 0.1631, decode.acc_seg: 93.3965, loss: 0.1631
2025-04-29 18:43:55,452 - mmseg - INFO - Iter [12100/20000]	lr: 3.160e-05, eta: 5:02:31, time: 2.154, data_time: 1.864, memory: 75916, decode.loss_ce: 0.1575, decode.acc_seg: 93.5219, loss: 0.1575
2025-04-29 18:45:43,143 - mmseg - INFO - Iter [12150/20000]	lr: 3.140e-05, eta: 5:00:31, time: 2.154, data_time: 1.863, memory: 75916, decode.loss_ce: 0.1681, decode.acc_seg: 93.5994, loss: 0.1681
2025-04-29 18:47:31,402 - mmseg - INFO - Iter [12200/20000]	lr: 3.120e-05, eta: 4:58:32, time: 2.165, data_time: 1.876, memory: 75916, decode.loss_ce: 0.1958, decode.acc_seg: 93.1938, loss: 0.1958
2025-04-29 18:49:32,662 - mmseg - INFO - Iter [12250/20000]	lr: 3.100e-05, eta: 4:56:41, time: 2.425, data_time: 2.136, memory: 75916, decode.loss_ce: 0.1696, decode.acc_seg: 93.2669, loss: 0.1696
2025-04-29 18:51:20,899 - mmseg - INFO - Iter [12300/20000]	lr: 3.080e-05, eta: 4:54:42, time: 2.165, data_time: 1.873, memory: 75916, decode.loss_ce: 0.1622, decode.acc_seg: 93.1536, loss: 0.1622
2025-04-29 18:53:09,140 - mmseg - INFO - Iter [12350/20000]	lr: 3.060e-05, eta: 4:52:43, time: 2.165, data_time: 1.875, memory: 75916, decode.loss_ce: 0.1487, decode.acc_seg: 93.8474, loss: 0.1487
2025-04-29 18:54:57,028 - mmseg - INFO - Iter [12400/20000]	lr: 3.040e-05, eta: 4:50:44, time: 2.158, data_time: 1.868, memory: 75916, decode.loss_ce: 0.1657, decode.acc_seg: 93.8110, loss: 0.1657
2025-04-29 18:56:56,509 - mmseg - INFO - Iter [12450/20000]	lr: 3.020e-05, eta: 4:48:52, time: 2.390, data_time: 2.101, memory: 75916, decode.loss_ce: 0.1520, decode.acc_seg: 93.8645, loss: 0.1520
2025-04-29 18:58:43,582 - mmseg - INFO - Iter [12500/20000]	lr: 3.000e-05, eta: 4:46:53, time: 2.141, data_time: 1.852, memory: 75916, decode.loss_ce: 0.1595, decode.acc_seg: 93.7475, loss: 0.1595
2025-04-29 19:00:31,477 - mmseg - INFO - Iter [12550/20000]	lr: 2.980e-05, eta: 4:44:54, time: 2.158, data_time: 1.868, memory: 75916, decode.loss_ce: 0.1692, decode.acc_seg: 93.4878, loss: 0.1692
User defined signal 2
