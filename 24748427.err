Loaded dependency [python3/3.11.4]: gcc/12.3.0-binutils-2.40
Loaded dependency [python3/3.11.4]: sqlite3/3.42.0
Loaded module: python3/3.11.4

Loading python3/3.11.4
  Loading requirement: gcc/12.3.0-binutils-2.40 sqlite3/3.42.0
Loaded module: cuda/11.3
/dtu/blackhole/0e/154958/miniconda3/envs/ldm/lib/python3.8/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
2025-04-22 07:53:29,944 - mmseg - INFO - Multi-processing start method is `None`
2025-04-22 07:53:30,022 - mmseg - INFO - OpenCV num_threads is `1
2025-04-22 07:53:30,022 - mmseg - INFO - OMP num threads is 1
2025-04-22 07:53:30,114 - mmseg - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.8.19 | packaged by conda-forge | (default, Mar 20 2024, 12:47:35) [GCC 12.3.0]
CUDA available: True
GPU 0: Tesla V100-PCIE-16GB
CUDA_HOME: /appl/cuda/11.3.0
NVCC: Cuda compilation tools, release 11.3, V11.3.58
GCC: gcc (GCC) 12.3.0
PyTorch: 1.11.0+cu113
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.5.2 (Git Hash a9302535553c73243c632ad3c4c80beec3d19a1e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.11.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

TorchVision: 0.12.0+cu113
OpenCV: 4.6.0
MMCV: 1.5.0
MMCV Compiler: GCC 7.3
MMCV CUDA Compiler: 11.3
MMSegmentation: 0.29.0+026b02c
------------------------------------------------------------

2025-04-22 07:53:30,114 - mmseg - INFO - Distributed training: False
2025-04-22 07:53:30,855 - mmseg - INFO - Config:
norm_cfg = dict(type='SyncBN', requires_grad=True)
model = dict(
    type='VPDSeg',
    pretrained='open-mmlab://resnet50_v1c',
    backbone=dict(
        type='ResNetV1c',
        depth=50,
        num_stages=4,
        out_indices=(0, 1, 2, 3),
        dilations=(1, 1, 1, 1),
        strides=(1, 2, 2, 2),
        norm_cfg=dict(type='SyncBN', requires_grad=True),
        norm_eval=False,
        style='pytorch',
        contract_dilation=True),
    neck=dict(
        type='FPN',
        in_channels=[320, 790, 1430, 1280],
        out_channels=256,
        num_outs=4),
    decode_head=dict(
        type='FPNHead',
        in_channels=[256, 256, 256, 256],
        in_index=[0, 1, 2, 3],
        feature_strides=[4, 8, 16, 32],
        channels=256,
        dropout_ratio=0.1,
        num_classes=150,
        norm_cfg=dict(type='SyncBN', requires_grad=True),
        align_corners=False,
        loss_decode=dict(
            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0)),
    train_cfg=dict(),
    test_cfg=dict(mode='whole', crop_size=(512, 512), stride=(341, 341)),
    sd_path='/work3/s203557/checkpoints/v1-5-pruned-emaonly.ckpt',
    sd_config=
    '/zhome/b6/d/154958/ADLCV_Project/VPD/segmentation/v1-inference.yaml',
    max_boxes=6)
dataset_type = 'ADE20KDataset'
data_root = '/work3/s203557/data/ade20k-dataset/versions/2/ADEChallengeData2016'
IMG_MEAN = [127.5, 127.5, 127.5]
IMG_VAR = [127.5, 127.5, 127.5]
img_norm_cfg = dict(
    mean=[127.5, 127.5, 127.5], std=[127.5, 127.5, 127.5], to_rgb=True)
crop_size = (512, 512)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations', reduce_zero_label=True),
    dict(type='Resize', img_scale=(2048, 512), ratio_range=(0.5, 2.0)),
    dict(type='RandomCrop', crop_size=(512, 512), cat_max_ratio=0.75),
    dict(type='RandomFlip', prob=0.5),
    dict(type='PhotoMetricDistortion'),
    dict(
        type='Normalize',
        mean=[127.5, 127.5, 127.5],
        std=[127.5, 127.5, 127.5],
        to_rgb=True),
    dict(type='Pad', size=(512, 512), pad_val=0, seg_pad_val=255),
    dict(type='GenerateBoundingBoxMasksFromSeg', max_boxes=6),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_semantic_seg', 'gt_bbox_masks'])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(2048, 512),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='RandomFlip'),
            dict(
                type='Normalize',
                mean=[127.5, 127.5, 127.5],
                std=[127.5, 127.5, 127.5],
                to_rgb=True),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ])
]
data = dict(
    samples_per_gpu=4,
    workers_per_gpu=8,
    train=dict(
        type='ADE20KDataset',
        data_root=
        '/work3/s203557/data/ade20k-dataset/versions/2/ADEChallengeData2016',
        img_dir='images/training',
        ann_dir='annotations/training',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations', reduce_zero_label=True),
            dict(type='Resize', img_scale=(2048, 512), ratio_range=(0.5, 2.0)),
            dict(type='RandomCrop', crop_size=(512, 512), cat_max_ratio=0.75),
            dict(type='RandomFlip', prob=0.5),
            dict(type='PhotoMetricDistortion'),
            dict(
                type='Normalize',
                mean=[127.5, 127.5, 127.5],
                std=[127.5, 127.5, 127.5],
                to_rgb=True),
            dict(type='Pad', size=(512, 512), pad_val=0, seg_pad_val=255),
            dict(type='GenerateBoundingBoxMasksFromSeg', max_boxes=6),
            dict(type='DefaultFormatBundle'),
            dict(
                type='Collect',
                keys=['img', 'gt_semantic_seg', 'gt_bbox_masks'])
        ]),
    val=dict(
        type='ADE20KDataset',
        data_root=
        '/work3/s203557/data/ade20k-dataset/versions/2/ADEChallengeData2016',
        img_dir='images/validation',
        ann_dir='annotations/validation',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(2048, 512),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[127.5, 127.5, 127.5],
                        std=[127.5, 127.5, 127.5],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]),
    test=dict(
        type='ADE20KDataset',
        data_root=
        '/work3/s203557/data/ade20k-dataset/versions/2/ADEChallengeData2016',
        img_dir='images/validation',
        ann_dir='annotations/validation',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(2048, 512),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[127.5, 127.5, 127.5],
                        std=[127.5, 127.5, 127.5],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]))
log_config = dict(
    interval=50, hooks=[dict(type='TextLoggerHook', by_epoch=False)])
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = '/work3/s203557/checkpoints/vpd.chkpt'
resume_from = None
workflow = [('train', 1)]
cudnn_benchmark = True
find_unused_parameters = True
optimizer = dict(
    type='AdamW',
    lr=8e-05,
    weight_decay=0.001,
    paramwise_cfg=dict(
        custom_keys=dict(
            unet=dict(lr_mult=0.1),
            encoder_vq=dict(lr_mult=0.0),
            text_encoder=dict(lr_mult=0.0),
            norm=dict(decay_mult=0.0))))
optimizer_config = dict()
lr_config = dict(
    policy='poly',
    power=1,
    min_lr=0.0,
    by_epoch=False,
    warmup='linear',
    warmup_iters=1500,
    warmup_ratio=1e-06)
runner = dict(type='IterBasedRunner', max_iters=10000)
checkpoint_config = dict(by_epoch=False, interval=1000)
evaluation = dict(interval=1000, metric='mIoU')
custom_imports = dict(
    imports=['segmentation.hooks.visualize_hook'], allow_failed_imports=False)
work_dir = '/work3/s203557/experiments/control_net_vpd/'
fp16 = dict(loss_scale=512.0)
custom_hooks = [
    dict(
        type='TrainVisualizeHook',
        interval=1000,
        num_samples=2,
        save_dir='vis')
]
gpu_ids = [0]
auto_resume = False

2025-04-22 07:53:30,856 - mmseg - INFO - Set random seed to 1764436587, deterministic: False
/dtu/blackhole/0e/154958/miniconda3/envs/ldm/lib/python3.8/site-packages/mmseg/models/losses/cross_entropy_loss.py:235: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.
  warnings.warn(
2025-04-22 07:53:42,858 - mmseg - INFO - initialize FPN with init_cfg {'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}
2025-04-22 07:53:42,879 - mmseg - INFO - initialize FPNHead with init_cfg {'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
segmentation/train.py:238: UserWarning: SyncBN is only supported with DDP. To be compatible with DP, we convert SyncBN to BN. Please use dist_train.sh which can avoid this error.
  warnings.warn(
2025-04-22 07:53:43,639 - mmseg - INFO - VPDSeg(
  (encoder_vq): AutoencoderKL(
    (encoder): Encoder(
      (conv_in): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (down): ModuleList(
        (0): Module(
          (block): ModuleList(
            (0): ResnetBlock(
              (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)
              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
            (1): ResnetBlock(
              (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)
              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (attn): ModuleList()
          (downsample): Downsample(
            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2))
          )
        )
        (1): Module(
          (block): ModuleList(
            (0): ResnetBlock(
              (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)
              (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (nin_shortcut): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): ResnetBlock(
              (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (attn): ModuleList()
          (downsample): Downsample(
            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))
          )
        )
        (2): Module(
          (block): ModuleList(
            (0): ResnetBlock(
              (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)
              (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (nin_shortcut): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): ResnetBlock(
              (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)
              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (attn): ModuleList()
          (downsample): Downsample(
            (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2))
          )
        )
        (3): Module(
          (block): ModuleList(
            (0): ResnetBlock(
              (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)
              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
            (1): ResnetBlock(
              (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)
              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (attn): ModuleList()
        )
      )
      (mid): Module(
        (block_1): ResnetBlock(
          (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)
          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (attn_1): AttnBlock(
          (norm): GroupNorm(32, 512, eps=1e-06, affine=True)
          (q): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (k): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (v): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (proj_out): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
        )
        (block_2): ResnetBlock(
          (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)
          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (norm_out): GroupNorm(32, 512, eps=1e-06, affine=True)
      (conv_out): Conv2d(512, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (loss): Identity()
    (quant_conv): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1))
    (post_quant_conv): Conv2d(4, 4, kernel_size=(1, 1), stride=(1, 1))
  )
  (unet): UNetWrapper(
    (unet): DiffusionWrapper(
      (diffusion_model): UNetModel(
        (time_embed): Sequential(
          (0): Linear(in_features=320, out_features=1280, bias=True)
          (1): SiLU()
          (2): Linear(in_features=1280, out_features=1280, bias=True)
        )
        (input_blocks): ModuleList(
          (0): TimestepEmbedSequential(
            (0): Conv2d(4, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (1): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=320, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Identity()
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 320, eps=1e-06, affine=True)
              (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=320, out_features=320, bias=False)
                    (to_v): Linear(in_features=320, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=320, out_features=2560, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=1280, out_features=320, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=768, out_features=320, bias=False)
                    (to_v): Linear(in_features=768, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (2): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=320, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Identity()
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 320, eps=1e-06, affine=True)
              (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=320, out_features=320, bias=False)
                    (to_v): Linear(in_features=320, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=320, out_features=2560, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=1280, out_features=320, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=768, out_features=320, bias=False)
                    (to_v): Linear(in_features=768, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (3): TimestepEmbedSequential(
            (0): Downsample(
              (op): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
            )
          )
          (4): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(320, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=640, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(320, 640, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 640, eps=1e-06, affine=True)
              (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=640, out_features=640, bias=False)
                    (to_v): Linear(in_features=640, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=640, out_features=5120, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=2560, out_features=640, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=768, out_features=640, bias=False)
                    (to_v): Linear(in_features=768, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (5): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=640, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Identity()
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 640, eps=1e-06, affine=True)
              (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=640, out_features=640, bias=False)
                    (to_v): Linear(in_features=640, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=640, out_features=5120, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=2560, out_features=640, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=768, out_features=640, bias=False)
                    (to_v): Linear(in_features=768, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (6): TimestepEmbedSequential(
            (0): Downsample(
              (op): Conv2d(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
            )
          )
          (7): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(640, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(640, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)
              (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_v): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=1280, out_features=10240, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=5120, out_features=1280, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=768, out_features=1280, bias=False)
                    (to_v): Linear(in_features=768, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (8): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Identity()
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)
              (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_v): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=1280, out_features=10240, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=5120, out_features=1280, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=768, out_features=1280, bias=False)
                    (to_v): Linear(in_features=768, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (9): TimestepEmbedSequential(
            (0): Downsample(
              (op): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
            )
          )
          (10): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Identity()
            )
          )
          (11): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Identity()
            )
          )
        )
        (middle_block): TimestepEmbedSequential(
          (0): ResBlock(
            (in_layers): Sequential(
              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
              (1): SiLU()
              (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
            (h_upd): Identity()
            (x_upd): Identity()
            (emb_layers): Sequential(
              (0): SiLU()
              (1): Linear(in_features=1280, out_features=1280, bias=True)
            )
            (out_layers): Sequential(
              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
              (1): SiLU()
              (2): Dropout(p=0, inplace=False)
              (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
            (skip_connection): Identity()
          )
          (1): SpatialTransformer(
            (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)
            (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
            (transformer_blocks): ModuleList(
              (0): BasicTransformerBlock(
                (attn1): CrossAttention(
                  (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                  (to_k): Linear(in_features=1280, out_features=1280, bias=False)
                  (to_v): Linear(in_features=1280, out_features=1280, bias=False)
                  (to_out): Sequential(
                    (0): Linear(in_features=1280, out_features=1280, bias=True)
                    (1): Dropout(p=0.0, inplace=False)
                  )
                )
                (ff): FeedForward(
                  (net): Sequential(
                    (0): GEGLU(
                      (proj): Linear(in_features=1280, out_features=10240, bias=True)
                    )
                    (1): Dropout(p=0.0, inplace=False)
                    (2): Linear(in_features=5120, out_features=1280, bias=True)
                  )
                )
                (attn2): CrossAttention(
                  (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                  (to_k): Linear(in_features=768, out_features=1280, bias=False)
                  (to_v): Linear(in_features=768, out_features=1280, bias=False)
                  (to_out): Sequential(
                    (0): Linear(in_features=1280, out_features=1280, bias=True)
                    (1): Dropout(p=0.0, inplace=False)
                  )
                )
                (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
              )
            )
            (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
          )
          (2): ResBlock(
            (in_layers): Sequential(
              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
              (1): SiLU()
              (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
            (h_upd): Identity()
            (x_upd): Identity()
            (emb_layers): Sequential(
              (0): SiLU()
              (1): Linear(in_features=1280, out_features=1280, bias=True)
            )
            (out_layers): Sequential(
              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
              (1): SiLU()
              (2): Dropout(p=0, inplace=False)
              (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
            (skip_connection): Identity()
          )
        )
        (output_blocks): ModuleList(
          (0): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (1): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (2): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): Upsample(
              (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (3): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)
              (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_v): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=1280, out_features=10240, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=5120, out_features=1280, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=768, out_features=1280, bias=False)
                    (to_v): Linear(in_features=768, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (4): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)
              (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_v): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=1280, out_features=10240, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=5120, out_features=1280, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=768, out_features=1280, bias=False)
                    (to_v): Linear(in_features=768, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (5): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 1920, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(1920, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(1920, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)
              (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_v): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=1280, out_features=10240, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=5120, out_features=1280, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=768, out_features=1280, bias=False)
                    (to_v): Linear(in_features=768, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
            (2): Upsample(
              (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (6): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 1920, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(1920, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=640, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(1920, 640, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 640, eps=1e-06, affine=True)
              (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=640, out_features=640, bias=False)
                    (to_v): Linear(in_features=640, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=640, out_features=5120, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=2560, out_features=640, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=768, out_features=640, bias=False)
                    (to_v): Linear(in_features=768, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (7): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(1280, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=640, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 640, eps=1e-06, affine=True)
              (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=640, out_features=640, bias=False)
                    (to_v): Linear(in_features=640, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=640, out_features=5120, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=2560, out_features=640, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=768, out_features=640, bias=False)
                    (to_v): Linear(in_features=768, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (8): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 960, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(960, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=640, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(960, 640, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 640, eps=1e-06, affine=True)
              (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=640, out_features=640, bias=False)
                    (to_v): Linear(in_features=640, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=640, out_features=5120, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=2560, out_features=640, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=768, out_features=640, bias=False)
                    (to_v): Linear(in_features=768, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
            )
            (2): Upsample(
              (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (9): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 960, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(960, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=320, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 320, eps=1e-06, affine=True)
              (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=320, out_features=320, bias=False)
                    (to_v): Linear(in_features=320, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=320, out_features=2560, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=1280, out_features=320, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=768, out_features=320, bias=False)
                    (to_v): Linear(in_features=768, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (10): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=320, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 320, eps=1e-06, affine=True)
              (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=320, out_features=320, bias=False)
                    (to_v): Linear(in_features=320, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=320, out_features=2560, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=1280, out_features=320, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=768, out_features=320, bias=False)
                    (to_v): Linear(in_features=768, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (11): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=320, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 320, eps=1e-06, affine=True)
              (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=320, out_features=320, bias=False)
                    (to_v): Linear(in_features=320, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=320, out_features=2560, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=1280, out_features=320, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=768, out_features=320, bias=False)
                    (to_v): Linear(in_features=768, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
            )
          )
        )
        (out): Sequential(
          (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
          (1): SiLU()
          (2): Conv2d(320, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
    )
    (trainable_unet): DiffusionWrapper(
      (diffusion_model): UNetModel(
        (time_embed): Sequential(
          (0): Linear(in_features=320, out_features=1280, bias=True)
          (1): SiLU()
          (2): Linear(in_features=1280, out_features=1280, bias=True)
        )
        (input_blocks): ModuleList(
          (0): TimestepEmbedSequential(
            (0): Conv2d(4, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (1): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=320, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Identity()
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 320, eps=1e-06, affine=True)
              (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=320, out_features=320, bias=False)
                    (to_v): Linear(in_features=320, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=320, out_features=2560, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=1280, out_features=320, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=768, out_features=320, bias=False)
                    (to_v): Linear(in_features=768, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (2): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=320, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Identity()
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 320, eps=1e-06, affine=True)
              (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=320, out_features=320, bias=False)
                    (to_v): Linear(in_features=320, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=320, out_features=2560, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=1280, out_features=320, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=768, out_features=320, bias=False)
                    (to_v): Linear(in_features=768, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (3): TimestepEmbedSequential(
            (0): Downsample(
              (op): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
            )
          )
          (4): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(320, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=640, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(320, 640, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 640, eps=1e-06, affine=True)
              (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=640, out_features=640, bias=False)
                    (to_v): Linear(in_features=640, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=640, out_features=5120, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=2560, out_features=640, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=768, out_features=640, bias=False)
                    (to_v): Linear(in_features=768, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (5): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=640, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Identity()
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 640, eps=1e-06, affine=True)
              (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=640, out_features=640, bias=False)
                    (to_v): Linear(in_features=640, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=640, out_features=5120, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=2560, out_features=640, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=768, out_features=640, bias=False)
                    (to_v): Linear(in_features=768, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (6): TimestepEmbedSequential(
            (0): Downsample(
              (op): Conv2d(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
            )
          )
          (7): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(640, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(640, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)
              (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_v): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=1280, out_features=10240, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=5120, out_features=1280, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=768, out_features=1280, bias=False)
                    (to_v): Linear(in_features=768, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (8): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Identity()
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)
              (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_v): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=1280, out_features=10240, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=5120, out_features=1280, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=768, out_features=1280, bias=False)
                    (to_v): Linear(in_features=768, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (9): TimestepEmbedSequential(
            (0): Downsample(
              (op): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
            )
          )
          (10): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Identity()
            )
          )
          (11): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Identity()
            )
          )
        )
        (middle_block): TimestepEmbedSequential(
          (0): ResBlock(
            (in_layers): Sequential(
              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
              (1): SiLU()
              (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
            (h_upd): Identity()
            (x_upd): Identity()
            (emb_layers): Sequential(
              (0): SiLU()
              (1): Linear(in_features=1280, out_features=1280, bias=True)
            )
            (out_layers): Sequential(
              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
              (1): SiLU()
              (2): Dropout(p=0, inplace=False)
              (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
            (skip_connection): Identity()
          )
          (1): SpatialTransformer(
            (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)
            (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
            (transformer_blocks): ModuleList(
              (0): BasicTransformerBlock(
                (attn1): CrossAttention(
                  (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                  (to_k): Linear(in_features=1280, out_features=1280, bias=False)
                  (to_v): Linear(in_features=1280, out_features=1280, bias=False)
                  (to_out): Sequential(
                    (0): Linear(in_features=1280, out_features=1280, bias=True)
                    (1): Dropout(p=0.0, inplace=False)
                  )
                )
                (ff): FeedForward(
                  (net): Sequential(
                    (0): GEGLU(
                      (proj): Linear(in_features=1280, out_features=10240, bias=True)
                    )
                    (1): Dropout(p=0.0, inplace=False)
                    (2): Linear(in_features=5120, out_features=1280, bias=True)
                  )
                )
                (attn2): CrossAttention(
                  (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                  (to_k): Linear(in_features=768, out_features=1280, bias=False)
                  (to_v): Linear(in_features=768, out_features=1280, bias=False)
                  (to_out): Sequential(
                    (0): Linear(in_features=1280, out_features=1280, bias=True)
                    (1): Dropout(p=0.0, inplace=False)
                  )
                )
                (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
              )
            )
            (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
          )
          (2): ResBlock(
            (in_layers): Sequential(
              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
              (1): SiLU()
              (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
            (h_upd): Identity()
            (x_upd): Identity()
            (emb_layers): Sequential(
              (0): SiLU()
              (1): Linear(in_features=1280, out_features=1280, bias=True)
            )
            (out_layers): Sequential(
              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
              (1): SiLU()
              (2): Dropout(p=0, inplace=False)
              (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
            (skip_connection): Identity()
          )
        )
        (output_blocks): ModuleList(
          (0): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (1): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (2): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): Upsample(
              (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (3): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)
              (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_v): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=1280, out_features=10240, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=5120, out_features=1280, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=768, out_features=1280, bias=False)
                    (to_v): Linear(in_features=768, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (4): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)
              (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_v): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=1280, out_features=10240, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=5120, out_features=1280, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=768, out_features=1280, bias=False)
                    (to_v): Linear(in_features=768, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (5): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 1920, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(1920, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(1920, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)
              (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_v): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=1280, out_features=10240, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=5120, out_features=1280, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=768, out_features=1280, bias=False)
                    (to_v): Linear(in_features=768, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
            (2): Upsample(
              (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (6): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 1920, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(1920, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=640, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(1920, 640, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 640, eps=1e-06, affine=True)
              (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=640, out_features=640, bias=False)
                    (to_v): Linear(in_features=640, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=640, out_features=5120, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=2560, out_features=640, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=768, out_features=640, bias=False)
                    (to_v): Linear(in_features=768, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (7): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(1280, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=640, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 640, eps=1e-06, affine=True)
              (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=640, out_features=640, bias=False)
                    (to_v): Linear(in_features=640, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=640, out_features=5120, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=2560, out_features=640, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=768, out_features=640, bias=False)
                    (to_v): Linear(in_features=768, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (8): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 960, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(960, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=640, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(960, 640, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 640, eps=1e-06, affine=True)
              (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=640, out_features=640, bias=False)
                    (to_v): Linear(in_features=640, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=640, out_features=5120, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=2560, out_features=640, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=768, out_features=640, bias=False)
                    (to_v): Linear(in_features=768, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
            )
            (2): Upsample(
              (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (9): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 960, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(960, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=320, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 320, eps=1e-06, affine=True)
              (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=320, out_features=320, bias=False)
                    (to_v): Linear(in_features=320, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=320, out_features=2560, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=1280, out_features=320, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=768, out_features=320, bias=False)
                    (to_v): Linear(in_features=768, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (10): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=320, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 320, eps=1e-06, affine=True)
              (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=320, out_features=320, bias=False)
                    (to_v): Linear(in_features=320, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=320, out_features=2560, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=1280, out_features=320, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=768, out_features=320, bias=False)
                    (to_v): Linear(in_features=768, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (11): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=320, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 320, eps=1e-06, affine=True)
              (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=320, out_features=320, bias=False)
                    (to_v): Linear(in_features=320, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=320, out_features=2560, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=1280, out_features=320, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=768, out_features=320, bias=False)
                    (to_v): Linear(in_features=768, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
            )
          )
        )
        (out): Sequential(
          (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
          (1): SiLU()
          (2): Conv2d(320, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
    )
    (zero_convs): ModuleList(
      (0): ZeroConv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
      (1): ZeroConv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
      (2): ZeroConv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
      (3): ZeroConv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
      (4): ZeroConv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
      (5): ZeroConv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (box_encoder): EncoderControlNet(
    (out64): Sequential(
      (0): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
    )
    (out32): Sequential(
      (0): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
    )
    (out16): Sequential(
      (0): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
    )
    (conv64): Sequential(
      (0): Conv2d(6, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (5): ReLU(inplace=True)
    )
    (conv32): Sequential(
      (0): Conv2d(320, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (1): ReLU(inplace=True)
    )
    (conv16): Sequential(
      (0): Conv2d(640, 1280, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (1): ReLU(inplace=True)
    )
  )
  (sd_model): LatentDiffusion(
    (model): None
    (first_stage_model): None
  )
  (text_adapter): TextAdapter(
    (fc): Sequential(
      (0): Linear(in_features=768, out_features=768, bias=True)
      (1): GELU()
      (2): Linear(in_features=768, out_features=768, bias=True)
    )
  )
  (neck): FPN(
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(320, 256, kernel_size=(1, 1), stride=(1, 1))
      )
      (1): ConvModule(
        (conv): Conv2d(790, 256, kernel_size=(1, 1), stride=(1, 1))
      )
      (2): ConvModule(
        (conv): Conv2d(1430, 256, kernel_size=(1, 1), stride=(1, 1))
      )
      (3): ConvModule(
        (conv): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (1): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (2): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (3): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
  )
  init_cfg={'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}
  (decode_head): FPNHead(
    input_transform=multiple_select, ignore_index=255, align_corners=False
    (loss_decode): CrossEntropyLoss(avg_non_ignore=False)
    (conv_seg): Conv2d(256, 150, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (scale_heads): ModuleList(
      (0): Sequential(
        (0): ConvModule(
          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (1): Sequential(
        (0): ConvModule(
          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): Upsample()
      )
      (2): Sequential(
        (0): ConvModule(
          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): Upsample()
        (2): ConvModule(
          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): Upsample()
      )
      (3): Sequential(
        (0): ConvModule(
          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): Upsample()
        (2): ConvModule(
          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): Upsample()
        (4): ConvModule(
          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (5): Upsample()
      )
    )
  )
  init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
)
2025-04-22 07:53:44,255 - mmseg - INFO - Loaded 20210 images
/dtu/blackhole/0e/154958/miniconda3/envs/ldm/lib/python3.8/site-packages/torch/utils/data/dataloader.py:487: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
2025-04-22 07:53:51,736 - mmseg - INFO - Loaded 2000 images
2025-04-22 07:53:51,739 - mmseg - INFO - load checkpoint from local path: /work3/s203557/checkpoints/vpd.chkpt
2025-04-22 07:53:54,629 - mmseg - WARNING - The model and loaded state dict do not match exactly

unexpected key in source state_dict: sd_model.lvlb_weights

missing keys in source state_dict: encoder_vq.encoder.conv_in.weight, encoder_vq.encoder.conv_in.bias, encoder_vq.encoder.down.0.block.0.norm1.weight, encoder_vq.encoder.down.0.block.0.norm1.bias, encoder_vq.encoder.down.0.block.0.conv1.weight, encoder_vq.encoder.down.0.block.0.conv1.bias, encoder_vq.encoder.down.0.block.0.norm2.weight, encoder_vq.encoder.down.0.block.0.norm2.bias, encoder_vq.encoder.down.0.block.0.conv2.weight, encoder_vq.encoder.down.0.block.0.conv2.bias, encoder_vq.encoder.down.0.block.1.norm1.weight, encoder_vq.encoder.down.0.block.1.norm1.bias, encoder_vq.encoder.down.0.block.1.conv1.weight, encoder_vq.encoder.down.0.block.1.conv1.bias, encoder_vq.encoder.down.0.block.1.norm2.weight, encoder_vq.encoder.down.0.block.1.norm2.bias, encoder_vq.encoder.down.0.block.1.conv2.weight, encoder_vq.encoder.down.0.block.1.conv2.bias, encoder_vq.encoder.down.0.downsample.conv.weight, encoder_vq.encoder.down.0.downsample.conv.bias, encoder_vq.encoder.down.1.block.0.norm1.weight, encoder_vq.encoder.down.1.block.0.norm1.bias, encoder_vq.encoder.down.1.block.0.conv1.weight, encoder_vq.encoder.down.1.block.0.conv1.bias, encoder_vq.encoder.down.1.block.0.norm2.weight, encoder_vq.encoder.down.1.block.0.norm2.bias, encoder_vq.encoder.down.1.block.0.conv2.weight, encoder_vq.encoder.down.1.block.0.conv2.bias, encoder_vq.encoder.down.1.block.0.nin_shortcut.weight, encoder_vq.encoder.down.1.block.0.nin_shortcut.bias, encoder_vq.encoder.down.1.block.1.norm1.weight, encoder_vq.encoder.down.1.block.1.norm1.bias, encoder_vq.encoder.down.1.block.1.conv1.weight, encoder_vq.encoder.down.1.block.1.conv1.bias, encoder_vq.encoder.down.1.block.1.norm2.weight, encoder_vq.encoder.down.1.block.1.norm2.bias, encoder_vq.encoder.down.1.block.1.conv2.weight, encoder_vq.encoder.down.1.block.1.conv2.bias, encoder_vq.encoder.down.1.downsample.conv.weight, encoder_vq.encoder.down.1.downsample.conv.bias, encoder_vq.encoder.down.2.block.0.norm1.weight, encoder_vq.encoder.down.2.block.0.norm1.bias, encoder_vq.encoder.down.2.block.0.conv1.weight, encoder_vq.encoder.down.2.block.0.conv1.bias, encoder_vq.encoder.down.2.block.0.norm2.weight, encoder_vq.encoder.down.2.block.0.norm2.bias, encoder_vq.encoder.down.2.block.0.conv2.weight, encoder_vq.encoder.down.2.block.0.conv2.bias, encoder_vq.encoder.down.2.block.0.nin_shortcut.weight, encoder_vq.encoder.down.2.block.0.nin_shortcut.bias, encoder_vq.encoder.down.2.block.1.norm1.weight, encoder_vq.encoder.down.2.block.1.norm1.bias, encoder_vq.encoder.down.2.block.1.conv1.weight, encoder_vq.encoder.down.2.block.1.conv1.bias, encoder_vq.encoder.down.2.block.1.norm2.weight, encoder_vq.encoder.down.2.block.1.norm2.bias, encoder_vq.encoder.down.2.block.1.conv2.weight, encoder_vq.encoder.down.2.block.1.conv2.bias, encoder_vq.encoder.down.2.downsample.conv.weight, encoder_vq.encoder.down.2.downsample.conv.bias, encoder_vq.encoder.down.3.block.0.norm1.weight, encoder_vq.encoder.down.3.block.0.norm1.bias, encoder_vq.encoder.down.3.block.0.conv1.weight, encoder_vq.encoder.down.3.block.0.conv1.bias, encoder_vq.encoder.down.3.block.0.norm2.weight, encoder_vq.encoder.down.3.block.0.norm2.bias, encoder_vq.encoder.down.3.block.0.conv2.weight, encoder_vq.encoder.down.3.block.0.conv2.bias, encoder_vq.encoder.down.3.block.1.norm1.weight, encoder_vq.encoder.down.3.block.1.norm1.bias, encoder_vq.encoder.down.3.block.1.conv1.weight, encoder_vq.encoder.down.3.block.1.conv1.bias, encoder_vq.encoder.down.3.block.1.norm2.weight, encoder_vq.encoder.down.3.block.1.norm2.bias, encoder_vq.encoder.down.3.block.1.conv2.weight, encoder_vq.encoder.down.3.block.1.conv2.bias, encoder_vq.encoder.mid.block_1.norm1.weight, encoder_vq.encoder.mid.block_1.norm1.bias, encoder_vq.encoder.mid.block_1.conv1.weight, encoder_vq.encoder.mid.block_1.conv1.bias, encoder_vq.encoder.mid.block_1.norm2.weight, encoder_vq.encoder.mid.block_1.norm2.bias, encoder_vq.encoder.mid.block_1.conv2.weight, encoder_vq.encoder.mid.block_1.conv2.bias, encoder_vq.encoder.mid.attn_1.norm.weight, encoder_vq.encoder.mid.attn_1.norm.bias, encoder_vq.encoder.mid.attn_1.q.weight, encoder_vq.encoder.mid.attn_1.q.bias, encoder_vq.encoder.mid.attn_1.k.weight, encoder_vq.encoder.mid.attn_1.k.bias, encoder_vq.encoder.mid.attn_1.v.weight, encoder_vq.encoder.mid.attn_1.v.bias, encoder_vq.encoder.mid.attn_1.proj_out.weight, encoder_vq.encoder.mid.attn_1.proj_out.bias, encoder_vq.encoder.mid.block_2.norm1.weight, encoder_vq.encoder.mid.block_2.norm1.bias, encoder_vq.encoder.mid.block_2.conv1.weight, encoder_vq.encoder.mid.block_2.conv1.bias, encoder_vq.encoder.mid.block_2.norm2.weight, encoder_vq.encoder.mid.block_2.norm2.bias, encoder_vq.encoder.mid.block_2.conv2.weight, encoder_vq.encoder.mid.block_2.conv2.bias, encoder_vq.encoder.norm_out.weight, encoder_vq.encoder.norm_out.bias, encoder_vq.encoder.conv_out.weight, encoder_vq.encoder.conv_out.bias, encoder_vq.quant_conv.weight, encoder_vq.quant_conv.bias, encoder_vq.post_quant_conv.weight, encoder_vq.post_quant_conv.bias, unet.trainable_unet.diffusion_model.time_embed.0.weight, unet.trainable_unet.diffusion_model.time_embed.0.bias, unet.trainable_unet.diffusion_model.time_embed.2.weight, unet.trainable_unet.diffusion_model.time_embed.2.bias, unet.trainable_unet.diffusion_model.input_blocks.0.0.weight, unet.trainable_unet.diffusion_model.input_blocks.0.0.bias, unet.trainable_unet.diffusion_model.input_blocks.1.0.in_layers.0.weight, unet.trainable_unet.diffusion_model.input_blocks.1.0.in_layers.0.bias, unet.trainable_unet.diffusion_model.input_blocks.1.0.in_layers.2.weight, unet.trainable_unet.diffusion_model.input_blocks.1.0.in_layers.2.bias, unet.trainable_unet.diffusion_model.input_blocks.1.0.emb_layers.1.weight, unet.trainable_unet.diffusion_model.input_blocks.1.0.emb_layers.1.bias, unet.trainable_unet.diffusion_model.input_blocks.1.0.out_layers.0.weight, unet.trainable_unet.diffusion_model.input_blocks.1.0.out_layers.0.bias, unet.trainable_unet.diffusion_model.input_blocks.1.0.out_layers.3.weight, unet.trainable_unet.diffusion_model.input_blocks.1.0.out_layers.3.bias, unet.trainable_unet.diffusion_model.input_blocks.1.1.norm.weight, unet.trainable_unet.diffusion_model.input_blocks.1.1.norm.bias, unet.trainable_unet.diffusion_model.input_blocks.1.1.proj_in.weight, unet.trainable_unet.diffusion_model.input_blocks.1.1.proj_in.bias, unet.trainable_unet.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_q.weight, unet.trainable_unet.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_k.weight, unet.trainable_unet.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_v.weight, unet.trainable_unet.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_out.0.weight, unet.trainable_unet.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_out.0.bias, unet.trainable_unet.diffusion_model.input_blocks.1.1.transformer_blocks.0.ff.net.0.proj.weight, unet.trainable_unet.diffusion_model.input_blocks.1.1.transformer_blocks.0.ff.net.0.proj.bias, unet.trainable_unet.diffusion_model.input_blocks.1.1.transformer_blocks.0.ff.net.2.weight, unet.trainable_unet.diffusion_model.input_blocks.1.1.transformer_blocks.0.ff.net.2.bias, unet.trainable_unet.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_q.weight, unet.trainable_unet.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_k.weight, unet.trainable_unet.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_v.weight, unet.trainable_unet.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_out.0.weight, unet.trainable_unet.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_out.0.bias, unet.trainable_unet.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm1.weight, unet.trainable_unet.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm1.bias, unet.trainable_unet.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm2.weight, unet.trainable_unet.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm2.bias, unet.trainable_unet.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm3.weight, unet.trainable_unet.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm3.bias, unet.trainable_unet.diffusion_model.input_blocks.1.1.proj_out.weight, unet.trainable_unet.diffusion_model.input_blocks.1.1.proj_out.bias, unet.trainable_unet.diffusion_model.input_blocks.2.0.in_layers.0.weight, unet.trainable_unet.diffusion_model.input_blocks.2.0.in_layers.0.bias, unet.trainable_unet.diffusion_model.input_blocks.2.0.in_layers.2.weight, unet.trainable_unet.diffusion_model.input_blocks.2.0.in_layers.2.bias, unet.trainable_unet.diffusion_model.input_blocks.2.0.emb_layers.1.weight, unet.trainable_unet.diffusion_model.input_blocks.2.0.emb_layers.1.bias, unet.trainable_unet.diffusion_model.input_blocks.2.0.out_layers.0.weight, unet.trainable_unet.diffusion_model.input_blocks.2.0.out_layers.0.bias, unet.trainable_unet.diffusion_model.input_blocks.2.0.out_layers.3.weight, unet.trainable_unet.diffusion_model.input_blocks.2.0.out_layers.3.bias, unet.trainable_unet.diffusion_model.input_blocks.2.1.norm.weight, unet.trainable_unet.diffusion_model.input_blocks.2.1.norm.bias, unet.trainable_unet.diffusion_model.input_blocks.2.1.proj_in.weight, unet.trainable_unet.diffusion_model.input_blocks.2.1.proj_in.bias, unet.trainable_unet.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_q.weight, unet.trainable_unet.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_k.weight, unet.trainable_unet.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_v.weight, unet.trainable_unet.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_out.0.weight, unet.trainable_unet.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_out.0.bias, unet.trainable_unet.diffusion_model.input_blocks.2.1.transformer_blocks.0.ff.net.0.proj.weight, unet.trainable_unet.diffusion_model.input_blocks.2.1.transformer_blocks.0.ff.net.0.proj.bias, unet.trainable_unet.diffusion_model.input_blocks.2.1.transformer_blocks.0.ff.net.2.weight, unet.trainable_unet.diffusion_model.input_blocks.2.1.transformer_blocks.0.ff.net.2.bias, unet.trainable_unet.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_q.weight, unet.trainable_unet.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_k.weight, unet.trainable_unet.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_v.weight, unet.trainable_unet.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_out.0.weight, unet.trainable_unet.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_out.0.bias, unet.trainable_unet.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm1.weight, unet.trainable_unet.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm1.bias, unet.trainable_unet.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm2.weight, unet.trainable_unet.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm2.bias, unet.trainable_unet.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm3.weight, unet.trainable_unet.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm3.bias, unet.trainable_unet.diffusion_model.input_blocks.2.1.proj_out.weight, unet.trainable_unet.diffusion_model.input_blocks.2.1.proj_out.bias, unet.trainable_unet.diffusion_model.input_blocks.3.0.op.weight, unet.trainable_unet.diffusion_model.input_blocks.3.0.op.bias, unet.trainable_unet.diffusion_model.input_blocks.4.0.in_layers.0.weight, unet.trainable_unet.diffusion_model.input_blocks.4.0.in_layers.0.bias, unet.trainable_unet.diffusion_model.input_blocks.4.0.in_layers.2.weight, unet.trainable_unet.diffusion_model.input_blocks.4.0.in_layers.2.bias, unet.trainable_unet.diffusion_model.input_blocks.4.0.emb_layers.1.weight, unet.trainable_unet.diffusion_model.input_blocks.4.0.emb_layers.1.bias, unet.trainable_unet.diffusion_model.input_blocks.4.0.out_layers.0.weight, unet.trainable_unet.diffusion_model.input_blocks.4.0.out_layers.0.bias, unet.trainable_unet.diffusion_model.input_blocks.4.0.out_layers.3.weight, unet.trainable_unet.diffusion_model.input_blocks.4.0.out_layers.3.bias, unet.trainable_unet.diffusion_model.input_blocks.4.0.skip_connection.weight, unet.trainable_unet.diffusion_model.input_blocks.4.0.skip_connection.bias, unet.trainable_unet.diffusion_model.input_blocks.4.1.norm.weight, unet.trainable_unet.diffusion_model.input_blocks.4.1.norm.bias, unet.trainable_unet.diffusion_model.input_blocks.4.1.proj_in.weight, unet.trainable_unet.diffusion_model.input_blocks.4.1.proj_in.bias, unet.trainable_unet.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_q.weight, unet.trainable_unet.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_k.weight, unet.trainable_unet.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_v.weight, unet.trainable_unet.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_out.0.weight, unet.trainable_unet.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_out.0.bias, unet.trainable_unet.diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.0.proj.weight, unet.trainable_unet.diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.0.proj.bias, unet.trainable_unet.diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.2.weight, unet.trainable_unet.diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.2.bias, unet.trainable_unet.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_q.weight, unet.trainable_unet.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_k.weight, unet.trainable_unet.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_v.weight, unet.trainable_unet.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_out.0.weight, unet.trainable_unet.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_out.0.bias, unet.trainable_unet.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm1.weight, unet.trainable_unet.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm1.bias, unet.trainable_unet.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm2.weight, unet.trainable_unet.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm2.bias, unet.trainable_unet.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm3.weight, unet.trainable_unet.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm3.bias, unet.trainable_unet.diffusion_model.input_blocks.4.1.proj_out.weight, unet.trainable_unet.diffusion_model.input_blocks.4.1.proj_out.bias, unet.trainable_unet.diffusion_model.input_blocks.5.0.in_layers.0.weight, unet.trainable_unet.diffusion_model.input_blocks.5.0.in_layers.0.bias, unet.trainable_unet.diffusion_model.input_blocks.5.0.in_layers.2.weight, unet.trainable_unet.diffusion_model.input_blocks.5.0.in_layers.2.bias, unet.trainable_unet.diffusion_model.input_blocks.5.0.emb_layers.1.weight, unet.trainable_unet.diffusion_model.input_blocks.5.0.emb_layers.1.bias, unet.trainable_unet.diffusion_model.input_blocks.5.0.out_layers.0.weight, unet.trainable_unet.diffusion_model.input_blocks.5.0.out_layers.0.bias, unet.trainable_unet.diffusion_model.input_blocks.5.0.out_layers.3.weight, unet.trainable_unet.diffusion_model.input_blocks.5.0.out_layers.3.bias, unet.trainable_unet.diffusion_model.input_blocks.5.1.norm.weight, unet.trainable_unet.diffusion_model.input_blocks.5.1.norm.bias, unet.trainable_unet.diffusion_model.input_blocks.5.1.proj_in.weight, unet.trainable_unet.diffusion_model.input_blocks.5.1.proj_in.bias, unet.trainable_unet.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_q.weight, unet.trainable_unet.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_k.weight, unet.trainable_unet.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_v.weight, unet.trainable_unet.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_out.0.weight, unet.trainable_unet.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_out.0.bias, unet.trainable_unet.diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.0.proj.weight, unet.trainable_unet.diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.0.proj.bias, unet.trainable_unet.diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.2.weight, unet.trainable_unet.diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.2.bias, unet.trainable_unet.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_q.weight, unet.trainable_unet.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_k.weight, unet.trainable_unet.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_v.weight, unet.trainable_unet.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_out.0.weight, unet.trainable_unet.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_out.0.bias, unet.trainable_unet.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm1.weight, unet.trainable_unet.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm1.bias, unet.trainable_unet.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm2.weight, unet.trainable_unet.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm2.bias, unet.trainable_unet.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm3.weight, unet.trainable_unet.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm3.bias, unet.trainable_unet.diffusion_model.input_blocks.5.1.proj_out.weight, unet.trainable_unet.diffusion_model.input_blocks.5.1.proj_out.bias, unet.trainable_unet.diffusion_model.input_blocks.6.0.op.weight, unet.trainable_unet.diffusion_model.input_blocks.6.0.op.bias, unet.trainable_unet.diffusion_model.input_blocks.7.0.in_layers.0.weight, unet.trainable_unet.diffusion_model.input_blocks.7.0.in_layers.0.bias, unet.trainable_unet.diffusion_model.input_blocks.7.0.in_layers.2.weight, unet.trainable_unet.diffusion_model.input_blocks.7.0.in_layers.2.bias, unet.trainable_unet.diffusion_model.input_blocks.7.0.emb_layers.1.weight, unet.trainable_unet.diffusion_model.input_blocks.7.0.emb_layers.1.bias, unet.trainable_unet.diffusion_model.input_blocks.7.0.out_layers.0.weight, unet.trainable_unet.diffusion_model.input_blocks.7.0.out_layers.0.bias, unet.trainable_unet.diffusion_model.input_blocks.7.0.out_layers.3.weight, unet.trainable_unet.diffusion_model.input_blocks.7.0.out_layers.3.bias, unet.trainable_unet.diffusion_model.input_blocks.7.0.skip_connection.weight, unet.trainable_unet.diffusion_model.input_blocks.7.0.skip_connection.bias, unet.trainable_unet.diffusion_model.input_blocks.7.1.norm.weight, unet.trainable_unet.diffusion_model.input_blocks.7.1.norm.bias, unet.trainable_unet.diffusion_model.input_blocks.7.1.proj_in.weight, unet.trainable_unet.diffusion_model.input_blocks.7.1.proj_in.bias, unet.trainable_unet.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_q.weight, unet.trainable_unet.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_k.weight, unet.trainable_unet.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_v.weight, unet.trainable_unet.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_out.0.weight, unet.trainable_unet.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_out.0.bias, unet.trainable_unet.diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.0.proj.weight, unet.trainable_unet.diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.0.proj.bias, unet.trainable_unet.diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.2.weight, unet.trainable_unet.diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.2.bias, unet.trainable_unet.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_q.weight, unet.trainable_unet.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_k.weight, unet.trainable_unet.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_v.weight, unet.trainable_unet.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_out.0.weight, unet.trainable_unet.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_out.0.bias, unet.trainable_unet.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm1.weight, unet.trainable_unet.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm1.bias, unet.trainable_unet.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm2.weight, unet.trainable_unet.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm2.bias, unet.trainable_unet.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm3.weight, unet.trainable_unet.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm3.bias, unet.trainable_unet.diffusion_model.input_blocks.7.1.proj_out.weight, unet.trainable_unet.diffusion_model.input_blocks.7.1.proj_out.bias, unet.trainable_unet.diffusion_model.input_blocks.8.0.in_layers.0.weight, unet.trainable_unet.diffusion_model.input_blocks.8.0.in_layers.0.bias, unet.trainable_unet.diffusion_model.input_blocks.8.0.in_layers.2.weight, unet.trainable_unet.diffusion_model.input_blocks.8.0.in_layers.2.bias, unet.trainable_unet.diffusion_model.input_blocks.8.0.emb_layers.1.weight, unet.trainable_unet.diffusion_model.input_blocks.8.0.emb_layers.1.bias, unet.trainable_unet.diffusion_model.input_blocks.8.0.out_layers.0.weight, unet.trainable_unet.diffusion_model.input_blocks.8.0.out_layers.0.bias, unet.trainable_unet.diffusion_model.input_blocks.8.0.out_layers.3.weight, unet.trainable_unet.diffusion_model.input_blocks.8.0.out_layers.3.bias, unet.trainable_unet.diffusion_model.input_blocks.8.1.norm.weight, unet.trainable_unet.diffusion_model.input_blocks.8.1.norm.bias, unet.trainable_unet.diffusion_model.input_blocks.8.1.proj_in.weight, unet.trainable_unet.diffusion_model.input_blocks.8.1.proj_in.bias, unet.trainable_unet.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_q.weight, unet.trainable_unet.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_k.weight, unet.trainable_unet.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_v.weight, unet.trainable_unet.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_out.0.weight, unet.trainable_unet.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_out.0.bias, unet.trainable_unet.diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.0.proj.weight, unet.trainable_unet.diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.0.proj.bias, unet.trainable_unet.diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.2.weight, unet.trainable_unet.diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.2.bias, unet.trainable_unet.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_q.weight, unet.trainable_unet.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_k.weight, unet.trainable_unet.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_v.weight, unet.trainable_unet.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_out.0.weight, unet.trainable_unet.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_out.0.bias, unet.trainable_unet.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm1.weight, unet.trainable_unet.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm1.bias, unet.trainable_unet.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm2.weight, unet.trainable_unet.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm2.bias, unet.trainable_unet.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm3.weight, unet.trainable_unet.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm3.bias, unet.trainable_unet.diffusion_model.input_blocks.8.1.proj_out.weight, unet.trainable_unet.diffusion_model.input_blocks.8.1.proj_out.bias, unet.trainable_unet.diffusion_model.input_blocks.9.0.op.weight, unet.trainable_unet.diffusion_model.input_blocks.9.0.op.bias, unet.trainable_unet.diffusion_model.input_blocks.10.0.in_layers.0.weight, unet.trainable_unet.diffusion_model.input_blocks.10.0.in_layers.0.bias, unet.trainable_unet.diffusion_model.input_blocks.10.0.in_layers.2.weight, unet.trainable_unet.diffusion_model.input_blocks.10.0.in_layers.2.bias, unet.trainable_unet.diffusion_model.input_blocks.10.0.emb_layers.1.weight, unet.trainable_unet.diffusion_model.input_blocks.10.0.emb_layers.1.bias, unet.trainable_unet.diffusion_model.input_blocks.10.0.out_layers.0.weight, unet.trainable_unet.diffusion_model.input_blocks.10.0.out_layers.0.bias, unet.trainable_unet.diffusion_model.input_blocks.10.0.out_layers.3.weight, unet.trainable_unet.diffusion_model.input_blocks.10.0.out_layers.3.bias, unet.trainable_unet.diffusion_model.input_blocks.11.0.in_layers.0.weight, unet.trainable_unet.diffusion_model.input_blocks.11.0.in_layers.0.bias, unet.trainable_unet.diffusion_model.input_blocks.11.0.in_layers.2.weight, unet.trainable_unet.diffusion_model.input_blocks.11.0.in_layers.2.bias, unet.trainable_unet.diffusion_model.input_blocks.11.0.emb_layers.1.weight, unet.trainable_unet.diffusion_model.input_blocks.11.0.emb_layers.1.bias, unet.trainable_unet.diffusion_model.input_blocks.11.0.out_layers.0.weight, unet.trainable_unet.diffusion_model.input_blocks.11.0.out_layers.0.bias, unet.trainable_unet.diffusion_model.input_blocks.11.0.out_layers.3.weight, unet.trainable_unet.diffusion_model.input_blocks.11.0.out_layers.3.bias, unet.trainable_unet.diffusion_model.middle_block.0.in_layers.0.weight, unet.trainable_unet.diffusion_model.middle_block.0.in_layers.0.bias, unet.trainable_unet.diffusion_model.middle_block.0.in_layers.2.weight, unet.trainable_unet.diffusion_model.middle_block.0.in_layers.2.bias, unet.trainable_unet.diffusion_model.middle_block.0.emb_layers.1.weight, unet.trainable_unet.diffusion_model.middle_block.0.emb_layers.1.bias, unet.trainable_unet.diffusion_model.middle_block.0.out_layers.0.weight, unet.trainable_unet.diffusion_model.middle_block.0.out_layers.0.bias, unet.trainable_unet.diffusion_model.middle_block.0.out_layers.3.weight, unet.trainable_unet.diffusion_model.middle_block.0.out_layers.3.bias, unet.trainable_unet.diffusion_model.middle_block.1.norm.weight, unet.trainable_unet.diffusion_model.middle_block.1.norm.bias, unet.trainable_unet.diffusion_model.middle_block.1.proj_in.weight, unet.trainable_unet.diffusion_model.middle_block.1.proj_in.bias, unet.trainable_unet.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_q.weight, unet.trainable_unet.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_k.weight, unet.trainable_unet.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_v.weight, unet.trainable_unet.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_out.0.weight, unet.trainable_unet.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_out.0.bias, unet.trainable_unet.diffusion_model.middle_block.1.transformer_blocks.0.ff.net.0.proj.weight, unet.trainable_unet.diffusion_model.middle_block.1.transformer_blocks.0.ff.net.0.proj.bias, unet.trainable_unet.diffusion_model.middle_block.1.transformer_blocks.0.ff.net.2.weight, unet.trainable_unet.diffusion_model.middle_block.1.transformer_blocks.0.ff.net.2.bias, unet.trainable_unet.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_q.weight, unet.trainable_unet.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_k.weight, unet.trainable_unet.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_v.weight, unet.trainable_unet.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_out.0.weight, unet.trainable_unet.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_out.0.bias, unet.trainable_unet.diffusion_model.middle_block.1.transformer_blocks.0.norm1.weight, unet.trainable_unet.diffusion_model.middle_block.1.transformer_blocks.0.norm1.bias, unet.trainable_unet.diffusion_model.middle_block.1.transformer_blocks.0.norm2.weight, unet.trainable_unet.diffusion_model.middle_block.1.transformer_blocks.0.norm2.bias, unet.trainable_unet.diffusion_model.middle_block.1.transformer_blocks.0.norm3.weight, unet.trainable_unet.diffusion_model.middle_block.1.transformer_blocks.0.norm3.bias, unet.trainable_unet.diffusion_model.middle_block.1.proj_out.weight, unet.trainable_unet.diffusion_model.middle_block.1.proj_out.bias, unet.trainable_unet.diffusion_model.middle_block.2.in_layers.0.weight, unet.trainable_unet.diffusion_model.middle_block.2.in_layers.0.bias, unet.trainable_unet.diffusion_model.middle_block.2.in_layers.2.weight, unet.trainable_unet.diffusion_model.middle_block.2.in_layers.2.bias, unet.trainable_unet.diffusion_model.middle_block.2.emb_layers.1.weight, unet.trainable_unet.diffusion_model.middle_block.2.emb_layers.1.bias, unet.trainable_unet.diffusion_model.middle_block.2.out_layers.0.weight, unet.trainable_unet.diffusion_model.middle_block.2.out_layers.0.bias, unet.trainable_unet.diffusion_model.middle_block.2.out_layers.3.weight, unet.trainable_unet.diffusion_model.middle_block.2.out_layers.3.bias, unet.trainable_unet.diffusion_model.output_blocks.0.0.in_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.0.0.in_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.0.0.in_layers.2.weight, unet.trainable_unet.diffusion_model.output_blocks.0.0.in_layers.2.bias, unet.trainable_unet.diffusion_model.output_blocks.0.0.emb_layers.1.weight, unet.trainable_unet.diffusion_model.output_blocks.0.0.emb_layers.1.bias, unet.trainable_unet.diffusion_model.output_blocks.0.0.out_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.0.0.out_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.0.0.out_layers.3.weight, unet.trainable_unet.diffusion_model.output_blocks.0.0.out_layers.3.bias, unet.trainable_unet.diffusion_model.output_blocks.0.0.skip_connection.weight, unet.trainable_unet.diffusion_model.output_blocks.0.0.skip_connection.bias, unet.trainable_unet.diffusion_model.output_blocks.1.0.in_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.1.0.in_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.1.0.in_layers.2.weight, unet.trainable_unet.diffusion_model.output_blocks.1.0.in_layers.2.bias, unet.trainable_unet.diffusion_model.output_blocks.1.0.emb_layers.1.weight, unet.trainable_unet.diffusion_model.output_blocks.1.0.emb_layers.1.bias, unet.trainable_unet.diffusion_model.output_blocks.1.0.out_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.1.0.out_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.1.0.out_layers.3.weight, unet.trainable_unet.diffusion_model.output_blocks.1.0.out_layers.3.bias, unet.trainable_unet.diffusion_model.output_blocks.1.0.skip_connection.weight, unet.trainable_unet.diffusion_model.output_blocks.1.0.skip_connection.bias, unet.trainable_unet.diffusion_model.output_blocks.2.0.in_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.2.0.in_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.2.0.in_layers.2.weight, unet.trainable_unet.diffusion_model.output_blocks.2.0.in_layers.2.bias, unet.trainable_unet.diffusion_model.output_blocks.2.0.emb_layers.1.weight, unet.trainable_unet.diffusion_model.output_blocks.2.0.emb_layers.1.bias, unet.trainable_unet.diffusion_model.output_blocks.2.0.out_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.2.0.out_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.2.0.out_layers.3.weight, unet.trainable_unet.diffusion_model.output_blocks.2.0.out_layers.3.bias, unet.trainable_unet.diffusion_model.output_blocks.2.0.skip_connection.weight, unet.trainable_unet.diffusion_model.output_blocks.2.0.skip_connection.bias, unet.trainable_unet.diffusion_model.output_blocks.2.1.conv.weight, unet.trainable_unet.diffusion_model.output_blocks.2.1.conv.bias, unet.trainable_unet.diffusion_model.output_blocks.3.0.in_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.3.0.in_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.3.0.in_layers.2.weight, unet.trainable_unet.diffusion_model.output_blocks.3.0.in_layers.2.bias, unet.trainable_unet.diffusion_model.output_blocks.3.0.emb_layers.1.weight, unet.trainable_unet.diffusion_model.output_blocks.3.0.emb_layers.1.bias, unet.trainable_unet.diffusion_model.output_blocks.3.0.out_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.3.0.out_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.3.0.out_layers.3.weight, unet.trainable_unet.diffusion_model.output_blocks.3.0.out_layers.3.bias, unet.trainable_unet.diffusion_model.output_blocks.3.0.skip_connection.weight, unet.trainable_unet.diffusion_model.output_blocks.3.0.skip_connection.bias, unet.trainable_unet.diffusion_model.output_blocks.3.1.norm.weight, unet.trainable_unet.diffusion_model.output_blocks.3.1.norm.bias, unet.trainable_unet.diffusion_model.output_blocks.3.1.proj_in.weight, unet.trainable_unet.diffusion_model.output_blocks.3.1.proj_in.bias, unet.trainable_unet.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_q.weight, unet.trainable_unet.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_k.weight, unet.trainable_unet.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_v.weight, unet.trainable_unet.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_out.0.weight, unet.trainable_unet.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_out.0.bias, unet.trainable_unet.diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.0.proj.weight, unet.trainable_unet.diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.0.proj.bias, unet.trainable_unet.diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.2.weight, unet.trainable_unet.diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.2.bias, unet.trainable_unet.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_q.weight, unet.trainable_unet.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_k.weight, unet.trainable_unet.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_v.weight, unet.trainable_unet.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_out.0.weight, unet.trainable_unet.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_out.0.bias, unet.trainable_unet.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm1.weight, unet.trainable_unet.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm1.bias, unet.trainable_unet.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm2.weight, unet.trainable_unet.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm2.bias, unet.trainable_unet.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm3.weight, unet.trainable_unet.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm3.bias, unet.trainable_unet.diffusion_model.output_blocks.3.1.proj_out.weight, unet.trainable_unet.diffusion_model.output_blocks.3.1.proj_out.bias, unet.trainable_unet.diffusion_model.output_blocks.4.0.in_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.4.0.in_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.4.0.in_layers.2.weight, unet.trainable_unet.diffusion_model.output_blocks.4.0.in_layers.2.bias, unet.trainable_unet.diffusion_model.output_blocks.4.0.emb_layers.1.weight, unet.trainable_unet.diffusion_model.output_blocks.4.0.emb_layers.1.bias, unet.trainable_unet.diffusion_model.output_blocks.4.0.out_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.4.0.out_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.4.0.out_layers.3.weight, unet.trainable_unet.diffusion_model.output_blocks.4.0.out_layers.3.bias, unet.trainable_unet.diffusion_model.output_blocks.4.0.skip_connection.weight, unet.trainable_unet.diffusion_model.output_blocks.4.0.skip_connection.bias, unet.trainable_unet.diffusion_model.output_blocks.4.1.norm.weight, unet.trainable_unet.diffusion_model.output_blocks.4.1.norm.bias, unet.trainable_unet.diffusion_model.output_blocks.4.1.proj_in.weight, unet.trainable_unet.diffusion_model.output_blocks.4.1.proj_in.bias, unet.trainable_unet.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_q.weight, unet.trainable_unet.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_k.weight, unet.trainable_unet.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_v.weight, unet.trainable_unet.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_out.0.weight, unet.trainable_unet.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_out.0.bias, unet.trainable_unet.diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.0.proj.weight, unet.trainable_unet.diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.0.proj.bias, unet.trainable_unet.diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.2.weight, unet.trainable_unet.diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.2.bias, unet.trainable_unet.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_q.weight, unet.trainable_unet.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_k.weight, unet.trainable_unet.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_v.weight, unet.trainable_unet.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_out.0.weight, unet.trainable_unet.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_out.0.bias, unet.trainable_unet.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm1.weight, unet.trainable_unet.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm1.bias, unet.trainable_unet.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm2.weight, unet.trainable_unet.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm2.bias, unet.trainable_unet.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm3.weight, unet.trainable_unet.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm3.bias, unet.trainable_unet.diffusion_model.output_blocks.4.1.proj_out.weight, unet.trainable_unet.diffusion_model.output_blocks.4.1.proj_out.bias, unet.trainable_unet.diffusion_model.output_blocks.5.0.in_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.5.0.in_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.5.0.in_layers.2.weight, unet.trainable_unet.diffusion_model.output_blocks.5.0.in_layers.2.bias, unet.trainable_unet.diffusion_model.output_blocks.5.0.emb_layers.1.weight, unet.trainable_unet.diffusion_model.output_blocks.5.0.emb_layers.1.bias, unet.trainable_unet.diffusion_model.output_blocks.5.0.out_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.5.0.out_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.5.0.out_layers.3.weight, unet.trainable_unet.diffusion_model.output_blocks.5.0.out_layers.3.bias, unet.trainable_unet.diffusion_model.output_blocks.5.0.skip_connection.weight, unet.trainable_unet.diffusion_model.output_blocks.5.0.skip_connection.bias, unet.trainable_unet.diffusion_model.output_blocks.5.1.norm.weight, unet.trainable_unet.diffusion_model.output_blocks.5.1.norm.bias, unet.trainable_unet.diffusion_model.output_blocks.5.1.proj_in.weight, unet.trainable_unet.diffusion_model.output_blocks.5.1.proj_in.bias, unet.trainable_unet.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_q.weight, unet.trainable_unet.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_k.weight, unet.trainable_unet.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_v.weight, unet.trainable_unet.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_out.0.weight, unet.trainable_unet.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_out.0.bias, unet.trainable_unet.diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.0.proj.weight, unet.trainable_unet.diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.0.proj.bias, unet.trainable_unet.diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.2.weight, unet.trainable_unet.diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.2.bias, unet.trainable_unet.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_q.weight, unet.trainable_unet.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_k.weight, unet.trainable_unet.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_v.weight, unet.trainable_unet.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_out.0.weight, unet.trainable_unet.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_out.0.bias, unet.trainable_unet.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm1.weight, unet.trainable_unet.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm1.bias, unet.trainable_unet.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm2.weight, unet.trainable_unet.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm2.bias, unet.trainable_unet.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm3.weight, unet.trainable_unet.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm3.bias, unet.trainable_unet.diffusion_model.output_blocks.5.1.proj_out.weight, unet.trainable_unet.diffusion_model.output_blocks.5.1.proj_out.bias, unet.trainable_unet.diffusion_model.output_blocks.5.2.conv.weight, unet.trainable_unet.diffusion_model.output_blocks.5.2.conv.bias, unet.trainable_unet.diffusion_model.output_blocks.6.0.in_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.6.0.in_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.6.0.in_layers.2.weight, unet.trainable_unet.diffusion_model.output_blocks.6.0.in_layers.2.bias, unet.trainable_unet.diffusion_model.output_blocks.6.0.emb_layers.1.weight, unet.trainable_unet.diffusion_model.output_blocks.6.0.emb_layers.1.bias, unet.trainable_unet.diffusion_model.output_blocks.6.0.out_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.6.0.out_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.6.0.out_layers.3.weight, unet.trainable_unet.diffusion_model.output_blocks.6.0.out_layers.3.bias, unet.trainable_unet.diffusion_model.output_blocks.6.0.skip_connection.weight, unet.trainable_unet.diffusion_model.output_blocks.6.0.skip_connection.bias, unet.trainable_unet.diffusion_model.output_blocks.6.1.norm.weight, unet.trainable_unet.diffusion_model.output_blocks.6.1.norm.bias, unet.trainable_unet.diffusion_model.output_blocks.6.1.proj_in.weight, unet.trainable_unet.diffusion_model.output_blocks.6.1.proj_in.bias, unet.trainable_unet.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_q.weight, unet.trainable_unet.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_k.weight, unet.trainable_unet.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_v.weight, unet.trainable_unet.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_out.0.weight, unet.trainable_unet.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_out.0.bias, unet.trainable_unet.diffusion_model.output_blocks.6.1.transformer_blocks.0.ff.net.0.proj.weight, unet.trainable_unet.diffusion_model.output_blocks.6.1.transformer_blocks.0.ff.net.0.proj.bias, unet.trainable_unet.diffusion_model.output_blocks.6.1.transformer_blocks.0.ff.net.2.weight, unet.trainable_unet.diffusion_model.output_blocks.6.1.transformer_blocks.0.ff.net.2.bias, unet.trainable_unet.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_q.weight, unet.trainable_unet.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_k.weight, unet.trainable_unet.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_v.weight, unet.trainable_unet.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_out.0.weight, unet.trainable_unet.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_out.0.bias, unet.trainable_unet.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm1.weight, unet.trainable_unet.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm1.bias, unet.trainable_unet.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm2.weight, unet.trainable_unet.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm2.bias, unet.trainable_unet.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm3.weight, unet.trainable_unet.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm3.bias, unet.trainable_unet.diffusion_model.output_blocks.6.1.proj_out.weight, unet.trainable_unet.diffusion_model.output_blocks.6.1.proj_out.bias, unet.trainable_unet.diffusion_model.output_blocks.7.0.in_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.7.0.in_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.7.0.in_layers.2.weight, unet.trainable_unet.diffusion_model.output_blocks.7.0.in_layers.2.bias, unet.trainable_unet.diffusion_model.output_blocks.7.0.emb_layers.1.weight, unet.trainable_unet.diffusion_model.output_blocks.7.0.emb_layers.1.bias, unet.trainable_unet.diffusion_model.output_blocks.7.0.out_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.7.0.out_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.7.0.out_layers.3.weight, unet.trainable_unet.diffusion_model.output_blocks.7.0.out_layers.3.bias, unet.trainable_unet.diffusion_model.output_blocks.7.0.skip_connection.weight, unet.trainable_unet.diffusion_model.output_blocks.7.0.skip_connection.bias, unet.trainable_unet.diffusion_model.output_blocks.7.1.norm.weight, unet.trainable_unet.diffusion_model.output_blocks.7.1.norm.bias, unet.trainable_unet.diffusion_model.output_blocks.7.1.proj_in.weight, unet.trainable_unet.diffusion_model.output_blocks.7.1.proj_in.bias, unet.trainable_unet.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_q.weight, unet.trainable_unet.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_k.weight, unet.trainable_unet.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_v.weight, unet.trainable_unet.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_out.0.weight, unet.trainable_unet.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_out.0.bias, unet.trainable_unet.diffusion_model.output_blocks.7.1.transformer_blocks.0.ff.net.0.proj.weight, unet.trainable_unet.diffusion_model.output_blocks.7.1.transformer_blocks.0.ff.net.0.proj.bias, unet.trainable_unet.diffusion_model.output_blocks.7.1.transformer_blocks.0.ff.net.2.weight, unet.trainable_unet.diffusion_model.output_blocks.7.1.transformer_blocks.0.ff.net.2.bias, unet.trainable_unet.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_q.weight, unet.trainable_unet.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_k.weight, unet.trainable_unet.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_v.weight, unet.trainable_unet.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_out.0.weight, unet.trainable_unet.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_out.0.bias, unet.trainable_unet.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm1.weight, unet.trainable_unet.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm1.bias, unet.trainable_unet.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm2.weight, unet.trainable_unet.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm2.bias, unet.trainable_unet.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm3.weight, unet.trainable_unet.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm3.bias, unet.trainable_unet.diffusion_model.output_blocks.7.1.proj_out.weight, unet.trainable_unet.diffusion_model.output_blocks.7.1.proj_out.bias, unet.trainable_unet.diffusion_model.output_blocks.8.0.in_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.8.0.in_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.8.0.in_layers.2.weight, unet.trainable_unet.diffusion_model.output_blocks.8.0.in_layers.2.bias, unet.trainable_unet.diffusion_model.output_blocks.8.0.emb_layers.1.weight, unet.trainable_unet.diffusion_model.output_blocks.8.0.emb_layers.1.bias, unet.trainable_unet.diffusion_model.output_blocks.8.0.out_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.8.0.out_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.8.0.out_layers.3.weight, unet.trainable_unet.diffusion_model.output_blocks.8.0.out_layers.3.bias, unet.trainable_unet.diffusion_model.output_blocks.8.0.skip_connection.weight, unet.trainable_unet.diffusion_model.output_blocks.8.0.skip_connection.bias, unet.trainable_unet.diffusion_model.output_blocks.8.1.norm.weight, unet.trainable_unet.diffusion_model.output_blocks.8.1.norm.bias, unet.trainable_unet.diffusion_model.output_blocks.8.1.proj_in.weight, unet.trainable_unet.diffusion_model.output_blocks.8.1.proj_in.bias, unet.trainable_unet.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_q.weight, unet.trainable_unet.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_k.weight, unet.trainable_unet.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_v.weight, unet.trainable_unet.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_out.0.weight, unet.trainable_unet.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_out.0.bias, unet.trainable_unet.diffusion_model.output_blocks.8.1.transformer_blocks.0.ff.net.0.proj.weight, unet.trainable_unet.diffusion_model.output_blocks.8.1.transformer_blocks.0.ff.net.0.proj.bias, unet.trainable_unet.diffusion_model.output_blocks.8.1.transformer_blocks.0.ff.net.2.weight, unet.trainable_unet.diffusion_model.output_blocks.8.1.transformer_blocks.0.ff.net.2.bias, unet.trainable_unet.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_q.weight, unet.trainable_unet.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_k.weight, unet.trainable_unet.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_v.weight, unet.trainable_unet.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_out.0.weight, unet.trainable_unet.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_out.0.bias, unet.trainable_unet.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm1.weight, unet.trainable_unet.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm1.bias, unet.trainable_unet.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm2.weight, unet.trainable_unet.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm2.bias, unet.trainable_unet.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm3.weight, unet.trainable_unet.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm3.bias, unet.trainable_unet.diffusion_model.output_blocks.8.1.proj_out.weight, unet.trainable_unet.diffusion_model.output_blocks.8.1.proj_out.bias, unet.trainable_unet.diffusion_model.output_blocks.8.2.conv.weight, unet.trainable_unet.diffusion_model.output_blocks.8.2.conv.bias, unet.trainable_unet.diffusion_model.output_blocks.9.0.in_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.9.0.in_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.9.0.in_layers.2.weight, unet.trainable_unet.diffusion_model.output_blocks.9.0.in_layers.2.bias, unet.trainable_unet.diffusion_model.output_blocks.9.0.emb_layers.1.weight, unet.trainable_unet.diffusion_model.output_blocks.9.0.emb_layers.1.bias, unet.trainable_unet.diffusion_model.output_blocks.9.0.out_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.9.0.out_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.9.0.out_layers.3.weight, unet.trainable_unet.diffusion_model.output_blocks.9.0.out_layers.3.bias, unet.trainable_unet.diffusion_model.output_blocks.9.0.skip_connection.weight, unet.trainable_unet.diffusion_model.output_blocks.9.0.skip_connection.bias, unet.trainable_unet.diffusion_model.output_blocks.9.1.norm.weight, unet.trainable_unet.diffusion_model.output_blocks.9.1.norm.bias, unet.trainable_unet.diffusion_model.output_blocks.9.1.proj_in.weight, unet.trainable_unet.diffusion_model.output_blocks.9.1.proj_in.bias, unet.trainable_unet.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_q.weight, unet.trainable_unet.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_k.weight, unet.trainable_unet.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_v.weight, unet.trainable_unet.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_out.0.weight, unet.trainable_unet.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_out.0.bias, unet.trainable_unet.diffusion_model.output_blocks.9.1.transformer_blocks.0.ff.net.0.proj.weight, unet.trainable_unet.diffusion_model.output_blocks.9.1.transformer_blocks.0.ff.net.0.proj.bias, unet.trainable_unet.diffusion_model.output_blocks.9.1.transformer_blocks.0.ff.net.2.weight, unet.trainable_unet.diffusion_model.output_blocks.9.1.transformer_blocks.0.ff.net.2.bias, unet.trainable_unet.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_q.weight, unet.trainable_unet.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_k.weight, unet.trainable_unet.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_v.weight, unet.trainable_unet.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_out.0.weight, unet.trainable_unet.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_out.0.bias, unet.trainable_unet.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm1.weight, unet.trainable_unet.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm1.bias, unet.trainable_unet.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm2.weight, unet.trainable_unet.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm2.bias, unet.trainable_unet.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm3.weight, unet.trainable_unet.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm3.bias, unet.trainable_unet.diffusion_model.output_blocks.9.1.proj_out.weight, unet.trainable_unet.diffusion_model.output_blocks.9.1.proj_out.bias, unet.trainable_unet.diffusion_model.output_blocks.10.0.in_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.10.0.in_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.10.0.in_layers.2.weight, unet.trainable_unet.diffusion_model.output_blocks.10.0.in_layers.2.bias, unet.trainable_unet.diffusion_model.output_blocks.10.0.emb_layers.1.weight, unet.trainable_unet.diffusion_model.output_blocks.10.0.emb_layers.1.bias, unet.trainable_unet.diffusion_model.output_blocks.10.0.out_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.10.0.out_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.10.0.out_layers.3.weight, unet.trainable_unet.diffusion_model.output_blocks.10.0.out_layers.3.bias, unet.trainable_unet.diffusion_model.output_blocks.10.0.skip_connection.weight, unet.trainable_unet.diffusion_model.output_blocks.10.0.skip_connection.bias, unet.trainable_unet.diffusion_model.output_blocks.10.1.norm.weight, unet.trainable_unet.diffusion_model.output_blocks.10.1.norm.bias, unet.trainable_unet.diffusion_model.output_blocks.10.1.proj_in.weight, unet.trainable_unet.diffusion_model.output_blocks.10.1.proj_in.bias, unet.trainable_unet.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_q.weight, unet.trainable_unet.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_k.weight, unet.trainable_unet.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_v.weight, unet.trainable_unet.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_out.0.weight, unet.trainable_unet.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_out.0.bias, unet.trainable_unet.diffusion_model.output_blocks.10.1.transformer_blocks.0.ff.net.0.proj.weight, unet.trainable_unet.diffusion_model.output_blocks.10.1.transformer_blocks.0.ff.net.0.proj.bias, unet.trainable_unet.diffusion_model.output_blocks.10.1.transformer_blocks.0.ff.net.2.weight, unet.trainable_unet.diffusion_model.output_blocks.10.1.transformer_blocks.0.ff.net.2.bias, unet.trainable_unet.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_q.weight, unet.trainable_unet.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_k.weight, unet.trainable_unet.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_v.weight, unet.trainable_unet.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_out.0.weight, unet.trainable_unet.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_out.0.bias, unet.trainable_unet.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm1.weight, unet.trainable_unet.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm1.bias, unet.trainable_unet.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm2.weight, unet.trainable_unet.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm2.bias, unet.trainable_unet.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm3.weight, unet.trainable_unet.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm3.bias, unet.trainable_unet.diffusion_model.output_blocks.10.1.proj_out.weight, unet.trainable_unet.diffusion_model.output_blocks.10.1.proj_out.bias, unet.trainable_unet.diffusion_model.output_blocks.11.0.in_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.11.0.in_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.11.0.in_layers.2.weight, unet.trainable_unet.diffusion_model.output_blocks.11.0.in_layers.2.bias, unet.trainable_unet.diffusion_model.output_blocks.11.0.emb_layers.1.weight, unet.trainable_unet.diffusion_model.output_blocks.11.0.emb_layers.1.bias, unet.trainable_unet.diffusion_model.output_blocks.11.0.out_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.11.0.out_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.11.0.out_layers.3.weight, unet.trainable_unet.diffusion_model.output_blocks.11.0.out_layers.3.bias, unet.trainable_unet.diffusion_model.output_blocks.11.0.skip_connection.weight, unet.trainable_unet.diffusion_model.output_blocks.11.0.skip_connection.bias, unet.trainable_unet.diffusion_model.output_blocks.11.1.norm.weight, unet.trainable_unet.diffusion_model.output_blocks.11.1.norm.bias, unet.trainable_unet.diffusion_model.output_blocks.11.1.proj_in.weight, unet.trainable_unet.diffusion_model.output_blocks.11.1.proj_in.bias, unet.trainable_unet.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_q.weight, unet.trainable_unet.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_k.weight, unet.trainable_unet.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_v.weight, unet.trainable_unet.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_out.0.weight, unet.trainable_unet.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_out.0.bias, unet.trainable_unet.diffusion_model.output_blocks.11.1.transformer_blocks.0.ff.net.0.proj.weight, unet.trainable_unet.diffusion_model.output_blocks.11.1.transformer_blocks.0.ff.net.0.proj.bias, unet.trainable_unet.diffusion_model.output_blocks.11.1.transformer_blocks.0.ff.net.2.weight, unet.trainable_unet.diffusion_model.output_blocks.11.1.transformer_blocks.0.ff.net.2.bias, unet.trainable_unet.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_q.weight, unet.trainable_unet.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_k.weight, unet.trainable_unet.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_v.weight, unet.trainable_unet.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_out.0.weight, unet.trainable_unet.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_out.0.bias, unet.trainable_unet.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm1.weight, unet.trainable_unet.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm1.bias, unet.trainable_unet.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm2.weight, unet.trainable_unet.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm2.bias, unet.trainable_unet.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm3.weight, unet.trainable_unet.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm3.bias, unet.trainable_unet.diffusion_model.output_blocks.11.1.proj_out.weight, unet.trainable_unet.diffusion_model.output_blocks.11.1.proj_out.bias, unet.trainable_unet.diffusion_model.out.0.weight, unet.trainable_unet.diffusion_model.out.0.bias, unet.trainable_unet.diffusion_model.out.2.weight, unet.trainable_unet.diffusion_model.out.2.bias, unet.zero_convs.0.weight, unet.zero_convs.0.bias, unet.zero_convs.1.weight, unet.zero_convs.1.bias, unet.zero_convs.2.weight, unet.zero_convs.2.bias, unet.zero_convs.3.weight, unet.zero_convs.3.bias, unet.zero_convs.4.weight, unet.zero_convs.4.bias, unet.zero_convs.5.weight, unet.zero_convs.5.bias, box_encoder.out64.0.weight, box_encoder.out64.0.bias, box_encoder.out32.0.weight, box_encoder.out32.0.bias, box_encoder.out16.0.weight, box_encoder.out16.0.bias, box_encoder.conv64.0.weight, box_encoder.conv64.0.bias, box_encoder.conv64.2.weight, box_encoder.conv64.2.bias, box_encoder.conv64.4.weight, box_encoder.conv64.4.bias, box_encoder.conv32.0.weight, box_encoder.conv32.0.bias, box_encoder.conv16.0.weight, box_encoder.conv16.0.bias

2025-04-22 07:53:54,648 - mmseg - INFO - Start running, host: s203557@n-62-20-3, work_dir: /work3/s203557/experiments/control_net_vpd
2025-04-22 07:53:54,648 - mmseg - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(NORMAL      ) TrainVisualizeHook                 
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
2025-04-22 07:53:54,649 - mmseg - INFO - workflow: [('train', 1)], max: 10000 iters
2025-04-22 07:53:54,649 - mmseg - INFO - Checkpoints will be saved to /work3/s203557/experiments/control_net_vpd by HardDiskBackend.
2025-04-22 07:54:41,002 - mmseg - INFO - Iter [50/10000]	lr: 2.601e-06, eta: 2:30:49, time: 0.909, data_time: 0.025, memory: 14101, decode.loss_ce: 0.1831, decode.acc_seg: 92.3511, loss: 0.1831
2025-04-22 07:55:21,253 - mmseg - INFO - Iter [100/10000]	lr: 5.228e-06, eta: 2:21:26, time: 0.805, data_time: 0.011, memory: 14101, decode.loss_ce: 0.1764, decode.acc_seg: 93.0019, loss: 0.1764
2025-04-22 07:56:01,741 - mmseg - INFO - Iter [150/10000]	lr: 7.828e-06, eta: 2:18:07, time: 0.810, data_time: 0.011, memory: 14101, decode.loss_ce: 0.1838, decode.acc_seg: 92.4608, loss: 0.1838
2025-04-22 07:56:42,344 - mmseg - INFO - Iter [200/10000]	lr: 1.040e-05, eta: 2:16:13, time: 0.812, data_time: 0.011, memory: 14101, decode.loss_ce: 0.1770, decode.acc_seg: 93.0803, loss: 0.1770
2025-04-22 07:57:22,998 - mmseg - INFO - Iter [250/10000]	lr: 1.295e-05, eta: 2:14:51, time: 0.813, data_time: 0.011, memory: 14101, decode.loss_ce: 0.2116, decode.acc_seg: 91.8404, loss: 0.2116
2025-04-22 07:58:03,661 - mmseg - INFO - Iter [300/10000]	lr: 1.547e-05, eta: 2:13:42, time: 0.813, data_time: 0.011, memory: 14101, decode.loss_ce: 0.2063, decode.acc_seg: 91.4906, loss: 0.2063
2025-04-22 07:58:44,263 - mmseg - INFO - Iter [350/10000]	lr: 1.796e-05, eta: 2:12:40, time: 0.812, data_time: 0.011, memory: 14101, decode.loss_ce: 0.1713, decode.acc_seg: 92.8997, loss: 0.1713
2025-04-22 07:59:24,913 - mmseg - INFO - Iter [400/10000]	lr: 2.043e-05, eta: 2:11:45, time: 0.813, data_time: 0.011, memory: 14101, decode.loss_ce: 0.1745, decode.acc_seg: 93.0394, loss: 0.1745
2025-04-22 08:00:05,515 - mmseg - INFO - Iter [450/10000]	lr: 2.287e-05, eta: 2:10:51, time: 0.812, data_time: 0.011, memory: 14101, decode.loss_ce: 0.1851, decode.acc_seg: 92.5686, loss: 0.1851
2025-04-22 08:00:46,153 - mmseg - INFO - Iter [500/10000]	lr: 2.529e-05, eta: 2:10:01, time: 0.813, data_time: 0.011, memory: 14101, decode.loss_ce: 0.1963, decode.acc_seg: 92.0479, loss: 0.1963
2025-04-22 08:01:26,797 - mmseg - INFO - Iter [550/10000]	lr: 2.767e-05, eta: 2:09:13, time: 0.813, data_time: 0.011, memory: 14101, decode.loss_ce: 0.1583, decode.acc_seg: 93.5993, loss: 0.1583
2025-04-22 08:02:07,465 - mmseg - INFO - Iter [600/10000]	lr: 3.003e-05, eta: 2:08:26, time: 0.813, data_time: 0.011, memory: 14101, decode.loss_ce: 0.1763, decode.acc_seg: 93.2676, loss: 0.1763
2025-04-22 08:02:48,175 - mmseg - INFO - Iter [650/10000]	lr: 3.237e-05, eta: 2:07:41, time: 0.814, data_time: 0.011, memory: 14101, decode.loss_ce: 0.1836, decode.acc_seg: 92.7921, loss: 0.1836
2025-04-22 08:03:28,810 - mmseg - INFO - Iter [700/10000]	lr: 3.467e-05, eta: 2:06:56, time: 0.813, data_time: 0.011, memory: 14101, decode.loss_ce: 0.1969, decode.acc_seg: 92.5951, loss: 0.1969
2025-04-22 08:04:09,420 - mmseg - INFO - Iter [750/10000]	lr: 3.695e-05, eta: 2:06:11, time: 0.812, data_time: 0.011, memory: 14101, decode.loss_ce: 0.1509, decode.acc_seg: 93.6780, loss: 0.1509
2025-04-22 08:04:50,067 - mmseg - INFO - Iter [800/10000]	lr: 3.921e-05, eta: 2:05:27, time: 0.813, data_time: 0.011, memory: 14101, decode.loss_ce: 0.1819, decode.acc_seg: 92.7167, loss: 0.1819
2025-04-22 08:05:30,681 - mmseg - INFO - Iter [850/10000]	lr: 4.144e-05, eta: 2:04:43, time: 0.812, data_time: 0.011, memory: 14101, decode.loss_ce: 0.1739, decode.acc_seg: 92.5595, loss: 0.1739
2025-04-22 08:06:11,329 - mmseg - INFO - Iter [900/10000]	lr: 4.364e-05, eta: 2:03:59, time: 0.813, data_time: 0.011, memory: 14101, decode.loss_ce: 0.1842, decode.acc_seg: 92.6788, loss: 0.1842
2025-04-22 08:06:51,983 - mmseg - INFO - Iter [950/10000]	lr: 4.581e-05, eta: 2:03:16, time: 0.813, data_time: 0.011, memory: 14101, decode.loss_ce: 0.1771, decode.acc_seg: 92.8308, loss: 0.1771
2025-04-22 08:07:32,670 - mmseg - INFO - Saving checkpoint at 1000 iterations
2025-04-22 08:07:45,841 - mmseg - INFO - Exp name: vpd_config.py
2025-04-22 08:07:45,842 - mmseg - INFO - Iter [1000/10000]	lr: 4.796e-05, eta: 2:04:32, time: 1.078, data_time: 0.011, memory: 14101, decode.loss_ce: 0.1676, decode.acc_seg: 93.1387, loss: 0.1676
Traceback (most recent call last):
  File "segmentation/train.py", line 274, in <module>
    main()
  File "segmentation/train.py", line 263, in main
    train_segmentor(
  File "/dtu/blackhole/0e/154958/miniconda3/envs/ldm/lib/python3.8/site-packages/mmseg/apis/train.py", line 194, in train_segmentor
    runner.run(data_loaders, cfg.workflow)
  File "/dtu/blackhole/0e/154958/miniconda3/envs/ldm/lib/python3.8/site-packages/mmcv/runner/iter_based_runner.py", line 134, in run
    iter_runner(iter_loaders[i], **kwargs)
  File "/dtu/blackhole/0e/154958/miniconda3/envs/ldm/lib/python3.8/site-packages/mmcv/runner/iter_based_runner.py", line 67, in train
    self.call_hook('after_train_iter')
  File "/dtu/blackhole/0e/154958/miniconda3/envs/ldm/lib/python3.8/site-packages/mmcv/runner/base_runner.py", line 309, in call_hook
    getattr(hook, fn_name)(self)
  File "/dtu/blackhole/0e/154958/miniconda3/envs/ldm/lib/python3.8/site-packages/mmcv/runner/hooks/evaluation.py", line 262, in after_train_iter
    self._do_evaluate(runner)
  File "/dtu/blackhole/0e/154958/miniconda3/envs/ldm/lib/python3.8/site-packages/mmseg/core/evaluation/eval_hooks.py", line 51, in _do_evaluate
    results = single_gpu_test(
  File "/dtu/blackhole/0e/154958/miniconda3/envs/ldm/lib/python3.8/site-packages/mmseg/apis/test.py", line 91, in single_gpu_test
    result = model(return_loss=False, **data)
  File "/dtu/blackhole/0e/154958/miniconda3/envs/ldm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/dtu/blackhole/0e/154958/miniconda3/envs/ldm/lib/python3.8/site-packages/mmcv/parallel/data_parallel.py", line 50, in forward
    return super().forward(*inputs, **kwargs)
  File "/dtu/blackhole/0e/154958/miniconda3/envs/ldm/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py", line 166, in forward
    return self.module(*inputs[0], **kwargs[0])
  File "/dtu/blackhole/0e/154958/miniconda3/envs/ldm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/dtu/blackhole/0e/154958/miniconda3/envs/ldm/lib/python3.8/site-packages/mmcv/runner/fp16_utils.py", line 110, in new_func
    return old_func(*args, **kwargs)
  File "/dtu/blackhole/0e/154958/miniconda3/envs/ldm/lib/python3.8/site-packages/mmseg/models/segmentors/base.py", line 110, in forward
    return self.forward_test(img, img_metas, **kwargs)
  File "/dtu/blackhole/0e/154958/miniconda3/envs/ldm/lib/python3.8/site-packages/mmseg/models/segmentors/base.py", line 92, in forward_test
    return self.simple_test(imgs[0], img_metas[0], **kwargs)
  File "/zhome/b6/d/154958/ADLCV_Project/VPD/segmentation/models/vpd_seg.py", line 329, in simple_test
    seg_logit = self.inference(img, img_meta, gt_bbox_masks=gt_bbox_masks,rescale= rescale)
  File "/zhome/b6/d/154958/ADLCV_Project/VPD/segmentation/models/vpd_seg.py", line 309, in inference
    seg_logits = self.whole_inference(img, img_meta, gt_bbox_masks=gt_bbox_masks, rescale=rescale)
  File "/zhome/b6/d/154958/ADLCV_Project/VPD/segmentation/models/vpd_seg.py", line 267, in whole_inference
    seg_logit = self.encode_decode(img, img_meta,gt_bbox_masks=gt_bbox_masks)
  File "/zhome/b6/d/154958/ADLCV_Project/VPD/segmentation/models/vpd_seg.py", line 207, in encode_decode
    x = self.extract_feat(img, boxes=gt_bbox_masks)
  File "/zhome/b6/d/154958/ADLCV_Project/VPD/segmentation/models/vpd_seg.py", line 117, in extract_feat
    outs = self.unet(latents, t, context=c_crossattn, box_control=box_feats)
  File "/dtu/blackhole/0e/154958/miniconda3/envs/ldm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/zhome/b6/d/154958/ADLCV_Project/VPD/vpd/models_anton.py", line 298, in forward
    h = torch.cat([h, hs.pop()], dim=1)
RuntimeError: Sizes of tensors must match except in dimension 1. Expected size 44 but got size 43 for tensor number 1 in the list.
