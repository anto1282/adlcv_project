Loaded dependency [python3/3.11.4]: gcc/12.3.0-binutils-2.40
Loaded dependency [python3/3.11.4]: sqlite3/3.42.0
Loaded module: python3/3.11.4

Loading python3/3.11.4
  Loading requirement: gcc/12.3.0-binutils-2.40 sqlite3/3.42.0
Loaded module: cuda/11.3
/dtu/blackhole/0e/154958/miniconda3/envs/ldm/lib/python3.8/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
2025-04-29 08:20:19,515 - mmseg - INFO - Multi-processing start method is `None`
2025-04-29 08:20:19,583 - mmseg - INFO - OpenCV num_threads is `1
2025-04-29 08:20:19,583 - mmseg - INFO - OMP num threads is 1
2025-04-29 08:20:19,687 - mmseg - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.8.19 | packaged by conda-forge | (default, Mar 20 2024, 12:47:35) [GCC 12.3.0]
CUDA available: True
GPU 0: Tesla V100-PCIE-32GB
CUDA_HOME: /appl/cuda/11.3.0
NVCC: Cuda compilation tools, release 11.3, V11.3.58
GCC: gcc (GCC) 12.3.0
PyTorch: 1.11.0+cu113
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.5.2 (Git Hash a9302535553c73243c632ad3c4c80beec3d19a1e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.11.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

TorchVision: 0.12.0+cu113
OpenCV: 4.6.0
MMCV: 1.5.0
MMCV Compiler: GCC 7.3
MMCV CUDA Compiler: 11.3
MMSegmentation: 0.29.0+036134c
------------------------------------------------------------

2025-04-29 08:20:19,688 - mmseg - INFO - Distributed training: False
2025-04-29 08:20:21,110 - mmseg - INFO - Config:
norm_cfg = dict(type='SyncBN', requires_grad=True)
model = dict(
    type='VPDSeg',
    pretrained='open-mmlab://resnet50_v1c',
    backbone=dict(
        type='ResNetV1c',
        depth=50,
        num_stages=4,
        out_indices=(0, 1, 2, 3),
        dilations=(1, 1, 1, 1),
        strides=(1, 2, 2, 2),
        norm_cfg=dict(type='SyncBN', requires_grad=True),
        norm_eval=False,
        style='pytorch',
        contract_dilation=True),
    neck=dict(
        type='FPN',
        in_channels=[320, 790, 1430, 1280],
        out_channels=256,
        num_outs=4),
    decode_head=dict(
        type='FPNHead',
        in_channels=[256, 256, 256, 256],
        in_index=[0, 1, 2, 3],
        feature_strides=[4, 8, 16, 32],
        channels=256,
        dropout_ratio=0.1,
        num_classes=150,
        norm_cfg=dict(type='SyncBN', requires_grad=True),
        align_corners=False,
        loss_decode=dict(
            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0)),
    train_cfg=dict(),
    test_cfg=dict(mode='slide', crop_size=(512, 512), stride=(341, 341)),
    sd_path='/work3/s203557/checkpoints/v1-5-pruned-emaonly.ckpt',
    sd_config=
    '/zhome/b6/d/154958/ADLCV_Project/VPD/segmentation/v1-inference.yaml',
    max_boxes=6)
dataset_type = 'ADE20KDataset'
data_root = '/work3/s203520/advanced_computer_vision/filtered_dataset'
IMG_MEAN = [127.5, 127.5, 127.5]
IMG_VAR = [127.5, 127.5, 127.5]
img_norm_cfg = dict(
    mean=[127.5, 127.5, 127.5], std=[127.5, 127.5, 127.5], to_rgb=True)
crop_size = (512, 512)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations', reduce_zero_label=True),
    dict(
        type='LoadPerClassMasksFromFolder',
        mask_root=
        '/work3/s203520/advanced_computer_vision/filtered_dataset/prompt_masks',
        types=['box', 'scribble', 'dot'],
        suffix='.npy',
        random_select=True),
    dict(type='ResizeWithBBox', img_scale=(2048, 512), ratio_range=(0.5, 2.0)),
    dict(type='RandomCropWithBBox', crop_size=(512, 512), cat_max_ratio=0.75),
    dict(type='RandomFlipWithBBox', prob=0.5),
    dict(type='PhotoMetricDistortion'),
    dict(
        type='Normalize',
        mean=[127.5, 127.5, 127.5],
        std=[127.5, 127.5, 127.5],
        to_rgb=True),
    dict(
        type='PadToSizeWithBBox', size=(512, 512), pad_val=0, seg_pad_val=255),
    dict(type='DefaultFormatBundle'),
    dict(
        type='Collect',
        keys=['img', 'gt_semantic_seg', 'gt_bbox_masks'],
        meta_keys=('filename', 'ori_shape', 'img_shape', 'pad_shape',
                   'scale_factor', 'input_type'))
]
val_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(512, 512),
        flip=False,
        transforms=[
            dict(
                type='LoadPerClassMasksFromFolder',
                mask_root=
                '/work3/s203520/advanced_computer_vision/filtered_dataset/prompt_masks',
                suffix='.npy',
                types=['box', 'scribble', 'dot'],
                random_select=True),
            dict(type='ResizeWithBBox', keep_ratio=False),
            dict(type='RandomFlipWithBBox', prob=0.0),
            dict(
                type='Normalize',
                mean=[127.5, 127.5, 127.5],
                std=[127.5, 127.5, 127.5],
                to_rgb=True),
            dict(type='ImageToTensor', keys=['img']),
            dict(
                type='Collect',
                keys=['img', 'gt_bbox_masks'],
                meta_keys=('filename', 'ori_shape', 'img_shape', 'pad_shape',
                           'scale_factor', 'input_type'))
        ])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(512, 512),
        flip=False,
        transforms=[
            dict(
                type='LoadPerClassMasksFromFolder',
                mask_root=
                '/work3/s203520/advanced_computer_vision/filtered_dataset/prompt_masks',
                suffix='.npy',
                types=['box', 'scribble', 'dot'],
                random_select=True),
            dict(type='ResizeWithBBox', keep_ratio=False),
            dict(type='RandomFlipWithBBox', prob=0.0),
            dict(
                type='Normalize',
                mean=[127.5, 127.5, 127.5],
                std=[127.5, 127.5, 127.5],
                to_rgb=True),
            dict(type='ImageToTensor', keys=['img']),
            dict(
                type='Collect',
                keys=['img', 'gt_bbox_masks'],
                meta_keys=('filename', 'ori_shape', 'img_shape', 'pad_shape',
                           'scale_factor', 'input_type'))
        ])
]
data = dict(
    samples_per_gpu=4,
    workers_per_gpu=8,
    train=dict(
        type='ADE20KDataset',
        data_root='/work3/s203520/advanced_computer_vision/filtered_dataset',
        img_dir='images/training',
        ann_dir='annotations/training',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations', reduce_zero_label=True),
            dict(
                type='LoadPerClassMasksFromFolder',
                mask_root=
                '/work3/s203520/advanced_computer_vision/filtered_dataset/prompt_masks',
                types=['box', 'scribble', 'dot'],
                suffix='.npy',
                random_select=True),
            dict(
                type='ResizeWithBBox',
                img_scale=(2048, 512),
                ratio_range=(0.5, 2.0)),
            dict(
                type='RandomCropWithBBox',
                crop_size=(512, 512),
                cat_max_ratio=0.75),
            dict(type='RandomFlipWithBBox', prob=0.5),
            dict(type='PhotoMetricDistortion'),
            dict(
                type='Normalize',
                mean=[127.5, 127.5, 127.5],
                std=[127.5, 127.5, 127.5],
                to_rgb=True),
            dict(
                type='PadToSizeWithBBox',
                size=(512, 512),
                pad_val=0,
                seg_pad_val=255),
            dict(type='DefaultFormatBundle'),
            dict(
                type='Collect',
                keys=['img', 'gt_semantic_seg', 'gt_bbox_masks'],
                meta_keys=('filename', 'ori_shape', 'img_shape', 'pad_shape',
                           'scale_factor', 'input_type'))
        ]),
    val=dict(
        type='ADE20KDataset',
        data_root='/work3/s203520/advanced_computer_vision/filtered_dataset',
        img_dir='images/validation',
        ann_dir='annotations/validation',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(512, 512),
                flip=False,
                transforms=[
                    dict(
                        type='LoadPerClassMasksFromFolder',
                        mask_root=
                        '/work3/s203520/advanced_computer_vision/filtered_dataset/prompt_masks',
                        suffix='.npy',
                        types=['box', 'scribble', 'dot'],
                        random_select=True),
                    dict(type='ResizeWithBBox', keep_ratio=False),
                    dict(type='RandomFlipWithBBox', prob=0.0),
                    dict(
                        type='Normalize',
                        mean=[127.5, 127.5, 127.5],
                        std=[127.5, 127.5, 127.5],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(
                        type='Collect',
                        keys=['img', 'gt_bbox_masks'],
                        meta_keys=('filename', 'ori_shape', 'img_shape',
                                   'pad_shape', 'scale_factor', 'input_type'))
                ])
        ]),
    test=dict(
        type='ADE20KDataset',
        data_root='/work3/s203520/advanced_computer_vision/filtered_dataset',
        img_dir='images/validation',
        ann_dir='annotations/validation',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(512, 512),
                flip=False,
                transforms=[
                    dict(
                        type='LoadPerClassMasksFromFolder',
                        mask_root=
                        '/work3/s203520/advanced_computer_vision/filtered_dataset/prompt_masks',
                        suffix='.npy',
                        types=['box', 'scribble', 'dot'],
                        random_select=True),
                    dict(type='ResizeWithBBox', keep_ratio=False),
                    dict(type='RandomFlipWithBBox', prob=0.0),
                    dict(
                        type='Normalize',
                        mean=[127.5, 127.5, 127.5],
                        std=[127.5, 127.5, 127.5],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(
                        type='Collect',
                        keys=['img', 'gt_bbox_masks'],
                        meta_keys=('filename', 'ori_shape', 'img_shape',
                                   'pad_shape', 'scale_factor', 'input_type'))
                ])
        ]))
log_config = dict(
    interval=50, hooks=[dict(type='TextLoggerHook', by_epoch=False)])
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = '/work3/s203557/checkpoints/vpd.chkpt'
resume_from = None
workflow = [('train', 1)]
cudnn_benchmark = True
find_unused_parameters = True
optimizer = dict(
    type='AdamW',
    lr=8e-05,
    weight_decay=0.001,
    paramwise_cfg=dict(
        custom_keys=dict(
            trainable_unet=dict(lr_mult=0.1), encoder_vq=dict(lr_mult=0.0))))
optimizer_config = dict()
lr_config = dict(
    policy='poly',
    power=1,
    min_lr=0.0,
    by_epoch=False,
    warmup='linear',
    warmup_iters=1500,
    warmup_ratio=1e-06)
runner = dict(type='IterBasedRunner', max_iters=20000)
checkpoint_config = dict(by_epoch=False, interval=2000)
evaluation = dict(interval=2000, metric='mIoU')
custom_imports = dict(
    imports=['segmentation.hooks.visualize_hook'], allow_failed_imports=False)
work_dir = '/work3/s203557/experiments/control_net_vpd/'
fp16 = dict(loss_scale=512.0)
custom_hooks = [
    dict(
        type='TrainVisualizeHook',
        interval=4000,
        num_samples=2,
        save_dir='vis')
]
gpu_ids = [0]
auto_resume = False

2025-04-29 08:20:21,111 - mmseg - INFO - Set random seed to 1913173666, deterministic: False
/dtu/blackhole/0e/154958/miniconda3/envs/ldm/lib/python3.8/site-packages/mmseg/models/losses/cross_entropy_loss.py:235: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.
  warnings.warn(
2025-04-29 08:20:33,878 - mmseg - INFO - initialize FPN with init_cfg {'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}
2025-04-29 08:20:33,900 - mmseg - INFO - initialize FPNHead with init_cfg {'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
segmentation/train.py:251: UserWarning: SyncBN is only supported with DDP. To be compatible with DP, we convert SyncBN to BN. Please use dist_train.sh which can avoid this error.
  warnings.warn(
2025-04-29 08:20:34,758 - mmseg - INFO - VPDSeg(
  (encoder_vq): AutoencoderKL(
    (encoder): Encoder(
      (conv_in): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (down): ModuleList(
        (0): Module(
          (block): ModuleList(
            (0): ResnetBlock(
              (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)
              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
            (1): ResnetBlock(
              (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)
              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (attn): ModuleList()
          (downsample): Downsample(
            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2))
          )
        )
        (1): Module(
          (block): ModuleList(
            (0): ResnetBlock(
              (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)
              (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (nin_shortcut): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): ResnetBlock(
              (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (attn): ModuleList()
          (downsample): Downsample(
            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))
          )
        )
        (2): Module(
          (block): ModuleList(
            (0): ResnetBlock(
              (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)
              (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (nin_shortcut): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): ResnetBlock(
              (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)
              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (attn): ModuleList()
          (downsample): Downsample(
            (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2))
          )
        )
        (3): Module(
          (block): ModuleList(
            (0): ResnetBlock(
              (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)
              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
            (1): ResnetBlock(
              (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)
              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (attn): ModuleList()
        )
      )
      (mid): Module(
        (block_1): ResnetBlock(
          (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)
          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (attn_1): AttnBlock(
          (norm): GroupNorm(32, 512, eps=1e-06, affine=True)
          (q): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (k): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (v): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (proj_out): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
        )
        (block_2): ResnetBlock(
          (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)
          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (norm_out): GroupNorm(32, 512, eps=1e-06, affine=True)
      (conv_out): Conv2d(512, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (loss): Identity()
    (quant_conv): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1))
    (post_quant_conv): Conv2d(4, 4, kernel_size=(1, 1), stride=(1, 1))
  )
  (unet): UNetWrapper(
    (unet): DiffusionWrapper(
      (diffusion_model): UNetModel(
        (time_embed): Sequential(
          (0): Linear(in_features=320, out_features=1280, bias=True)
          (1): SiLU()
          (2): Linear(in_features=1280, out_features=1280, bias=True)
        )
        (input_blocks): ModuleList(
          (0): TimestepEmbedSequential(
            (0): Conv2d(4, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (1): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=320, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Identity()
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 320, eps=1e-06, affine=True)
              (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=320, out_features=320, bias=False)
                    (to_v): Linear(in_features=320, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=320, out_features=2560, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=1280, out_features=320, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=768, out_features=320, bias=False)
                    (to_v): Linear(in_features=768, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (2): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=320, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Identity()
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 320, eps=1e-06, affine=True)
              (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=320, out_features=320, bias=False)
                    (to_v): Linear(in_features=320, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=320, out_features=2560, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=1280, out_features=320, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=768, out_features=320, bias=False)
                    (to_v): Linear(in_features=768, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (3): TimestepEmbedSequential(
            (0): Downsample(
              (op): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
            )
          )
          (4): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(320, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=640, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(320, 640, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 640, eps=1e-06, affine=True)
              (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=640, out_features=640, bias=False)
                    (to_v): Linear(in_features=640, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=640, out_features=5120, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=2560, out_features=640, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=768, out_features=640, bias=False)
                    (to_v): Linear(in_features=768, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (5): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=640, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Identity()
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 640, eps=1e-06, affine=True)
              (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=640, out_features=640, bias=False)
                    (to_v): Linear(in_features=640, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=640, out_features=5120, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=2560, out_features=640, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=768, out_features=640, bias=False)
                    (to_v): Linear(in_features=768, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (6): TimestepEmbedSequential(
            (0): Downsample(
              (op): Conv2d(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
            )
          )
          (7): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(640, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(640, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)
              (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_v): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=1280, out_features=10240, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=5120, out_features=1280, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=768, out_features=1280, bias=False)
                    (to_v): Linear(in_features=768, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (8): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Identity()
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)
              (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_v): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=1280, out_features=10240, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=5120, out_features=1280, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=768, out_features=1280, bias=False)
                    (to_v): Linear(in_features=768, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (9): TimestepEmbedSequential(
            (0): Downsample(
              (op): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
            )
          )
          (10): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Identity()
            )
          )
          (11): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Identity()
            )
          )
        )
        (middle_block): TimestepEmbedSequential(
          (0): ResBlock(
            (in_layers): Sequential(
              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
              (1): SiLU()
              (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
            (h_upd): Identity()
            (x_upd): Identity()
            (emb_layers): Sequential(
              (0): SiLU()
              (1): Linear(in_features=1280, out_features=1280, bias=True)
            )
            (out_layers): Sequential(
              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
              (1): SiLU()
              (2): Dropout(p=0, inplace=False)
              (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
            (skip_connection): Identity()
          )
          (1): SpatialTransformer(
            (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)
            (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
            (transformer_blocks): ModuleList(
              (0): BasicTransformerBlock(
                (attn1): CrossAttention(
                  (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                  (to_k): Linear(in_features=1280, out_features=1280, bias=False)
                  (to_v): Linear(in_features=1280, out_features=1280, bias=False)
                  (to_out): Sequential(
                    (0): Linear(in_features=1280, out_features=1280, bias=True)
                    (1): Dropout(p=0.0, inplace=False)
                  )
                )
                (ff): FeedForward(
                  (net): Sequential(
                    (0): GEGLU(
                      (proj): Linear(in_features=1280, out_features=10240, bias=True)
                    )
                    (1): Dropout(p=0.0, inplace=False)
                    (2): Linear(in_features=5120, out_features=1280, bias=True)
                  )
                )
                (attn2): CrossAttention(
                  (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                  (to_k): Linear(in_features=768, out_features=1280, bias=False)
                  (to_v): Linear(in_features=768, out_features=1280, bias=False)
                  (to_out): Sequential(
                    (0): Linear(in_features=1280, out_features=1280, bias=True)
                    (1): Dropout(p=0.0, inplace=False)
                  )
                )
                (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
              )
            )
            (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
          )
          (2): ResBlock(
            (in_layers): Sequential(
              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
              (1): SiLU()
              (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
            (h_upd): Identity()
            (x_upd): Identity()
            (emb_layers): Sequential(
              (0): SiLU()
              (1): Linear(in_features=1280, out_features=1280, bias=True)
            )
            (out_layers): Sequential(
              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
              (1): SiLU()
              (2): Dropout(p=0, inplace=False)
              (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
            (skip_connection): Identity()
          )
        )
        (output_blocks): ModuleList(
          (0): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (1): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (2): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): Upsample(
              (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (3): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)
              (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_v): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=1280, out_features=10240, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=5120, out_features=1280, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=768, out_features=1280, bias=False)
                    (to_v): Linear(in_features=768, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (4): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)
              (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_v): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=1280, out_features=10240, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=5120, out_features=1280, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=768, out_features=1280, bias=False)
                    (to_v): Linear(in_features=768, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (5): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 1920, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(1920, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(1920, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)
              (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_v): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=1280, out_features=10240, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=5120, out_features=1280, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=768, out_features=1280, bias=False)
                    (to_v): Linear(in_features=768, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
            (2): Upsample(
              (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (6): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 1920, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(1920, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=640, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(1920, 640, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 640, eps=1e-06, affine=True)
              (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=640, out_features=640, bias=False)
                    (to_v): Linear(in_features=640, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=640, out_features=5120, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=2560, out_features=640, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=768, out_features=640, bias=False)
                    (to_v): Linear(in_features=768, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (7): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(1280, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=640, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 640, eps=1e-06, affine=True)
              (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=640, out_features=640, bias=False)
                    (to_v): Linear(in_features=640, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=640, out_features=5120, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=2560, out_features=640, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=768, out_features=640, bias=False)
                    (to_v): Linear(in_features=768, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (8): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 960, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(960, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=640, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(960, 640, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 640, eps=1e-06, affine=True)
              (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=640, out_features=640, bias=False)
                    (to_v): Linear(in_features=640, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=640, out_features=5120, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=2560, out_features=640, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=768, out_features=640, bias=False)
                    (to_v): Linear(in_features=768, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
            )
            (2): Upsample(
              (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (9): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 960, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(960, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=320, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 320, eps=1e-06, affine=True)
              (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=320, out_features=320, bias=False)
                    (to_v): Linear(in_features=320, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=320, out_features=2560, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=1280, out_features=320, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=768, out_features=320, bias=False)
                    (to_v): Linear(in_features=768, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (10): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=320, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 320, eps=1e-06, affine=True)
              (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=320, out_features=320, bias=False)
                    (to_v): Linear(in_features=320, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=320, out_features=2560, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=1280, out_features=320, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=768, out_features=320, bias=False)
                    (to_v): Linear(in_features=768, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (11): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=320, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 320, eps=1e-06, affine=True)
              (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=320, out_features=320, bias=False)
                    (to_v): Linear(in_features=320, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=320, out_features=2560, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=1280, out_features=320, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=768, out_features=320, bias=False)
                    (to_v): Linear(in_features=768, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
            )
          )
        )
        (out): Sequential(
          (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
          (1): SiLU()
          (2): Conv2d(320, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
    )
    (trainable_unet): DiffusionWrapper(
      (diffusion_model): UNetModel(
        (time_embed): Sequential(
          (0): Linear(in_features=320, out_features=1280, bias=True)
          (1): SiLU()
          (2): Linear(in_features=1280, out_features=1280, bias=True)
        )
        (input_blocks): ModuleList(
          (0): TimestepEmbedSequential(
            (0): Conv2d(4, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (1): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=320, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Identity()
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 320, eps=1e-06, affine=True)
              (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=320, out_features=320, bias=False)
                    (to_v): Linear(in_features=320, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=320, out_features=2560, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=1280, out_features=320, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=768, out_features=320, bias=False)
                    (to_v): Linear(in_features=768, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (2): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=320, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Identity()
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 320, eps=1e-06, affine=True)
              (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=320, out_features=320, bias=False)
                    (to_v): Linear(in_features=320, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=320, out_features=2560, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=1280, out_features=320, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=768, out_features=320, bias=False)
                    (to_v): Linear(in_features=768, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (3): TimestepEmbedSequential(
            (0): Downsample(
              (op): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
            )
          )
          (4): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(320, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=640, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(320, 640, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 640, eps=1e-06, affine=True)
              (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=640, out_features=640, bias=False)
                    (to_v): Linear(in_features=640, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=640, out_features=5120, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=2560, out_features=640, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=768, out_features=640, bias=False)
                    (to_v): Linear(in_features=768, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (5): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=640, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Identity()
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 640, eps=1e-06, affine=True)
              (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=640, out_features=640, bias=False)
                    (to_v): Linear(in_features=640, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=640, out_features=5120, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=2560, out_features=640, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=768, out_features=640, bias=False)
                    (to_v): Linear(in_features=768, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (6): TimestepEmbedSequential(
            (0): Downsample(
              (op): Conv2d(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
            )
          )
          (7): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(640, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(640, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)
              (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_v): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=1280, out_features=10240, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=5120, out_features=1280, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=768, out_features=1280, bias=False)
                    (to_v): Linear(in_features=768, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (8): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Identity()
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)
              (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_v): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=1280, out_features=10240, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=5120, out_features=1280, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=768, out_features=1280, bias=False)
                    (to_v): Linear(in_features=768, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (9): TimestepEmbedSequential(
            (0): Downsample(
              (op): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
            )
          )
          (10): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Identity()
            )
          )
          (11): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Identity()
            )
          )
        )
        (middle_block): TimestepEmbedSequential(
          (0): ResBlock(
            (in_layers): Sequential(
              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
              (1): SiLU()
              (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
            (h_upd): Identity()
            (x_upd): Identity()
            (emb_layers): Sequential(
              (0): SiLU()
              (1): Linear(in_features=1280, out_features=1280, bias=True)
            )
            (out_layers): Sequential(
              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
              (1): SiLU()
              (2): Dropout(p=0, inplace=False)
              (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
            (skip_connection): Identity()
          )
          (1): SpatialTransformer(
            (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)
            (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
            (transformer_blocks): ModuleList(
              (0): BasicTransformerBlock(
                (attn1): CrossAttention(
                  (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                  (to_k): Linear(in_features=1280, out_features=1280, bias=False)
                  (to_v): Linear(in_features=1280, out_features=1280, bias=False)
                  (to_out): Sequential(
                    (0): Linear(in_features=1280, out_features=1280, bias=True)
                    (1): Dropout(p=0.0, inplace=False)
                  )
                )
                (ff): FeedForward(
                  (net): Sequential(
                    (0): GEGLU(
                      (proj): Linear(in_features=1280, out_features=10240, bias=True)
                    )
                    (1): Dropout(p=0.0, inplace=False)
                    (2): Linear(in_features=5120, out_features=1280, bias=True)
                  )
                )
                (attn2): CrossAttention(
                  (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                  (to_k): Linear(in_features=768, out_features=1280, bias=False)
                  (to_v): Linear(in_features=768, out_features=1280, bias=False)
                  (to_out): Sequential(
                    (0): Linear(in_features=1280, out_features=1280, bias=True)
                    (1): Dropout(p=0.0, inplace=False)
                  )
                )
                (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
              )
            )
            (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
          )
          (2): ResBlock(
            (in_layers): Sequential(
              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
              (1): SiLU()
              (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
            (h_upd): Identity()
            (x_upd): Identity()
            (emb_layers): Sequential(
              (0): SiLU()
              (1): Linear(in_features=1280, out_features=1280, bias=True)
            )
            (out_layers): Sequential(
              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
              (1): SiLU()
              (2): Dropout(p=0, inplace=False)
              (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
            (skip_connection): Identity()
          )
        )
        (output_blocks): ModuleList(
          (0): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (1): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (2): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): Upsample(
              (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (3): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)
              (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_v): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=1280, out_features=10240, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=5120, out_features=1280, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=768, out_features=1280, bias=False)
                    (to_v): Linear(in_features=768, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (4): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)
              (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_v): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=1280, out_features=10240, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=5120, out_features=1280, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=768, out_features=1280, bias=False)
                    (to_v): Linear(in_features=768, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (5): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 1920, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(1920, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(1920, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)
              (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_v): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=1280, out_features=10240, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=5120, out_features=1280, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=768, out_features=1280, bias=False)
                    (to_v): Linear(in_features=768, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
            (2): Upsample(
              (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (6): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 1920, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(1920, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=640, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(1920, 640, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 640, eps=1e-06, affine=True)
              (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=640, out_features=640, bias=False)
                    (to_v): Linear(in_features=640, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=640, out_features=5120, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=2560, out_features=640, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=768, out_features=640, bias=False)
                    (to_v): Linear(in_features=768, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (7): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(1280, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=640, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 640, eps=1e-06, affine=True)
              (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=640, out_features=640, bias=False)
                    (to_v): Linear(in_features=640, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=640, out_features=5120, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=2560, out_features=640, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=768, out_features=640, bias=False)
                    (to_v): Linear(in_features=768, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (8): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 960, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(960, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=640, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(960, 640, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 640, eps=1e-06, affine=True)
              (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=640, out_features=640, bias=False)
                    (to_v): Linear(in_features=640, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=640, out_features=5120, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=2560, out_features=640, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=768, out_features=640, bias=False)
                    (to_v): Linear(in_features=768, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
            )
            (2): Upsample(
              (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (9): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 960, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(960, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=320, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 320, eps=1e-06, affine=True)
              (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=320, out_features=320, bias=False)
                    (to_v): Linear(in_features=320, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=320, out_features=2560, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=1280, out_features=320, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=768, out_features=320, bias=False)
                    (to_v): Linear(in_features=768, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (10): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=320, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 320, eps=1e-06, affine=True)
              (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=320, out_features=320, bias=False)
                    (to_v): Linear(in_features=320, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=320, out_features=2560, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=1280, out_features=320, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=768, out_features=320, bias=False)
                    (to_v): Linear(in_features=768, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (11): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=320, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 320, eps=1e-06, affine=True)
              (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=320, out_features=320, bias=False)
                    (to_v): Linear(in_features=320, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=320, out_features=2560, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=1280, out_features=320, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=768, out_features=320, bias=False)
                    (to_v): Linear(in_features=768, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
            )
          )
        )
        (out): Sequential(
          (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
          (1): SiLU()
          (2): Conv2d(320, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
    )
    (zero_convs): ModuleList(
      (0): ZeroConv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
      (1): ZeroConv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
      (2): ZeroConv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
      (3): ZeroConv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
      (4): ZeroConv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
      (5): ZeroConv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (box_encoder): EncoderControlNet(
    (box_cnn): Sequential(
      (0): Conv2d(1, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (3): ReLU(inplace=True)
    )
    (scribble_cnn): Sequential(
      (0): Conv2d(1, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (3): ReLU(inplace=True)
    )
    (dot_cnn): Sequential(
      (0): Conv2d(1, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (3): ReLU(inplace=True)
    )
    (out64): Sequential(
      (0): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
    )
    (out32): Sequential(
      (0): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
    )
    (out16): Sequential(
      (0): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
    )
    (conv64): Sequential(
      (0): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (1): ReLU(inplace=True)
    )
    (conv32): Sequential(
      (0): Conv2d(320, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (1): ReLU(inplace=True)
    )
    (conv16): Sequential(
      (0): Conv2d(640, 1280, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (1): ReLU(inplace=True)
    )
  )
  (sd_model): LatentDiffusion(
    (model): None
    (first_stage_model): None
  )
  (text_adapter): TextAdapter(
    (fc): Sequential(
      (0): Linear(in_features=768, out_features=768, bias=True)
      (1): GELU()
      (2): Linear(in_features=768, out_features=768, bias=True)
    )
  )
  (neck): FPN(
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(320, 256, kernel_size=(1, 1), stride=(1, 1))
      )
      (1): ConvModule(
        (conv): Conv2d(790, 256, kernel_size=(1, 1), stride=(1, 1))
      )
      (2): ConvModule(
        (conv): Conv2d(1430, 256, kernel_size=(1, 1), stride=(1, 1))
      )
      (3): ConvModule(
        (conv): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (1): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (2): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (3): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
  )
  init_cfg={'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}
  (decode_head): FPNHead(
    input_transform=multiple_select, ignore_index=255, align_corners=False
    (loss_decode): CrossEntropyLoss(avg_non_ignore=False)
    (conv_seg): Conv2d(256, 150, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (scale_heads): ModuleList(
      (0): Sequential(
        (0): ConvModule(
          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (1): Sequential(
        (0): ConvModule(
          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): Upsample()
      )
      (2): Sequential(
        (0): ConvModule(
          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): Upsample()
        (2): ConvModule(
          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): Upsample()
      )
      (3): Sequential(
        (0): ConvModule(
          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): Upsample()
        (2): ConvModule(
          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): Upsample()
        (4): ConvModule(
          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (5): Upsample()
      )
    )
  )
  init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
)
2025-04-29 08:20:34,997 - mmseg - INFO - Loaded 7725 images
/dtu/blackhole/0e/154958/miniconda3/envs/ldm/lib/python3.8/site-packages/torch/utils/data/dataloader.py:487: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
2025-04-29 08:20:43,147 - mmseg - INFO - Loaded 851 images
2025-04-29 08:20:43,150 - mmseg - INFO - load checkpoint from local path: /work3/s203557/checkpoints/vpd.chkpt
2025-04-29 08:20:46,057 - mmseg - WARNING - The model and loaded state dict do not match exactly

unexpected key in source state_dict: sd_model.lvlb_weights

missing keys in source state_dict: encoder_vq.encoder.conv_in.weight, encoder_vq.encoder.conv_in.bias, encoder_vq.encoder.down.0.block.0.norm1.weight, encoder_vq.encoder.down.0.block.0.norm1.bias, encoder_vq.encoder.down.0.block.0.conv1.weight, encoder_vq.encoder.down.0.block.0.conv1.bias, encoder_vq.encoder.down.0.block.0.norm2.weight, encoder_vq.encoder.down.0.block.0.norm2.bias, encoder_vq.encoder.down.0.block.0.conv2.weight, encoder_vq.encoder.down.0.block.0.conv2.bias, encoder_vq.encoder.down.0.block.1.norm1.weight, encoder_vq.encoder.down.0.block.1.norm1.bias, encoder_vq.encoder.down.0.block.1.conv1.weight, encoder_vq.encoder.down.0.block.1.conv1.bias, encoder_vq.encoder.down.0.block.1.norm2.weight, encoder_vq.encoder.down.0.block.1.norm2.bias, encoder_vq.encoder.down.0.block.1.conv2.weight, encoder_vq.encoder.down.0.block.1.conv2.bias, encoder_vq.encoder.down.0.downsample.conv.weight, encoder_vq.encoder.down.0.downsample.conv.bias, encoder_vq.encoder.down.1.block.0.norm1.weight, encoder_vq.encoder.down.1.block.0.norm1.bias, encoder_vq.encoder.down.1.block.0.conv1.weight, encoder_vq.encoder.down.1.block.0.conv1.bias, encoder_vq.encoder.down.1.block.0.norm2.weight, encoder_vq.encoder.down.1.block.0.norm2.bias, encoder_vq.encoder.down.1.block.0.conv2.weight, encoder_vq.encoder.down.1.block.0.conv2.bias, encoder_vq.encoder.down.1.block.0.nin_shortcut.weight, encoder_vq.encoder.down.1.block.0.nin_shortcut.bias, encoder_vq.encoder.down.1.block.1.norm1.weight, encoder_vq.encoder.down.1.block.1.norm1.bias, encoder_vq.encoder.down.1.block.1.conv1.weight, encoder_vq.encoder.down.1.block.1.conv1.bias, encoder_vq.encoder.down.1.block.1.norm2.weight, encoder_vq.encoder.down.1.block.1.norm2.bias, encoder_vq.encoder.down.1.block.1.conv2.weight, encoder_vq.encoder.down.1.block.1.conv2.bias, encoder_vq.encoder.down.1.downsample.conv.weight, encoder_vq.encoder.down.1.downsample.conv.bias, encoder_vq.encoder.down.2.block.0.norm1.weight, encoder_vq.encoder.down.2.block.0.norm1.bias, encoder_vq.encoder.down.2.block.0.conv1.weight, encoder_vq.encoder.down.2.block.0.conv1.bias, encoder_vq.encoder.down.2.block.0.norm2.weight, encoder_vq.encoder.down.2.block.0.norm2.bias, encoder_vq.encoder.down.2.block.0.conv2.weight, encoder_vq.encoder.down.2.block.0.conv2.bias, encoder_vq.encoder.down.2.block.0.nin_shortcut.weight, encoder_vq.encoder.down.2.block.0.nin_shortcut.bias, encoder_vq.encoder.down.2.block.1.norm1.weight, encoder_vq.encoder.down.2.block.1.norm1.bias, encoder_vq.encoder.down.2.block.1.conv1.weight, encoder_vq.encoder.down.2.block.1.conv1.bias, encoder_vq.encoder.down.2.block.1.norm2.weight, encoder_vq.encoder.down.2.block.1.norm2.bias, encoder_vq.encoder.down.2.block.1.conv2.weight, encoder_vq.encoder.down.2.block.1.conv2.bias, encoder_vq.encoder.down.2.downsample.conv.weight, encoder_vq.encoder.down.2.downsample.conv.bias, encoder_vq.encoder.down.3.block.0.norm1.weight, encoder_vq.encoder.down.3.block.0.norm1.bias, encoder_vq.encoder.down.3.block.0.conv1.weight, encoder_vq.encoder.down.3.block.0.conv1.bias, encoder_vq.encoder.down.3.block.0.norm2.weight, encoder_vq.encoder.down.3.block.0.norm2.bias, encoder_vq.encoder.down.3.block.0.conv2.weight, encoder_vq.encoder.down.3.block.0.conv2.bias, encoder_vq.encoder.down.3.block.1.norm1.weight, encoder_vq.encoder.down.3.block.1.norm1.bias, encoder_vq.encoder.down.3.block.1.conv1.weight, encoder_vq.encoder.down.3.block.1.conv1.bias, encoder_vq.encoder.down.3.block.1.norm2.weight, encoder_vq.encoder.down.3.block.1.norm2.bias, encoder_vq.encoder.down.3.block.1.conv2.weight, encoder_vq.encoder.down.3.block.1.conv2.bias, encoder_vq.encoder.mid.block_1.norm1.weight, encoder_vq.encoder.mid.block_1.norm1.bias, encoder_vq.encoder.mid.block_1.conv1.weight, encoder_vq.encoder.mid.block_1.conv1.bias, encoder_vq.encoder.mid.block_1.norm2.weight, encoder_vq.encoder.mid.block_1.norm2.bias, encoder_vq.encoder.mid.block_1.conv2.weight, encoder_vq.encoder.mid.block_1.conv2.bias, encoder_vq.encoder.mid.attn_1.norm.weight, encoder_vq.encoder.mid.attn_1.norm.bias, encoder_vq.encoder.mid.attn_1.q.weight, encoder_vq.encoder.mid.attn_1.q.bias, encoder_vq.encoder.mid.attn_1.k.weight, encoder_vq.encoder.mid.attn_1.k.bias, encoder_vq.encoder.mid.attn_1.v.weight, encoder_vq.encoder.mid.attn_1.v.bias, encoder_vq.encoder.mid.attn_1.proj_out.weight, encoder_vq.encoder.mid.attn_1.proj_out.bias, encoder_vq.encoder.mid.block_2.norm1.weight, encoder_vq.encoder.mid.block_2.norm1.bias, encoder_vq.encoder.mid.block_2.conv1.weight, encoder_vq.encoder.mid.block_2.conv1.bias, encoder_vq.encoder.mid.block_2.norm2.weight, encoder_vq.encoder.mid.block_2.norm2.bias, encoder_vq.encoder.mid.block_2.conv2.weight, encoder_vq.encoder.mid.block_2.conv2.bias, encoder_vq.encoder.norm_out.weight, encoder_vq.encoder.norm_out.bias, encoder_vq.encoder.conv_out.weight, encoder_vq.encoder.conv_out.bias, encoder_vq.quant_conv.weight, encoder_vq.quant_conv.bias, encoder_vq.post_quant_conv.weight, encoder_vq.post_quant_conv.bias, unet.trainable_unet.diffusion_model.time_embed.0.weight, unet.trainable_unet.diffusion_model.time_embed.0.bias, unet.trainable_unet.diffusion_model.time_embed.2.weight, unet.trainable_unet.diffusion_model.time_embed.2.bias, unet.trainable_unet.diffusion_model.input_blocks.0.0.weight, unet.trainable_unet.diffusion_model.input_blocks.0.0.bias, unet.trainable_unet.diffusion_model.input_blocks.1.0.in_layers.0.weight, unet.trainable_unet.diffusion_model.input_blocks.1.0.in_layers.0.bias, unet.trainable_unet.diffusion_model.input_blocks.1.0.in_layers.2.weight, unet.trainable_unet.diffusion_model.input_blocks.1.0.in_layers.2.bias, unet.trainable_unet.diffusion_model.input_blocks.1.0.emb_layers.1.weight, unet.trainable_unet.diffusion_model.input_blocks.1.0.emb_layers.1.bias, unet.trainable_unet.diffusion_model.input_blocks.1.0.out_layers.0.weight, unet.trainable_unet.diffusion_model.input_blocks.1.0.out_layers.0.bias, unet.trainable_unet.diffusion_model.input_blocks.1.0.out_layers.3.weight, unet.trainable_unet.diffusion_model.input_blocks.1.0.out_layers.3.bias, unet.trainable_unet.diffusion_model.input_blocks.1.1.norm.weight, unet.trainable_unet.diffusion_model.input_blocks.1.1.norm.bias, unet.trainable_unet.diffusion_model.input_blocks.1.1.proj_in.weight, unet.trainable_unet.diffusion_model.input_blocks.1.1.proj_in.bias, unet.trainable_unet.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_q.weight, unet.trainable_unet.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_k.weight, unet.trainable_unet.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_v.weight, unet.trainable_unet.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_out.0.weight, unet.trainable_unet.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_out.0.bias, unet.trainable_unet.diffusion_model.input_blocks.1.1.transformer_blocks.0.ff.net.0.proj.weight, unet.trainable_unet.diffusion_model.input_blocks.1.1.transformer_blocks.0.ff.net.0.proj.bias, unet.trainable_unet.diffusion_model.input_blocks.1.1.transformer_blocks.0.ff.net.2.weight, unet.trainable_unet.diffusion_model.input_blocks.1.1.transformer_blocks.0.ff.net.2.bias, unet.trainable_unet.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_q.weight, unet.trainable_unet.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_k.weight, unet.trainable_unet.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_v.weight, unet.trainable_unet.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_out.0.weight, unet.trainable_unet.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_out.0.bias, unet.trainable_unet.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm1.weight, unet.trainable_unet.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm1.bias, unet.trainable_unet.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm2.weight, unet.trainable_unet.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm2.bias, unet.trainable_unet.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm3.weight, unet.trainable_unet.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm3.bias, unet.trainable_unet.diffusion_model.input_blocks.1.1.proj_out.weight, unet.trainable_unet.diffusion_model.input_blocks.1.1.proj_out.bias, unet.trainable_unet.diffusion_model.input_blocks.2.0.in_layers.0.weight, unet.trainable_unet.diffusion_model.input_blocks.2.0.in_layers.0.bias, unet.trainable_unet.diffusion_model.input_blocks.2.0.in_layers.2.weight, unet.trainable_unet.diffusion_model.input_blocks.2.0.in_layers.2.bias, unet.trainable_unet.diffusion_model.input_blocks.2.0.emb_layers.1.weight, unet.trainable_unet.diffusion_model.input_blocks.2.0.emb_layers.1.bias, unet.trainable_unet.diffusion_model.input_blocks.2.0.out_layers.0.weight, unet.trainable_unet.diffusion_model.input_blocks.2.0.out_layers.0.bias, unet.trainable_unet.diffusion_model.input_blocks.2.0.out_layers.3.weight, unet.trainable_unet.diffusion_model.input_blocks.2.0.out_layers.3.bias, unet.trainable_unet.diffusion_model.input_blocks.2.1.norm.weight, unet.trainable_unet.diffusion_model.input_blocks.2.1.norm.bias, unet.trainable_unet.diffusion_model.input_blocks.2.1.proj_in.weight, unet.trainable_unet.diffusion_model.input_blocks.2.1.proj_in.bias, unet.trainable_unet.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_q.weight, unet.trainable_unet.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_k.weight, unet.trainable_unet.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_v.weight, unet.trainable_unet.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_out.0.weight, unet.trainable_unet.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_out.0.bias, unet.trainable_unet.diffusion_model.input_blocks.2.1.transformer_blocks.0.ff.net.0.proj.weight, unet.trainable_unet.diffusion_model.input_blocks.2.1.transformer_blocks.0.ff.net.0.proj.bias, unet.trainable_unet.diffusion_model.input_blocks.2.1.transformer_blocks.0.ff.net.2.weight, unet.trainable_unet.diffusion_model.input_blocks.2.1.transformer_blocks.0.ff.net.2.bias, unet.trainable_unet.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_q.weight, unet.trainable_unet.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_k.weight, unet.trainable_unet.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_v.weight, unet.trainable_unet.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_out.0.weight, unet.trainable_unet.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_out.0.bias, unet.trainable_unet.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm1.weight, unet.trainable_unet.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm1.bias, unet.trainable_unet.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm2.weight, unet.trainable_unet.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm2.bias, unet.trainable_unet.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm3.weight, unet.trainable_unet.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm3.bias, unet.trainable_unet.diffusion_model.input_blocks.2.1.proj_out.weight, unet.trainable_unet.diffusion_model.input_blocks.2.1.proj_out.bias, unet.trainable_unet.diffusion_model.input_blocks.3.0.op.weight, unet.trainable_unet.diffusion_model.input_blocks.3.0.op.bias, unet.trainable_unet.diffusion_model.input_blocks.4.0.in_layers.0.weight, unet.trainable_unet.diffusion_model.input_blocks.4.0.in_layers.0.bias, unet.trainable_unet.diffusion_model.input_blocks.4.0.in_layers.2.weight, unet.trainable_unet.diffusion_model.input_blocks.4.0.in_layers.2.bias, unet.trainable_unet.diffusion_model.input_blocks.4.0.emb_layers.1.weight, unet.trainable_unet.diffusion_model.input_blocks.4.0.emb_layers.1.bias, unet.trainable_unet.diffusion_model.input_blocks.4.0.out_layers.0.weight, unet.trainable_unet.diffusion_model.input_blocks.4.0.out_layers.0.bias, unet.trainable_unet.diffusion_model.input_blocks.4.0.out_layers.3.weight, unet.trainable_unet.diffusion_model.input_blocks.4.0.out_layers.3.bias, unet.trainable_unet.diffusion_model.input_blocks.4.0.skip_connection.weight, unet.trainable_unet.diffusion_model.input_blocks.4.0.skip_connection.bias, unet.trainable_unet.diffusion_model.input_blocks.4.1.norm.weight, unet.trainable_unet.diffusion_model.input_blocks.4.1.norm.bias, unet.trainable_unet.diffusion_model.input_blocks.4.1.proj_in.weight, unet.trainable_unet.diffusion_model.input_blocks.4.1.proj_in.bias, unet.trainable_unet.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_q.weight, unet.trainable_unet.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_k.weight, unet.trainable_unet.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_v.weight, unet.trainable_unet.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_out.0.weight, unet.trainable_unet.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_out.0.bias, unet.trainable_unet.diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.0.proj.weight, unet.trainable_unet.diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.0.proj.bias, unet.trainable_unet.diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.2.weight, unet.trainable_unet.diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.2.bias, unet.trainable_unet.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_q.weight, unet.trainable_unet.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_k.weight, unet.trainable_unet.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_v.weight, unet.trainable_unet.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_out.0.weight, unet.trainable_unet.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_out.0.bias, unet.trainable_unet.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm1.weight, unet.trainable_unet.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm1.bias, unet.trainable_unet.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm2.weight, unet.trainable_unet.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm2.bias, unet.trainable_unet.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm3.weight, unet.trainable_unet.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm3.bias, unet.trainable_unet.diffusion_model.input_blocks.4.1.proj_out.weight, unet.trainable_unet.diffusion_model.input_blocks.4.1.proj_out.bias, unet.trainable_unet.diffusion_model.input_blocks.5.0.in_layers.0.weight, unet.trainable_unet.diffusion_model.input_blocks.5.0.in_layers.0.bias, unet.trainable_unet.diffusion_model.input_blocks.5.0.in_layers.2.weight, unet.trainable_unet.diffusion_model.input_blocks.5.0.in_layers.2.bias, unet.trainable_unet.diffusion_model.input_blocks.5.0.emb_layers.1.weight, unet.trainable_unet.diffusion_model.input_blocks.5.0.emb_layers.1.bias, unet.trainable_unet.diffusion_model.input_blocks.5.0.out_layers.0.weight, unet.trainable_unet.diffusion_model.input_blocks.5.0.out_layers.0.bias, unet.trainable_unet.diffusion_model.input_blocks.5.0.out_layers.3.weight, unet.trainable_unet.diffusion_model.input_blocks.5.0.out_layers.3.bias, unet.trainable_unet.diffusion_model.input_blocks.5.1.norm.weight, unet.trainable_unet.diffusion_model.input_blocks.5.1.norm.bias, unet.trainable_unet.diffusion_model.input_blocks.5.1.proj_in.weight, unet.trainable_unet.diffusion_model.input_blocks.5.1.proj_in.bias, unet.trainable_unet.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_q.weight, unet.trainable_unet.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_k.weight, unet.trainable_unet.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_v.weight, unet.trainable_unet.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_out.0.weight, unet.trainable_unet.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_out.0.bias, unet.trainable_unet.diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.0.proj.weight, unet.trainable_unet.diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.0.proj.bias, unet.trainable_unet.diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.2.weight, unet.trainable_unet.diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.2.bias, unet.trainable_unet.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_q.weight, unet.trainable_unet.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_k.weight, unet.trainable_unet.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_v.weight, unet.trainable_unet.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_out.0.weight, unet.trainable_unet.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_out.0.bias, unet.trainable_unet.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm1.weight, unet.trainable_unet.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm1.bias, unet.trainable_unet.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm2.weight, unet.trainable_unet.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm2.bias, unet.trainable_unet.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm3.weight, unet.trainable_unet.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm3.bias, unet.trainable_unet.diffusion_model.input_blocks.5.1.proj_out.weight, unet.trainable_unet.diffusion_model.input_blocks.5.1.proj_out.bias, unet.trainable_unet.diffusion_model.input_blocks.6.0.op.weight, unet.trainable_unet.diffusion_model.input_blocks.6.0.op.bias, unet.trainable_unet.diffusion_model.input_blocks.7.0.in_layers.0.weight, unet.trainable_unet.diffusion_model.input_blocks.7.0.in_layers.0.bias, unet.trainable_unet.diffusion_model.input_blocks.7.0.in_layers.2.weight, unet.trainable_unet.diffusion_model.input_blocks.7.0.in_layers.2.bias, unet.trainable_unet.diffusion_model.input_blocks.7.0.emb_layers.1.weight, unet.trainable_unet.diffusion_model.input_blocks.7.0.emb_layers.1.bias, unet.trainable_unet.diffusion_model.input_blocks.7.0.out_layers.0.weight, unet.trainable_unet.diffusion_model.input_blocks.7.0.out_layers.0.bias, unet.trainable_unet.diffusion_model.input_blocks.7.0.out_layers.3.weight, unet.trainable_unet.diffusion_model.input_blocks.7.0.out_layers.3.bias, unet.trainable_unet.diffusion_model.input_blocks.7.0.skip_connection.weight, unet.trainable_unet.diffusion_model.input_blocks.7.0.skip_connection.bias, unet.trainable_unet.diffusion_model.input_blocks.7.1.norm.weight, unet.trainable_unet.diffusion_model.input_blocks.7.1.norm.bias, unet.trainable_unet.diffusion_model.input_blocks.7.1.proj_in.weight, unet.trainable_unet.diffusion_model.input_blocks.7.1.proj_in.bias, unet.trainable_unet.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_q.weight, unet.trainable_unet.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_k.weight, unet.trainable_unet.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_v.weight, unet.trainable_unet.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_out.0.weight, unet.trainable_unet.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_out.0.bias, unet.trainable_unet.diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.0.proj.weight, unet.trainable_unet.diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.0.proj.bias, unet.trainable_unet.diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.2.weight, unet.trainable_unet.diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.2.bias, unet.trainable_unet.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_q.weight, unet.trainable_unet.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_k.weight, unet.trainable_unet.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_v.weight, unet.trainable_unet.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_out.0.weight, unet.trainable_unet.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_out.0.bias, unet.trainable_unet.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm1.weight, unet.trainable_unet.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm1.bias, unet.trainable_unet.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm2.weight, unet.trainable_unet.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm2.bias, unet.trainable_unet.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm3.weight, unet.trainable_unet.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm3.bias, unet.trainable_unet.diffusion_model.input_blocks.7.1.proj_out.weight, unet.trainable_unet.diffusion_model.input_blocks.7.1.proj_out.bias, unet.trainable_unet.diffusion_model.input_blocks.8.0.in_layers.0.weight, unet.trainable_unet.diffusion_model.input_blocks.8.0.in_layers.0.bias, unet.trainable_unet.diffusion_model.input_blocks.8.0.in_layers.2.weight, unet.trainable_unet.diffusion_model.input_blocks.8.0.in_layers.2.bias, unet.trainable_unet.diffusion_model.input_blocks.8.0.emb_layers.1.weight, unet.trainable_unet.diffusion_model.input_blocks.8.0.emb_layers.1.bias, unet.trainable_unet.diffusion_model.input_blocks.8.0.out_layers.0.weight, unet.trainable_unet.diffusion_model.input_blocks.8.0.out_layers.0.bias, unet.trainable_unet.diffusion_model.input_blocks.8.0.out_layers.3.weight, unet.trainable_unet.diffusion_model.input_blocks.8.0.out_layers.3.bias, unet.trainable_unet.diffusion_model.input_blocks.8.1.norm.weight, unet.trainable_unet.diffusion_model.input_blocks.8.1.norm.bias, unet.trainable_unet.diffusion_model.input_blocks.8.1.proj_in.weight, unet.trainable_unet.diffusion_model.input_blocks.8.1.proj_in.bias, unet.trainable_unet.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_q.weight, unet.trainable_unet.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_k.weight, unet.trainable_unet.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_v.weight, unet.trainable_unet.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_out.0.weight, unet.trainable_unet.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_out.0.bias, unet.trainable_unet.diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.0.proj.weight, unet.trainable_unet.diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.0.proj.bias, unet.trainable_unet.diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.2.weight, unet.trainable_unet.diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.2.bias, unet.trainable_unet.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_q.weight, unet.trainable_unet.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_k.weight, unet.trainable_unet.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_v.weight, unet.trainable_unet.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_out.0.weight, unet.trainable_unet.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_out.0.bias, unet.trainable_unet.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm1.weight, unet.trainable_unet.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm1.bias, unet.trainable_unet.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm2.weight, unet.trainable_unet.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm2.bias, unet.trainable_unet.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm3.weight, unet.trainable_unet.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm3.bias, unet.trainable_unet.diffusion_model.input_blocks.8.1.proj_out.weight, unet.trainable_unet.diffusion_model.input_blocks.8.1.proj_out.bias, unet.trainable_unet.diffusion_model.input_blocks.9.0.op.weight, unet.trainable_unet.diffusion_model.input_blocks.9.0.op.bias, unet.trainable_unet.diffusion_model.input_blocks.10.0.in_layers.0.weight, unet.trainable_unet.diffusion_model.input_blocks.10.0.in_layers.0.bias, unet.trainable_unet.diffusion_model.input_blocks.10.0.in_layers.2.weight, unet.trainable_unet.diffusion_model.input_blocks.10.0.in_layers.2.bias, unet.trainable_unet.diffusion_model.input_blocks.10.0.emb_layers.1.weight, unet.trainable_unet.diffusion_model.input_blocks.10.0.emb_layers.1.bias, unet.trainable_unet.diffusion_model.input_blocks.10.0.out_layers.0.weight, unet.trainable_unet.diffusion_model.input_blocks.10.0.out_layers.0.bias, unet.trainable_unet.diffusion_model.input_blocks.10.0.out_layers.3.weight, unet.trainable_unet.diffusion_model.input_blocks.10.0.out_layers.3.bias, unet.trainable_unet.diffusion_model.input_blocks.11.0.in_layers.0.weight, unet.trainable_unet.diffusion_model.input_blocks.11.0.in_layers.0.bias, unet.trainable_unet.diffusion_model.input_blocks.11.0.in_layers.2.weight, unet.trainable_unet.diffusion_model.input_blocks.11.0.in_layers.2.bias, unet.trainable_unet.diffusion_model.input_blocks.11.0.emb_layers.1.weight, unet.trainable_unet.diffusion_model.input_blocks.11.0.emb_layers.1.bias, unet.trainable_unet.diffusion_model.input_blocks.11.0.out_layers.0.weight, unet.trainable_unet.diffusion_model.input_blocks.11.0.out_layers.0.bias, unet.trainable_unet.diffusion_model.input_blocks.11.0.out_layers.3.weight, unet.trainable_unet.diffusion_model.input_blocks.11.0.out_layers.3.bias, unet.trainable_unet.diffusion_model.middle_block.0.in_layers.0.weight, unet.trainable_unet.diffusion_model.middle_block.0.in_layers.0.bias, unet.trainable_unet.diffusion_model.middle_block.0.in_layers.2.weight, unet.trainable_unet.diffusion_model.middle_block.0.in_layers.2.bias, unet.trainable_unet.diffusion_model.middle_block.0.emb_layers.1.weight, unet.trainable_unet.diffusion_model.middle_block.0.emb_layers.1.bias, unet.trainable_unet.diffusion_model.middle_block.0.out_layers.0.weight, unet.trainable_unet.diffusion_model.middle_block.0.out_layers.0.bias, unet.trainable_unet.diffusion_model.middle_block.0.out_layers.3.weight, unet.trainable_unet.diffusion_model.middle_block.0.out_layers.3.bias, unet.trainable_unet.diffusion_model.middle_block.1.norm.weight, unet.trainable_unet.diffusion_model.middle_block.1.norm.bias, unet.trainable_unet.diffusion_model.middle_block.1.proj_in.weight, unet.trainable_unet.diffusion_model.middle_block.1.proj_in.bias, unet.trainable_unet.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_q.weight, unet.trainable_unet.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_k.weight, unet.trainable_unet.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_v.weight, unet.trainable_unet.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_out.0.weight, unet.trainable_unet.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_out.0.bias, unet.trainable_unet.diffusion_model.middle_block.1.transformer_blocks.0.ff.net.0.proj.weight, unet.trainable_unet.diffusion_model.middle_block.1.transformer_blocks.0.ff.net.0.proj.bias, unet.trainable_unet.diffusion_model.middle_block.1.transformer_blocks.0.ff.net.2.weight, unet.trainable_unet.diffusion_model.middle_block.1.transformer_blocks.0.ff.net.2.bias, unet.trainable_unet.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_q.weight, unet.trainable_unet.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_k.weight, unet.trainable_unet.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_v.weight, unet.trainable_unet.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_out.0.weight, unet.trainable_unet.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_out.0.bias, unet.trainable_unet.diffusion_model.middle_block.1.transformer_blocks.0.norm1.weight, unet.trainable_unet.diffusion_model.middle_block.1.transformer_blocks.0.norm1.bias, unet.trainable_unet.diffusion_model.middle_block.1.transformer_blocks.0.norm2.weight, unet.trainable_unet.diffusion_model.middle_block.1.transformer_blocks.0.norm2.bias, unet.trainable_unet.diffusion_model.middle_block.1.transformer_blocks.0.norm3.weight, unet.trainable_unet.diffusion_model.middle_block.1.transformer_blocks.0.norm3.bias, unet.trainable_unet.diffusion_model.middle_block.1.proj_out.weight, unet.trainable_unet.diffusion_model.middle_block.1.proj_out.bias, unet.trainable_unet.diffusion_model.middle_block.2.in_layers.0.weight, unet.trainable_unet.diffusion_model.middle_block.2.in_layers.0.bias, unet.trainable_unet.diffusion_model.middle_block.2.in_layers.2.weight, unet.trainable_unet.diffusion_model.middle_block.2.in_layers.2.bias, unet.trainable_unet.diffusion_model.middle_block.2.emb_layers.1.weight, unet.trainable_unet.diffusion_model.middle_block.2.emb_layers.1.bias, unet.trainable_unet.diffusion_model.middle_block.2.out_layers.0.weight, unet.trainable_unet.diffusion_model.middle_block.2.out_layers.0.bias, unet.trainable_unet.diffusion_model.middle_block.2.out_layers.3.weight, unet.trainable_unet.diffusion_model.middle_block.2.out_layers.3.bias, unet.trainable_unet.diffusion_model.output_blocks.0.0.in_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.0.0.in_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.0.0.in_layers.2.weight, unet.trainable_unet.diffusion_model.output_blocks.0.0.in_layers.2.bias, unet.trainable_unet.diffusion_model.output_blocks.0.0.emb_layers.1.weight, unet.trainable_unet.diffusion_model.output_blocks.0.0.emb_layers.1.bias, unet.trainable_unet.diffusion_model.output_blocks.0.0.out_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.0.0.out_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.0.0.out_layers.3.weight, unet.trainable_unet.diffusion_model.output_blocks.0.0.out_layers.3.bias, unet.trainable_unet.diffusion_model.output_blocks.0.0.skip_connection.weight, unet.trainable_unet.diffusion_model.output_blocks.0.0.skip_connection.bias, unet.trainable_unet.diffusion_model.output_blocks.1.0.in_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.1.0.in_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.1.0.in_layers.2.weight, unet.trainable_unet.diffusion_model.output_blocks.1.0.in_layers.2.bias, unet.trainable_unet.diffusion_model.output_blocks.1.0.emb_layers.1.weight, unet.trainable_unet.diffusion_model.output_blocks.1.0.emb_layers.1.bias, unet.trainable_unet.diffusion_model.output_blocks.1.0.out_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.1.0.out_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.1.0.out_layers.3.weight, unet.trainable_unet.diffusion_model.output_blocks.1.0.out_layers.3.bias, unet.trainable_unet.diffusion_model.output_blocks.1.0.skip_connection.weight, unet.trainable_unet.diffusion_model.output_blocks.1.0.skip_connection.bias, unet.trainable_unet.diffusion_model.output_blocks.2.0.in_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.2.0.in_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.2.0.in_layers.2.weight, unet.trainable_unet.diffusion_model.output_blocks.2.0.in_layers.2.bias, unet.trainable_unet.diffusion_model.output_blocks.2.0.emb_layers.1.weight, unet.trainable_unet.diffusion_model.output_blocks.2.0.emb_layers.1.bias, unet.trainable_unet.diffusion_model.output_blocks.2.0.out_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.2.0.out_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.2.0.out_layers.3.weight, unet.trainable_unet.diffusion_model.output_blocks.2.0.out_layers.3.bias, unet.trainable_unet.diffusion_model.output_blocks.2.0.skip_connection.weight, unet.trainable_unet.diffusion_model.output_blocks.2.0.skip_connection.bias, unet.trainable_unet.diffusion_model.output_blocks.2.1.conv.weight, unet.trainable_unet.diffusion_model.output_blocks.2.1.conv.bias, unet.trainable_unet.diffusion_model.output_blocks.3.0.in_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.3.0.in_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.3.0.in_layers.2.weight, unet.trainable_unet.diffusion_model.output_blocks.3.0.in_layers.2.bias, unet.trainable_unet.diffusion_model.output_blocks.3.0.emb_layers.1.weight, unet.trainable_unet.diffusion_model.output_blocks.3.0.emb_layers.1.bias, unet.trainable_unet.diffusion_model.output_blocks.3.0.out_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.3.0.out_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.3.0.out_layers.3.weight, unet.trainable_unet.diffusion_model.output_blocks.3.0.out_layers.3.bias, unet.trainable_unet.diffusion_model.output_blocks.3.0.skip_connection.weight, unet.trainable_unet.diffusion_model.output_blocks.3.0.skip_connection.bias, unet.trainable_unet.diffusion_model.output_blocks.3.1.norm.weight, unet.trainable_unet.diffusion_model.output_blocks.3.1.norm.bias, unet.trainable_unet.diffusion_model.output_blocks.3.1.proj_in.weight, unet.trainable_unet.diffusion_model.output_blocks.3.1.proj_in.bias, unet.trainable_unet.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_q.weight, unet.trainable_unet.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_k.weight, unet.trainable_unet.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_v.weight, unet.trainable_unet.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_out.0.weight, unet.trainable_unet.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_out.0.bias, unet.trainable_unet.diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.0.proj.weight, unet.trainable_unet.diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.0.proj.bias, unet.trainable_unet.diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.2.weight, unet.trainable_unet.diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.2.bias, unet.trainable_unet.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_q.weight, unet.trainable_unet.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_k.weight, unet.trainable_unet.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_v.weight, unet.trainable_unet.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_out.0.weight, unet.trainable_unet.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_out.0.bias, unet.trainable_unet.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm1.weight, unet.trainable_unet.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm1.bias, unet.trainable_unet.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm2.weight, unet.trainable_unet.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm2.bias, unet.trainable_unet.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm3.weight, unet.trainable_unet.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm3.bias, unet.trainable_unet.diffusion_model.output_blocks.3.1.proj_out.weight, unet.trainable_unet.diffusion_model.output_blocks.3.1.proj_out.bias, unet.trainable_unet.diffusion_model.output_blocks.4.0.in_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.4.0.in_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.4.0.in_layers.2.weight, unet.trainable_unet.diffusion_model.output_blocks.4.0.in_layers.2.bias, unet.trainable_unet.diffusion_model.output_blocks.4.0.emb_layers.1.weight, unet.trainable_unet.diffusion_model.output_blocks.4.0.emb_layers.1.bias, unet.trainable_unet.diffusion_model.output_blocks.4.0.out_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.4.0.out_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.4.0.out_layers.3.weight, unet.trainable_unet.diffusion_model.output_blocks.4.0.out_layers.3.bias, unet.trainable_unet.diffusion_model.output_blocks.4.0.skip_connection.weight, unet.trainable_unet.diffusion_model.output_blocks.4.0.skip_connection.bias, unet.trainable_unet.diffusion_model.output_blocks.4.1.norm.weight, unet.trainable_unet.diffusion_model.output_blocks.4.1.norm.bias, unet.trainable_unet.diffusion_model.output_blocks.4.1.proj_in.weight, unet.trainable_unet.diffusion_model.output_blocks.4.1.proj_in.bias, unet.trainable_unet.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_q.weight, unet.trainable_unet.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_k.weight, unet.trainable_unet.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_v.weight, unet.trainable_unet.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_out.0.weight, unet.trainable_unet.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_out.0.bias, unet.trainable_unet.diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.0.proj.weight, unet.trainable_unet.diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.0.proj.bias, unet.trainable_unet.diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.2.weight, unet.trainable_unet.diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.2.bias, unet.trainable_unet.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_q.weight, unet.trainable_unet.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_k.weight, unet.trainable_unet.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_v.weight, unet.trainable_unet.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_out.0.weight, unet.trainable_unet.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_out.0.bias, unet.trainable_unet.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm1.weight, unet.trainable_unet.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm1.bias, unet.trainable_unet.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm2.weight, unet.trainable_unet.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm2.bias, unet.trainable_unet.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm3.weight, unet.trainable_unet.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm3.bias, unet.trainable_unet.diffusion_model.output_blocks.4.1.proj_out.weight, unet.trainable_unet.diffusion_model.output_blocks.4.1.proj_out.bias, unet.trainable_unet.diffusion_model.output_blocks.5.0.in_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.5.0.in_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.5.0.in_layers.2.weight, unet.trainable_unet.diffusion_model.output_blocks.5.0.in_layers.2.bias, unet.trainable_unet.diffusion_model.output_blocks.5.0.emb_layers.1.weight, unet.trainable_unet.diffusion_model.output_blocks.5.0.emb_layers.1.bias, unet.trainable_unet.diffusion_model.output_blocks.5.0.out_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.5.0.out_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.5.0.out_layers.3.weight, unet.trainable_unet.diffusion_model.output_blocks.5.0.out_layers.3.bias, unet.trainable_unet.diffusion_model.output_blocks.5.0.skip_connection.weight, unet.trainable_unet.diffusion_model.output_blocks.5.0.skip_connection.bias, unet.trainable_unet.diffusion_model.output_blocks.5.1.norm.weight, unet.trainable_unet.diffusion_model.output_blocks.5.1.norm.bias, unet.trainable_unet.diffusion_model.output_blocks.5.1.proj_in.weight, unet.trainable_unet.diffusion_model.output_blocks.5.1.proj_in.bias, unet.trainable_unet.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_q.weight, unet.trainable_unet.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_k.weight, unet.trainable_unet.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_v.weight, unet.trainable_unet.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_out.0.weight, unet.trainable_unet.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_out.0.bias, unet.trainable_unet.diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.0.proj.weight, unet.trainable_unet.diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.0.proj.bias, unet.trainable_unet.diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.2.weight, unet.trainable_unet.diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.2.bias, unet.trainable_unet.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_q.weight, unet.trainable_unet.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_k.weight, unet.trainable_unet.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_v.weight, unet.trainable_unet.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_out.0.weight, unet.trainable_unet.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_out.0.bias, unet.trainable_unet.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm1.weight, unet.trainable_unet.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm1.bias, unet.trainable_unet.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm2.weight, unet.trainable_unet.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm2.bias, unet.trainable_unet.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm3.weight, unet.trainable_unet.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm3.bias, unet.trainable_unet.diffusion_model.output_blocks.5.1.proj_out.weight, unet.trainable_unet.diffusion_model.output_blocks.5.1.proj_out.bias, unet.trainable_unet.diffusion_model.output_blocks.5.2.conv.weight, unet.trainable_unet.diffusion_model.output_blocks.5.2.conv.bias, unet.trainable_unet.diffusion_model.output_blocks.6.0.in_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.6.0.in_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.6.0.in_layers.2.weight, unet.trainable_unet.diffusion_model.output_blocks.6.0.in_layers.2.bias, unet.trainable_unet.diffusion_model.output_blocks.6.0.emb_layers.1.weight, unet.trainable_unet.diffusion_model.output_blocks.6.0.emb_layers.1.bias, unet.trainable_unet.diffusion_model.output_blocks.6.0.out_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.6.0.out_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.6.0.out_layers.3.weight, unet.trainable_unet.diffusion_model.output_blocks.6.0.out_layers.3.bias, unet.trainable_unet.diffusion_model.output_blocks.6.0.skip_connection.weight, unet.trainable_unet.diffusion_model.output_blocks.6.0.skip_connection.bias, unet.trainable_unet.diffusion_model.output_blocks.6.1.norm.weight, unet.trainable_unet.diffusion_model.output_blocks.6.1.norm.bias, unet.trainable_unet.diffusion_model.output_blocks.6.1.proj_in.weight, unet.trainable_unet.diffusion_model.output_blocks.6.1.proj_in.bias, unet.trainable_unet.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_q.weight, unet.trainable_unet.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_k.weight, unet.trainable_unet.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_v.weight, unet.trainable_unet.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_out.0.weight, unet.trainable_unet.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_out.0.bias, unet.trainable_unet.diffusion_model.output_blocks.6.1.transformer_blocks.0.ff.net.0.proj.weight, unet.trainable_unet.diffusion_model.output_blocks.6.1.transformer_blocks.0.ff.net.0.proj.bias, unet.trainable_unet.diffusion_model.output_blocks.6.1.transformer_blocks.0.ff.net.2.weight, unet.trainable_unet.diffusion_model.output_blocks.6.1.transformer_blocks.0.ff.net.2.bias, unet.trainable_unet.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_q.weight, unet.trainable_unet.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_k.weight, unet.trainable_unet.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_v.weight, unet.trainable_unet.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_out.0.weight, unet.trainable_unet.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_out.0.bias, unet.trainable_unet.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm1.weight, unet.trainable_unet.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm1.bias, unet.trainable_unet.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm2.weight, unet.trainable_unet.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm2.bias, unet.trainable_unet.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm3.weight, unet.trainable_unet.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm3.bias, unet.trainable_unet.diffusion_model.output_blocks.6.1.proj_out.weight, unet.trainable_unet.diffusion_model.output_blocks.6.1.proj_out.bias, unet.trainable_unet.diffusion_model.output_blocks.7.0.in_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.7.0.in_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.7.0.in_layers.2.weight, unet.trainable_unet.diffusion_model.output_blocks.7.0.in_layers.2.bias, unet.trainable_unet.diffusion_model.output_blocks.7.0.emb_layers.1.weight, unet.trainable_unet.diffusion_model.output_blocks.7.0.emb_layers.1.bias, unet.trainable_unet.diffusion_model.output_blocks.7.0.out_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.7.0.out_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.7.0.out_layers.3.weight, unet.trainable_unet.diffusion_model.output_blocks.7.0.out_layers.3.bias, unet.trainable_unet.diffusion_model.output_blocks.7.0.skip_connection.weight, unet.trainable_unet.diffusion_model.output_blocks.7.0.skip_connection.bias, unet.trainable_unet.diffusion_model.output_blocks.7.1.norm.weight, unet.trainable_unet.diffusion_model.output_blocks.7.1.norm.bias, unet.trainable_unet.diffusion_model.output_blocks.7.1.proj_in.weight, unet.trainable_unet.diffusion_model.output_blocks.7.1.proj_in.bias, unet.trainable_unet.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_q.weight, unet.trainable_unet.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_k.weight, unet.trainable_unet.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_v.weight, unet.trainable_unet.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_out.0.weight, unet.trainable_unet.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_out.0.bias, unet.trainable_unet.diffusion_model.output_blocks.7.1.transformer_blocks.0.ff.net.0.proj.weight, unet.trainable_unet.diffusion_model.output_blocks.7.1.transformer_blocks.0.ff.net.0.proj.bias, unet.trainable_unet.diffusion_model.output_blocks.7.1.transformer_blocks.0.ff.net.2.weight, unet.trainable_unet.diffusion_model.output_blocks.7.1.transformer_blocks.0.ff.net.2.bias, unet.trainable_unet.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_q.weight, unet.trainable_unet.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_k.weight, unet.trainable_unet.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_v.weight, unet.trainable_unet.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_out.0.weight, unet.trainable_unet.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_out.0.bias, unet.trainable_unet.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm1.weight, unet.trainable_unet.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm1.bias, unet.trainable_unet.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm2.weight, unet.trainable_unet.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm2.bias, unet.trainable_unet.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm3.weight, unet.trainable_unet.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm3.bias, unet.trainable_unet.diffusion_model.output_blocks.7.1.proj_out.weight, unet.trainable_unet.diffusion_model.output_blocks.7.1.proj_out.bias, unet.trainable_unet.diffusion_model.output_blocks.8.0.in_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.8.0.in_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.8.0.in_layers.2.weight, unet.trainable_unet.diffusion_model.output_blocks.8.0.in_layers.2.bias, unet.trainable_unet.diffusion_model.output_blocks.8.0.emb_layers.1.weight, unet.trainable_unet.diffusion_model.output_blocks.8.0.emb_layers.1.bias, unet.trainable_unet.diffusion_model.output_blocks.8.0.out_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.8.0.out_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.8.0.out_layers.3.weight, unet.trainable_unet.diffusion_model.output_blocks.8.0.out_layers.3.bias, unet.trainable_unet.diffusion_model.output_blocks.8.0.skip_connection.weight, unet.trainable_unet.diffusion_model.output_blocks.8.0.skip_connection.bias, unet.trainable_unet.diffusion_model.output_blocks.8.1.norm.weight, unet.trainable_unet.diffusion_model.output_blocks.8.1.norm.bias, unet.trainable_unet.diffusion_model.output_blocks.8.1.proj_in.weight, unet.trainable_unet.diffusion_model.output_blocks.8.1.proj_in.bias, unet.trainable_unet.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_q.weight, unet.trainable_unet.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_k.weight, unet.trainable_unet.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_v.weight, unet.trainable_unet.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_out.0.weight, unet.trainable_unet.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_out.0.bias, unet.trainable_unet.diffusion_model.output_blocks.8.1.transformer_blocks.0.ff.net.0.proj.weight, unet.trainable_unet.diffusion_model.output_blocks.8.1.transformer_blocks.0.ff.net.0.proj.bias, unet.trainable_unet.diffusion_model.output_blocks.8.1.transformer_blocks.0.ff.net.2.weight, unet.trainable_unet.diffusion_model.output_blocks.8.1.transformer_blocks.0.ff.net.2.bias, unet.trainable_unet.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_q.weight, unet.trainable_unet.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_k.weight, unet.trainable_unet.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_v.weight, unet.trainable_unet.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_out.0.weight, unet.trainable_unet.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_out.0.bias, unet.trainable_unet.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm1.weight, unet.trainable_unet.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm1.bias, unet.trainable_unet.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm2.weight, unet.trainable_unet.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm2.bias, unet.trainable_unet.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm3.weight, unet.trainable_unet.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm3.bias, unet.trainable_unet.diffusion_model.output_blocks.8.1.proj_out.weight, unet.trainable_unet.diffusion_model.output_blocks.8.1.proj_out.bias, unet.trainable_unet.diffusion_model.output_blocks.8.2.conv.weight, unet.trainable_unet.diffusion_model.output_blocks.8.2.conv.bias, unet.trainable_unet.diffusion_model.output_blocks.9.0.in_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.9.0.in_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.9.0.in_layers.2.weight, unet.trainable_unet.diffusion_model.output_blocks.9.0.in_layers.2.bias, unet.trainable_unet.diffusion_model.output_blocks.9.0.emb_layers.1.weight, unet.trainable_unet.diffusion_model.output_blocks.9.0.emb_layers.1.bias, unet.trainable_unet.diffusion_model.output_blocks.9.0.out_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.9.0.out_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.9.0.out_layers.3.weight, unet.trainable_unet.diffusion_model.output_blocks.9.0.out_layers.3.bias, unet.trainable_unet.diffusion_model.output_blocks.9.0.skip_connection.weight, unet.trainable_unet.diffusion_model.output_blocks.9.0.skip_connection.bias, unet.trainable_unet.diffusion_model.output_blocks.9.1.norm.weight, unet.trainable_unet.diffusion_model.output_blocks.9.1.norm.bias, unet.trainable_unet.diffusion_model.output_blocks.9.1.proj_in.weight, unet.trainable_unet.diffusion_model.output_blocks.9.1.proj_in.bias, unet.trainable_unet.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_q.weight, unet.trainable_unet.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_k.weight, unet.trainable_unet.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_v.weight, unet.trainable_unet.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_out.0.weight, unet.trainable_unet.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_out.0.bias, unet.trainable_unet.diffusion_model.output_blocks.9.1.transformer_blocks.0.ff.net.0.proj.weight, unet.trainable_unet.diffusion_model.output_blocks.9.1.transformer_blocks.0.ff.net.0.proj.bias, unet.trainable_unet.diffusion_model.output_blocks.9.1.transformer_blocks.0.ff.net.2.weight, unet.trainable_unet.diffusion_model.output_blocks.9.1.transformer_blocks.0.ff.net.2.bias, unet.trainable_unet.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_q.weight, unet.trainable_unet.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_k.weight, unet.trainable_unet.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_v.weight, unet.trainable_unet.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_out.0.weight, unet.trainable_unet.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_out.0.bias, unet.trainable_unet.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm1.weight, unet.trainable_unet.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm1.bias, unet.trainable_unet.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm2.weight, unet.trainable_unet.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm2.bias, unet.trainable_unet.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm3.weight, unet.trainable_unet.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm3.bias, unet.trainable_unet.diffusion_model.output_blocks.9.1.proj_out.weight, unet.trainable_unet.diffusion_model.output_blocks.9.1.proj_out.bias, unet.trainable_unet.diffusion_model.output_blocks.10.0.in_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.10.0.in_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.10.0.in_layers.2.weight, unet.trainable_unet.diffusion_model.output_blocks.10.0.in_layers.2.bias, unet.trainable_unet.diffusion_model.output_blocks.10.0.emb_layers.1.weight, unet.trainable_unet.diffusion_model.output_blocks.10.0.emb_layers.1.bias, unet.trainable_unet.diffusion_model.output_blocks.10.0.out_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.10.0.out_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.10.0.out_layers.3.weight, unet.trainable_unet.diffusion_model.output_blocks.10.0.out_layers.3.bias, unet.trainable_unet.diffusion_model.output_blocks.10.0.skip_connection.weight, unet.trainable_unet.diffusion_model.output_blocks.10.0.skip_connection.bias, unet.trainable_unet.diffusion_model.output_blocks.10.1.norm.weight, unet.trainable_unet.diffusion_model.output_blocks.10.1.norm.bias, unet.trainable_unet.diffusion_model.output_blocks.10.1.proj_in.weight, unet.trainable_unet.diffusion_model.output_blocks.10.1.proj_in.bias, unet.trainable_unet.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_q.weight, unet.trainable_unet.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_k.weight, unet.trainable_unet.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_v.weight, unet.trainable_unet.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_out.0.weight, unet.trainable_unet.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_out.0.bias, unet.trainable_unet.diffusion_model.output_blocks.10.1.transformer_blocks.0.ff.net.0.proj.weight, unet.trainable_unet.diffusion_model.output_blocks.10.1.transformer_blocks.0.ff.net.0.proj.bias, unet.trainable_unet.diffusion_model.output_blocks.10.1.transformer_blocks.0.ff.net.2.weight, unet.trainable_unet.diffusion_model.output_blocks.10.1.transformer_blocks.0.ff.net.2.bias, unet.trainable_unet.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_q.weight, unet.trainable_unet.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_k.weight, unet.trainable_unet.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_v.weight, unet.trainable_unet.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_out.0.weight, unet.trainable_unet.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_out.0.bias, unet.trainable_unet.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm1.weight, unet.trainable_unet.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm1.bias, unet.trainable_unet.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm2.weight, unet.trainable_unet.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm2.bias, unet.trainable_unet.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm3.weight, unet.trainable_unet.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm3.bias, unet.trainable_unet.diffusion_model.output_blocks.10.1.proj_out.weight, unet.trainable_unet.diffusion_model.output_blocks.10.1.proj_out.bias, unet.trainable_unet.diffusion_model.output_blocks.11.0.in_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.11.0.in_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.11.0.in_layers.2.weight, unet.trainable_unet.diffusion_model.output_blocks.11.0.in_layers.2.bias, unet.trainable_unet.diffusion_model.output_blocks.11.0.emb_layers.1.weight, unet.trainable_unet.diffusion_model.output_blocks.11.0.emb_layers.1.bias, unet.trainable_unet.diffusion_model.output_blocks.11.0.out_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.11.0.out_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.11.0.out_layers.3.weight, unet.trainable_unet.diffusion_model.output_blocks.11.0.out_layers.3.bias, unet.trainable_unet.diffusion_model.output_blocks.11.0.skip_connection.weight, unet.trainable_unet.diffusion_model.output_blocks.11.0.skip_connection.bias, unet.trainable_unet.diffusion_model.output_blocks.11.1.norm.weight, unet.trainable_unet.diffusion_model.output_blocks.11.1.norm.bias, unet.trainable_unet.diffusion_model.output_blocks.11.1.proj_in.weight, unet.trainable_unet.diffusion_model.output_blocks.11.1.proj_in.bias, unet.trainable_unet.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_q.weight, unet.trainable_unet.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_k.weight, unet.trainable_unet.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_v.weight, unet.trainable_unet.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_out.0.weight, unet.trainable_unet.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_out.0.bias, unet.trainable_unet.diffusion_model.output_blocks.11.1.transformer_blocks.0.ff.net.0.proj.weight, unet.trainable_unet.diffusion_model.output_blocks.11.1.transformer_blocks.0.ff.net.0.proj.bias, unet.trainable_unet.diffusion_model.output_blocks.11.1.transformer_blocks.0.ff.net.2.weight, unet.trainable_unet.diffusion_model.output_blocks.11.1.transformer_blocks.0.ff.net.2.bias, unet.trainable_unet.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_q.weight, unet.trainable_unet.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_k.weight, unet.trainable_unet.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_v.weight, unet.trainable_unet.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_out.0.weight, unet.trainable_unet.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_out.0.bias, unet.trainable_unet.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm1.weight, unet.trainable_unet.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm1.bias, unet.trainable_unet.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm2.weight, unet.trainable_unet.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm2.bias, unet.trainable_unet.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm3.weight, unet.trainable_unet.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm3.bias, unet.trainable_unet.diffusion_model.output_blocks.11.1.proj_out.weight, unet.trainable_unet.diffusion_model.output_blocks.11.1.proj_out.bias, unet.trainable_unet.diffusion_model.out.0.weight, unet.trainable_unet.diffusion_model.out.0.bias, unet.trainable_unet.diffusion_model.out.2.weight, unet.trainable_unet.diffusion_model.out.2.bias, unet.zero_convs.0.weight, unet.zero_convs.0.bias, unet.zero_convs.1.weight, unet.zero_convs.1.bias, unet.zero_convs.2.weight, unet.zero_convs.2.bias, unet.zero_convs.3.weight, unet.zero_convs.3.bias, unet.zero_convs.4.weight, unet.zero_convs.4.bias, unet.zero_convs.5.weight, unet.zero_convs.5.bias, box_encoder.box_cnn.0.weight, box_encoder.box_cnn.0.bias, box_encoder.box_cnn.2.weight, box_encoder.box_cnn.2.bias, box_encoder.scribble_cnn.0.weight, box_encoder.scribble_cnn.0.bias, box_encoder.scribble_cnn.2.weight, box_encoder.scribble_cnn.2.bias, box_encoder.dot_cnn.0.weight, box_encoder.dot_cnn.0.bias, box_encoder.dot_cnn.2.weight, box_encoder.dot_cnn.2.bias, box_encoder.out64.0.weight, box_encoder.out64.0.bias, box_encoder.out32.0.weight, box_encoder.out32.0.bias, box_encoder.out16.0.weight, box_encoder.out16.0.bias, box_encoder.conv64.0.weight, box_encoder.conv64.0.bias, box_encoder.conv32.0.weight, box_encoder.conv32.0.bias, box_encoder.conv16.0.weight, box_encoder.conv16.0.bias

2025-04-29 08:20:46,076 - mmseg - INFO - Start running, host: s203557@n-62-20-16, work_dir: /work3/s203557/experiments/control_net_vpd
2025-04-29 08:20:46,077 - mmseg - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(NORMAL      ) TrainVisualizeHook                 
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(NORMAL      ) TrainVisualizeHook                 
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
2025-04-29 08:20:46,077 - mmseg - INFO - workflow: [('train', 1)], max: 20000 iters
2025-04-29 08:20:46,078 - mmseg - INFO - Checkpoints will be saved to /work3/s203557/experiments/control_net_vpd by HardDiskBackend.
2025-04-29 08:23:16,934 - mmseg - INFO - Iter [50/20000]	lr: 2.607e-06, eta: 16:37:46, time: 3.001, data_time: 1.497, memory: 27523, decode.loss_ce: 0.1733, decode.acc_seg: 93.0602, loss: 0.1733
2025-04-29 08:24:55,823 - mmseg - INFO - Iter [100/20000]	lr: 5.254e-06, eta: 13:45:36, time: 1.978, data_time: 1.167, memory: 27523, decode.loss_ce: 0.1497, decode.acc_seg: 93.9617, loss: 0.1497
2025-04-29 08:26:35,302 - mmseg - INFO - Iter [150/20000]	lr: 7.888e-06, eta: 12:48:25, time: 1.990, data_time: 1.178, memory: 27523, decode.loss_ce: 0.1726, decode.acc_seg: 92.6482, loss: 0.1726
2025-04-29 08:28:11,814 - mmseg - INFO - Iter [200/20000]	lr: 1.051e-05, eta: 12:14:07, time: 1.930, data_time: 1.119, memory: 27523, decode.loss_ce: 0.1600, decode.acc_seg: 93.8128, loss: 0.1600
2025-04-29 08:29:47,772 - mmseg - INFO - Iter [250/20000]	lr: 1.311e-05, eta: 11:52:09, time: 1.919, data_time: 1.108, memory: 27523, decode.loss_ce: 0.2169, decode.acc_seg: 92.2265, loss: 0.2169
2025-04-29 08:31:26,306 - mmseg - INFO - Iter [300/20000]	lr: 1.571e-05, eta: 11:39:48, time: 1.971, data_time: 1.158, memory: 27523, decode.loss_ce: 0.1776, decode.acc_seg: 92.9167, loss: 0.1776
2025-04-29 08:32:57,374 - mmseg - INFO - Iter [350/20000]	lr: 1.829e-05, eta: 11:23:31, time: 1.821, data_time: 1.009, memory: 27523, decode.loss_ce: 0.1734, decode.acc_seg: 93.3685, loss: 0.1734
2025-04-29 08:34:36,361 - mmseg - INFO - Iter [400/20000]	lr: 2.086e-05, eta: 11:17:23, time: 1.980, data_time: 1.165, memory: 27523, decode.loss_ce: 0.1608, decode.acc_seg: 93.6795, loss: 0.1608
2025-04-29 08:36:25,164 - mmseg - INFO - Iter [450/20000]	lr: 2.341e-05, eta: 11:19:22, time: 2.176, data_time: 1.363, memory: 27523, decode.loss_ce: 0.1552, decode.acc_seg: 93.7929, loss: 0.1552
2025-04-29 08:38:03,488 - mmseg - INFO - Iter [500/20000]	lr: 2.595e-05, eta: 11:13:47, time: 1.966, data_time: 1.154, memory: 27523, decode.loss_ce: 0.1694, decode.acc_seg: 93.2580, loss: 0.1694
2025-04-29 08:39:38,709 - mmseg - INFO - Iter [550/20000]	lr: 2.848e-05, eta: 11:07:05, time: 1.904, data_time: 1.092, memory: 27523, decode.loss_ce: 0.1657, decode.acc_seg: 93.5325, loss: 0.1657
2025-04-29 08:41:10,900 - mmseg - INFO - Iter [600/20000]	lr: 3.099e-05, eta: 10:59:36, time: 1.844, data_time: 1.031, memory: 27523, decode.loss_ce: 0.1769, decode.acc_seg: 92.9343, loss: 0.1769
2025-04-29 08:42:54,982 - mmseg - INFO - Iter [650/20000]	lr: 3.349e-05, eta: 10:58:56, time: 2.082, data_time: 1.269, memory: 27523, decode.loss_ce: 0.1700, decode.acc_seg: 93.3121, loss: 0.1700
2025-04-29 08:44:34,154 - mmseg - INFO - Iter [700/20000]	lr: 3.598e-05, eta: 10:55:51, time: 1.983, data_time: 1.170, memory: 27523, decode.loss_ce: 0.2073, decode.acc_seg: 91.8837, loss: 0.2073
2025-04-29 08:46:09,146 - mmseg - INFO - Iter [750/20000]	lr: 3.845e-05, eta: 10:51:11, time: 1.900, data_time: 1.087, memory: 27523, decode.loss_ce: 0.1910, decode.acc_seg: 92.6369, loss: 0.1910
2025-04-29 08:47:47,374 - mmseg - INFO - Iter [800/20000]	lr: 4.091e-05, eta: 10:48:11, time: 1.965, data_time: 1.153, memory: 27523, decode.loss_ce: 0.1605, decode.acc_seg: 93.7415, loss: 0.1605
2025-04-29 08:49:34,071 - mmseg - INFO - Iter [850/20000]	lr: 4.336e-05, eta: 10:48:32, time: 2.134, data_time: 1.322, memory: 27523, decode.loss_ce: 0.1856, decode.acc_seg: 92.9334, loss: 0.1856
2025-04-29 08:51:12,134 - mmseg - INFO - Iter [900/20000]	lr: 4.579e-05, eta: 10:45:35, time: 1.961, data_time: 1.148, memory: 27523, decode.loss_ce: 0.1705, decode.acc_seg: 93.2056, loss: 0.1705
2025-04-29 08:52:48,324 - mmseg - INFO - Iter [950/20000]	lr: 4.821e-05, eta: 10:42:09, time: 1.924, data_time: 1.111, memory: 27523, decode.loss_ce: 0.1449, decode.acc_seg: 94.2226, loss: 0.1449
2025-04-29 08:54:21,656 - mmseg - INFO - Exp name: vpd_config.py
2025-04-29 08:54:21,656 - mmseg - INFO - Iter [1000/20000]	lr: 5.062e-05, eta: 10:38:00, time: 1.867, data_time: 1.055, memory: 27523, decode.loss_ce: 0.1571, decode.acc_seg: 93.7091, loss: 0.1571
2025-04-29 08:56:10,714 - mmseg - INFO - Iter [1050/20000]	lr: 5.301e-05, eta: 10:38:49, time: 2.181, data_time: 1.369, memory: 27523, decode.loss_ce: 0.1739, decode.acc_seg: 92.9437, loss: 0.1739
2025-04-29 08:57:49,634 - mmseg - INFO - Iter [1100/20000]	lr: 5.539e-05, eta: 10:36:30, time: 1.978, data_time: 1.167, memory: 27523, decode.loss_ce: 0.1799, decode.acc_seg: 92.6891, loss: 0.1799
2025-04-29 08:59:27,037 - mmseg - INFO - Iter [1150/20000]	lr: 5.776e-05, eta: 10:33:50, time: 1.948, data_time: 1.137, memory: 27523, decode.loss_ce: 0.1650, decode.acc_seg: 93.6822, loss: 0.1650
2025-04-29 09:01:04,861 - mmseg - INFO - Iter [1200/20000]	lr: 6.011e-05, eta: 10:31:21, time: 1.956, data_time: 1.144, memory: 27523, decode.loss_ce: 0.1703, decode.acc_seg: 93.2047, loss: 0.1703
2025-04-29 09:02:49,749 - mmseg - INFO - Iter [1250/20000]	lr: 6.245e-05, eta: 10:30:42, time: 2.098, data_time: 1.286, memory: 27523, decode.loss_ce: 0.2169, decode.acc_seg: 92.3765, loss: 0.2169
2025-04-29 09:04:23,693 - mmseg - INFO - Iter [1300/20000]	lr: 6.478e-05, eta: 10:27:21, time: 1.879, data_time: 1.067, memory: 27523, decode.loss_ce: 0.1788, decode.acc_seg: 92.6371, loss: 0.1788
2025-04-29 09:05:58,401 - mmseg - INFO - Iter [1350/20000]	lr: 6.709e-05, eta: 10:24:18, time: 1.894, data_time: 1.083, memory: 27523, decode.loss_ce: 0.1658, decode.acc_seg: 93.3130, loss: 0.1658
2025-04-29 09:07:32,669 - mmseg - INFO - Iter [1400/20000]	lr: 6.939e-05, eta: 10:21:16, time: 1.885, data_time: 1.073, memory: 27523, decode.loss_ce: 0.1653, decode.acc_seg: 93.5990, loss: 0.1653
2025-04-29 09:09:14,862 - mmseg - INFO - Iter [1450/20000]	lr: 7.168e-05, eta: 10:20:01, time: 2.044, data_time: 1.232, memory: 27523, decode.loss_ce: 0.1631, decode.acc_seg: 93.4547, loss: 0.1631
2025-04-29 09:10:53,007 - mmseg - INFO - Iter [1500/20000]	lr: 7.395e-05, eta: 10:17:55, time: 1.963, data_time: 1.151, memory: 27523, decode.loss_ce: 0.2060, decode.acc_seg: 92.6611, loss: 0.2060
2025-04-29 09:12:27,892 - mmseg - INFO - Iter [1550/20000]	lr: 7.380e-05, eta: 10:15:11, time: 1.898, data_time: 1.085, memory: 27523, decode.loss_ce: 0.1684, decode.acc_seg: 93.5132, loss: 0.1684
2025-04-29 09:14:01,724 - mmseg - INFO - Iter [1600/20000]	lr: 7.360e-05, eta: 10:12:20, time: 1.877, data_time: 1.065, memory: 27523, decode.loss_ce: 0.1623, decode.acc_seg: 93.6360, loss: 0.1623
2025-04-29 09:15:40,483 - mmseg - INFO - Iter [1650/20000]	lr: 7.340e-05, eta: 10:10:28, time: 1.975, data_time: 1.163, memory: 27523, decode.loss_ce: 0.1755, decode.acc_seg: 92.6787, loss: 0.1755
2025-04-29 09:17:07,437 - mmseg - INFO - Iter [1700/20000]	lr: 7.320e-05, eta: 10:06:30, time: 1.739, data_time: 0.927, memory: 27523, decode.loss_ce: 0.1902, decode.acc_seg: 92.1381, loss: 0.1902
2025-04-29 09:18:45,382 - mmseg - INFO - Iter [1750/20000]	lr: 7.300e-05, eta: 10:04:35, time: 1.959, data_time: 1.145, memory: 27523, decode.loss_ce: 0.1820, decode.acc_seg: 92.8930, loss: 0.1820
2025-04-29 09:20:22,221 - mmseg - INFO - Iter [1800/20000]	lr: 7.280e-05, eta: 10:02:30, time: 1.937, data_time: 1.125, memory: 27523, decode.loss_ce: 0.1572, decode.acc_seg: 93.5360, loss: 0.1572
2025-04-29 09:22:08,766 - mmseg - INFO - Iter [1850/20000]	lr: 7.260e-05, eta: 10:02:02, time: 2.131, data_time: 1.318, memory: 27523, decode.loss_ce: 0.1951, decode.acc_seg: 92.6626, loss: 0.1951
2025-04-29 09:23:43,968 - mmseg - INFO - Iter [1900/20000]	lr: 7.240e-05, eta: 9:59:41, time: 1.904, data_time: 1.091, memory: 27523, decode.loss_ce: 0.1700, decode.acc_seg: 93.2519, loss: 0.1700
2025-04-29 09:25:27,542 - mmseg - INFO - Iter [1950/20000]	lr: 7.220e-05, eta: 9:58:40, time: 2.071, data_time: 1.260, memory: 27523, decode.loss_ce: 0.1602, decode.acc_seg: 93.5660, loss: 0.1602
2025-04-29 09:27:06,827 - mmseg - INFO - Saving checkpoint at 2000 iterations
2025-04-29 09:27:20,534 - mmseg - INFO - Exp name: vpd_config.py
2025-04-29 09:27:20,535 - mmseg - INFO - Iter [2000/20000]	lr: 7.200e-05, eta: 9:59:02, time: 2.260, data_time: 1.174, memory: 27523, decode.loss_ce: 0.1779, decode.acc_seg: 92.5160, loss: 0.1779
2025-04-29 09:30:42,785 - mmseg - INFO - per class results:
2025-04-29 09:30:42,794 - mmseg - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        | 79.81 | 89.59 |
|       building      | 85.08 | 93.75 |
|         sky         | 93.58 | 97.22 |
|        floor        | 82.38 | 90.22 |
|         tree        | 73.65 | 86.85 |
|       ceiling       | 86.65 | 94.66 |
|         road        | 86.09 | 92.35 |
|         bed         | 91.21 | 96.86 |
|      windowpane     | 67.01 | 84.32 |
|        grass        | 73.93 | 88.86 |
|       cabinet       | 57.67 | 73.74 |
|       sidewalk      | 69.01 | 82.52 |
|        person       | 80.83 | 90.83 |
|        earth        | 32.34 | 53.11 |
|         door        | 58.67 | 73.45 |
|        table        | 66.36 | 78.46 |
|       mountain      | 35.82 | 49.32 |
|        plant        | 49.69 |  56.1 |
|       curtain       |  72.1 | 85.01 |
|        chair        | 63.78 | 77.14 |
|         car         | 83.07 | 91.18 |
|        water        | 51.19 | 88.36 |
|       painting      | 74.42 | 89.09 |
|         sofa        | 71.94 | 83.25 |
|        shelf        | 48.88 | 61.09 |
|        house        | 40.92 | 66.15 |
|         sea         | 70.02 | 88.12 |
|        mirror       | 82.38 | 92.31 |
|         rug         | 66.49 | 79.32 |
|        field        |  32.3 | 48.41 |
|       armchair      | 51.57 | 76.53 |
|         seat        | 53.83 | 85.24 |
|        fence        | 26.81 | 41.54 |
|         desk        | 46.09 | 72.49 |
|         rock        |  48.2 | 61.21 |
|       wardrobe      | 54.58 | 73.46 |
|         lamp        | 67.74 |  79.7 |
|       bathtub       | 92.09 | 95.97 |
|       railing       | 44.37 | 61.21 |
|       cushion       | 61.77 | 73.01 |
|         base        | 29.61 | 53.23 |
|         box         | 33.51 | 41.22 |
|        column       | 52.56 | 58.46 |
|      signboard      | 31.31 | 42.29 |
|   chest of drawers  | 49.13 |  69.2 |
|       counter       | 47.21 | 64.35 |
|         sand        | 77.32 | 88.69 |
|         sink        | 66.26 | 71.56 |
|      skyscraper     | 48.72 | 97.11 |
|      fireplace      | 67.34 | 92.44 |
|     refrigerator    | 60.19 | 68.81 |
|      grandstand     | 44.37 | 84.27 |
|         path        | 39.88 | 49.81 |
|        stairs       | 33.79 | 38.47 |
|        runway       | 94.19 | 99.47 |
|         case        | 44.31 | 74.95 |
|      pool table     | 92.97 | 95.75 |
|        pillow       | 57.15 | 65.05 |
|     screen door     | 80.53 | 83.75 |
|       stairway      | 34.22 |  46.1 |
|        river        | 26.44 | 28.69 |
|        bridge       | 71.69 | 83.91 |
|       bookcase      | 41.37 |  54.4 |
|        blind        | 58.24 | 59.83 |
|     coffee table    |  60.3 | 72.29 |
|        toilet       | 87.05 | 91.47 |
|        flower       | 50.64 | 62.12 |
|         book        |  43.3 | 64.54 |
|         hill        | 17.52 | 24.96 |
|        bench        | 39.05 | 42.32 |
|      countertop     | 54.16 | 82.95 |
|        stove        | 75.49 | 96.31 |
|         palm        | 54.22 | 71.63 |
|    kitchen island   | 43.48 | 72.72 |
|       computer      | 68.34 | 83.16 |
|     swivel chair    | 58.41 | 78.27 |
|         boat        | 17.18 | 18.57 |
|         bar         | 40.93 | 45.15 |
|    arcade machine   | 78.93 | 91.04 |
|        hovel        |  3.94 |  5.81 |
|         bus         |  79.5 | 90.57 |
|        towel        | 61.61 | 74.67 |
|        light        | 54.19 | 59.59 |
|        truck        | 32.03 | 41.22 |
|        tower        | 39.66 | 61.84 |
|      chandelier     |  71.1 | 89.39 |
|        awning       | 17.08 | 18.09 |
|     streetlight     | 24.65 | 31.05 |
|        booth        | 24.62 | 30.97 |
| television receiver |  61.2 | 73.05 |
|       airplane      | 30.07 | 31.88 |
|      dirt track     |  9.24 | 20.33 |
|       apparel       |  33.1 |  39.1 |
|         pole        |  39.0 | 48.85 |
|         land        |  4.12 |  5.61 |
|      bannister      | 17.72 | 25.05 |
|      escalator      | 35.79 | 45.07 |
|       ottoman       | 53.13 | 77.34 |
|        bottle       | 26.67 |  44.3 |
|        buffet       | 38.34 | 46.59 |
|        poster       | 45.14 | 57.32 |
|        stage        | 42.58 | 62.56 |
|         van         | 37.37 | 48.09 |
|         ship        | 12.97 | 95.13 |
|       fountain      | 31.27 | 32.78 |
|    conveyer belt    |  91.2 |  98.1 |
|        canopy       | 35.08 | 45.76 |
|        washer       | 37.44 | 37.47 |
|      plaything      | 30.07 | 63.82 |
|    swimming pool    | 65.46 | 67.57 |
|        stool        | 47.17 | 60.68 |
|        barrel       |  0.0  |  0.0  |
|        basket       | 37.66 | 47.71 |
|      waterfall      | 92.32 | 97.37 |
|         tent        |  0.0  |  nan  |
|         bag         | 14.96 | 17.04 |
|       minibike      | 73.35 | 89.42 |
|        cradle       | 80.37 | 99.28 |
|         oven        | 54.71 | 70.04 |
|         ball        | 47.55 | 55.37 |
|         food        | 41.75 | 48.13 |
|         step        | 26.11 | 31.97 |
|         tank        | 89.15 | 91.83 |
|      trade name     | 28.25 | 31.68 |
|      microwave      |  71.8 | 82.67 |
|         pot         | 55.23 | 62.42 |
|        animal       | 75.37 |  77.0 |
|       bicycle       | 59.34 |  69.1 |
|         lake        |  0.0  |  0.0  |
|      dishwasher     | 77.89 | 92.57 |
|        screen       | 61.76 | 83.93 |
|       blanket       | 37.16 |  39.6 |
|      sculpture      | 73.98 | 82.39 |
|         hood        | 39.15 | 47.44 |
|        sconce       | 45.43 | 54.48 |
|         vase        | 32.18 |  51.7 |
|    traffic light    |  32.9 | 47.66 |
|         tray        | 15.39 | 23.09 |
|        ashcan       | 34.89 | 46.26 |
|         fan         | 61.13 | 68.29 |
|         pier        | 30.81 | 48.03 |
|      crt screen     | 30.84 | 41.13 |
|        plate        |  60.8 | 76.81 |
|       monitor       | 70.12 | 79.84 |
|    bulletin board   | 58.95 | 66.69 |
|        shower       | 16.63 | 28.49 |
|       radiator      | 54.19 | 64.32 |
|        glass        | 14.57 |  16.1 |
|        clock        | 40.68 | 47.22 |
|         flag        | 45.51 | 53.15 |
+---------------------+-------+-------+
2025-04-29 09:30:42,794 - mmseg - INFO - Summary:
2025-04-29 09:30:42,794 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 84.11 | 51.07 | 63.83 |
+-------+-------+-------+
2025-04-29 09:30:42,795 - mmseg - INFO - Exp name: vpd_config.py
2025-04-29 09:30:42,796 - mmseg - INFO - Iter(val) [851]	aAcc: 0.8411, mIoU: 0.5107, mAcc: 0.6383, IoU.wall: 0.7981, IoU.building: 0.8508, IoU.sky: 0.9358, IoU.floor: 0.8238, IoU.tree: 0.7365, IoU.ceiling: 0.8665, IoU.road: 0.8609, IoU.bed : 0.9121, IoU.windowpane: 0.6701, IoU.grass: 0.7393, IoU.cabinet: 0.5767, IoU.sidewalk: 0.6901, IoU.person: 0.8083, IoU.earth: 0.3234, IoU.door: 0.5867, IoU.table: 0.6636, IoU.mountain: 0.3582, IoU.plant: 0.4969, IoU.curtain: 0.7210, IoU.chair: 0.6378, IoU.car: 0.8307, IoU.water: 0.5119, IoU.painting: 0.7442, IoU.sofa: 0.7194, IoU.shelf: 0.4888, IoU.house: 0.4092, IoU.sea: 0.7002, IoU.mirror: 0.8238, IoU.rug: 0.6649, IoU.field: 0.3230, IoU.armchair: 0.5157, IoU.seat: 0.5383, IoU.fence: 0.2681, IoU.desk: 0.4609, IoU.rock: 0.4820, IoU.wardrobe: 0.5458, IoU.lamp: 0.6774, IoU.bathtub: 0.9209, IoU.railing: 0.4437, IoU.cushion: 0.6177, IoU.base: 0.2961, IoU.box: 0.3351, IoU.column: 0.5256, IoU.signboard: 0.3131, IoU.chest of drawers: 0.4913, IoU.counter: 0.4721, IoU.sand: 0.7732, IoU.sink: 0.6626, IoU.skyscraper: 0.4872, IoU.fireplace: 0.6734, IoU.refrigerator: 0.6019, IoU.grandstand: 0.4437, IoU.path: 0.3988, IoU.stairs: 0.3379, IoU.runway: 0.9419, IoU.case: 0.4431, IoU.pool table: 0.9297, IoU.pillow: 0.5715, IoU.screen door: 0.8053, IoU.stairway: 0.3422, IoU.river: 0.2644, IoU.bridge: 0.7169, IoU.bookcase: 0.4137, IoU.blind: 0.5824, IoU.coffee table: 0.6030, IoU.toilet: 0.8705, IoU.flower: 0.5064, IoU.book: 0.4330, IoU.hill: 0.1752, IoU.bench: 0.3905, IoU.countertop: 0.5416, IoU.stove: 0.7549, IoU.palm: 0.5422, IoU.kitchen island: 0.4348, IoU.computer: 0.6834, IoU.swivel chair: 0.5841, IoU.boat: 0.1718, IoU.bar: 0.4093, IoU.arcade machine: 0.7893, IoU.hovel: 0.0394, IoU.bus: 0.7950, IoU.towel: 0.6161, IoU.light: 0.5419, IoU.truck: 0.3203, IoU.tower: 0.3966, IoU.chandelier: 0.7110, IoU.awning: 0.1708, IoU.streetlight: 0.2465, IoU.booth: 0.2462, IoU.television receiver: 0.6120, IoU.airplane: 0.3007, IoU.dirt track: 0.0924, IoU.apparel: 0.3310, IoU.pole: 0.3900, IoU.land: 0.0412, IoU.bannister: 0.1772, IoU.escalator: 0.3579, IoU.ottoman: 0.5313, IoU.bottle: 0.2667, IoU.buffet: 0.3834, IoU.poster: 0.4514, IoU.stage: 0.4258, IoU.van: 0.3737, IoU.ship: 0.1297, IoU.fountain: 0.3127, IoU.conveyer belt: 0.9120, IoU.canopy: 0.3508, IoU.washer: 0.3744, IoU.plaything: 0.3007, IoU.swimming pool: 0.6546, IoU.stool: 0.4717, IoU.barrel: 0.0000, IoU.basket: 0.3766, IoU.waterfall: 0.9232, IoU.tent: 0.0000, IoU.bag: 0.1496, IoU.minibike: 0.7335, IoU.cradle: 0.8037, IoU.oven: 0.5471, IoU.ball: 0.4755, IoU.food: 0.4175, IoU.step: 0.2611, IoU.tank: 0.8915, IoU.trade name: 0.2825, IoU.microwave: 0.7180, IoU.pot: 0.5523, IoU.animal: 0.7537, IoU.bicycle: 0.5934, IoU.lake: 0.0000, IoU.dishwasher: 0.7789, IoU.screen: 0.6176, IoU.blanket: 0.3716, IoU.sculpture: 0.7398, IoU.hood: 0.3915, IoU.sconce: 0.4543, IoU.vase: 0.3218, IoU.traffic light: 0.3290, IoU.tray: 0.1539, IoU.ashcan: 0.3489, IoU.fan: 0.6113, IoU.pier: 0.3081, IoU.crt screen: 0.3084, IoU.plate: 0.6080, IoU.monitor: 0.7012, IoU.bulletin board: 0.5895, IoU.shower: 0.1663, IoU.radiator: 0.5419, IoU.glass: 0.1457, IoU.clock: 0.4068, IoU.flag: 0.4551, Acc.wall: 0.8959, Acc.building: 0.9375, Acc.sky: 0.9722, Acc.floor: 0.9022, Acc.tree: 0.8685, Acc.ceiling: 0.9466, Acc.road: 0.9235, Acc.bed : 0.9686, Acc.windowpane: 0.8432, Acc.grass: 0.8886, Acc.cabinet: 0.7374, Acc.sidewalk: 0.8252, Acc.person: 0.9083, Acc.earth: 0.5311, Acc.door: 0.7345, Acc.table: 0.7846, Acc.mountain: 0.4932, Acc.plant: 0.5610, Acc.curtain: 0.8501, Acc.chair: 0.7714, Acc.car: 0.9118, Acc.water: 0.8836, Acc.painting: 0.8909, Acc.sofa: 0.8325, Acc.shelf: 0.6109, Acc.house: 0.6615, Acc.sea: 0.8812, Acc.mirror: 0.9231, Acc.rug: 0.7932, Acc.field: 0.4841, Acc.armchair: 0.7653, Acc.seat: 0.8524, Acc.fence: 0.4154, Acc.desk: 0.7249, Acc.rock: 0.6121, Acc.wardrobe: 0.7346, Acc.lamp: 0.7970, Acc.bathtub: 0.9597, Acc.railing: 0.6121, Acc.cushion: 0.7301, Acc.base: 0.5323, Acc.box: 0.4122, Acc.column: 0.5846, Acc.signboard: 0.4229, Acc.chest of drawers: 0.6920, Acc.counter: 0.6435, Acc.sand: 0.8869, Acc.sink: 0.7156, Acc.skyscraper: 0.9711, Acc.fireplace: 0.9244, Acc.refrigerator: 0.6881, Acc.grandstand: 0.8427, Acc.path: 0.4981, Acc.stairs: 0.3847, Acc.runway: 0.9947, Acc.case: 0.7495, Acc.pool table: 0.9575, Acc.pillow: 0.6505, Acc.screen door: 0.8375, Acc.stairway: 0.4610, Acc.river: 0.2869, Acc.bridge: 0.8391, Acc.bookcase: 0.5440, Acc.blind: 0.5983, Acc.coffee table: 0.7229, Acc.toilet: 0.9147, Acc.flower: 0.6212, Acc.book: 0.6454, Acc.hill: 0.2496, Acc.bench: 0.4232, Acc.countertop: 0.8295, Acc.stove: 0.9631, Acc.palm: 0.7163, Acc.kitchen island: 0.7272, Acc.computer: 0.8316, Acc.swivel chair: 0.7827, Acc.boat: 0.1857, Acc.bar: 0.4515, Acc.arcade machine: 0.9104, Acc.hovel: 0.0581, Acc.bus: 0.9057, Acc.towel: 0.7467, Acc.light: 0.5959, Acc.truck: 0.4122, Acc.tower: 0.6184, Acc.chandelier: 0.8939, Acc.awning: 0.1809, Acc.streetlight: 0.3105, Acc.booth: 0.3097, Acc.television receiver: 0.7305, Acc.airplane: 0.3188, Acc.dirt track: 0.2033, Acc.apparel: 0.3910, Acc.pole: 0.4885, Acc.land: 0.0561, Acc.bannister: 0.2505, Acc.escalator: 0.4507, Acc.ottoman: 0.7734, Acc.bottle: 0.4430, Acc.buffet: 0.4659, Acc.poster: 0.5732, Acc.stage: 0.6256, Acc.van: 0.4809, Acc.ship: 0.9513, Acc.fountain: 0.3278, Acc.conveyer belt: 0.9810, Acc.canopy: 0.4576, Acc.washer: 0.3747, Acc.plaything: 0.6382, Acc.swimming pool: 0.6757, Acc.stool: 0.6068, Acc.barrel: 0.0000, Acc.basket: 0.4771, Acc.waterfall: 0.9737, Acc.tent: nan, Acc.bag: 0.1704, Acc.minibike: 0.8942, Acc.cradle: 0.9928, Acc.oven: 0.7004, Acc.ball: 0.5537, Acc.food: 0.4813, Acc.step: 0.3197, Acc.tank: 0.9183, Acc.trade name: 0.3168, Acc.microwave: 0.8267, Acc.pot: 0.6242, Acc.animal: 0.7700, Acc.bicycle: 0.6910, Acc.lake: 0.0000, Acc.dishwasher: 0.9257, Acc.screen: 0.8393, Acc.blanket: 0.3960, Acc.sculpture: 0.8239, Acc.hood: 0.4744, Acc.sconce: 0.5448, Acc.vase: 0.5170, Acc.traffic light: 0.4766, Acc.tray: 0.2309, Acc.ashcan: 0.4626, Acc.fan: 0.6829, Acc.pier: 0.4803, Acc.crt screen: 0.4113, Acc.plate: 0.7681, Acc.monitor: 0.7984, Acc.bulletin board: 0.6669, Acc.shower: 0.2849, Acc.radiator: 0.6432, Acc.glass: 0.1610, Acc.clock: 0.4722, Acc.flag: 0.5315
2025-04-29 09:31:54,165 - mmseg - INFO - Iter [2050/20000]	lr: 7.180e-05, eta: 10:22:44, time: 5.472, data_time: 4.658, memory: 27523, decode.loss_ce: 0.1744, decode.acc_seg: 92.9700, loss: 0.1744
2025-04-29 09:33:07,298 - mmseg - INFO - Iter [2100/20000]	lr: 7.160e-05, eta: 10:16:36, time: 1.463, data_time: 0.649, memory: 27523, decode.loss_ce: 0.1581, decode.acc_seg: 93.8514, loss: 0.1581
2025-04-29 09:34:46,705 - mmseg - INFO - Iter [2150/20000]	lr: 7.140e-05, eta: 10:14:20, time: 1.988, data_time: 1.176, memory: 27523, decode.loss_ce: 0.1661, decode.acc_seg: 93.4662, loss: 0.1661
2025-04-29 09:36:18,025 - mmseg - INFO - Iter [2200/20000]	lr: 7.120e-05, eta: 10:11:00, time: 1.826, data_time: 1.015, memory: 27523, decode.loss_ce: 0.1589, decode.acc_seg: 93.3333, loss: 0.1589
2025-04-29 09:37:46,531 - mmseg - INFO - Iter [2250/20000]	lr: 7.100e-05, eta: 10:07:23, time: 1.770, data_time: 0.958, memory: 27523, decode.loss_ce: 0.1457, decode.acc_seg: 94.0119, loss: 0.1457
2025-04-29 09:39:19,546 - mmseg - INFO - Iter [2300/20000]	lr: 7.080e-05, eta: 10:04:26, time: 1.860, data_time: 1.047, memory: 27523, decode.loss_ce: 0.1754, decode.acc_seg: 93.3771, loss: 0.1754
2025-04-29 09:40:50,115 - mmseg - INFO - Iter [2350/20000]	lr: 7.060e-05, eta: 10:01:15, time: 1.811, data_time: 0.998, memory: 27523, decode.loss_ce: 0.1560, decode.acc_seg: 93.5815, loss: 0.1560
2025-04-29 09:42:05,778 - mmseg - INFO - Iter [2400/20000]	lr: 7.040e-05, eta: 9:56:18, time: 1.513, data_time: 0.699, memory: 27523, decode.loss_ce: 0.1724, decode.acc_seg: 93.1459, loss: 0.1724
2025-04-29 09:43:47,245 - mmseg - INFO - Iter [2450/20000]	lr: 7.020e-05, eta: 9:54:35, time: 2.029, data_time: 1.217, memory: 27523, decode.loss_ce: 0.1634, decode.acc_seg: 93.6482, loss: 0.1634
2025-04-29 09:45:02,424 - mmseg - INFO - Iter [2500/20000]	lr: 7.000e-05, eta: 9:49:48, time: 1.504, data_time: 0.688, memory: 27523, decode.loss_ce: 0.1572, decode.acc_seg: 93.8646, loss: 0.1572
2025-04-29 09:46:33,569 - mmseg - INFO - Iter [2550/20000]	lr: 6.980e-05, eta: 9:46:59, time: 1.823, data_time: 1.010, memory: 27523, decode.loss_ce: 0.1652, decode.acc_seg: 93.1628, loss: 0.1652
2025-04-29 09:47:57,190 - mmseg - INFO - Iter [2600/20000]	lr: 6.960e-05, eta: 9:43:22, time: 1.672, data_time: 0.861, memory: 27523, decode.loss_ce: 0.1554, decode.acc_seg: 93.5363, loss: 0.1554
2025-04-29 09:49:41,679 - mmseg - INFO - Iter [2650/20000]	lr: 6.940e-05, eta: 9:42:07, time: 2.090, data_time: 1.277, memory: 27523, decode.loss_ce: 0.1756, decode.acc_seg: 92.8524, loss: 0.1756
2025-04-29 09:51:18,841 - mmseg - INFO - Iter [2700/20000]	lr: 6.920e-05, eta: 9:40:04, time: 1.943, data_time: 1.130, memory: 27523, decode.loss_ce: 0.1953, decode.acc_seg: 92.7004, loss: 0.1953
2025-04-29 09:52:58,048 - mmseg - INFO - Iter [2750/20000]	lr: 6.900e-05, eta: 9:38:15, time: 1.984, data_time: 1.170, memory: 27523, decode.loss_ce: 0.1865, decode.acc_seg: 93.0742, loss: 0.1865
2025-04-29 09:54:39,056 - mmseg - INFO - Iter [2800/20000]	lr: 6.880e-05, eta: 9:36:37, time: 2.020, data_time: 1.209, memory: 27523, decode.loss_ce: 0.1592, decode.acc_seg: 93.6900, loss: 0.1592
2025-04-29 09:56:23,659 - mmseg - INFO - Iter [2850/20000]	lr: 6.860e-05, eta: 9:35:21, time: 2.092, data_time: 1.279, memory: 27523, decode.loss_ce: 0.1614, decode.acc_seg: 93.4714, loss: 0.1614
2025-04-29 09:57:54,683 - mmseg - INFO - Iter [2900/20000]	lr: 6.840e-05, eta: 9:32:43, time: 1.820, data_time: 1.009, memory: 27523, decode.loss_ce: 0.1556, decode.acc_seg: 93.9100, loss: 0.1556
2025-04-29 09:59:28,307 - mmseg - INFO - Iter [2950/20000]	lr: 6.820e-05, eta: 9:30:23, time: 1.872, data_time: 1.060, memory: 27523, decode.loss_ce: 0.1516, decode.acc_seg: 93.6026, loss: 0.1516
2025-04-29 10:00:58,042 - mmseg - INFO - Exp name: vpd_config.py
2025-04-29 10:00:58,043 - mmseg - INFO - Iter [3000/20000]	lr: 6.800e-05, eta: 9:27:43, time: 1.795, data_time: 0.982, memory: 27523, decode.loss_ce: 0.1607, decode.acc_seg: 93.5347, loss: 0.1607
2025-04-29 10:02:24,576 - mmseg - INFO - Iter [3050/20000]	lr: 6.780e-05, eta: 9:24:47, time: 1.731, data_time: 0.919, memory: 27523, decode.loss_ce: 0.1804, decode.acc_seg: 93.1558, loss: 0.1804
2025-04-29 10:03:38,463 - mmseg - INFO - Iter [3100/20000]	lr: 6.760e-05, eta: 9:20:44, time: 1.478, data_time: 0.664, memory: 27523, decode.loss_ce: 0.1838, decode.acc_seg: 93.2845, loss: 0.1838
2025-04-29 10:05:17,757 - mmseg - INFO - Iter [3150/20000]	lr: 6.740e-05, eta: 9:19:04, time: 1.986, data_time: 1.173, memory: 27523, decode.loss_ce: 0.1565, decode.acc_seg: 93.7240, loss: 0.1565
2025-04-29 10:06:44,931 - mmseg - INFO - Iter [3200/20000]	lr: 6.720e-05, eta: 9:16:19, time: 1.743, data_time: 0.931, memory: 27523, decode.loss_ce: 0.1949, decode.acc_seg: 92.5956, loss: 0.1949
2025-04-29 10:07:53,176 - mmseg - INFO - Iter [3250/20000]	lr: 6.700e-05, eta: 9:11:59, time: 1.365, data_time: 0.551, memory: 27523, decode.loss_ce: 0.1825, decode.acc_seg: 93.0869, loss: 0.1825
2025-04-29 10:08:49,440 - mmseg - INFO - Iter [3300/20000]	lr: 6.680e-05, eta: 9:06:45, time: 1.125, data_time: 0.310, memory: 27523, decode.loss_ce: 0.1622, decode.acc_seg: 93.4275, loss: 0.1622
2025-04-29 10:10:06,299 - mmseg - INFO - Iter [3350/20000]	lr: 6.660e-05, eta: 9:03:21, time: 1.537, data_time: 0.722, memory: 27523, decode.loss_ce: 0.1613, decode.acc_seg: 93.6047, loss: 0.1613
2025-04-29 10:11:45,682 - mmseg - INFO - Iter [3400/20000]	lr: 6.640e-05, eta: 9:01:50, time: 1.988, data_time: 1.174, memory: 27523, decode.loss_ce: 0.1837, decode.acc_seg: 92.8797, loss: 0.1837
2025-04-29 10:13:14,632 - mmseg - INFO - Iter [3450/20000]	lr: 6.620e-05, eta: 8:59:29, time: 1.779, data_time: 0.967, memory: 27523, decode.loss_ce: 0.1472, decode.acc_seg: 94.0061, loss: 0.1472
2025-04-29 10:14:46,938 - mmseg - INFO - Iter [3500/20000]	lr: 6.600e-05, eta: 8:57:25, time: 1.846, data_time: 1.034, memory: 27523, decode.loss_ce: 0.1559, decode.acc_seg: 93.9056, loss: 0.1559
2025-04-29 10:16:22,423 - mmseg - INFO - Iter [3550/20000]	lr: 6.580e-05, eta: 8:55:37, time: 1.910, data_time: 1.097, memory: 27523, decode.loss_ce: 0.1754, decode.acc_seg: 92.9716, loss: 0.1754
