Loaded dependency [python3/3.11.4]: gcc/12.3.0-binutils-2.40
Loaded dependency [python3/3.11.4]: sqlite3/3.42.0
Loaded module: python3/3.11.4

Loading python3/3.11.4
  Loading requirement: gcc/12.3.0-binutils-2.40 sqlite3/3.42.0
Loaded module: cuda/11.3
/dtu/blackhole/0e/154958/miniconda3/envs/ldm/lib/python3.8/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
2025-04-22 18:36:47,463 - mmseg - INFO - Multi-processing start method is `None`
2025-04-22 18:36:47,531 - mmseg - INFO - OpenCV num_threads is `1
2025-04-22 18:36:47,531 - mmseg - INFO - OMP num threads is 1
2025-04-22 18:36:47,654 - mmseg - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.8.19 | packaged by conda-forge | (default, Mar 20 2024, 12:47:35) [GCC 12.3.0]
CUDA available: True
GPU 0: NVIDIA A100 80GB PCIe
CUDA_HOME: /appl/cuda/11.3.0
NVCC: Cuda compilation tools, release 11.3, V11.3.58
GCC: gcc (GCC) 12.3.0
PyTorch: 1.11.0+cu113
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.5.2 (Git Hash a9302535553c73243c632ad3c4c80beec3d19a1e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.11.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

TorchVision: 0.12.0+cu113
OpenCV: 4.6.0
MMCV: 1.5.0
MMCV Compiler: GCC 7.3
MMCV CUDA Compiler: 11.3
MMSegmentation: 0.29.0+a6d2f4a
------------------------------------------------------------

2025-04-22 18:36:47,654 - mmseg - INFO - Distributed training: False
2025-04-22 18:36:48,339 - mmseg - INFO - Config:
norm_cfg = dict(type='SyncBN', requires_grad=True)
model = dict(
    type='VPDSeg',
    pretrained='open-mmlab://resnet50_v1c',
    backbone=dict(
        type='ResNetV1c',
        depth=50,
        num_stages=4,
        out_indices=(0, 1, 2, 3),
        dilations=(1, 1, 1, 1),
        strides=(1, 2, 2, 2),
        norm_cfg=dict(type='SyncBN', requires_grad=True),
        norm_eval=False,
        style='pytorch',
        contract_dilation=True),
    neck=dict(
        type='FPN',
        in_channels=[320, 790, 1430, 1280],
        out_channels=256,
        num_outs=4),
    decode_head=dict(
        type='FPNHead',
        in_channels=[256, 256, 256, 256],
        in_index=[0, 1, 2, 3],
        feature_strides=[4, 8, 16, 32],
        channels=256,
        dropout_ratio=0.1,
        num_classes=150,
        norm_cfg=dict(type='SyncBN', requires_grad=True),
        align_corners=False,
        loss_decode=dict(
            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0)),
    train_cfg=dict(),
    test_cfg=dict(mode='whole', crop_size=(512, 512), stride=(341, 341)),
    sd_path='/work3/s203557/checkpoints/v1-5-pruned-emaonly.ckpt',
    sd_config=
    '/zhome/b6/d/154958/ADLCV_Project/VPD/segmentation/v1-inference.yaml',
    max_boxes=6)
dataset_type = 'ADE20KDataset'
data_root = '/work3/s203557/data/ade20k-dataset/versions/2/ADEChallengeData2016'
IMG_MEAN = [127.5, 127.5, 127.5]
IMG_VAR = [127.5, 127.5, 127.5]
img_norm_cfg = dict(
    mean=[127.5, 127.5, 127.5], std=[127.5, 127.5, 127.5], to_rgb=True)
crop_size = (512, 512)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations', reduce_zero_label=True),
    dict(type='Resize', img_scale=(2048, 512), ratio_range=(0.5, 2.0)),
    dict(type='RandomCrop', crop_size=(512, 512), cat_max_ratio=0.75),
    dict(type='RandomFlip', prob=0.5),
    dict(type='PhotoMetricDistortion'),
    dict(
        type='Normalize',
        mean=[127.5, 127.5, 127.5],
        std=[127.5, 127.5, 127.5],
        to_rgb=True),
    dict(type='Pad', size=(512, 512), pad_val=0, seg_pad_val=255),
    dict(type='GenerateBoundingBoxMasksFromSeg', max_boxes=6),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_semantic_seg', 'gt_bbox_masks'])
]
val_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations', reduce_zero_label=True),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(512, 512),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='Pad', size=(512, 512), pad_val=0, seg_pad_val=255),
            dict(type='RandomFlip', prob=0.0),
            dict(
                type='Normalize',
                mean=[127.5, 127.5, 127.5],
                std=[127.5, 127.5, 127.5],
                to_rgb=True),
            dict(type='GenerateBoundingBoxMasksFromSeg', max_boxes=6),
            dict(type='DefaultFormatBundle'),
            dict(type='Collect', keys=['img', 'gt_bbox_masks'])
        ])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations', reduce_zero_label=True),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(2048, 512),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='RandomFlip'),
            dict(
                type='Normalize',
                mean=[127.5, 127.5, 127.5],
                std=[127.5, 127.5, 127.5],
                to_rgb=True),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='GenerateBoundingBoxMasksFromSeg', max_boxes=6),
            dict(
                type='Collect',
                keys=['img', 'gt_semantic_seg', 'gt_bbox_masks'])
        ])
]
data = dict(
    samples_per_gpu=4,
    workers_per_gpu=8,
    train=dict(
        type='ADE20KDataset',
        data_root=
        '/work3/s203557/data/ade20k-dataset/versions/2/ADEChallengeData2016',
        img_dir='images/training',
        ann_dir='annotations/training',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations', reduce_zero_label=True),
            dict(type='Resize', img_scale=(2048, 512), ratio_range=(0.5, 2.0)),
            dict(type='RandomCrop', crop_size=(512, 512), cat_max_ratio=0.75),
            dict(type='RandomFlip', prob=0.5),
            dict(type='PhotoMetricDistortion'),
            dict(
                type='Normalize',
                mean=[127.5, 127.5, 127.5],
                std=[127.5, 127.5, 127.5],
                to_rgb=True),
            dict(type='Pad', size=(512, 512), pad_val=0, seg_pad_val=255),
            dict(type='GenerateBoundingBoxMasksFromSeg', max_boxes=6),
            dict(type='DefaultFormatBundle'),
            dict(
                type='Collect',
                keys=['img', 'gt_semantic_seg', 'gt_bbox_masks'])
        ]),
    val=dict(
        type='ADE20KDataset',
        data_root=
        '/work3/s203557/data/ade20k-dataset/versions/2/ADEChallengeData2016',
        img_dir='images/validation',
        ann_dir='annotations/validation',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations', reduce_zero_label=True),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(512, 512),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(
                        type='Pad',
                        size=(512, 512),
                        pad_val=0,
                        seg_pad_val=255),
                    dict(type='RandomFlip', prob=0.0),
                    dict(
                        type='Normalize',
                        mean=[127.5, 127.5, 127.5],
                        std=[127.5, 127.5, 127.5],
                        to_rgb=True),
                    dict(type='GenerateBoundingBoxMasksFromSeg', max_boxes=6),
                    dict(type='DefaultFormatBundle'),
                    dict(type='Collect', keys=['img', 'gt_bbox_masks'])
                ])
        ],
        test_mode=False),
    test=dict(
        type='ADE20KDataset',
        data_root=
        '/work3/s203557/data/ade20k-dataset/versions/2/ADEChallengeData2016',
        img_dir='images/validation',
        ann_dir='annotations/validation',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations', reduce_zero_label=True),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(2048, 512),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[127.5, 127.5, 127.5],
                        std=[127.5, 127.5, 127.5],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='GenerateBoundingBoxMasksFromSeg', max_boxes=6),
                    dict(
                        type='Collect',
                        keys=['img', 'gt_semantic_seg', 'gt_bbox_masks'])
                ])
        ]))
log_config = dict(
    interval=50, hooks=[dict(type='TextLoggerHook', by_epoch=False)])
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = '/work3/s203557/checkpoints/vpd.chkpt'
resume_from = None
workflow = [('train', 1)]
cudnn_benchmark = True
find_unused_parameters = True
optimizer = dict(
    type='AdamW',
    lr=8e-05,
    weight_decay=0.001,
    paramwise_cfg=dict(
        custom_keys=dict(
            unet=dict(lr_mult=0.1),
            encoder_vq=dict(lr_mult=0.0),
            text_encoder=dict(lr_mult=0.0),
            norm=dict(decay_mult=0.0))))
optimizer_config = dict()
lr_config = dict(
    policy='poly',
    power=1,
    min_lr=0.0,
    by_epoch=False,
    warmup='linear',
    warmup_iters=1500,
    warmup_ratio=1e-06)
runner = dict(type='IterBasedRunner', max_iters=40000)
checkpoint_config = dict(by_epoch=False, interval=4000)
evaluation = dict(interval=4000, metric='mIoU')
custom_imports = dict(
    imports=['segmentation.hooks.visualize_hook'], allow_failed_imports=False)
work_dir = '/work3/s203557/experiments/control_net_vpd/'
fp16 = dict(loss_scale=512.0)
custom_hooks = [
    dict(
        type='TrainVisualizeHook',
        interval=1000,
        num_samples=2,
        save_dir='vis')
]
gpu_ids = [0]
auto_resume = False

2025-04-22 18:36:48,340 - mmseg - INFO - Set random seed to 1856505100, deterministic: False
/dtu/blackhole/0e/154958/miniconda3/envs/ldm/lib/python3.8/site-packages/mmseg/models/losses/cross_entropy_loss.py:235: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.
  warnings.warn(
2025-04-22 18:36:58,608 - mmseg - INFO - initialize FPN with init_cfg {'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}
2025-04-22 18:36:58,625 - mmseg - INFO - initialize FPNHead with init_cfg {'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
segmentation/train.py:238: UserWarning: SyncBN is only supported with DDP. To be compatible with DP, we convert SyncBN to BN. Please use dist_train.sh which can avoid this error.
  warnings.warn(
2025-04-22 18:36:59,196 - mmseg - INFO - VPDSeg(
  (encoder_vq): AutoencoderKL(
    (encoder): Encoder(
      (conv_in): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (down): ModuleList(
        (0): Module(
          (block): ModuleList(
            (0): ResnetBlock(
              (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)
              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
            (1): ResnetBlock(
              (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)
              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (attn): ModuleList()
          (downsample): Downsample(
            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2))
          )
        )
        (1): Module(
          (block): ModuleList(
            (0): ResnetBlock(
              (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)
              (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (nin_shortcut): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): ResnetBlock(
              (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (attn): ModuleList()
          (downsample): Downsample(
            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))
          )
        )
        (2): Module(
          (block): ModuleList(
            (0): ResnetBlock(
              (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)
              (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (nin_shortcut): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): ResnetBlock(
              (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)
              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (attn): ModuleList()
          (downsample): Downsample(
            (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2))
          )
        )
        (3): Module(
          (block): ModuleList(
            (0): ResnetBlock(
              (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)
              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
            (1): ResnetBlock(
              (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)
              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (attn): ModuleList()
        )
      )
      (mid): Module(
        (block_1): ResnetBlock(
          (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)
          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (attn_1): AttnBlock(
          (norm): GroupNorm(32, 512, eps=1e-06, affine=True)
          (q): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (k): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (v): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (proj_out): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
        )
        (block_2): ResnetBlock(
          (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)
          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (norm_out): GroupNorm(32, 512, eps=1e-06, affine=True)
      (conv_out): Conv2d(512, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (loss): Identity()
    (quant_conv): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1))
    (post_quant_conv): Conv2d(4, 4, kernel_size=(1, 1), stride=(1, 1))
  )
  (unet): UNetWrapper(
    (unet): DiffusionWrapper(
      (diffusion_model): UNetModel(
        (time_embed): Sequential(
          (0): Linear(in_features=320, out_features=1280, bias=True)
          (1): SiLU()
          (2): Linear(in_features=1280, out_features=1280, bias=True)
        )
        (input_blocks): ModuleList(
          (0): TimestepEmbedSequential(
            (0): Conv2d(4, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (1): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=320, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Identity()
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 320, eps=1e-06, affine=True)
              (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=320, out_features=320, bias=False)
                    (to_v): Linear(in_features=320, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=320, out_features=2560, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=1280, out_features=320, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=768, out_features=320, bias=False)
                    (to_v): Linear(in_features=768, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (2): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=320, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Identity()
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 320, eps=1e-06, affine=True)
              (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=320, out_features=320, bias=False)
                    (to_v): Linear(in_features=320, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=320, out_features=2560, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=1280, out_features=320, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=768, out_features=320, bias=False)
                    (to_v): Linear(in_features=768, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (3): TimestepEmbedSequential(
            (0): Downsample(
              (op): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
            )
          )
          (4): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(320, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=640, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(320, 640, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 640, eps=1e-06, affine=True)
              (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=640, out_features=640, bias=False)
                    (to_v): Linear(in_features=640, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=640, out_features=5120, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=2560, out_features=640, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=768, out_features=640, bias=False)
                    (to_v): Linear(in_features=768, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (5): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=640, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Identity()
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 640, eps=1e-06, affine=True)
              (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=640, out_features=640, bias=False)
                    (to_v): Linear(in_features=640, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=640, out_features=5120, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=2560, out_features=640, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=768, out_features=640, bias=False)
                    (to_v): Linear(in_features=768, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (6): TimestepEmbedSequential(
            (0): Downsample(
              (op): Conv2d(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
            )
          )
          (7): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(640, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(640, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)
              (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_v): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=1280, out_features=10240, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=5120, out_features=1280, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=768, out_features=1280, bias=False)
                    (to_v): Linear(in_features=768, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (8): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Identity()
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)
              (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_v): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=1280, out_features=10240, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=5120, out_features=1280, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=768, out_features=1280, bias=False)
                    (to_v): Linear(in_features=768, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (9): TimestepEmbedSequential(
            (0): Downsample(
              (op): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
            )
          )
          (10): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Identity()
            )
          )
          (11): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Identity()
            )
          )
        )
        (middle_block): TimestepEmbedSequential(
          (0): ResBlock(
            (in_layers): Sequential(
              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
              (1): SiLU()
              (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
            (h_upd): Identity()
            (x_upd): Identity()
            (emb_layers): Sequential(
              (0): SiLU()
              (1): Linear(in_features=1280, out_features=1280, bias=True)
            )
            (out_layers): Sequential(
              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
              (1): SiLU()
              (2): Dropout(p=0, inplace=False)
              (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
            (skip_connection): Identity()
          )
          (1): SpatialTransformer(
            (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)
            (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
            (transformer_blocks): ModuleList(
              (0): BasicTransformerBlock(
                (attn1): CrossAttention(
                  (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                  (to_k): Linear(in_features=1280, out_features=1280, bias=False)
                  (to_v): Linear(in_features=1280, out_features=1280, bias=False)
                  (to_out): Sequential(
                    (0): Linear(in_features=1280, out_features=1280, bias=True)
                    (1): Dropout(p=0.0, inplace=False)
                  )
                )
                (ff): FeedForward(
                  (net): Sequential(
                    (0): GEGLU(
                      (proj): Linear(in_features=1280, out_features=10240, bias=True)
                    )
                    (1): Dropout(p=0.0, inplace=False)
                    (2): Linear(in_features=5120, out_features=1280, bias=True)
                  )
                )
                (attn2): CrossAttention(
                  (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                  (to_k): Linear(in_features=768, out_features=1280, bias=False)
                  (to_v): Linear(in_features=768, out_features=1280, bias=False)
                  (to_out): Sequential(
                    (0): Linear(in_features=1280, out_features=1280, bias=True)
                    (1): Dropout(p=0.0, inplace=False)
                  )
                )
                (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
              )
            )
            (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
          )
          (2): ResBlock(
            (in_layers): Sequential(
              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
              (1): SiLU()
              (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
            (h_upd): Identity()
            (x_upd): Identity()
            (emb_layers): Sequential(
              (0): SiLU()
              (1): Linear(in_features=1280, out_features=1280, bias=True)
            )
            (out_layers): Sequential(
              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
              (1): SiLU()
              (2): Dropout(p=0, inplace=False)
              (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
            (skip_connection): Identity()
          )
        )
        (output_blocks): ModuleList(
          (0): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (1): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (2): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): Upsample(
              (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (3): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)
              (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_v): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=1280, out_features=10240, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=5120, out_features=1280, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=768, out_features=1280, bias=False)
                    (to_v): Linear(in_features=768, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (4): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)
              (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_v): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=1280, out_features=10240, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=5120, out_features=1280, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=768, out_features=1280, bias=False)
                    (to_v): Linear(in_features=768, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (5): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 1920, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(1920, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(1920, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)
              (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_v): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=1280, out_features=10240, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=5120, out_features=1280, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=768, out_features=1280, bias=False)
                    (to_v): Linear(in_features=768, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
            (2): Upsample(
              (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (6): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 1920, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(1920, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=640, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(1920, 640, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 640, eps=1e-06, affine=True)
              (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=640, out_features=640, bias=False)
                    (to_v): Linear(in_features=640, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=640, out_features=5120, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=2560, out_features=640, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=768, out_features=640, bias=False)
                    (to_v): Linear(in_features=768, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (7): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(1280, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=640, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 640, eps=1e-06, affine=True)
              (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=640, out_features=640, bias=False)
                    (to_v): Linear(in_features=640, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=640, out_features=5120, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=2560, out_features=640, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=768, out_features=640, bias=False)
                    (to_v): Linear(in_features=768, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (8): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 960, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(960, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=640, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(960, 640, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 640, eps=1e-06, affine=True)
              (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=640, out_features=640, bias=False)
                    (to_v): Linear(in_features=640, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=640, out_features=5120, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=2560, out_features=640, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=768, out_features=640, bias=False)
                    (to_v): Linear(in_features=768, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
            )
            (2): Upsample(
              (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (9): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 960, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(960, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=320, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 320, eps=1e-06, affine=True)
              (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=320, out_features=320, bias=False)
                    (to_v): Linear(in_features=320, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=320, out_features=2560, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=1280, out_features=320, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=768, out_features=320, bias=False)
                    (to_v): Linear(in_features=768, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (10): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=320, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 320, eps=1e-06, affine=True)
              (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=320, out_features=320, bias=False)
                    (to_v): Linear(in_features=320, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=320, out_features=2560, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=1280, out_features=320, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=768, out_features=320, bias=False)
                    (to_v): Linear(in_features=768, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (11): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=320, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 320, eps=1e-06, affine=True)
              (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=320, out_features=320, bias=False)
                    (to_v): Linear(in_features=320, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=320, out_features=2560, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=1280, out_features=320, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=768, out_features=320, bias=False)
                    (to_v): Linear(in_features=768, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
            )
          )
        )
        (out): Sequential(
          (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
          (1): SiLU()
          (2): Conv2d(320, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
    )
    (trainable_unet): DiffusionWrapper(
      (diffusion_model): UNetModel(
        (time_embed): Sequential(
          (0): Linear(in_features=320, out_features=1280, bias=True)
          (1): SiLU()
          (2): Linear(in_features=1280, out_features=1280, bias=True)
        )
        (input_blocks): ModuleList(
          (0): TimestepEmbedSequential(
            (0): Conv2d(4, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (1): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=320, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Identity()
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 320, eps=1e-06, affine=True)
              (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=320, out_features=320, bias=False)
                    (to_v): Linear(in_features=320, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=320, out_features=2560, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=1280, out_features=320, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=768, out_features=320, bias=False)
                    (to_v): Linear(in_features=768, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (2): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=320, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Identity()
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 320, eps=1e-06, affine=True)
              (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=320, out_features=320, bias=False)
                    (to_v): Linear(in_features=320, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=320, out_features=2560, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=1280, out_features=320, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=768, out_features=320, bias=False)
                    (to_v): Linear(in_features=768, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (3): TimestepEmbedSequential(
            (0): Downsample(
              (op): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
            )
          )
          (4): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(320, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=640, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(320, 640, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 640, eps=1e-06, affine=True)
              (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=640, out_features=640, bias=False)
                    (to_v): Linear(in_features=640, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=640, out_features=5120, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=2560, out_features=640, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=768, out_features=640, bias=False)
                    (to_v): Linear(in_features=768, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (5): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=640, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Identity()
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 640, eps=1e-06, affine=True)
              (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=640, out_features=640, bias=False)
                    (to_v): Linear(in_features=640, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=640, out_features=5120, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=2560, out_features=640, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=768, out_features=640, bias=False)
                    (to_v): Linear(in_features=768, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (6): TimestepEmbedSequential(
            (0): Downsample(
              (op): Conv2d(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
            )
          )
          (7): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(640, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(640, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)
              (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_v): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=1280, out_features=10240, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=5120, out_features=1280, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=768, out_features=1280, bias=False)
                    (to_v): Linear(in_features=768, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (8): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Identity()
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)
              (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_v): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=1280, out_features=10240, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=5120, out_features=1280, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=768, out_features=1280, bias=False)
                    (to_v): Linear(in_features=768, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (9): TimestepEmbedSequential(
            (0): Downsample(
              (op): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
            )
          )
          (10): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Identity()
            )
          )
          (11): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Identity()
            )
          )
        )
        (middle_block): TimestepEmbedSequential(
          (0): ResBlock(
            (in_layers): Sequential(
              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
              (1): SiLU()
              (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
            (h_upd): Identity()
            (x_upd): Identity()
            (emb_layers): Sequential(
              (0): SiLU()
              (1): Linear(in_features=1280, out_features=1280, bias=True)
            )
            (out_layers): Sequential(
              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
              (1): SiLU()
              (2): Dropout(p=0, inplace=False)
              (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
            (skip_connection): Identity()
          )
          (1): SpatialTransformer(
            (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)
            (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
            (transformer_blocks): ModuleList(
              (0): BasicTransformerBlock(
                (attn1): CrossAttention(
                  (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                  (to_k): Linear(in_features=1280, out_features=1280, bias=False)
                  (to_v): Linear(in_features=1280, out_features=1280, bias=False)
                  (to_out): Sequential(
                    (0): Linear(in_features=1280, out_features=1280, bias=True)
                    (1): Dropout(p=0.0, inplace=False)
                  )
                )
                (ff): FeedForward(
                  (net): Sequential(
                    (0): GEGLU(
                      (proj): Linear(in_features=1280, out_features=10240, bias=True)
                    )
                    (1): Dropout(p=0.0, inplace=False)
                    (2): Linear(in_features=5120, out_features=1280, bias=True)
                  )
                )
                (attn2): CrossAttention(
                  (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                  (to_k): Linear(in_features=768, out_features=1280, bias=False)
                  (to_v): Linear(in_features=768, out_features=1280, bias=False)
                  (to_out): Sequential(
                    (0): Linear(in_features=1280, out_features=1280, bias=True)
                    (1): Dropout(p=0.0, inplace=False)
                  )
                )
                (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
              )
            )
            (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
          )
          (2): ResBlock(
            (in_layers): Sequential(
              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
              (1): SiLU()
              (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
            (h_upd): Identity()
            (x_upd): Identity()
            (emb_layers): Sequential(
              (0): SiLU()
              (1): Linear(in_features=1280, out_features=1280, bias=True)
            )
            (out_layers): Sequential(
              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
              (1): SiLU()
              (2): Dropout(p=0, inplace=False)
              (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
            (skip_connection): Identity()
          )
        )
        (output_blocks): ModuleList(
          (0): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (1): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (2): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): Upsample(
              (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (3): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)
              (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_v): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=1280, out_features=10240, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=5120, out_features=1280, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=768, out_features=1280, bias=False)
                    (to_v): Linear(in_features=768, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (4): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)
              (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_v): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=1280, out_features=10240, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=5120, out_features=1280, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=768, out_features=1280, bias=False)
                    (to_v): Linear(in_features=768, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (5): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 1920, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(1920, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=1280, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(1920, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)
              (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_v): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=1280, out_features=10240, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=5120, out_features=1280, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                    (to_k): Linear(in_features=768, out_features=1280, bias=False)
                    (to_v): Linear(in_features=768, out_features=1280, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=1280, out_features=1280, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
            )
            (2): Upsample(
              (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (6): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 1920, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(1920, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=640, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(1920, 640, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 640, eps=1e-06, affine=True)
              (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=640, out_features=640, bias=False)
                    (to_v): Linear(in_features=640, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=640, out_features=5120, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=2560, out_features=640, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=768, out_features=640, bias=False)
                    (to_v): Linear(in_features=768, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (7): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(1280, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=640, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 640, eps=1e-06, affine=True)
              (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=640, out_features=640, bias=False)
                    (to_v): Linear(in_features=640, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=640, out_features=5120, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=2560, out_features=640, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=768, out_features=640, bias=False)
                    (to_v): Linear(in_features=768, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (8): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 960, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(960, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=640, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(960, 640, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 640, eps=1e-06, affine=True)
              (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=640, out_features=640, bias=False)
                    (to_v): Linear(in_features=640, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=640, out_features=5120, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=2560, out_features=640, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=640, out_features=640, bias=False)
                    (to_k): Linear(in_features=768, out_features=640, bias=False)
                    (to_v): Linear(in_features=768, out_features=640, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=640, out_features=640, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
            )
            (2): Upsample(
              (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (9): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 960, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(960, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=320, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 320, eps=1e-06, affine=True)
              (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=320, out_features=320, bias=False)
                    (to_v): Linear(in_features=320, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=320, out_features=2560, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=1280, out_features=320, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=768, out_features=320, bias=False)
                    (to_v): Linear(in_features=768, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (10): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=320, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 320, eps=1e-06, affine=True)
              (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=320, out_features=320, bias=False)
                    (to_v): Linear(in_features=320, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=320, out_features=2560, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=1280, out_features=320, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=768, out_features=320, bias=False)
                    (to_v): Linear(in_features=768, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (11): TimestepEmbedSequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (emb_layers): Sequential(
                (0): SiLU()
                (1): Linear(in_features=1280, out_features=320, bias=True)
              )
              (out_layers): Sequential(
                (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): SpatialTransformer(
              (norm): GroupNorm(32, 320, eps=1e-06, affine=True)
              (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
              (transformer_blocks): ModuleList(
                (0): BasicTransformerBlock(
                  (attn1): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=320, out_features=320, bias=False)
                    (to_v): Linear(in_features=320, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (ff): FeedForward(
                    (net): Sequential(
                      (0): GEGLU(
                        (proj): Linear(in_features=320, out_features=2560, bias=True)
                      )
                      (1): Dropout(p=0.0, inplace=False)
                      (2): Linear(in_features=1280, out_features=320, bias=True)
                    )
                  )
                  (attn2): CrossAttention(
                    (to_q): Linear(in_features=320, out_features=320, bias=False)
                    (to_k): Linear(in_features=768, out_features=320, bias=False)
                    (to_v): Linear(in_features=768, out_features=320, bias=False)
                    (to_out): Sequential(
                      (0): Linear(in_features=320, out_features=320, bias=True)
                      (1): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                  (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                )
              )
              (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
            )
          )
        )
        (out): Sequential(
          (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
          (1): SiLU()
          (2): Conv2d(320, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
    )
    (zero_convs): ModuleList(
      (0): ZeroConv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
      (1): ZeroConv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
      (2): ZeroConv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
      (3): ZeroConv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
      (4): ZeroConv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
      (5): ZeroConv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (box_encoder): EncoderControlNet(
    (out64): Sequential(
      (0): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
    )
    (out32): Sequential(
      (0): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
    )
    (out16): Sequential(
      (0): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
    )
    (conv64): Sequential(
      (0): Conv2d(6, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (5): ReLU(inplace=True)
    )
    (conv32): Sequential(
      (0): Conv2d(320, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (1): ReLU(inplace=True)
    )
    (conv16): Sequential(
      (0): Conv2d(640, 1280, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (1): ReLU(inplace=True)
    )
  )
  (sd_model): LatentDiffusion(
    (model): None
    (first_stage_model): None
  )
  (text_adapter): TextAdapter(
    (fc): Sequential(
      (0): Linear(in_features=768, out_features=768, bias=True)
      (1): GELU()
      (2): Linear(in_features=768, out_features=768, bias=True)
    )
  )
  (neck): FPN(
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(320, 256, kernel_size=(1, 1), stride=(1, 1))
      )
      (1): ConvModule(
        (conv): Conv2d(790, 256, kernel_size=(1, 1), stride=(1, 1))
      )
      (2): ConvModule(
        (conv): Conv2d(1430, 256, kernel_size=(1, 1), stride=(1, 1))
      )
      (3): ConvModule(
        (conv): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (1): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (2): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (3): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
  )
  init_cfg={'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}
  (decode_head): FPNHead(
    input_transform=multiple_select, ignore_index=255, align_corners=False
    (loss_decode): CrossEntropyLoss(avg_non_ignore=False)
    (conv_seg): Conv2d(256, 150, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (scale_heads): ModuleList(
      (0): Sequential(
        (0): ConvModule(
          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (1): Sequential(
        (0): ConvModule(
          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): Upsample()
      )
      (2): Sequential(
        (0): ConvModule(
          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): Upsample()
        (2): ConvModule(
          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): Upsample()
      )
      (3): Sequential(
        (0): ConvModule(
          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): Upsample()
        (2): ConvModule(
          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): Upsample()
        (4): ConvModule(
          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (5): Upsample()
      )
    )
  )
  init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
)
2025-04-22 18:37:00,010 - mmseg - INFO - Loaded 20210 images
/dtu/blackhole/0e/154958/miniconda3/envs/ldm/lib/python3.8/site-packages/torch/utils/data/dataloader.py:487: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
2025-04-22 18:37:06,679 - mmseg - INFO - Loaded 2000 images
2025-04-22 18:37:06,681 - mmseg - INFO - load checkpoint from local path: /work3/s203557/checkpoints/vpd.chkpt
2025-04-22 18:37:08,898 - mmseg - WARNING - The model and loaded state dict do not match exactly

unexpected key in source state_dict: sd_model.lvlb_weights

missing keys in source state_dict: encoder_vq.encoder.conv_in.weight, encoder_vq.encoder.conv_in.bias, encoder_vq.encoder.down.0.block.0.norm1.weight, encoder_vq.encoder.down.0.block.0.norm1.bias, encoder_vq.encoder.down.0.block.0.conv1.weight, encoder_vq.encoder.down.0.block.0.conv1.bias, encoder_vq.encoder.down.0.block.0.norm2.weight, encoder_vq.encoder.down.0.block.0.norm2.bias, encoder_vq.encoder.down.0.block.0.conv2.weight, encoder_vq.encoder.down.0.block.0.conv2.bias, encoder_vq.encoder.down.0.block.1.norm1.weight, encoder_vq.encoder.down.0.block.1.norm1.bias, encoder_vq.encoder.down.0.block.1.conv1.weight, encoder_vq.encoder.down.0.block.1.conv1.bias, encoder_vq.encoder.down.0.block.1.norm2.weight, encoder_vq.encoder.down.0.block.1.norm2.bias, encoder_vq.encoder.down.0.block.1.conv2.weight, encoder_vq.encoder.down.0.block.1.conv2.bias, encoder_vq.encoder.down.0.downsample.conv.weight, encoder_vq.encoder.down.0.downsample.conv.bias, encoder_vq.encoder.down.1.block.0.norm1.weight, encoder_vq.encoder.down.1.block.0.norm1.bias, encoder_vq.encoder.down.1.block.0.conv1.weight, encoder_vq.encoder.down.1.block.0.conv1.bias, encoder_vq.encoder.down.1.block.0.norm2.weight, encoder_vq.encoder.down.1.block.0.norm2.bias, encoder_vq.encoder.down.1.block.0.conv2.weight, encoder_vq.encoder.down.1.block.0.conv2.bias, encoder_vq.encoder.down.1.block.0.nin_shortcut.weight, encoder_vq.encoder.down.1.block.0.nin_shortcut.bias, encoder_vq.encoder.down.1.block.1.norm1.weight, encoder_vq.encoder.down.1.block.1.norm1.bias, encoder_vq.encoder.down.1.block.1.conv1.weight, encoder_vq.encoder.down.1.block.1.conv1.bias, encoder_vq.encoder.down.1.block.1.norm2.weight, encoder_vq.encoder.down.1.block.1.norm2.bias, encoder_vq.encoder.down.1.block.1.conv2.weight, encoder_vq.encoder.down.1.block.1.conv2.bias, encoder_vq.encoder.down.1.downsample.conv.weight, encoder_vq.encoder.down.1.downsample.conv.bias, encoder_vq.encoder.down.2.block.0.norm1.weight, encoder_vq.encoder.down.2.block.0.norm1.bias, encoder_vq.encoder.down.2.block.0.conv1.weight, encoder_vq.encoder.down.2.block.0.conv1.bias, encoder_vq.encoder.down.2.block.0.norm2.weight, encoder_vq.encoder.down.2.block.0.norm2.bias, encoder_vq.encoder.down.2.block.0.conv2.weight, encoder_vq.encoder.down.2.block.0.conv2.bias, encoder_vq.encoder.down.2.block.0.nin_shortcut.weight, encoder_vq.encoder.down.2.block.0.nin_shortcut.bias, encoder_vq.encoder.down.2.block.1.norm1.weight, encoder_vq.encoder.down.2.block.1.norm1.bias, encoder_vq.encoder.down.2.block.1.conv1.weight, encoder_vq.encoder.down.2.block.1.conv1.bias, encoder_vq.encoder.down.2.block.1.norm2.weight, encoder_vq.encoder.down.2.block.1.norm2.bias, encoder_vq.encoder.down.2.block.1.conv2.weight, encoder_vq.encoder.down.2.block.1.conv2.bias, encoder_vq.encoder.down.2.downsample.conv.weight, encoder_vq.encoder.down.2.downsample.conv.bias, encoder_vq.encoder.down.3.block.0.norm1.weight, encoder_vq.encoder.down.3.block.0.norm1.bias, encoder_vq.encoder.down.3.block.0.conv1.weight, encoder_vq.encoder.down.3.block.0.conv1.bias, encoder_vq.encoder.down.3.block.0.norm2.weight, encoder_vq.encoder.down.3.block.0.norm2.bias, encoder_vq.encoder.down.3.block.0.conv2.weight, encoder_vq.encoder.down.3.block.0.conv2.bias, encoder_vq.encoder.down.3.block.1.norm1.weight, encoder_vq.encoder.down.3.block.1.norm1.bias, encoder_vq.encoder.down.3.block.1.conv1.weight, encoder_vq.encoder.down.3.block.1.conv1.bias, encoder_vq.encoder.down.3.block.1.norm2.weight, encoder_vq.encoder.down.3.block.1.norm2.bias, encoder_vq.encoder.down.3.block.1.conv2.weight, encoder_vq.encoder.down.3.block.1.conv2.bias, encoder_vq.encoder.mid.block_1.norm1.weight, encoder_vq.encoder.mid.block_1.norm1.bias, encoder_vq.encoder.mid.block_1.conv1.weight, encoder_vq.encoder.mid.block_1.conv1.bias, encoder_vq.encoder.mid.block_1.norm2.weight, encoder_vq.encoder.mid.block_1.norm2.bias, encoder_vq.encoder.mid.block_1.conv2.weight, encoder_vq.encoder.mid.block_1.conv2.bias, encoder_vq.encoder.mid.attn_1.norm.weight, encoder_vq.encoder.mid.attn_1.norm.bias, encoder_vq.encoder.mid.attn_1.q.weight, encoder_vq.encoder.mid.attn_1.q.bias, encoder_vq.encoder.mid.attn_1.k.weight, encoder_vq.encoder.mid.attn_1.k.bias, encoder_vq.encoder.mid.attn_1.v.weight, encoder_vq.encoder.mid.attn_1.v.bias, encoder_vq.encoder.mid.attn_1.proj_out.weight, encoder_vq.encoder.mid.attn_1.proj_out.bias, encoder_vq.encoder.mid.block_2.norm1.weight, encoder_vq.encoder.mid.block_2.norm1.bias, encoder_vq.encoder.mid.block_2.conv1.weight, encoder_vq.encoder.mid.block_2.conv1.bias, encoder_vq.encoder.mid.block_2.norm2.weight, encoder_vq.encoder.mid.block_2.norm2.bias, encoder_vq.encoder.mid.block_2.conv2.weight, encoder_vq.encoder.mid.block_2.conv2.bias, encoder_vq.encoder.norm_out.weight, encoder_vq.encoder.norm_out.bias, encoder_vq.encoder.conv_out.weight, encoder_vq.encoder.conv_out.bias, encoder_vq.quant_conv.weight, encoder_vq.quant_conv.bias, encoder_vq.post_quant_conv.weight, encoder_vq.post_quant_conv.bias, unet.trainable_unet.diffusion_model.time_embed.0.weight, unet.trainable_unet.diffusion_model.time_embed.0.bias, unet.trainable_unet.diffusion_model.time_embed.2.weight, unet.trainable_unet.diffusion_model.time_embed.2.bias, unet.trainable_unet.diffusion_model.input_blocks.0.0.weight, unet.trainable_unet.diffusion_model.input_blocks.0.0.bias, unet.trainable_unet.diffusion_model.input_blocks.1.0.in_layers.0.weight, unet.trainable_unet.diffusion_model.input_blocks.1.0.in_layers.0.bias, unet.trainable_unet.diffusion_model.input_blocks.1.0.in_layers.2.weight, unet.trainable_unet.diffusion_model.input_blocks.1.0.in_layers.2.bias, unet.trainable_unet.diffusion_model.input_blocks.1.0.emb_layers.1.weight, unet.trainable_unet.diffusion_model.input_blocks.1.0.emb_layers.1.bias, unet.trainable_unet.diffusion_model.input_blocks.1.0.out_layers.0.weight, unet.trainable_unet.diffusion_model.input_blocks.1.0.out_layers.0.bias, unet.trainable_unet.diffusion_model.input_blocks.1.0.out_layers.3.weight, unet.trainable_unet.diffusion_model.input_blocks.1.0.out_layers.3.bias, unet.trainable_unet.diffusion_model.input_blocks.1.1.norm.weight, unet.trainable_unet.diffusion_model.input_blocks.1.1.norm.bias, unet.trainable_unet.diffusion_model.input_blocks.1.1.proj_in.weight, unet.trainable_unet.diffusion_model.input_blocks.1.1.proj_in.bias, unet.trainable_unet.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_q.weight, unet.trainable_unet.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_k.weight, unet.trainable_unet.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_v.weight, unet.trainable_unet.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_out.0.weight, unet.trainable_unet.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_out.0.bias, unet.trainable_unet.diffusion_model.input_blocks.1.1.transformer_blocks.0.ff.net.0.proj.weight, unet.trainable_unet.diffusion_model.input_blocks.1.1.transformer_blocks.0.ff.net.0.proj.bias, unet.trainable_unet.diffusion_model.input_blocks.1.1.transformer_blocks.0.ff.net.2.weight, unet.trainable_unet.diffusion_model.input_blocks.1.1.transformer_blocks.0.ff.net.2.bias, unet.trainable_unet.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_q.weight, unet.trainable_unet.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_k.weight, unet.trainable_unet.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_v.weight, unet.trainable_unet.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_out.0.weight, unet.trainable_unet.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_out.0.bias, unet.trainable_unet.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm1.weight, unet.trainable_unet.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm1.bias, unet.trainable_unet.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm2.weight, unet.trainable_unet.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm2.bias, unet.trainable_unet.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm3.weight, unet.trainable_unet.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm3.bias, unet.trainable_unet.diffusion_model.input_blocks.1.1.proj_out.weight, unet.trainable_unet.diffusion_model.input_blocks.1.1.proj_out.bias, unet.trainable_unet.diffusion_model.input_blocks.2.0.in_layers.0.weight, unet.trainable_unet.diffusion_model.input_blocks.2.0.in_layers.0.bias, unet.trainable_unet.diffusion_model.input_blocks.2.0.in_layers.2.weight, unet.trainable_unet.diffusion_model.input_blocks.2.0.in_layers.2.bias, unet.trainable_unet.diffusion_model.input_blocks.2.0.emb_layers.1.weight, unet.trainable_unet.diffusion_model.input_blocks.2.0.emb_layers.1.bias, unet.trainable_unet.diffusion_model.input_blocks.2.0.out_layers.0.weight, unet.trainable_unet.diffusion_model.input_blocks.2.0.out_layers.0.bias, unet.trainable_unet.diffusion_model.input_blocks.2.0.out_layers.3.weight, unet.trainable_unet.diffusion_model.input_blocks.2.0.out_layers.3.bias, unet.trainable_unet.diffusion_model.input_blocks.2.1.norm.weight, unet.trainable_unet.diffusion_model.input_blocks.2.1.norm.bias, unet.trainable_unet.diffusion_model.input_blocks.2.1.proj_in.weight, unet.trainable_unet.diffusion_model.input_blocks.2.1.proj_in.bias, unet.trainable_unet.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_q.weight, unet.trainable_unet.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_k.weight, unet.trainable_unet.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_v.weight, unet.trainable_unet.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_out.0.weight, unet.trainable_unet.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_out.0.bias, unet.trainable_unet.diffusion_model.input_blocks.2.1.transformer_blocks.0.ff.net.0.proj.weight, unet.trainable_unet.diffusion_model.input_blocks.2.1.transformer_blocks.0.ff.net.0.proj.bias, unet.trainable_unet.diffusion_model.input_blocks.2.1.transformer_blocks.0.ff.net.2.weight, unet.trainable_unet.diffusion_model.input_blocks.2.1.transformer_blocks.0.ff.net.2.bias, unet.trainable_unet.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_q.weight, unet.trainable_unet.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_k.weight, unet.trainable_unet.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_v.weight, unet.trainable_unet.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_out.0.weight, unet.trainable_unet.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_out.0.bias, unet.trainable_unet.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm1.weight, unet.trainable_unet.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm1.bias, unet.trainable_unet.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm2.weight, unet.trainable_unet.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm2.bias, unet.trainable_unet.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm3.weight, unet.trainable_unet.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm3.bias, unet.trainable_unet.diffusion_model.input_blocks.2.1.proj_out.weight, unet.trainable_unet.diffusion_model.input_blocks.2.1.proj_out.bias, unet.trainable_unet.diffusion_model.input_blocks.3.0.op.weight, unet.trainable_unet.diffusion_model.input_blocks.3.0.op.bias, unet.trainable_unet.diffusion_model.input_blocks.4.0.in_layers.0.weight, unet.trainable_unet.diffusion_model.input_blocks.4.0.in_layers.0.bias, unet.trainable_unet.diffusion_model.input_blocks.4.0.in_layers.2.weight, unet.trainable_unet.diffusion_model.input_blocks.4.0.in_layers.2.bias, unet.trainable_unet.diffusion_model.input_blocks.4.0.emb_layers.1.weight, unet.trainable_unet.diffusion_model.input_blocks.4.0.emb_layers.1.bias, unet.trainable_unet.diffusion_model.input_blocks.4.0.out_layers.0.weight, unet.trainable_unet.diffusion_model.input_blocks.4.0.out_layers.0.bias, unet.trainable_unet.diffusion_model.input_blocks.4.0.out_layers.3.weight, unet.trainable_unet.diffusion_model.input_blocks.4.0.out_layers.3.bias, unet.trainable_unet.diffusion_model.input_blocks.4.0.skip_connection.weight, unet.trainable_unet.diffusion_model.input_blocks.4.0.skip_connection.bias, unet.trainable_unet.diffusion_model.input_blocks.4.1.norm.weight, unet.trainable_unet.diffusion_model.input_blocks.4.1.norm.bias, unet.trainable_unet.diffusion_model.input_blocks.4.1.proj_in.weight, unet.trainable_unet.diffusion_model.input_blocks.4.1.proj_in.bias, unet.trainable_unet.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_q.weight, unet.trainable_unet.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_k.weight, unet.trainable_unet.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_v.weight, unet.trainable_unet.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_out.0.weight, unet.trainable_unet.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_out.0.bias, unet.trainable_unet.diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.0.proj.weight, unet.trainable_unet.diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.0.proj.bias, unet.trainable_unet.diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.2.weight, unet.trainable_unet.diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.2.bias, unet.trainable_unet.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_q.weight, unet.trainable_unet.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_k.weight, unet.trainable_unet.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_v.weight, unet.trainable_unet.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_out.0.weight, unet.trainable_unet.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_out.0.bias, unet.trainable_unet.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm1.weight, unet.trainable_unet.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm1.bias, unet.trainable_unet.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm2.weight, unet.trainable_unet.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm2.bias, unet.trainable_unet.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm3.weight, unet.trainable_unet.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm3.bias, unet.trainable_unet.diffusion_model.input_blocks.4.1.proj_out.weight, unet.trainable_unet.diffusion_model.input_blocks.4.1.proj_out.bias, unet.trainable_unet.diffusion_model.input_blocks.5.0.in_layers.0.weight, unet.trainable_unet.diffusion_model.input_blocks.5.0.in_layers.0.bias, unet.trainable_unet.diffusion_model.input_blocks.5.0.in_layers.2.weight, unet.trainable_unet.diffusion_model.input_blocks.5.0.in_layers.2.bias, unet.trainable_unet.diffusion_model.input_blocks.5.0.emb_layers.1.weight, unet.trainable_unet.diffusion_model.input_blocks.5.0.emb_layers.1.bias, unet.trainable_unet.diffusion_model.input_blocks.5.0.out_layers.0.weight, unet.trainable_unet.diffusion_model.input_blocks.5.0.out_layers.0.bias, unet.trainable_unet.diffusion_model.input_blocks.5.0.out_layers.3.weight, unet.trainable_unet.diffusion_model.input_blocks.5.0.out_layers.3.bias, unet.trainable_unet.diffusion_model.input_blocks.5.1.norm.weight, unet.trainable_unet.diffusion_model.input_blocks.5.1.norm.bias, unet.trainable_unet.diffusion_model.input_blocks.5.1.proj_in.weight, unet.trainable_unet.diffusion_model.input_blocks.5.1.proj_in.bias, unet.trainable_unet.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_q.weight, unet.trainable_unet.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_k.weight, unet.trainable_unet.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_v.weight, unet.trainable_unet.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_out.0.weight, unet.trainable_unet.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_out.0.bias, unet.trainable_unet.diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.0.proj.weight, unet.trainable_unet.diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.0.proj.bias, unet.trainable_unet.diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.2.weight, unet.trainable_unet.diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.2.bias, unet.trainable_unet.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_q.weight, unet.trainable_unet.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_k.weight, unet.trainable_unet.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_v.weight, unet.trainable_unet.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_out.0.weight, unet.trainable_unet.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_out.0.bias, unet.trainable_unet.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm1.weight, unet.trainable_unet.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm1.bias, unet.trainable_unet.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm2.weight, unet.trainable_unet.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm2.bias, unet.trainable_unet.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm3.weight, unet.trainable_unet.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm3.bias, unet.trainable_unet.diffusion_model.input_blocks.5.1.proj_out.weight, unet.trainable_unet.diffusion_model.input_blocks.5.1.proj_out.bias, unet.trainable_unet.diffusion_model.input_blocks.6.0.op.weight, unet.trainable_unet.diffusion_model.input_blocks.6.0.op.bias, unet.trainable_unet.diffusion_model.input_blocks.7.0.in_layers.0.weight, unet.trainable_unet.diffusion_model.input_blocks.7.0.in_layers.0.bias, unet.trainable_unet.diffusion_model.input_blocks.7.0.in_layers.2.weight, unet.trainable_unet.diffusion_model.input_blocks.7.0.in_layers.2.bias, unet.trainable_unet.diffusion_model.input_blocks.7.0.emb_layers.1.weight, unet.trainable_unet.diffusion_model.input_blocks.7.0.emb_layers.1.bias, unet.trainable_unet.diffusion_model.input_blocks.7.0.out_layers.0.weight, unet.trainable_unet.diffusion_model.input_blocks.7.0.out_layers.0.bias, unet.trainable_unet.diffusion_model.input_blocks.7.0.out_layers.3.weight, unet.trainable_unet.diffusion_model.input_blocks.7.0.out_layers.3.bias, unet.trainable_unet.diffusion_model.input_blocks.7.0.skip_connection.weight, unet.trainable_unet.diffusion_model.input_blocks.7.0.skip_connection.bias, unet.trainable_unet.diffusion_model.input_blocks.7.1.norm.weight, unet.trainable_unet.diffusion_model.input_blocks.7.1.norm.bias, unet.trainable_unet.diffusion_model.input_blocks.7.1.proj_in.weight, unet.trainable_unet.diffusion_model.input_blocks.7.1.proj_in.bias, unet.trainable_unet.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_q.weight, unet.trainable_unet.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_k.weight, unet.trainable_unet.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_v.weight, unet.trainable_unet.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_out.0.weight, unet.trainable_unet.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_out.0.bias, unet.trainable_unet.diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.0.proj.weight, unet.trainable_unet.diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.0.proj.bias, unet.trainable_unet.diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.2.weight, unet.trainable_unet.diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.2.bias, unet.trainable_unet.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_q.weight, unet.trainable_unet.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_k.weight, unet.trainable_unet.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_v.weight, unet.trainable_unet.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_out.0.weight, unet.trainable_unet.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_out.0.bias, unet.trainable_unet.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm1.weight, unet.trainable_unet.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm1.bias, unet.trainable_unet.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm2.weight, unet.trainable_unet.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm2.bias, unet.trainable_unet.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm3.weight, unet.trainable_unet.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm3.bias, unet.trainable_unet.diffusion_model.input_blocks.7.1.proj_out.weight, unet.trainable_unet.diffusion_model.input_blocks.7.1.proj_out.bias, unet.trainable_unet.diffusion_model.input_blocks.8.0.in_layers.0.weight, unet.trainable_unet.diffusion_model.input_blocks.8.0.in_layers.0.bias, unet.trainable_unet.diffusion_model.input_blocks.8.0.in_layers.2.weight, unet.trainable_unet.diffusion_model.input_blocks.8.0.in_layers.2.bias, unet.trainable_unet.diffusion_model.input_blocks.8.0.emb_layers.1.weight, unet.trainable_unet.diffusion_model.input_blocks.8.0.emb_layers.1.bias, unet.trainable_unet.diffusion_model.input_blocks.8.0.out_layers.0.weight, unet.trainable_unet.diffusion_model.input_blocks.8.0.out_layers.0.bias, unet.trainable_unet.diffusion_model.input_blocks.8.0.out_layers.3.weight, unet.trainable_unet.diffusion_model.input_blocks.8.0.out_layers.3.bias, unet.trainable_unet.diffusion_model.input_blocks.8.1.norm.weight, unet.trainable_unet.diffusion_model.input_blocks.8.1.norm.bias, unet.trainable_unet.diffusion_model.input_blocks.8.1.proj_in.weight, unet.trainable_unet.diffusion_model.input_blocks.8.1.proj_in.bias, unet.trainable_unet.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_q.weight, unet.trainable_unet.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_k.weight, unet.trainable_unet.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_v.weight, unet.trainable_unet.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_out.0.weight, unet.trainable_unet.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_out.0.bias, unet.trainable_unet.diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.0.proj.weight, unet.trainable_unet.diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.0.proj.bias, unet.trainable_unet.diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.2.weight, unet.trainable_unet.diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.2.bias, unet.trainable_unet.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_q.weight, unet.trainable_unet.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_k.weight, unet.trainable_unet.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_v.weight, unet.trainable_unet.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_out.0.weight, unet.trainable_unet.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_out.0.bias, unet.trainable_unet.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm1.weight, unet.trainable_unet.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm1.bias, unet.trainable_unet.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm2.weight, unet.trainable_unet.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm2.bias, unet.trainable_unet.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm3.weight, unet.trainable_unet.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm3.bias, unet.trainable_unet.diffusion_model.input_blocks.8.1.proj_out.weight, unet.trainable_unet.diffusion_model.input_blocks.8.1.proj_out.bias, unet.trainable_unet.diffusion_model.input_blocks.9.0.op.weight, unet.trainable_unet.diffusion_model.input_blocks.9.0.op.bias, unet.trainable_unet.diffusion_model.input_blocks.10.0.in_layers.0.weight, unet.trainable_unet.diffusion_model.input_blocks.10.0.in_layers.0.bias, unet.trainable_unet.diffusion_model.input_blocks.10.0.in_layers.2.weight, unet.trainable_unet.diffusion_model.input_blocks.10.0.in_layers.2.bias, unet.trainable_unet.diffusion_model.input_blocks.10.0.emb_layers.1.weight, unet.trainable_unet.diffusion_model.input_blocks.10.0.emb_layers.1.bias, unet.trainable_unet.diffusion_model.input_blocks.10.0.out_layers.0.weight, unet.trainable_unet.diffusion_model.input_blocks.10.0.out_layers.0.bias, unet.trainable_unet.diffusion_model.input_blocks.10.0.out_layers.3.weight, unet.trainable_unet.diffusion_model.input_blocks.10.0.out_layers.3.bias, unet.trainable_unet.diffusion_model.input_blocks.11.0.in_layers.0.weight, unet.trainable_unet.diffusion_model.input_blocks.11.0.in_layers.0.bias, unet.trainable_unet.diffusion_model.input_blocks.11.0.in_layers.2.weight, unet.trainable_unet.diffusion_model.input_blocks.11.0.in_layers.2.bias, unet.trainable_unet.diffusion_model.input_blocks.11.0.emb_layers.1.weight, unet.trainable_unet.diffusion_model.input_blocks.11.0.emb_layers.1.bias, unet.trainable_unet.diffusion_model.input_blocks.11.0.out_layers.0.weight, unet.trainable_unet.diffusion_model.input_blocks.11.0.out_layers.0.bias, unet.trainable_unet.diffusion_model.input_blocks.11.0.out_layers.3.weight, unet.trainable_unet.diffusion_model.input_blocks.11.0.out_layers.3.bias, unet.trainable_unet.diffusion_model.middle_block.0.in_layers.0.weight, unet.trainable_unet.diffusion_model.middle_block.0.in_layers.0.bias, unet.trainable_unet.diffusion_model.middle_block.0.in_layers.2.weight, unet.trainable_unet.diffusion_model.middle_block.0.in_layers.2.bias, unet.trainable_unet.diffusion_model.middle_block.0.emb_layers.1.weight, unet.trainable_unet.diffusion_model.middle_block.0.emb_layers.1.bias, unet.trainable_unet.diffusion_model.middle_block.0.out_layers.0.weight, unet.trainable_unet.diffusion_model.middle_block.0.out_layers.0.bias, unet.trainable_unet.diffusion_model.middle_block.0.out_layers.3.weight, unet.trainable_unet.diffusion_model.middle_block.0.out_layers.3.bias, unet.trainable_unet.diffusion_model.middle_block.1.norm.weight, unet.trainable_unet.diffusion_model.middle_block.1.norm.bias, unet.trainable_unet.diffusion_model.middle_block.1.proj_in.weight, unet.trainable_unet.diffusion_model.middle_block.1.proj_in.bias, unet.trainable_unet.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_q.weight, unet.trainable_unet.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_k.weight, unet.trainable_unet.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_v.weight, unet.trainable_unet.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_out.0.weight, unet.trainable_unet.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_out.0.bias, unet.trainable_unet.diffusion_model.middle_block.1.transformer_blocks.0.ff.net.0.proj.weight, unet.trainable_unet.diffusion_model.middle_block.1.transformer_blocks.0.ff.net.0.proj.bias, unet.trainable_unet.diffusion_model.middle_block.1.transformer_blocks.0.ff.net.2.weight, unet.trainable_unet.diffusion_model.middle_block.1.transformer_blocks.0.ff.net.2.bias, unet.trainable_unet.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_q.weight, unet.trainable_unet.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_k.weight, unet.trainable_unet.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_v.weight, unet.trainable_unet.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_out.0.weight, unet.trainable_unet.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_out.0.bias, unet.trainable_unet.diffusion_model.middle_block.1.transformer_blocks.0.norm1.weight, unet.trainable_unet.diffusion_model.middle_block.1.transformer_blocks.0.norm1.bias, unet.trainable_unet.diffusion_model.middle_block.1.transformer_blocks.0.norm2.weight, unet.trainable_unet.diffusion_model.middle_block.1.transformer_blocks.0.norm2.bias, unet.trainable_unet.diffusion_model.middle_block.1.transformer_blocks.0.norm3.weight, unet.trainable_unet.diffusion_model.middle_block.1.transformer_blocks.0.norm3.bias, unet.trainable_unet.diffusion_model.middle_block.1.proj_out.weight, unet.trainable_unet.diffusion_model.middle_block.1.proj_out.bias, unet.trainable_unet.diffusion_model.middle_block.2.in_layers.0.weight, unet.trainable_unet.diffusion_model.middle_block.2.in_layers.0.bias, unet.trainable_unet.diffusion_model.middle_block.2.in_layers.2.weight, unet.trainable_unet.diffusion_model.middle_block.2.in_layers.2.bias, unet.trainable_unet.diffusion_model.middle_block.2.emb_layers.1.weight, unet.trainable_unet.diffusion_model.middle_block.2.emb_layers.1.bias, unet.trainable_unet.diffusion_model.middle_block.2.out_layers.0.weight, unet.trainable_unet.diffusion_model.middle_block.2.out_layers.0.bias, unet.trainable_unet.diffusion_model.middle_block.2.out_layers.3.weight, unet.trainable_unet.diffusion_model.middle_block.2.out_layers.3.bias, unet.trainable_unet.diffusion_model.output_blocks.0.0.in_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.0.0.in_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.0.0.in_layers.2.weight, unet.trainable_unet.diffusion_model.output_blocks.0.0.in_layers.2.bias, unet.trainable_unet.diffusion_model.output_blocks.0.0.emb_layers.1.weight, unet.trainable_unet.diffusion_model.output_blocks.0.0.emb_layers.1.bias, unet.trainable_unet.diffusion_model.output_blocks.0.0.out_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.0.0.out_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.0.0.out_layers.3.weight, unet.trainable_unet.diffusion_model.output_blocks.0.0.out_layers.3.bias, unet.trainable_unet.diffusion_model.output_blocks.0.0.skip_connection.weight, unet.trainable_unet.diffusion_model.output_blocks.0.0.skip_connection.bias, unet.trainable_unet.diffusion_model.output_blocks.1.0.in_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.1.0.in_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.1.0.in_layers.2.weight, unet.trainable_unet.diffusion_model.output_blocks.1.0.in_layers.2.bias, unet.trainable_unet.diffusion_model.output_blocks.1.0.emb_layers.1.weight, unet.trainable_unet.diffusion_model.output_blocks.1.0.emb_layers.1.bias, unet.trainable_unet.diffusion_model.output_blocks.1.0.out_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.1.0.out_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.1.0.out_layers.3.weight, unet.trainable_unet.diffusion_model.output_blocks.1.0.out_layers.3.bias, unet.trainable_unet.diffusion_model.output_blocks.1.0.skip_connection.weight, unet.trainable_unet.diffusion_model.output_blocks.1.0.skip_connection.bias, unet.trainable_unet.diffusion_model.output_blocks.2.0.in_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.2.0.in_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.2.0.in_layers.2.weight, unet.trainable_unet.diffusion_model.output_blocks.2.0.in_layers.2.bias, unet.trainable_unet.diffusion_model.output_blocks.2.0.emb_layers.1.weight, unet.trainable_unet.diffusion_model.output_blocks.2.0.emb_layers.1.bias, unet.trainable_unet.diffusion_model.output_blocks.2.0.out_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.2.0.out_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.2.0.out_layers.3.weight, unet.trainable_unet.diffusion_model.output_blocks.2.0.out_layers.3.bias, unet.trainable_unet.diffusion_model.output_blocks.2.0.skip_connection.weight, unet.trainable_unet.diffusion_model.output_blocks.2.0.skip_connection.bias, unet.trainable_unet.diffusion_model.output_blocks.2.1.conv.weight, unet.trainable_unet.diffusion_model.output_blocks.2.1.conv.bias, unet.trainable_unet.diffusion_model.output_blocks.3.0.in_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.3.0.in_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.3.0.in_layers.2.weight, unet.trainable_unet.diffusion_model.output_blocks.3.0.in_layers.2.bias, unet.trainable_unet.diffusion_model.output_blocks.3.0.emb_layers.1.weight, unet.trainable_unet.diffusion_model.output_blocks.3.0.emb_layers.1.bias, unet.trainable_unet.diffusion_model.output_blocks.3.0.out_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.3.0.out_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.3.0.out_layers.3.weight, unet.trainable_unet.diffusion_model.output_blocks.3.0.out_layers.3.bias, unet.trainable_unet.diffusion_model.output_blocks.3.0.skip_connection.weight, unet.trainable_unet.diffusion_model.output_blocks.3.0.skip_connection.bias, unet.trainable_unet.diffusion_model.output_blocks.3.1.norm.weight, unet.trainable_unet.diffusion_model.output_blocks.3.1.norm.bias, unet.trainable_unet.diffusion_model.output_blocks.3.1.proj_in.weight, unet.trainable_unet.diffusion_model.output_blocks.3.1.proj_in.bias, unet.trainable_unet.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_q.weight, unet.trainable_unet.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_k.weight, unet.trainable_unet.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_v.weight, unet.trainable_unet.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_out.0.weight, unet.trainable_unet.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_out.0.bias, unet.trainable_unet.diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.0.proj.weight, unet.trainable_unet.diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.0.proj.bias, unet.trainable_unet.diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.2.weight, unet.trainable_unet.diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.2.bias, unet.trainable_unet.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_q.weight, unet.trainable_unet.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_k.weight, unet.trainable_unet.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_v.weight, unet.trainable_unet.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_out.0.weight, unet.trainable_unet.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_out.0.bias, unet.trainable_unet.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm1.weight, unet.trainable_unet.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm1.bias, unet.trainable_unet.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm2.weight, unet.trainable_unet.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm2.bias, unet.trainable_unet.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm3.weight, unet.trainable_unet.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm3.bias, unet.trainable_unet.diffusion_model.output_blocks.3.1.proj_out.weight, unet.trainable_unet.diffusion_model.output_blocks.3.1.proj_out.bias, unet.trainable_unet.diffusion_model.output_blocks.4.0.in_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.4.0.in_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.4.0.in_layers.2.weight, unet.trainable_unet.diffusion_model.output_blocks.4.0.in_layers.2.bias, unet.trainable_unet.diffusion_model.output_blocks.4.0.emb_layers.1.weight, unet.trainable_unet.diffusion_model.output_blocks.4.0.emb_layers.1.bias, unet.trainable_unet.diffusion_model.output_blocks.4.0.out_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.4.0.out_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.4.0.out_layers.3.weight, unet.trainable_unet.diffusion_model.output_blocks.4.0.out_layers.3.bias, unet.trainable_unet.diffusion_model.output_blocks.4.0.skip_connection.weight, unet.trainable_unet.diffusion_model.output_blocks.4.0.skip_connection.bias, unet.trainable_unet.diffusion_model.output_blocks.4.1.norm.weight, unet.trainable_unet.diffusion_model.output_blocks.4.1.norm.bias, unet.trainable_unet.diffusion_model.output_blocks.4.1.proj_in.weight, unet.trainable_unet.diffusion_model.output_blocks.4.1.proj_in.bias, unet.trainable_unet.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_q.weight, unet.trainable_unet.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_k.weight, unet.trainable_unet.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_v.weight, unet.trainable_unet.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_out.0.weight, unet.trainable_unet.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_out.0.bias, unet.trainable_unet.diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.0.proj.weight, unet.trainable_unet.diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.0.proj.bias, unet.trainable_unet.diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.2.weight, unet.trainable_unet.diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.2.bias, unet.trainable_unet.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_q.weight, unet.trainable_unet.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_k.weight, unet.trainable_unet.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_v.weight, unet.trainable_unet.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_out.0.weight, unet.trainable_unet.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_out.0.bias, unet.trainable_unet.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm1.weight, unet.trainable_unet.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm1.bias, unet.trainable_unet.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm2.weight, unet.trainable_unet.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm2.bias, unet.trainable_unet.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm3.weight, unet.trainable_unet.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm3.bias, unet.trainable_unet.diffusion_model.output_blocks.4.1.proj_out.weight, unet.trainable_unet.diffusion_model.output_blocks.4.1.proj_out.bias, unet.trainable_unet.diffusion_model.output_blocks.5.0.in_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.5.0.in_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.5.0.in_layers.2.weight, unet.trainable_unet.diffusion_model.output_blocks.5.0.in_layers.2.bias, unet.trainable_unet.diffusion_model.output_blocks.5.0.emb_layers.1.weight, unet.trainable_unet.diffusion_model.output_blocks.5.0.emb_layers.1.bias, unet.trainable_unet.diffusion_model.output_blocks.5.0.out_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.5.0.out_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.5.0.out_layers.3.weight, unet.trainable_unet.diffusion_model.output_blocks.5.0.out_layers.3.bias, unet.trainable_unet.diffusion_model.output_blocks.5.0.skip_connection.weight, unet.trainable_unet.diffusion_model.output_blocks.5.0.skip_connection.bias, unet.trainable_unet.diffusion_model.output_blocks.5.1.norm.weight, unet.trainable_unet.diffusion_model.output_blocks.5.1.norm.bias, unet.trainable_unet.diffusion_model.output_blocks.5.1.proj_in.weight, unet.trainable_unet.diffusion_model.output_blocks.5.1.proj_in.bias, unet.trainable_unet.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_q.weight, unet.trainable_unet.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_k.weight, unet.trainable_unet.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_v.weight, unet.trainable_unet.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_out.0.weight, unet.trainable_unet.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_out.0.bias, unet.trainable_unet.diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.0.proj.weight, unet.trainable_unet.diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.0.proj.bias, unet.trainable_unet.diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.2.weight, unet.trainable_unet.diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.2.bias, unet.trainable_unet.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_q.weight, unet.trainable_unet.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_k.weight, unet.trainable_unet.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_v.weight, unet.trainable_unet.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_out.0.weight, unet.trainable_unet.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_out.0.bias, unet.trainable_unet.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm1.weight, unet.trainable_unet.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm1.bias, unet.trainable_unet.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm2.weight, unet.trainable_unet.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm2.bias, unet.trainable_unet.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm3.weight, unet.trainable_unet.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm3.bias, unet.trainable_unet.diffusion_model.output_blocks.5.1.proj_out.weight, unet.trainable_unet.diffusion_model.output_blocks.5.1.proj_out.bias, unet.trainable_unet.diffusion_model.output_blocks.5.2.conv.weight, unet.trainable_unet.diffusion_model.output_blocks.5.2.conv.bias, unet.trainable_unet.diffusion_model.output_blocks.6.0.in_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.6.0.in_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.6.0.in_layers.2.weight, unet.trainable_unet.diffusion_model.output_blocks.6.0.in_layers.2.bias, unet.trainable_unet.diffusion_model.output_blocks.6.0.emb_layers.1.weight, unet.trainable_unet.diffusion_model.output_blocks.6.0.emb_layers.1.bias, unet.trainable_unet.diffusion_model.output_blocks.6.0.out_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.6.0.out_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.6.0.out_layers.3.weight, unet.trainable_unet.diffusion_model.output_blocks.6.0.out_layers.3.bias, unet.trainable_unet.diffusion_model.output_blocks.6.0.skip_connection.weight, unet.trainable_unet.diffusion_model.output_blocks.6.0.skip_connection.bias, unet.trainable_unet.diffusion_model.output_blocks.6.1.norm.weight, unet.trainable_unet.diffusion_model.output_blocks.6.1.norm.bias, unet.trainable_unet.diffusion_model.output_blocks.6.1.proj_in.weight, unet.trainable_unet.diffusion_model.output_blocks.6.1.proj_in.bias, unet.trainable_unet.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_q.weight, unet.trainable_unet.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_k.weight, unet.trainable_unet.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_v.weight, unet.trainable_unet.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_out.0.weight, unet.trainable_unet.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_out.0.bias, unet.trainable_unet.diffusion_model.output_blocks.6.1.transformer_blocks.0.ff.net.0.proj.weight, unet.trainable_unet.diffusion_model.output_blocks.6.1.transformer_blocks.0.ff.net.0.proj.bias, unet.trainable_unet.diffusion_model.output_blocks.6.1.transformer_blocks.0.ff.net.2.weight, unet.trainable_unet.diffusion_model.output_blocks.6.1.transformer_blocks.0.ff.net.2.bias, unet.trainable_unet.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_q.weight, unet.trainable_unet.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_k.weight, unet.trainable_unet.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_v.weight, unet.trainable_unet.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_out.0.weight, unet.trainable_unet.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_out.0.bias, unet.trainable_unet.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm1.weight, unet.trainable_unet.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm1.bias, unet.trainable_unet.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm2.weight, unet.trainable_unet.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm2.bias, unet.trainable_unet.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm3.weight, unet.trainable_unet.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm3.bias, unet.trainable_unet.diffusion_model.output_blocks.6.1.proj_out.weight, unet.trainable_unet.diffusion_model.output_blocks.6.1.proj_out.bias, unet.trainable_unet.diffusion_model.output_blocks.7.0.in_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.7.0.in_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.7.0.in_layers.2.weight, unet.trainable_unet.diffusion_model.output_blocks.7.0.in_layers.2.bias, unet.trainable_unet.diffusion_model.output_blocks.7.0.emb_layers.1.weight, unet.trainable_unet.diffusion_model.output_blocks.7.0.emb_layers.1.bias, unet.trainable_unet.diffusion_model.output_blocks.7.0.out_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.7.0.out_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.7.0.out_layers.3.weight, unet.trainable_unet.diffusion_model.output_blocks.7.0.out_layers.3.bias, unet.trainable_unet.diffusion_model.output_blocks.7.0.skip_connection.weight, unet.trainable_unet.diffusion_model.output_blocks.7.0.skip_connection.bias, unet.trainable_unet.diffusion_model.output_blocks.7.1.norm.weight, unet.trainable_unet.diffusion_model.output_blocks.7.1.norm.bias, unet.trainable_unet.diffusion_model.output_blocks.7.1.proj_in.weight, unet.trainable_unet.diffusion_model.output_blocks.7.1.proj_in.bias, unet.trainable_unet.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_q.weight, unet.trainable_unet.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_k.weight, unet.trainable_unet.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_v.weight, unet.trainable_unet.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_out.0.weight, unet.trainable_unet.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_out.0.bias, unet.trainable_unet.diffusion_model.output_blocks.7.1.transformer_blocks.0.ff.net.0.proj.weight, unet.trainable_unet.diffusion_model.output_blocks.7.1.transformer_blocks.0.ff.net.0.proj.bias, unet.trainable_unet.diffusion_model.output_blocks.7.1.transformer_blocks.0.ff.net.2.weight, unet.trainable_unet.diffusion_model.output_blocks.7.1.transformer_blocks.0.ff.net.2.bias, unet.trainable_unet.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_q.weight, unet.trainable_unet.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_k.weight, unet.trainable_unet.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_v.weight, unet.trainable_unet.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_out.0.weight, unet.trainable_unet.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_out.0.bias, unet.trainable_unet.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm1.weight, unet.trainable_unet.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm1.bias, unet.trainable_unet.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm2.weight, unet.trainable_unet.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm2.bias, unet.trainable_unet.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm3.weight, unet.trainable_unet.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm3.bias, unet.trainable_unet.diffusion_model.output_blocks.7.1.proj_out.weight, unet.trainable_unet.diffusion_model.output_blocks.7.1.proj_out.bias, unet.trainable_unet.diffusion_model.output_blocks.8.0.in_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.8.0.in_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.8.0.in_layers.2.weight, unet.trainable_unet.diffusion_model.output_blocks.8.0.in_layers.2.bias, unet.trainable_unet.diffusion_model.output_blocks.8.0.emb_layers.1.weight, unet.trainable_unet.diffusion_model.output_blocks.8.0.emb_layers.1.bias, unet.trainable_unet.diffusion_model.output_blocks.8.0.out_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.8.0.out_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.8.0.out_layers.3.weight, unet.trainable_unet.diffusion_model.output_blocks.8.0.out_layers.3.bias, unet.trainable_unet.diffusion_model.output_blocks.8.0.skip_connection.weight, unet.trainable_unet.diffusion_model.output_blocks.8.0.skip_connection.bias, unet.trainable_unet.diffusion_model.output_blocks.8.1.norm.weight, unet.trainable_unet.diffusion_model.output_blocks.8.1.norm.bias, unet.trainable_unet.diffusion_model.output_blocks.8.1.proj_in.weight, unet.trainable_unet.diffusion_model.output_blocks.8.1.proj_in.bias, unet.trainable_unet.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_q.weight, unet.trainable_unet.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_k.weight, unet.trainable_unet.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_v.weight, unet.trainable_unet.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_out.0.weight, unet.trainable_unet.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_out.0.bias, unet.trainable_unet.diffusion_model.output_blocks.8.1.transformer_blocks.0.ff.net.0.proj.weight, unet.trainable_unet.diffusion_model.output_blocks.8.1.transformer_blocks.0.ff.net.0.proj.bias, unet.trainable_unet.diffusion_model.output_blocks.8.1.transformer_blocks.0.ff.net.2.weight, unet.trainable_unet.diffusion_model.output_blocks.8.1.transformer_blocks.0.ff.net.2.bias, unet.trainable_unet.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_q.weight, unet.trainable_unet.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_k.weight, unet.trainable_unet.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_v.weight, unet.trainable_unet.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_out.0.weight, unet.trainable_unet.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_out.0.bias, unet.trainable_unet.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm1.weight, unet.trainable_unet.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm1.bias, unet.trainable_unet.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm2.weight, unet.trainable_unet.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm2.bias, unet.trainable_unet.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm3.weight, unet.trainable_unet.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm3.bias, unet.trainable_unet.diffusion_model.output_blocks.8.1.proj_out.weight, unet.trainable_unet.diffusion_model.output_blocks.8.1.proj_out.bias, unet.trainable_unet.diffusion_model.output_blocks.8.2.conv.weight, unet.trainable_unet.diffusion_model.output_blocks.8.2.conv.bias, unet.trainable_unet.diffusion_model.output_blocks.9.0.in_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.9.0.in_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.9.0.in_layers.2.weight, unet.trainable_unet.diffusion_model.output_blocks.9.0.in_layers.2.bias, unet.trainable_unet.diffusion_model.output_blocks.9.0.emb_layers.1.weight, unet.trainable_unet.diffusion_model.output_blocks.9.0.emb_layers.1.bias, unet.trainable_unet.diffusion_model.output_blocks.9.0.out_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.9.0.out_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.9.0.out_layers.3.weight, unet.trainable_unet.diffusion_model.output_blocks.9.0.out_layers.3.bias, unet.trainable_unet.diffusion_model.output_blocks.9.0.skip_connection.weight, unet.trainable_unet.diffusion_model.output_blocks.9.0.skip_connection.bias, unet.trainable_unet.diffusion_model.output_blocks.9.1.norm.weight, unet.trainable_unet.diffusion_model.output_blocks.9.1.norm.bias, unet.trainable_unet.diffusion_model.output_blocks.9.1.proj_in.weight, unet.trainable_unet.diffusion_model.output_blocks.9.1.proj_in.bias, unet.trainable_unet.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_q.weight, unet.trainable_unet.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_k.weight, unet.trainable_unet.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_v.weight, unet.trainable_unet.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_out.0.weight, unet.trainable_unet.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_out.0.bias, unet.trainable_unet.diffusion_model.output_blocks.9.1.transformer_blocks.0.ff.net.0.proj.weight, unet.trainable_unet.diffusion_model.output_blocks.9.1.transformer_blocks.0.ff.net.0.proj.bias, unet.trainable_unet.diffusion_model.output_blocks.9.1.transformer_blocks.0.ff.net.2.weight, unet.trainable_unet.diffusion_model.output_blocks.9.1.transformer_blocks.0.ff.net.2.bias, unet.trainable_unet.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_q.weight, unet.trainable_unet.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_k.weight, unet.trainable_unet.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_v.weight, unet.trainable_unet.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_out.0.weight, unet.trainable_unet.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_out.0.bias, unet.trainable_unet.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm1.weight, unet.trainable_unet.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm1.bias, unet.trainable_unet.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm2.weight, unet.trainable_unet.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm2.bias, unet.trainable_unet.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm3.weight, unet.trainable_unet.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm3.bias, unet.trainable_unet.diffusion_model.output_blocks.9.1.proj_out.weight, unet.trainable_unet.diffusion_model.output_blocks.9.1.proj_out.bias, unet.trainable_unet.diffusion_model.output_blocks.10.0.in_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.10.0.in_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.10.0.in_layers.2.weight, unet.trainable_unet.diffusion_model.output_blocks.10.0.in_layers.2.bias, unet.trainable_unet.diffusion_model.output_blocks.10.0.emb_layers.1.weight, unet.trainable_unet.diffusion_model.output_blocks.10.0.emb_layers.1.bias, unet.trainable_unet.diffusion_model.output_blocks.10.0.out_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.10.0.out_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.10.0.out_layers.3.weight, unet.trainable_unet.diffusion_model.output_blocks.10.0.out_layers.3.bias, unet.trainable_unet.diffusion_model.output_blocks.10.0.skip_connection.weight, unet.trainable_unet.diffusion_model.output_blocks.10.0.skip_connection.bias, unet.trainable_unet.diffusion_model.output_blocks.10.1.norm.weight, unet.trainable_unet.diffusion_model.output_blocks.10.1.norm.bias, unet.trainable_unet.diffusion_model.output_blocks.10.1.proj_in.weight, unet.trainable_unet.diffusion_model.output_blocks.10.1.proj_in.bias, unet.trainable_unet.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_q.weight, unet.trainable_unet.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_k.weight, unet.trainable_unet.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_v.weight, unet.trainable_unet.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_out.0.weight, unet.trainable_unet.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_out.0.bias, unet.trainable_unet.diffusion_model.output_blocks.10.1.transformer_blocks.0.ff.net.0.proj.weight, unet.trainable_unet.diffusion_model.output_blocks.10.1.transformer_blocks.0.ff.net.0.proj.bias, unet.trainable_unet.diffusion_model.output_blocks.10.1.transformer_blocks.0.ff.net.2.weight, unet.trainable_unet.diffusion_model.output_blocks.10.1.transformer_blocks.0.ff.net.2.bias, unet.trainable_unet.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_q.weight, unet.trainable_unet.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_k.weight, unet.trainable_unet.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_v.weight, unet.trainable_unet.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_out.0.weight, unet.trainable_unet.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_out.0.bias, unet.trainable_unet.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm1.weight, unet.trainable_unet.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm1.bias, unet.trainable_unet.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm2.weight, unet.trainable_unet.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm2.bias, unet.trainable_unet.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm3.weight, unet.trainable_unet.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm3.bias, unet.trainable_unet.diffusion_model.output_blocks.10.1.proj_out.weight, unet.trainable_unet.diffusion_model.output_blocks.10.1.proj_out.bias, unet.trainable_unet.diffusion_model.output_blocks.11.0.in_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.11.0.in_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.11.0.in_layers.2.weight, unet.trainable_unet.diffusion_model.output_blocks.11.0.in_layers.2.bias, unet.trainable_unet.diffusion_model.output_blocks.11.0.emb_layers.1.weight, unet.trainable_unet.diffusion_model.output_blocks.11.0.emb_layers.1.bias, unet.trainable_unet.diffusion_model.output_blocks.11.0.out_layers.0.weight, unet.trainable_unet.diffusion_model.output_blocks.11.0.out_layers.0.bias, unet.trainable_unet.diffusion_model.output_blocks.11.0.out_layers.3.weight, unet.trainable_unet.diffusion_model.output_blocks.11.0.out_layers.3.bias, unet.trainable_unet.diffusion_model.output_blocks.11.0.skip_connection.weight, unet.trainable_unet.diffusion_model.output_blocks.11.0.skip_connection.bias, unet.trainable_unet.diffusion_model.output_blocks.11.1.norm.weight, unet.trainable_unet.diffusion_model.output_blocks.11.1.norm.bias, unet.trainable_unet.diffusion_model.output_blocks.11.1.proj_in.weight, unet.trainable_unet.diffusion_model.output_blocks.11.1.proj_in.bias, unet.trainable_unet.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_q.weight, unet.trainable_unet.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_k.weight, unet.trainable_unet.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_v.weight, unet.trainable_unet.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_out.0.weight, unet.trainable_unet.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_out.0.bias, unet.trainable_unet.diffusion_model.output_blocks.11.1.transformer_blocks.0.ff.net.0.proj.weight, unet.trainable_unet.diffusion_model.output_blocks.11.1.transformer_blocks.0.ff.net.0.proj.bias, unet.trainable_unet.diffusion_model.output_blocks.11.1.transformer_blocks.0.ff.net.2.weight, unet.trainable_unet.diffusion_model.output_blocks.11.1.transformer_blocks.0.ff.net.2.bias, unet.trainable_unet.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_q.weight, unet.trainable_unet.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_k.weight, unet.trainable_unet.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_v.weight, unet.trainable_unet.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_out.0.weight, unet.trainable_unet.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_out.0.bias, unet.trainable_unet.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm1.weight, unet.trainable_unet.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm1.bias, unet.trainable_unet.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm2.weight, unet.trainable_unet.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm2.bias, unet.trainable_unet.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm3.weight, unet.trainable_unet.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm3.bias, unet.trainable_unet.diffusion_model.output_blocks.11.1.proj_out.weight, unet.trainable_unet.diffusion_model.output_blocks.11.1.proj_out.bias, unet.trainable_unet.diffusion_model.out.0.weight, unet.trainable_unet.diffusion_model.out.0.bias, unet.trainable_unet.diffusion_model.out.2.weight, unet.trainable_unet.diffusion_model.out.2.bias, unet.zero_convs.0.weight, unet.zero_convs.0.bias, unet.zero_convs.1.weight, unet.zero_convs.1.bias, unet.zero_convs.2.weight, unet.zero_convs.2.bias, unet.zero_convs.3.weight, unet.zero_convs.3.bias, unet.zero_convs.4.weight, unet.zero_convs.4.bias, unet.zero_convs.5.weight, unet.zero_convs.5.bias, box_encoder.out64.0.weight, box_encoder.out64.0.bias, box_encoder.out32.0.weight, box_encoder.out32.0.bias, box_encoder.out16.0.weight, box_encoder.out16.0.bias, box_encoder.conv64.0.weight, box_encoder.conv64.0.bias, box_encoder.conv64.2.weight, box_encoder.conv64.2.bias, box_encoder.conv64.4.weight, box_encoder.conv64.4.bias, box_encoder.conv32.0.weight, box_encoder.conv32.0.bias, box_encoder.conv16.0.weight, box_encoder.conv16.0.bias

2025-04-22 18:37:08,912 - mmseg - INFO - Start running, host: s203557@n-62-18-13, work_dir: /work3/s203557/experiments/control_net_vpd
2025-04-22 18:37:08,912 - mmseg - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(NORMAL      ) TrainVisualizeHook                 
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
2025-04-22 18:37:08,912 - mmseg - INFO - workflow: [('train', 1)], max: 40000 iters
2025-04-22 18:37:08,913 - mmseg - INFO - Checkpoints will be saved to /work3/s203557/experiments/control_net_vpd by HardDiskBackend.
2025-04-22 18:37:40,000 - mmseg - INFO - Iter [50/40000]	lr: 2.610e-06, eta: 6:42:47, time: 0.605, data_time: 0.018, memory: 75933, decode.loss_ce: 0.1515, decode.acc_seg: 93.7330, loss: 0.1515
2025-04-22 18:37:54,917 - mmseg - INFO - Iter [100/40000]	lr: 5.267e-06, eta: 5:00:20, time: 0.298, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1450, decode.acc_seg: 94.2367, loss: 0.1450
2025-04-22 18:38:09,881 - mmseg - INFO - Iter [150/40000]	lr: 7.917e-06, eta: 4:26:13, time: 0.299, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1377, decode.acc_seg: 94.5445, loss: 0.1377
2025-04-22 18:38:24,887 - mmseg - INFO - Iter [200/40000]	lr: 1.056e-05, eta: 4:09:11, time: 0.300, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1471, decode.acc_seg: 94.1517, loss: 0.1471
2025-04-22 18:38:39,972 - mmseg - INFO - Iter [250/40000]	lr: 1.320e-05, eta: 3:59:04, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1421, decode.acc_seg: 94.0547, loss: 0.1421
2025-04-22 18:38:55,066 - mmseg - INFO - Iter [300/40000]	lr: 1.583e-05, eta: 3:52:16, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1340, decode.acc_seg: 94.4575, loss: 0.1340
2025-04-22 18:39:10,230 - mmseg - INFO - Iter [350/40000]	lr: 1.845e-05, eta: 3:47:28, time: 0.303, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1130, decode.acc_seg: 95.0805, loss: 0.1130
2025-04-22 18:39:25,420 - mmseg - INFO - Iter [400/40000]	lr: 2.107e-05, eta: 3:43:50, time: 0.304, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1424, decode.acc_seg: 94.2717, loss: 0.1424
2025-04-22 18:39:40,545 - mmseg - INFO - Iter [450/40000]	lr: 2.368e-05, eta: 3:40:52, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1359, decode.acc_seg: 94.5603, loss: 0.1359
2025-04-22 18:39:55,669 - mmseg - INFO - Iter [500/40000]	lr: 2.628e-05, eta: 3:38:27, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1306, decode.acc_seg: 94.5837, loss: 0.1306
2025-04-22 18:40:10,812 - mmseg - INFO - Iter [550/40000]	lr: 2.888e-05, eta: 3:36:26, time: 0.303, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1466, decode.acc_seg: 93.9366, loss: 0.1466
2025-04-22 18:40:25,956 - mmseg - INFO - Iter [600/40000]	lr: 3.147e-05, eta: 3:34:43, time: 0.303, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1273, decode.acc_seg: 94.8551, loss: 0.1273
2025-04-22 18:40:41,102 - mmseg - INFO - Iter [650/40000]	lr: 3.405e-05, eta: 3:33:14, time: 0.303, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1276, decode.acc_seg: 94.9371, loss: 0.1276
2025-04-22 18:40:56,230 - mmseg - INFO - Iter [700/40000]	lr: 3.663e-05, eta: 3:31:54, time: 0.303, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1412, decode.acc_seg: 94.2104, loss: 0.1412
2025-04-22 18:41:11,349 - mmseg - INFO - Iter [750/40000]	lr: 3.920e-05, eta: 3:30:43, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1373, decode.acc_seg: 94.0457, loss: 0.1373
2025-04-22 18:41:26,467 - mmseg - INFO - Iter [800/40000]	lr: 4.176e-05, eta: 3:29:38, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1284, decode.acc_seg: 94.5858, loss: 0.1284
2025-04-22 18:41:41,582 - mmseg - INFO - Iter [850/40000]	lr: 4.432e-05, eta: 3:28:39, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1247, decode.acc_seg: 94.5880, loss: 0.1247
2025-04-22 18:41:56,693 - mmseg - INFO - Iter [900/40000]	lr: 4.687e-05, eta: 3:27:45, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1459, decode.acc_seg: 94.1714, loss: 0.1459
2025-04-22 18:42:11,802 - mmseg - INFO - Iter [950/40000]	lr: 4.941e-05, eta: 3:26:55, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1291, decode.acc_seg: 94.7941, loss: 0.1291
2025-04-22 18:42:26,907 - mmseg - INFO - Exp name: vpd_config.py
2025-04-22 18:42:26,908 - mmseg - INFO - Iter [1000/40000]	lr: 5.195e-05, eta: 3:26:08, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1313, decode.acc_seg: 94.5402, loss: 0.1313
2025-04-22 18:42:42,782 - mmseg - INFO - Iter [1050/40000]	lr: 5.448e-05, eta: 3:25:53, time: 0.318, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1310, decode.acc_seg: 94.6267, loss: 0.1310
2025-04-22 18:42:57,922 - mmseg - INFO - Iter [1100/40000]	lr: 5.700e-05, eta: 3:25:12, time: 0.303, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1333, decode.acc_seg: 94.4440, loss: 0.1333
2025-04-22 18:43:13,042 - mmseg - INFO - Iter [1150/40000]	lr: 5.952e-05, eta: 3:24:32, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1557, decode.acc_seg: 93.7451, loss: 0.1557
2025-04-22 18:43:28,157 - mmseg - INFO - Iter [1200/40000]	lr: 6.203e-05, eta: 3:23:54, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1547, decode.acc_seg: 93.7287, loss: 0.1547
2025-04-22 18:43:43,275 - mmseg - INFO - Iter [1250/40000]	lr: 6.453e-05, eta: 3:23:18, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1266, decode.acc_seg: 94.5785, loss: 0.1266
2025-04-22 18:43:58,392 - mmseg - INFO - Iter [1300/40000]	lr: 6.703e-05, eta: 3:22:44, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1399, decode.acc_seg: 94.3577, loss: 0.1399
2025-04-22 18:44:13,509 - mmseg - INFO - Iter [1350/40000]	lr: 6.952e-05, eta: 3:22:11, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1350, decode.acc_seg: 94.4974, loss: 0.1350
2025-04-22 18:44:28,636 - mmseg - INFO - Iter [1400/40000]	lr: 7.200e-05, eta: 3:21:40, time: 0.303, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1246, decode.acc_seg: 94.8779, loss: 0.1246
2025-04-22 18:44:43,764 - mmseg - INFO - Iter [1450/40000]	lr: 7.448e-05, eta: 3:21:10, time: 0.303, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1547, decode.acc_seg: 93.7450, loss: 0.1547
2025-04-22 18:44:58,901 - mmseg - INFO - Iter [1500/40000]	lr: 7.695e-05, eta: 3:20:41, time: 0.303, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1672, decode.acc_seg: 93.4836, loss: 0.1672
2025-04-22 18:45:14,005 - mmseg - INFO - Iter [1550/40000]	lr: 7.690e-05, eta: 3:20:12, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1376, decode.acc_seg: 94.5020, loss: 0.1376
2025-04-22 18:45:29,108 - mmseg - INFO - Iter [1600/40000]	lr: 7.680e-05, eta: 3:19:44, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1426, decode.acc_seg: 94.1098, loss: 0.1426
2025-04-22 18:45:44,232 - mmseg - INFO - Iter [1650/40000]	lr: 7.670e-05, eta: 3:19:17, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1472, decode.acc_seg: 93.8501, loss: 0.1472
2025-04-22 18:45:59,361 - mmseg - INFO - Iter [1700/40000]	lr: 7.660e-05, eta: 3:18:51, time: 0.303, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1196, decode.acc_seg: 94.7558, loss: 0.1196
2025-04-22 18:46:14,464 - mmseg - INFO - Iter [1750/40000]	lr: 7.650e-05, eta: 3:18:25, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1382, decode.acc_seg: 94.1220, loss: 0.1382
2025-04-22 18:46:29,562 - mmseg - INFO - Iter [1800/40000]	lr: 7.640e-05, eta: 3:18:00, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1443, decode.acc_seg: 94.2933, loss: 0.1443
2025-04-22 18:46:44,659 - mmseg - INFO - Iter [1850/40000]	lr: 7.630e-05, eta: 3:17:35, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1446, decode.acc_seg: 94.0311, loss: 0.1446
2025-04-22 18:46:59,764 - mmseg - INFO - Iter [1900/40000]	lr: 7.620e-05, eta: 3:17:11, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1407, decode.acc_seg: 94.3468, loss: 0.1407
2025-04-22 18:47:14,861 - mmseg - INFO - Iter [1950/40000]	lr: 7.610e-05, eta: 3:16:47, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1336, decode.acc_seg: 94.3788, loss: 0.1336
2025-04-22 18:47:29,951 - mmseg - INFO - Exp name: vpd_config.py
2025-04-22 18:47:29,952 - mmseg - INFO - Iter [2000/40000]	lr: 7.600e-05, eta: 3:16:23, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1413, decode.acc_seg: 94.2225, loss: 0.1413
2025-04-22 18:47:45,749 - mmseg - INFO - Iter [2050/40000]	lr: 7.590e-05, eta: 3:16:13, time: 0.316, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1455, decode.acc_seg: 93.6969, loss: 0.1455
2025-04-22 18:48:00,859 - mmseg - INFO - Iter [2100/40000]	lr: 7.580e-05, eta: 3:15:50, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1422, decode.acc_seg: 94.2238, loss: 0.1422
2025-04-22 18:48:15,959 - mmseg - INFO - Iter [2150/40000]	lr: 7.570e-05, eta: 3:15:28, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1313, decode.acc_seg: 94.4343, loss: 0.1313
2025-04-22 18:48:31,067 - mmseg - INFO - Iter [2200/40000]	lr: 7.560e-05, eta: 3:15:06, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1370, decode.acc_seg: 93.9833, loss: 0.1370
2025-04-22 18:48:46,167 - mmseg - INFO - Iter [2250/40000]	lr: 7.550e-05, eta: 3:14:44, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1259, decode.acc_seg: 94.8206, loss: 0.1259
2025-04-22 18:49:01,273 - mmseg - INFO - Iter [2300/40000]	lr: 7.540e-05, eta: 3:14:22, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1439, decode.acc_seg: 94.2054, loss: 0.1439
2025-04-22 18:49:16,356 - mmseg - INFO - Iter [2350/40000]	lr: 7.530e-05, eta: 3:14:00, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1383, decode.acc_seg: 94.4093, loss: 0.1383
2025-04-22 18:49:31,432 - mmseg - INFO - Iter [2400/40000]	lr: 7.520e-05, eta: 3:13:39, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1326, decode.acc_seg: 94.1279, loss: 0.1326
2025-04-22 18:49:46,513 - mmseg - INFO - Iter [2450/40000]	lr: 7.510e-05, eta: 3:13:18, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1348, decode.acc_seg: 94.3193, loss: 0.1348
2025-04-22 18:50:01,596 - mmseg - INFO - Iter [2500/40000]	lr: 7.500e-05, eta: 3:12:57, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1469, decode.acc_seg: 94.0399, loss: 0.1469
2025-04-22 18:50:16,682 - mmseg - INFO - Iter [2550/40000]	lr: 7.490e-05, eta: 3:12:36, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1301, decode.acc_seg: 94.5428, loss: 0.1301
2025-04-22 18:50:31,768 - mmseg - INFO - Iter [2600/40000]	lr: 7.480e-05, eta: 3:12:16, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1474, decode.acc_seg: 94.0851, loss: 0.1474
2025-04-22 18:50:46,848 - mmseg - INFO - Iter [2650/40000]	lr: 7.470e-05, eta: 3:11:56, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1360, decode.acc_seg: 94.5419, loss: 0.1360
2025-04-22 18:51:01,932 - mmseg - INFO - Iter [2700/40000]	lr: 7.460e-05, eta: 3:11:36, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1625, decode.acc_seg: 93.3142, loss: 0.1625
2025-04-22 18:51:17,014 - mmseg - INFO - Iter [2750/40000]	lr: 7.450e-05, eta: 3:11:16, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1505, decode.acc_seg: 93.6930, loss: 0.1505
2025-04-22 18:51:32,104 - mmseg - INFO - Iter [2800/40000]	lr: 7.440e-05, eta: 3:10:56, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1468, decode.acc_seg: 94.1006, loss: 0.1468
2025-04-22 18:51:47,182 - mmseg - INFO - Iter [2850/40000]	lr: 7.430e-05, eta: 3:10:37, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1510, decode.acc_seg: 93.5904, loss: 0.1510
2025-04-22 18:52:02,271 - mmseg - INFO - Iter [2900/40000]	lr: 7.420e-05, eta: 3:10:17, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1503, decode.acc_seg: 93.8941, loss: 0.1503
2025-04-22 18:52:17,352 - mmseg - INFO - Iter [2950/40000]	lr: 7.410e-05, eta: 3:09:58, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1228, decode.acc_seg: 94.8066, loss: 0.1228
2025-04-22 18:52:32,431 - mmseg - INFO - Exp name: vpd_config.py
2025-04-22 18:52:32,432 - mmseg - INFO - Iter [3000/40000]	lr: 7.400e-05, eta: 3:09:39, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1400, decode.acc_seg: 93.9492, loss: 0.1400
2025-04-22 18:52:48,214 - mmseg - INFO - Iter [3050/40000]	lr: 7.390e-05, eta: 3:09:29, time: 0.316, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1663, decode.acc_seg: 93.5445, loss: 0.1663
2025-04-22 18:53:03,335 - mmseg - INFO - Iter [3100/40000]	lr: 7.380e-05, eta: 3:09:10, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1349, decode.acc_seg: 94.3585, loss: 0.1349
2025-04-22 18:53:18,445 - mmseg - INFO - Iter [3150/40000]	lr: 7.370e-05, eta: 3:08:51, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1382, decode.acc_seg: 94.1152, loss: 0.1382
2025-04-22 18:53:33,565 - mmseg - INFO - Iter [3200/40000]	lr: 7.360e-05, eta: 3:08:33, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1401, decode.acc_seg: 94.2462, loss: 0.1401
2025-04-22 18:53:48,661 - mmseg - INFO - Iter [3250/40000]	lr: 7.350e-05, eta: 3:08:15, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1480, decode.acc_seg: 94.2992, loss: 0.1480
2025-04-22 18:54:03,759 - mmseg - INFO - Iter [3300/40000]	lr: 7.340e-05, eta: 3:07:56, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1496, decode.acc_seg: 93.9550, loss: 0.1496
2025-04-22 18:54:18,861 - mmseg - INFO - Iter [3350/40000]	lr: 7.330e-05, eta: 3:07:38, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1401, decode.acc_seg: 94.1333, loss: 0.1401
2025-04-22 18:54:33,954 - mmseg - INFO - Iter [3400/40000]	lr: 7.320e-05, eta: 3:07:20, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1529, decode.acc_seg: 94.1436, loss: 0.1529
2025-04-22 18:54:49,054 - mmseg - INFO - Iter [3450/40000]	lr: 7.310e-05, eta: 3:07:02, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1343, decode.acc_seg: 94.5281, loss: 0.1343
2025-04-22 18:55:04,147 - mmseg - INFO - Iter [3500/40000]	lr: 7.300e-05, eta: 3:06:44, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1301, decode.acc_seg: 94.4584, loss: 0.1301
2025-04-22 18:55:19,242 - mmseg - INFO - Iter [3550/40000]	lr: 7.290e-05, eta: 3:06:26, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1272, decode.acc_seg: 94.7968, loss: 0.1272
2025-04-22 18:55:34,338 - mmseg - INFO - Iter [3600/40000]	lr: 7.280e-05, eta: 3:06:08, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1425, decode.acc_seg: 94.1961, loss: 0.1425
2025-04-22 18:55:49,445 - mmseg - INFO - Iter [3650/40000]	lr: 7.270e-05, eta: 3:05:50, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1360, decode.acc_seg: 94.0615, loss: 0.1360
2025-04-22 18:56:04,538 - mmseg - INFO - Iter [3700/40000]	lr: 7.260e-05, eta: 3:05:33, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1224, decode.acc_seg: 94.7707, loss: 0.1224
2025-04-22 18:56:19,645 - mmseg - INFO - Iter [3750/40000]	lr: 7.250e-05, eta: 3:05:15, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1418, decode.acc_seg: 94.1022, loss: 0.1418
2025-04-22 18:56:34,747 - mmseg - INFO - Iter [3800/40000]	lr: 7.240e-05, eta: 3:04:57, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1522, decode.acc_seg: 93.9861, loss: 0.1522
2025-04-22 18:56:49,836 - mmseg - INFO - Iter [3850/40000]	lr: 7.230e-05, eta: 3:04:40, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1383, decode.acc_seg: 94.3149, loss: 0.1383
2025-04-22 18:57:04,932 - mmseg - INFO - Iter [3900/40000]	lr: 7.220e-05, eta: 3:04:22, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1362, decode.acc_seg: 94.4286, loss: 0.1362
2025-04-22 18:57:20,026 - mmseg - INFO - Iter [3950/40000]	lr: 7.210e-05, eta: 3:04:05, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1376, decode.acc_seg: 94.4829, loss: 0.1376
2025-04-22 18:57:35,129 - mmseg - INFO - Saving checkpoint at 4000 iterations
2025-04-22 18:57:45,680 - mmseg - INFO - Exp name: vpd_config.py
2025-04-22 18:57:45,680 - mmseg - INFO - Iter [4000/40000]	lr: 7.200e-05, eta: 3:05:23, time: 0.513, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1408, decode.acc_seg: 93.8006, loss: 0.1408
2025-04-22 19:01:27,148 - mmseg - INFO - per class results:
2025-04-22 19:01:27,155 - mmseg - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        | 46.85 | 60.31 |
|       building      | 54.32 | 63.16 |
|         sky         | 49.16 | 73.84 |
|        floor        | 31.63 | 72.64 |
|         tree        | 43.23 | 59.36 |
|       ceiling       | 62.51 | 66.38 |
|         road        | 35.66 | 76.91 |
|         bed         | 31.39 | 45.04 |
|      windowpane     | 36.16 | 45.95 |
|        grass        | 25.03 | 38.12 |
|       cabinet       | 29.05 | 39.38 |
|       sidewalk      | 14.71 | 24.41 |
|        person       | 31.67 | 43.65 |
|        earth        | 21.16 | 34.06 |
|         door        | 30.77 | 40.78 |
|        table        | 15.57 | 24.78 |
|       mountain      | 40.78 |  54.6 |
|        plant        | 21.52 | 28.63 |
|       curtain       | 45.04 | 55.53 |
|        chair        | 13.39 |  20.7 |
|         car         |  13.5 | 20.84 |
|        water        | 32.06 | 53.61 |
|       painting      | 32.53 | 41.43 |
|         sofa        | 14.66 | 23.55 |
|        shelf        | 26.92 | 38.71 |
|        house        | 29.09 | 46.39 |
|         sea         | 37.25 | 63.29 |
|        mirror       | 40.81 |  50.0 |
|         rug         |  14.7 | 22.02 |
|        field        | 20.49 | 39.77 |
|       armchair      | 11.26 | 18.19 |
|         seat        | 26.07 | 41.37 |
|        fence        | 11.07 | 17.75 |
|         desk        | 15.88 | 29.77 |
|         rock        | 24.43 | 36.48 |
|       wardrobe      | 36.69 | 46.52 |
|         lamp        | 20.45 | 29.42 |
|       bathtub       | 38.51 | 48.84 |
|       railing       | 12.49 | 18.01 |
|       cushion       |  7.44 |  11.6 |
|         base        | 13.53 | 22.88 |
|         box         |  9.41 | 12.76 |
|        column       | 28.31 | 34.48 |
|      signboard      | 10.36 | 15.45 |
|   chest of drawers  | 15.91 | 23.31 |
|       counter       |  8.8  | 14.01 |
|         sand        | 27.79 | 46.03 |
|         sink        | 16.56 | 24.04 |
|      skyscraper     | 46.07 | 56.92 |
|      fireplace      | 31.58 | 44.28 |
|     refrigerator    | 42.69 | 50.84 |
|      grandstand     | 30.26 | 59.03 |
|         path        |  6.43 |  9.57 |
|        stairs       |  9.77 | 13.98 |
|        runway       | 30.84 | 48.62 |
|         case        | 30.62 | 44.04 |
|      pool table     | 25.52 | 37.53 |
|        pillow       | 10.64 | 15.99 |
|     screen door     | 36.45 | 46.74 |
|       stairway      | 16.51 | 22.78 |
|        river        | 16.25 | 28.24 |
|        bridge       |  18.3 | 30.49 |
|       bookcase      | 26.72 | 37.59 |
|        blind        | 36.84 | 41.67 |
|     coffee table    |  4.12 |  7.28 |
|        toilet       | 18.68 | 27.34 |
|        flower       | 13.82 | 22.43 |
|         book        | 24.21 | 34.61 |
|         hill        |  8.99 | 15.66 |
|        bench        | 14.25 | 19.75 |
|      countertop     | 11.94 | 20.51 |
|        stove        | 23.43 |  33.3 |
|         palm        | 29.79 |  44.5 |
|    kitchen island   | 10.13 | 23.76 |
|       computer      | 31.92 | 46.58 |
|     swivel chair    | 15.38 | 23.92 |
|         boat        | 10.83 | 16.98 |
|         bar         | 27.57 | 41.42 |
|    arcade machine   | 20.98 | 25.64 |
|        hovel        | 15.89 | 20.06 |
|         bus         | 39.78 | 50.44 |
|        towel        | 16.44 | 23.56 |
|        light        | 20.12 | 24.96 |
|        truck        |  6.44 |  13.9 |
|        tower        |  5.54 | 10.97 |
|      chandelier     | 29.37 | 40.97 |
|        awning       |  4.2  |  5.84 |
|     streetlight     | 12.74 | 17.62 |
|        booth        | 22.66 | 32.74 |
| television receiver | 14.99 | 23.48 |
|       airplane      |  9.82 | 15.33 |
|      dirt track     |  1.77 | 10.01 |
|       apparel       |  18.1 | 25.26 |
|         pole        |  9.36 | 13.03 |
|         land        |  2.15 |  2.85 |
|      bannister      |  5.48 |  9.28 |
|      escalator      | 15.68 | 22.01 |
|       ottoman       |  2.03 |  3.42 |
|        bottle       |  8.3  | 12.41 |
|        buffet       | 27.54 | 32.99 |
|        poster       | 30.06 | 38.31 |
|        stage        | 11.22 | 21.48 |
|         van         |  7.26 | 11.95 |
|         ship        |  30.2 | 62.45 |
|       fountain      |  6.84 |  8.6  |
|    conveyer belt    |  28.4 | 47.03 |
|        canopy       |  16.7 | 24.43 |
|        washer       | 35.68 | 41.08 |
|      plaything      |  5.91 | 10.04 |
|    swimming pool    | 16.87 |  25.9 |
|        stool        |  8.49 | 11.23 |
|        barrel       |  0.01 |  0.03 |
|        basket       |  4.71 |  6.71 |
|      waterfall      | 39.33 | 55.03 |
|         tent        |  36.1 |  45.3 |
|         bag         |  2.36 |  3.43 |
|       minibike      | 14.86 | 22.19 |
|        cradle       | 32.74 | 46.74 |
|         oven        |  24.0 | 31.46 |
|         ball        |  16.3 | 24.99 |
|         food        | 28.08 | 37.66 |
|         step        |  0.01 |  0.01 |
|         tank        | 26.72 | 37.49 |
|      trade name     |  4.22 |  4.78 |
|      microwave      | 41.22 | 52.55 |
|         pot         | 11.09 | 15.87 |
|        animal       | 21.35 | 27.65 |
|       bicycle       |  3.9  |  6.82 |
|         lake        | 32.76 | 38.73 |
|      dishwasher     | 12.93 | 16.93 |
|        screen       | 37.76 | 50.51 |
|       blanket       |  2.65 |  3.52 |
|      sculpture      | 18.44 | 29.35 |
|         hood        | 25.89 | 37.54 |
|        sconce       |  11.2 | 15.72 |
|         vase        |  5.06 |  9.22 |
|    traffic light    | 14.83 | 22.89 |
|         tray        |  2.61 |  4.46 |
|        ashcan       |  1.45 |  2.53 |
|         fan         | 19.48 | 27.41 |
|         pier        |  0.44 |  0.77 |
|      crt screen     |  8.61 | 12.32 |
|        plate        | 10.69 | 15.86 |
|       monitor       | 38.12 | 45.85 |
|    bulletin board   | 31.49 | 42.26 |
|        shower       |  0.19 |  0.59 |
|       radiator      |  8.45 | 12.52 |
|        glass        |  0.2  |  0.23 |
|        clock        | 23.07 | 28.13 |
|         flag        | 36.72 | 41.96 |
+---------------------+-------+-------+
2025-04-22 19:01:27,155 - mmseg - INFO - Summary:
2025-04-22 19:01:27,156 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 53.41 | 20.63 | 29.62 |
+-------+-------+-------+
2025-04-22 19:01:27,156 - mmseg - INFO - Exp name: vpd_config.py
2025-04-22 19:01:27,157 - mmseg - INFO - Iter(val) [2000]	aAcc: 0.5341, mIoU: 0.2063, mAcc: 0.2962, IoU.wall: 0.4685, IoU.building: 0.5432, IoU.sky: 0.4916, IoU.floor: 0.3163, IoU.tree: 0.4323, IoU.ceiling: 0.6251, IoU.road: 0.3566, IoU.bed : 0.3139, IoU.windowpane: 0.3616, IoU.grass: 0.2503, IoU.cabinet: 0.2905, IoU.sidewalk: 0.1471, IoU.person: 0.3167, IoU.earth: 0.2116, IoU.door: 0.3077, IoU.table: 0.1557, IoU.mountain: 0.4078, IoU.plant: 0.2152, IoU.curtain: 0.4504, IoU.chair: 0.1339, IoU.car: 0.1350, IoU.water: 0.3206, IoU.painting: 0.3253, IoU.sofa: 0.1466, IoU.shelf: 0.2692, IoU.house: 0.2909, IoU.sea: 0.3725, IoU.mirror: 0.4081, IoU.rug: 0.1470, IoU.field: 0.2049, IoU.armchair: 0.1126, IoU.seat: 0.2607, IoU.fence: 0.1107, IoU.desk: 0.1588, IoU.rock: 0.2443, IoU.wardrobe: 0.3669, IoU.lamp: 0.2045, IoU.bathtub: 0.3851, IoU.railing: 0.1249, IoU.cushion: 0.0744, IoU.base: 0.1353, IoU.box: 0.0941, IoU.column: 0.2831, IoU.signboard: 0.1036, IoU.chest of drawers: 0.1591, IoU.counter: 0.0880, IoU.sand: 0.2779, IoU.sink: 0.1656, IoU.skyscraper: 0.4607, IoU.fireplace: 0.3158, IoU.refrigerator: 0.4269, IoU.grandstand: 0.3026, IoU.path: 0.0643, IoU.stairs: 0.0977, IoU.runway: 0.3084, IoU.case: 0.3062, IoU.pool table: 0.2552, IoU.pillow: 0.1064, IoU.screen door: 0.3645, IoU.stairway: 0.1651, IoU.river: 0.1625, IoU.bridge: 0.1830, IoU.bookcase: 0.2672, IoU.blind: 0.3684, IoU.coffee table: 0.0412, IoU.toilet: 0.1868, IoU.flower: 0.1382, IoU.book: 0.2421, IoU.hill: 0.0899, IoU.bench: 0.1425, IoU.countertop: 0.1194, IoU.stove: 0.2343, IoU.palm: 0.2979, IoU.kitchen island: 0.1013, IoU.computer: 0.3192, IoU.swivel chair: 0.1538, IoU.boat: 0.1083, IoU.bar: 0.2757, IoU.arcade machine: 0.2098, IoU.hovel: 0.1589, IoU.bus: 0.3978, IoU.towel: 0.1644, IoU.light: 0.2012, IoU.truck: 0.0644, IoU.tower: 0.0554, IoU.chandelier: 0.2937, IoU.awning: 0.0420, IoU.streetlight: 0.1274, IoU.booth: 0.2266, IoU.television receiver: 0.1499, IoU.airplane: 0.0982, IoU.dirt track: 0.0177, IoU.apparel: 0.1810, IoU.pole: 0.0936, IoU.land: 0.0215, IoU.bannister: 0.0548, IoU.escalator: 0.1568, IoU.ottoman: 0.0203, IoU.bottle: 0.0830, IoU.buffet: 0.2754, IoU.poster: 0.3006, IoU.stage: 0.1122, IoU.van: 0.0726, IoU.ship: 0.3020, IoU.fountain: 0.0684, IoU.conveyer belt: 0.2840, IoU.canopy: 0.1670, IoU.washer: 0.3568, IoU.plaything: 0.0591, IoU.swimming pool: 0.1687, IoU.stool: 0.0849, IoU.barrel: 0.0001, IoU.basket: 0.0471, IoU.waterfall: 0.3933, IoU.tent: 0.3610, IoU.bag: 0.0236, IoU.minibike: 0.1486, IoU.cradle: 0.3274, IoU.oven: 0.2400, IoU.ball: 0.1630, IoU.food: 0.2808, IoU.step: 0.0001, IoU.tank: 0.2672, IoU.trade name: 0.0422, IoU.microwave: 0.4122, IoU.pot: 0.1109, IoU.animal: 0.2135, IoU.bicycle: 0.0390, IoU.lake: 0.3276, IoU.dishwasher: 0.1293, IoU.screen: 0.3776, IoU.blanket: 0.0265, IoU.sculpture: 0.1844, IoU.hood: 0.2589, IoU.sconce: 0.1120, IoU.vase: 0.0506, IoU.traffic light: 0.1483, IoU.tray: 0.0261, IoU.ashcan: 0.0145, IoU.fan: 0.1948, IoU.pier: 0.0044, IoU.crt screen: 0.0861, IoU.plate: 0.1069, IoU.monitor: 0.3812, IoU.bulletin board: 0.3149, IoU.shower: 0.0019, IoU.radiator: 0.0845, IoU.glass: 0.0020, IoU.clock: 0.2307, IoU.flag: 0.3672, Acc.wall: 0.6031, Acc.building: 0.6316, Acc.sky: 0.7384, Acc.floor: 0.7264, Acc.tree: 0.5936, Acc.ceiling: 0.6638, Acc.road: 0.7691, Acc.bed : 0.4504, Acc.windowpane: 0.4595, Acc.grass: 0.3812, Acc.cabinet: 0.3938, Acc.sidewalk: 0.2441, Acc.person: 0.4365, Acc.earth: 0.3406, Acc.door: 0.4078, Acc.table: 0.2478, Acc.mountain: 0.5460, Acc.plant: 0.2863, Acc.curtain: 0.5553, Acc.chair: 0.2070, Acc.car: 0.2084, Acc.water: 0.5361, Acc.painting: 0.4143, Acc.sofa: 0.2355, Acc.shelf: 0.3871, Acc.house: 0.4639, Acc.sea: 0.6329, Acc.mirror: 0.5000, Acc.rug: 0.2202, Acc.field: 0.3977, Acc.armchair: 0.1819, Acc.seat: 0.4137, Acc.fence: 0.1775, Acc.desk: 0.2977, Acc.rock: 0.3648, Acc.wardrobe: 0.4652, Acc.lamp: 0.2942, Acc.bathtub: 0.4884, Acc.railing: 0.1801, Acc.cushion: 0.1160, Acc.base: 0.2288, Acc.box: 0.1276, Acc.column: 0.3448, Acc.signboard: 0.1545, Acc.chest of drawers: 0.2331, Acc.counter: 0.1401, Acc.sand: 0.4603, Acc.sink: 0.2404, Acc.skyscraper: 0.5692, Acc.fireplace: 0.4428, Acc.refrigerator: 0.5084, Acc.grandstand: 0.5903, Acc.path: 0.0957, Acc.stairs: 0.1398, Acc.runway: 0.4862, Acc.case: 0.4404, Acc.pool table: 0.3753, Acc.pillow: 0.1599, Acc.screen door: 0.4674, Acc.stairway: 0.2278, Acc.river: 0.2824, Acc.bridge: 0.3049, Acc.bookcase: 0.3759, Acc.blind: 0.4167, Acc.coffee table: 0.0728, Acc.toilet: 0.2734, Acc.flower: 0.2243, Acc.book: 0.3461, Acc.hill: 0.1566, Acc.bench: 0.1975, Acc.countertop: 0.2051, Acc.stove: 0.3330, Acc.palm: 0.4450, Acc.kitchen island: 0.2376, Acc.computer: 0.4658, Acc.swivel chair: 0.2392, Acc.boat: 0.1698, Acc.bar: 0.4142, Acc.arcade machine: 0.2564, Acc.hovel: 0.2006, Acc.bus: 0.5044, Acc.towel: 0.2356, Acc.light: 0.2496, Acc.truck: 0.1390, Acc.tower: 0.1097, Acc.chandelier: 0.4097, Acc.awning: 0.0584, Acc.streetlight: 0.1762, Acc.booth: 0.3274, Acc.television receiver: 0.2348, Acc.airplane: 0.1533, Acc.dirt track: 0.1001, Acc.apparel: 0.2526, Acc.pole: 0.1303, Acc.land: 0.0285, Acc.bannister: 0.0928, Acc.escalator: 0.2201, Acc.ottoman: 0.0342, Acc.bottle: 0.1241, Acc.buffet: 0.3299, Acc.poster: 0.3831, Acc.stage: 0.2148, Acc.van: 0.1195, Acc.ship: 0.6245, Acc.fountain: 0.0860, Acc.conveyer belt: 0.4703, Acc.canopy: 0.2443, Acc.washer: 0.4108, Acc.plaything: 0.1004, Acc.swimming pool: 0.2590, Acc.stool: 0.1123, Acc.barrel: 0.0003, Acc.basket: 0.0671, Acc.waterfall: 0.5503, Acc.tent: 0.4530, Acc.bag: 0.0343, Acc.minibike: 0.2219, Acc.cradle: 0.4674, Acc.oven: 0.3146, Acc.ball: 0.2499, Acc.food: 0.3766, Acc.step: 0.0001, Acc.tank: 0.3749, Acc.trade name: 0.0478, Acc.microwave: 0.5255, Acc.pot: 0.1587, Acc.animal: 0.2765, Acc.bicycle: 0.0682, Acc.lake: 0.3873, Acc.dishwasher: 0.1693, Acc.screen: 0.5051, Acc.blanket: 0.0352, Acc.sculpture: 0.2935, Acc.hood: 0.3754, Acc.sconce: 0.1572, Acc.vase: 0.0922, Acc.traffic light: 0.2289, Acc.tray: 0.0446, Acc.ashcan: 0.0253, Acc.fan: 0.2741, Acc.pier: 0.0077, Acc.crt screen: 0.1232, Acc.plate: 0.1586, Acc.monitor: 0.4585, Acc.bulletin board: 0.4226, Acc.shower: 0.0059, Acc.radiator: 0.1252, Acc.glass: 0.0023, Acc.clock: 0.2813, Acc.flag: 0.4196
2025-04-22 19:01:42,802 - mmseg - INFO - Iter [4050/40000]	lr: 7.190e-05, eta: 3:37:55, time: 4.742, data_time: 4.437, memory: 75933, decode.loss_ce: 0.1701, decode.acc_seg: 93.7616, loss: 0.1701
2025-04-22 19:01:57,906 - mmseg - INFO - Iter [4100/40000]	lr: 7.180e-05, eta: 3:37:10, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1443, decode.acc_seg: 94.2447, loss: 0.1443
2025-04-22 19:02:13,036 - mmseg - INFO - Iter [4150/40000]	lr: 7.170e-05, eta: 3:36:26, time: 0.303, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1397, decode.acc_seg: 94.4108, loss: 0.1397
2025-04-22 19:02:28,159 - mmseg - INFO - Iter [4200/40000]	lr: 7.160e-05, eta: 3:35:42, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1305, decode.acc_seg: 94.4692, loss: 0.1305
2025-04-22 19:02:43,284 - mmseg - INFO - Iter [4250/40000]	lr: 7.150e-05, eta: 3:34:59, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1493, decode.acc_seg: 93.8313, loss: 0.1493
2025-04-22 19:02:58,433 - mmseg - INFO - Iter [4300/40000]	lr: 7.140e-05, eta: 3:34:17, time: 0.303, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1393, decode.acc_seg: 94.0589, loss: 0.1393
2025-04-22 19:03:13,560 - mmseg - INFO - Iter [4350/40000]	lr: 7.130e-05, eta: 3:33:35, time: 0.303, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1403, decode.acc_seg: 94.3028, loss: 0.1403
2025-04-22 19:03:28,681 - mmseg - INFO - Iter [4400/40000]	lr: 7.120e-05, eta: 3:32:54, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1530, decode.acc_seg: 93.4696, loss: 0.1530
2025-04-22 19:03:43,794 - mmseg - INFO - Iter [4450/40000]	lr: 7.110e-05, eta: 3:32:14, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1251, decode.acc_seg: 95.0419, loss: 0.1251
2025-04-22 19:03:58,904 - mmseg - INFO - Iter [4500/40000]	lr: 7.100e-05, eta: 3:31:34, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1520, decode.acc_seg: 93.8982, loss: 0.1520
2025-04-22 19:04:14,009 - mmseg - INFO - Iter [4550/40000]	lr: 7.090e-05, eta: 3:30:54, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1424, decode.acc_seg: 94.2597, loss: 0.1424
2025-04-22 19:04:29,121 - mmseg - INFO - Iter [4600/40000]	lr: 7.080e-05, eta: 3:30:15, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1410, decode.acc_seg: 94.1723, loss: 0.1410
2025-04-22 19:04:44,212 - mmseg - INFO - Iter [4650/40000]	lr: 7.070e-05, eta: 3:29:37, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1340, decode.acc_seg: 94.5723, loss: 0.1340
2025-04-22 19:04:59,290 - mmseg - INFO - Iter [4700/40000]	lr: 7.060e-05, eta: 3:28:59, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1471, decode.acc_seg: 94.2029, loss: 0.1471
2025-04-22 19:05:14,358 - mmseg - INFO - Iter [4750/40000]	lr: 7.050e-05, eta: 3:28:21, time: 0.301, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1287, decode.acc_seg: 94.6236, loss: 0.1287
2025-04-22 19:05:29,434 - mmseg - INFO - Iter [4800/40000]	lr: 7.040e-05, eta: 3:27:44, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1410, decode.acc_seg: 94.2072, loss: 0.1410
2025-04-22 19:05:44,506 - mmseg - INFO - Iter [4850/40000]	lr: 7.030e-05, eta: 3:27:07, time: 0.301, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1395, decode.acc_seg: 94.0075, loss: 0.1395
2025-04-22 19:05:59,580 - mmseg - INFO - Iter [4900/40000]	lr: 7.020e-05, eta: 3:26:31, time: 0.301, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1380, decode.acc_seg: 94.4576, loss: 0.1380
2025-04-22 19:06:14,665 - mmseg - INFO - Iter [4950/40000]	lr: 7.010e-05, eta: 3:25:55, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1372, decode.acc_seg: 94.4082, loss: 0.1372
2025-04-22 19:06:29,744 - mmseg - INFO - Exp name: vpd_config.py
2025-04-22 19:06:29,745 - mmseg - INFO - Iter [5000/40000]	lr: 7.000e-05, eta: 3:25:19, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1478, decode.acc_seg: 94.1867, loss: 0.1478
2025-04-22 19:06:45,496 - mmseg - INFO - Iter [5050/40000]	lr: 6.990e-05, eta: 3:24:49, time: 0.315, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1540, decode.acc_seg: 93.8023, loss: 0.1540
2025-04-22 19:07:00,587 - mmseg - INFO - Iter [5100/40000]	lr: 6.980e-05, eta: 3:24:14, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1358, decode.acc_seg: 94.3697, loss: 0.1358
2025-04-22 19:07:15,664 - mmseg - INFO - Iter [5150/40000]	lr: 6.970e-05, eta: 3:23:40, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1310, decode.acc_seg: 94.4959, loss: 0.1310
2025-04-22 19:07:30,740 - mmseg - INFO - Iter [5200/40000]	lr: 6.960e-05, eta: 3:23:06, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1451, decode.acc_seg: 94.4315, loss: 0.1451
2025-04-22 19:07:45,838 - mmseg - INFO - Iter [5250/40000]	lr: 6.950e-05, eta: 3:22:32, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1387, decode.acc_seg: 94.1512, loss: 0.1387
2025-04-22 19:08:00,926 - mmseg - INFO - Iter [5300/40000]	lr: 6.940e-05, eta: 3:21:59, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1616, decode.acc_seg: 93.4971, loss: 0.1616
2025-04-22 19:08:16,006 - mmseg - INFO - Iter [5350/40000]	lr: 6.930e-05, eta: 3:21:26, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1423, decode.acc_seg: 94.1715, loss: 0.1423
2025-04-22 19:08:31,095 - mmseg - INFO - Iter [5400/40000]	lr: 6.920e-05, eta: 3:20:54, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1369, decode.acc_seg: 94.3056, loss: 0.1369
2025-04-22 19:08:46,199 - mmseg - INFO - Iter [5450/40000]	lr: 6.910e-05, eta: 3:20:22, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1307, decode.acc_seg: 94.6474, loss: 0.1307
2025-04-22 19:09:01,308 - mmseg - INFO - Iter [5500/40000]	lr: 6.900e-05, eta: 3:19:50, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1407, decode.acc_seg: 94.0982, loss: 0.1407
2025-04-22 19:09:16,403 - mmseg - INFO - Iter [5550/40000]	lr: 6.890e-05, eta: 3:19:18, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1352, decode.acc_seg: 94.3041, loss: 0.1352
2025-04-22 19:09:31,500 - mmseg - INFO - Iter [5600/40000]	lr: 6.880e-05, eta: 3:18:47, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1274, decode.acc_seg: 94.7553, loss: 0.1274
2025-04-22 19:09:46,593 - mmseg - INFO - Iter [5650/40000]	lr: 6.870e-05, eta: 3:18:16, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1418, decode.acc_seg: 94.4136, loss: 0.1418
2025-04-22 19:10:01,685 - mmseg - INFO - Iter [5700/40000]	lr: 6.860e-05, eta: 3:17:46, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1482, decode.acc_seg: 94.0882, loss: 0.1482
2025-04-22 19:10:16,767 - mmseg - INFO - Iter [5750/40000]	lr: 6.850e-05, eta: 3:17:15, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1453, decode.acc_seg: 94.1789, loss: 0.1453
2025-04-22 19:10:31,867 - mmseg - INFO - Iter [5800/40000]	lr: 6.840e-05, eta: 3:16:45, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1542, decode.acc_seg: 93.3794, loss: 0.1542
2025-04-22 19:10:46,956 - mmseg - INFO - Iter [5850/40000]	lr: 6.830e-05, eta: 3:16:15, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1544, decode.acc_seg: 94.1040, loss: 0.1544
2025-04-22 19:11:02,050 - mmseg - INFO - Iter [5900/40000]	lr: 6.820e-05, eta: 3:15:45, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1411, decode.acc_seg: 94.3083, loss: 0.1411
2025-04-22 19:11:17,141 - mmseg - INFO - Iter [5950/40000]	lr: 6.810e-05, eta: 3:15:16, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1358, decode.acc_seg: 94.2525, loss: 0.1358
2025-04-22 19:11:32,220 - mmseg - INFO - Exp name: vpd_config.py
2025-04-22 19:11:32,221 - mmseg - INFO - Iter [6000/40000]	lr: 6.800e-05, eta: 3:14:47, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1416, decode.acc_seg: 93.9970, loss: 0.1416
2025-04-22 19:11:48,001 - mmseg - INFO - Iter [6050/40000]	lr: 6.790e-05, eta: 3:14:22, time: 0.316, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1641, decode.acc_seg: 93.2614, loss: 0.1641
2025-04-22 19:12:03,130 - mmseg - INFO - Iter [6100/40000]	lr: 6.780e-05, eta: 3:13:53, time: 0.303, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1389, decode.acc_seg: 94.0391, loss: 0.1389
2025-04-22 19:12:18,238 - mmseg - INFO - Iter [6150/40000]	lr: 6.770e-05, eta: 3:13:25, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1266, decode.acc_seg: 94.7244, loss: 0.1266
2025-04-22 19:12:33,316 - mmseg - INFO - Iter [6200/40000]	lr: 6.760e-05, eta: 3:12:56, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1379, decode.acc_seg: 94.1941, loss: 0.1379
2025-04-22 19:12:48,426 - mmseg - INFO - Iter [6250/40000]	lr: 6.750e-05, eta: 3:12:28, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1384, decode.acc_seg: 94.3299, loss: 0.1384
2025-04-22 19:13:03,544 - mmseg - INFO - Iter [6300/40000]	lr: 6.740e-05, eta: 3:12:00, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1269, decode.acc_seg: 94.8519, loss: 0.1269
2025-04-22 19:13:18,658 - mmseg - INFO - Iter [6350/40000]	lr: 6.730e-05, eta: 3:11:33, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1532, decode.acc_seg: 93.6114, loss: 0.1532
2025-04-22 19:13:33,756 - mmseg - INFO - Iter [6400/40000]	lr: 6.720e-05, eta: 3:11:05, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1450, decode.acc_seg: 94.0257, loss: 0.1450
2025-04-22 19:13:48,847 - mmseg - INFO - Iter [6450/40000]	lr: 6.710e-05, eta: 3:10:38, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1411, decode.acc_seg: 93.7919, loss: 0.1411
2025-04-22 19:14:03,961 - mmseg - INFO - Iter [6500/40000]	lr: 6.700e-05, eta: 3:10:11, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1520, decode.acc_seg: 93.8382, loss: 0.1520
2025-04-22 19:14:19,066 - mmseg - INFO - Iter [6550/40000]	lr: 6.690e-05, eta: 3:09:44, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1383, decode.acc_seg: 94.2809, loss: 0.1383
2025-04-22 19:14:34,172 - mmseg - INFO - Iter [6600/40000]	lr: 6.680e-05, eta: 3:09:17, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1325, decode.acc_seg: 94.4294, loss: 0.1325
2025-04-22 19:14:49,273 - mmseg - INFO - Iter [6650/40000]	lr: 6.670e-05, eta: 3:08:51, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1402, decode.acc_seg: 94.4405, loss: 0.1402
2025-04-22 19:15:04,389 - mmseg - INFO - Iter [6700/40000]	lr: 6.660e-05, eta: 3:08:25, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1310, decode.acc_seg: 94.4935, loss: 0.1310
2025-04-22 19:15:19,505 - mmseg - INFO - Iter [6750/40000]	lr: 6.650e-05, eta: 3:07:59, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1376, decode.acc_seg: 94.3661, loss: 0.1376
2025-04-22 19:15:34,605 - mmseg - INFO - Iter [6800/40000]	lr: 6.640e-05, eta: 3:07:32, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1412, decode.acc_seg: 94.3431, loss: 0.1412
2025-04-22 19:15:49,695 - mmseg - INFO - Iter [6850/40000]	lr: 6.630e-05, eta: 3:07:07, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1439, decode.acc_seg: 94.5739, loss: 0.1439
2025-04-22 19:16:04,790 - mmseg - INFO - Iter [6900/40000]	lr: 6.620e-05, eta: 3:06:41, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1423, decode.acc_seg: 94.3839, loss: 0.1423
2025-04-22 19:16:19,876 - mmseg - INFO - Iter [6950/40000]	lr: 6.610e-05, eta: 3:06:15, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1474, decode.acc_seg: 94.0196, loss: 0.1474
2025-04-22 19:16:34,975 - mmseg - INFO - Exp name: vpd_config.py
2025-04-22 19:16:34,976 - mmseg - INFO - Iter [7000/40000]	lr: 6.600e-05, eta: 3:05:50, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1305, decode.acc_seg: 94.5147, loss: 0.1305
2025-04-22 19:16:50,816 - mmseg - INFO - Iter [7050/40000]	lr: 6.590e-05, eta: 3:05:28, time: 0.317, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1321, decode.acc_seg: 94.5679, loss: 0.1321
2025-04-22 19:17:05,950 - mmseg - INFO - Iter [7100/40000]	lr: 6.580e-05, eta: 3:05:03, time: 0.303, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1376, decode.acc_seg: 94.2528, loss: 0.1376
2025-04-22 19:17:21,050 - mmseg - INFO - Iter [7150/40000]	lr: 6.570e-05, eta: 3:04:38, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1373, decode.acc_seg: 94.2559, loss: 0.1373
2025-04-22 19:17:36,142 - mmseg - INFO - Iter [7200/40000]	lr: 6.560e-05, eta: 3:04:13, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1424, decode.acc_seg: 94.1382, loss: 0.1424
2025-04-22 19:17:51,232 - mmseg - INFO - Iter [7250/40000]	lr: 6.550e-05, eta: 3:03:48, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1327, decode.acc_seg: 94.5837, loss: 0.1327
2025-04-22 19:18:06,308 - mmseg - INFO - Iter [7300/40000]	lr: 6.540e-05, eta: 3:03:23, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1284, decode.acc_seg: 94.6904, loss: 0.1284
2025-04-22 19:18:21,374 - mmseg - INFO - Iter [7350/40000]	lr: 6.530e-05, eta: 3:02:59, time: 0.301, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1396, decode.acc_seg: 94.5957, loss: 0.1396
2025-04-22 19:18:36,439 - mmseg - INFO - Iter [7400/40000]	lr: 6.520e-05, eta: 3:02:34, time: 0.301, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1481, decode.acc_seg: 93.8648, loss: 0.1481
2025-04-22 19:18:51,517 - mmseg - INFO - Iter [7450/40000]	lr: 6.510e-05, eta: 3:02:10, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1380, decode.acc_seg: 94.3213, loss: 0.1380
2025-04-22 19:19:06,604 - mmseg - INFO - Iter [7500/40000]	lr: 6.500e-05, eta: 3:01:46, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1434, decode.acc_seg: 93.8484, loss: 0.1434
2025-04-22 19:19:21,684 - mmseg - INFO - Iter [7550/40000]	lr: 6.490e-05, eta: 3:01:22, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1370, decode.acc_seg: 94.4735, loss: 0.1370
2025-04-22 19:19:36,749 - mmseg - INFO - Iter [7600/40000]	lr: 6.480e-05, eta: 3:00:58, time: 0.301, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1491, decode.acc_seg: 94.0207, loss: 0.1491
2025-04-22 19:19:51,830 - mmseg - INFO - Iter [7650/40000]	lr: 6.470e-05, eta: 3:00:34, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1473, decode.acc_seg: 93.8888, loss: 0.1473
2025-04-22 19:20:06,912 - mmseg - INFO - Iter [7700/40000]	lr: 6.460e-05, eta: 3:00:10, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1340, decode.acc_seg: 94.2675, loss: 0.1340
2025-04-22 19:20:21,993 - mmseg - INFO - Iter [7750/40000]	lr: 6.450e-05, eta: 2:59:46, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1353, decode.acc_seg: 94.5780, loss: 0.1353
2025-04-22 19:20:37,067 - mmseg - INFO - Iter [7800/40000]	lr: 6.440e-05, eta: 2:59:23, time: 0.301, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1266, decode.acc_seg: 94.8536, loss: 0.1266
2025-04-22 19:20:52,143 - mmseg - INFO - Iter [7850/40000]	lr: 6.430e-05, eta: 2:58:59, time: 0.301, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1517, decode.acc_seg: 93.9621, loss: 0.1517
2025-04-22 19:21:07,217 - mmseg - INFO - Iter [7900/40000]	lr: 6.420e-05, eta: 2:58:36, time: 0.301, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1516, decode.acc_seg: 94.2343, loss: 0.1516
2025-04-22 19:21:22,293 - mmseg - INFO - Iter [7950/40000]	lr: 6.410e-05, eta: 2:58:13, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1424, decode.acc_seg: 94.1067, loss: 0.1424
2025-04-22 19:21:37,362 - mmseg - INFO - Saving checkpoint at 8000 iterations
2025-04-22 19:21:46,841 - mmseg - INFO - Exp name: vpd_config.py
2025-04-22 19:21:46,842 - mmseg - INFO - Iter [8000/40000]	lr: 6.400e-05, eta: 2:58:28, time: 0.491, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1366, decode.acc_seg: 93.9883, loss: 0.1366
2025-04-22 19:25:21,750 - mmseg - INFO - per class results:
2025-04-22 19:25:21,757 - mmseg - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        | 46.86 |  60.4 |
|       building      |  54.6 | 63.91 |
|         sky         | 54.99 | 74.15 |
|        floor        | 32.91 | 78.26 |
|         tree        | 44.81 | 57.79 |
|       ceiling       | 62.03 | 65.54 |
|         road        |  35.5 | 80.54 |
|         bed         | 30.27 | 43.03 |
|      windowpane     | 36.33 | 46.65 |
|        grass        | 24.61 | 36.59 |
|       cabinet       |  29.1 | 38.38 |
|       sidewalk      | 13.53 | 21.62 |
|        person       | 30.92 | 41.58 |
|        earth        | 21.73 | 36.97 |
|         door        | 30.59 | 41.41 |
|        table        |  15.3 | 24.17 |
|       mountain      | 41.02 | 56.67 |
|        plant        | 21.61 |  28.5 |
|       curtain       | 45.57 | 54.37 |
|        chair        | 13.71 | 21.38 |
|         car         | 13.35 | 20.85 |
|        water        | 32.16 | 55.39 |
|       painting      | 32.51 |  41.6 |
|         sofa        | 14.28 | 22.35 |
|        shelf        | 26.82 | 37.48 |
|        house        | 28.54 | 44.37 |
|         sea         |  37.9 | 64.97 |
|        mirror       | 41.11 | 49.79 |
|         rug         | 14.66 | 21.92 |
|        field        | 19.94 | 46.14 |
|       armchair      | 11.61 |  19.2 |
|         seat        | 25.85 | 40.63 |
|        fence        | 10.51 |  16.7 |
|         desk        |  16.3 | 28.58 |
|         rock        | 24.47 | 37.16 |
|       wardrobe      | 37.59 | 50.29 |
|         lamp        | 20.11 | 27.89 |
|       bathtub       | 38.48 | 47.45 |
|       railing       | 12.97 |  20.0 |
|       cushion       |  7.32 | 11.42 |
|         base        | 14.37 | 24.53 |
|         box         | 10.22 | 14.46 |
|        column       | 28.71 | 35.42 |
|      signboard      |  9.47 | 14.55 |
|   chest of drawers  | 15.98 | 23.68 |
|       counter       |  9.46 | 15.99 |
|         sand        | 26.65 | 45.89 |
|         sink        | 16.47 | 24.01 |
|      skyscraper     | 45.55 | 55.92 |
|      fireplace      | 31.87 | 45.28 |
|     refrigerator    | 43.05 | 50.15 |
|      grandstand     | 29.41 | 59.89 |
|         path        |  6.73 | 10.34 |
|        stairs       | 10.69 | 15.35 |
|        runway       | 30.81 | 48.19 |
|         case        |  31.6 | 45.75 |
|      pool table     | 26.11 | 39.04 |
|        pillow       | 10.57 | 16.24 |
|     screen door     | 40.43 | 51.98 |
|       stairway      | 17.21 | 21.82 |
|        river        | 16.65 | 24.69 |
|        bridge       | 18.39 | 30.23 |
|       bookcase      |  26.3 | 35.71 |
|        blind        | 37.21 | 42.16 |
|     coffee table    |  4.15 |  7.43 |
|        toilet       | 18.24 | 26.23 |
|        flower       | 14.27 | 23.71 |
|         book        | 24.75 | 34.82 |
|         hill        |  9.3  | 14.66 |
|        bench        | 14.09 | 20.35 |
|      countertop     | 11.71 |  20.5 |
|        stove        | 23.76 | 33.89 |
|         palm        | 30.41 |  44.4 |
|    kitchen island   |  9.77 | 20.56 |
|       computer      | 33.02 | 47.49 |
|     swivel chair    | 15.84 | 24.22 |
|         boat        | 10.61 | 16.79 |
|         bar         | 25.99 |  38.0 |
|    arcade machine   | 22.45 | 28.03 |
|        hovel        | 15.94 | 18.42 |
|         bus         | 39.57 | 50.72 |
|        towel        |  17.2 | 26.99 |
|        light        | 20.81 | 26.72 |
|        truck        |  6.17 | 11.92 |
|        tower        |  6.82 | 13.71 |
|      chandelier     | 29.37 |  41.8 |
|        awning       |  4.65 |  7.18 |
|     streetlight     | 12.72 | 17.62 |
|        booth        | 24.64 | 41.01 |
| television receiver | 14.24 |  22.1 |
|       airplane      |  9.96 | 15.71 |
|      dirt track     |  0.82 |  4.19 |
|       apparel       | 17.35 | 28.59 |
|         pole        |  8.75 | 11.89 |
|         land        |  3.32 |  4.86 |
|      bannister      |  5.11 |  6.87 |
|      escalator      |  13.3 | 17.23 |
|       ottoman       |  2.0  |  3.42 |
|        bottle       |  7.16 | 11.78 |
|        buffet       | 27.02 | 31.75 |
|        poster       | 28.34 | 41.47 |
|        stage        | 11.12 | 23.99 |
|         van         |  6.07 |  9.4  |
|         ship        | 34.48 | 55.89 |
|       fountain      |  5.38 |  6.41 |
|    conveyer belt    | 27.48 | 51.83 |
|        canopy       | 18.42 | 26.19 |
|        washer       | 35.31 | 40.94 |
|      plaything      |  5.63 |  9.92 |
|    swimming pool    | 19.89 | 30.02 |
|        stool        |  8.28 | 11.17 |
|        barrel       |  0.16 |  0.91 |
|        basket       |  4.7  |  6.75 |
|      waterfall      | 39.93 | 52.78 |
|         tent        | 37.58 | 45.28 |
|         bag         |  2.3  |  3.35 |
|       minibike      | 14.87 | 22.23 |
|        cradle       | 32.98 | 46.95 |
|         oven        | 23.45 | 29.61 |
|         ball        | 16.03 | 25.92 |
|         food        | 26.58 | 33.28 |
|         step        |  0.04 |  0.05 |
|         tank        | 28.22 |  35.4 |
|      trade name     |  6.33 |  8.46 |
|      microwave      | 41.31 | 52.96 |
|         pot         | 10.02 | 13.92 |
|        animal       | 20.76 | 27.07 |
|       bicycle       |  3.94 |  6.81 |
|         lake        | 32.12 | 38.18 |
|      dishwasher     | 14.09 | 18.86 |
|        screen       | 36.82 | 51.01 |
|       blanket       |  2.74 |  3.61 |
|      sculpture      | 18.36 | 32.16 |
|         hood        | 25.91 | 37.92 |
|        sconce       | 12.32 | 18.17 |
|         vase        |  5.26 |  9.02 |
|    traffic light    | 14.99 | 26.16 |
|         tray        |  3.35 |  6.6  |
|        ashcan       |  1.58 |  3.13 |
|         fan         | 20.89 |  30.7 |
|         pier        |  0.4  |  0.65 |
|      crt screen     |  8.01 | 12.49 |
|        plate        | 10.34 | 16.78 |
|       monitor       | 36.32 | 46.88 |
|    bulletin board   | 31.49 | 43.02 |
|        shower       |  0.37 |  1.24 |
|       radiator      |  8.08 | 12.03 |
|        glass        |  0.29 |  0.34 |
|        clock        | 24.44 | 29.96 |
|         flag        | 36.92 | 44.92 |
+---------------------+-------+-------+
2025-04-22 19:25:21,757 - mmseg - INFO - Summary:
2025-04-22 19:25:21,758 - mmseg - INFO - 
+-------+-------+------+
|  aAcc |  mIoU | mAcc |
+-------+-------+------+
| 53.92 | 20.78 | 29.9 |
+-------+-------+------+
2025-04-22 19:25:21,758 - mmseg - INFO - Exp name: vpd_config.py
2025-04-22 19:25:21,759 - mmseg - INFO - Iter(val) [2000]	aAcc: 0.5392, mIoU: 0.2078, mAcc: 0.2990, IoU.wall: 0.4686, IoU.building: 0.5460, IoU.sky: 0.5499, IoU.floor: 0.3291, IoU.tree: 0.4481, IoU.ceiling: 0.6203, IoU.road: 0.3550, IoU.bed : 0.3027, IoU.windowpane: 0.3633, IoU.grass: 0.2461, IoU.cabinet: 0.2910, IoU.sidewalk: 0.1353, IoU.person: 0.3092, IoU.earth: 0.2173, IoU.door: 0.3059, IoU.table: 0.1530, IoU.mountain: 0.4102, IoU.plant: 0.2161, IoU.curtain: 0.4557, IoU.chair: 0.1371, IoU.car: 0.1335, IoU.water: 0.3216, IoU.painting: 0.3251, IoU.sofa: 0.1428, IoU.shelf: 0.2682, IoU.house: 0.2854, IoU.sea: 0.3790, IoU.mirror: 0.4111, IoU.rug: 0.1466, IoU.field: 0.1994, IoU.armchair: 0.1161, IoU.seat: 0.2585, IoU.fence: 0.1051, IoU.desk: 0.1630, IoU.rock: 0.2447, IoU.wardrobe: 0.3759, IoU.lamp: 0.2011, IoU.bathtub: 0.3848, IoU.railing: 0.1297, IoU.cushion: 0.0732, IoU.base: 0.1437, IoU.box: 0.1022, IoU.column: 0.2871, IoU.signboard: 0.0947, IoU.chest of drawers: 0.1598, IoU.counter: 0.0946, IoU.sand: 0.2665, IoU.sink: 0.1647, IoU.skyscraper: 0.4555, IoU.fireplace: 0.3187, IoU.refrigerator: 0.4305, IoU.grandstand: 0.2941, IoU.path: 0.0673, IoU.stairs: 0.1069, IoU.runway: 0.3081, IoU.case: 0.3160, IoU.pool table: 0.2611, IoU.pillow: 0.1057, IoU.screen door: 0.4043, IoU.stairway: 0.1721, IoU.river: 0.1665, IoU.bridge: 0.1839, IoU.bookcase: 0.2630, IoU.blind: 0.3721, IoU.coffee table: 0.0415, IoU.toilet: 0.1824, IoU.flower: 0.1427, IoU.book: 0.2475, IoU.hill: 0.0930, IoU.bench: 0.1409, IoU.countertop: 0.1171, IoU.stove: 0.2376, IoU.palm: 0.3041, IoU.kitchen island: 0.0977, IoU.computer: 0.3302, IoU.swivel chair: 0.1584, IoU.boat: 0.1061, IoU.bar: 0.2599, IoU.arcade machine: 0.2245, IoU.hovel: 0.1594, IoU.bus: 0.3957, IoU.towel: 0.1720, IoU.light: 0.2081, IoU.truck: 0.0617, IoU.tower: 0.0682, IoU.chandelier: 0.2937, IoU.awning: 0.0465, IoU.streetlight: 0.1272, IoU.booth: 0.2464, IoU.television receiver: 0.1424, IoU.airplane: 0.0996, IoU.dirt track: 0.0082, IoU.apparel: 0.1735, IoU.pole: 0.0875, IoU.land: 0.0332, IoU.bannister: 0.0511, IoU.escalator: 0.1330, IoU.ottoman: 0.0200, IoU.bottle: 0.0716, IoU.buffet: 0.2702, IoU.poster: 0.2834, IoU.stage: 0.1112, IoU.van: 0.0607, IoU.ship: 0.3448, IoU.fountain: 0.0538, IoU.conveyer belt: 0.2748, IoU.canopy: 0.1842, IoU.washer: 0.3531, IoU.plaything: 0.0563, IoU.swimming pool: 0.1989, IoU.stool: 0.0828, IoU.barrel: 0.0016, IoU.basket: 0.0470, IoU.waterfall: 0.3993, IoU.tent: 0.3758, IoU.bag: 0.0230, IoU.minibike: 0.1487, IoU.cradle: 0.3298, IoU.oven: 0.2345, IoU.ball: 0.1603, IoU.food: 0.2658, IoU.step: 0.0004, IoU.tank: 0.2822, IoU.trade name: 0.0633, IoU.microwave: 0.4131, IoU.pot: 0.1002, IoU.animal: 0.2076, IoU.bicycle: 0.0394, IoU.lake: 0.3212, IoU.dishwasher: 0.1409, IoU.screen: 0.3682, IoU.blanket: 0.0274, IoU.sculpture: 0.1836, IoU.hood: 0.2591, IoU.sconce: 0.1232, IoU.vase: 0.0526, IoU.traffic light: 0.1499, IoU.tray: 0.0335, IoU.ashcan: 0.0158, IoU.fan: 0.2089, IoU.pier: 0.0040, IoU.crt screen: 0.0801, IoU.plate: 0.1034, IoU.monitor: 0.3632, IoU.bulletin board: 0.3149, IoU.shower: 0.0037, IoU.radiator: 0.0808, IoU.glass: 0.0029, IoU.clock: 0.2444, IoU.flag: 0.3692, Acc.wall: 0.6040, Acc.building: 0.6391, Acc.sky: 0.7415, Acc.floor: 0.7826, Acc.tree: 0.5779, Acc.ceiling: 0.6554, Acc.road: 0.8054, Acc.bed : 0.4303, Acc.windowpane: 0.4665, Acc.grass: 0.3659, Acc.cabinet: 0.3838, Acc.sidewalk: 0.2162, Acc.person: 0.4158, Acc.earth: 0.3697, Acc.door: 0.4141, Acc.table: 0.2417, Acc.mountain: 0.5667, Acc.plant: 0.2850, Acc.curtain: 0.5437, Acc.chair: 0.2138, Acc.car: 0.2085, Acc.water: 0.5539, Acc.painting: 0.4160, Acc.sofa: 0.2235, Acc.shelf: 0.3748, Acc.house: 0.4437, Acc.sea: 0.6497, Acc.mirror: 0.4979, Acc.rug: 0.2192, Acc.field: 0.4614, Acc.armchair: 0.1920, Acc.seat: 0.4063, Acc.fence: 0.1670, Acc.desk: 0.2858, Acc.rock: 0.3716, Acc.wardrobe: 0.5029, Acc.lamp: 0.2789, Acc.bathtub: 0.4745, Acc.railing: 0.2000, Acc.cushion: 0.1142, Acc.base: 0.2453, Acc.box: 0.1446, Acc.column: 0.3542, Acc.signboard: 0.1455, Acc.chest of drawers: 0.2368, Acc.counter: 0.1599, Acc.sand: 0.4589, Acc.sink: 0.2401, Acc.skyscraper: 0.5592, Acc.fireplace: 0.4528, Acc.refrigerator: 0.5015, Acc.grandstand: 0.5989, Acc.path: 0.1034, Acc.stairs: 0.1535, Acc.runway: 0.4819, Acc.case: 0.4575, Acc.pool table: 0.3904, Acc.pillow: 0.1624, Acc.screen door: 0.5198, Acc.stairway: 0.2182, Acc.river: 0.2469, Acc.bridge: 0.3023, Acc.bookcase: 0.3571, Acc.blind: 0.4216, Acc.coffee table: 0.0743, Acc.toilet: 0.2623, Acc.flower: 0.2371, Acc.book: 0.3482, Acc.hill: 0.1466, Acc.bench: 0.2035, Acc.countertop: 0.2050, Acc.stove: 0.3389, Acc.palm: 0.4440, Acc.kitchen island: 0.2056, Acc.computer: 0.4749, Acc.swivel chair: 0.2422, Acc.boat: 0.1679, Acc.bar: 0.3800, Acc.arcade machine: 0.2803, Acc.hovel: 0.1842, Acc.bus: 0.5072, Acc.towel: 0.2699, Acc.light: 0.2672, Acc.truck: 0.1192, Acc.tower: 0.1371, Acc.chandelier: 0.4180, Acc.awning: 0.0718, Acc.streetlight: 0.1762, Acc.booth: 0.4101, Acc.television receiver: 0.2210, Acc.airplane: 0.1571, Acc.dirt track: 0.0419, Acc.apparel: 0.2859, Acc.pole: 0.1189, Acc.land: 0.0486, Acc.bannister: 0.0687, Acc.escalator: 0.1723, Acc.ottoman: 0.0342, Acc.bottle: 0.1178, Acc.buffet: 0.3175, Acc.poster: 0.4147, Acc.stage: 0.2399, Acc.van: 0.0940, Acc.ship: 0.5589, Acc.fountain: 0.0641, Acc.conveyer belt: 0.5183, Acc.canopy: 0.2619, Acc.washer: 0.4094, Acc.plaything: 0.0992, Acc.swimming pool: 0.3002, Acc.stool: 0.1117, Acc.barrel: 0.0091, Acc.basket: 0.0675, Acc.waterfall: 0.5278, Acc.tent: 0.4528, Acc.bag: 0.0335, Acc.minibike: 0.2223, Acc.cradle: 0.4695, Acc.oven: 0.2961, Acc.ball: 0.2592, Acc.food: 0.3328, Acc.step: 0.0005, Acc.tank: 0.3540, Acc.trade name: 0.0846, Acc.microwave: 0.5296, Acc.pot: 0.1392, Acc.animal: 0.2707, Acc.bicycle: 0.0681, Acc.lake: 0.3818, Acc.dishwasher: 0.1886, Acc.screen: 0.5101, Acc.blanket: 0.0361, Acc.sculpture: 0.3216, Acc.hood: 0.3792, Acc.sconce: 0.1817, Acc.vase: 0.0902, Acc.traffic light: 0.2616, Acc.tray: 0.0660, Acc.ashcan: 0.0313, Acc.fan: 0.3070, Acc.pier: 0.0065, Acc.crt screen: 0.1249, Acc.plate: 0.1678, Acc.monitor: 0.4688, Acc.bulletin board: 0.4302, Acc.shower: 0.0124, Acc.radiator: 0.1203, Acc.glass: 0.0034, Acc.clock: 0.2996, Acc.flag: 0.4492
2025-04-22 19:25:37,589 - mmseg - INFO - Iter [8050/40000]	lr: 6.390e-05, eta: 3:12:20, time: 4.615, data_time: 4.306, memory: 75933, decode.loss_ce: 0.1531, decode.acc_seg: 94.0109, loss: 0.1531
2025-04-22 19:25:52,671 - mmseg - INFO - Iter [8100/40000]	lr: 6.380e-05, eta: 3:11:51, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1498, decode.acc_seg: 93.6441, loss: 0.1498
2025-04-22 19:26:07,797 - mmseg - INFO - Iter [8150/40000]	lr: 6.370e-05, eta: 3:11:21, time: 0.303, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1418, decode.acc_seg: 94.0687, loss: 0.1418
2025-04-22 19:26:22,925 - mmseg - INFO - Iter [8200/40000]	lr: 6.360e-05, eta: 3:10:52, time: 0.303, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1430, decode.acc_seg: 94.1957, loss: 0.1430
2025-04-22 19:26:38,048 - mmseg - INFO - Iter [8250/40000]	lr: 6.350e-05, eta: 3:10:23, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1241, decode.acc_seg: 94.8843, loss: 0.1241
2025-04-22 19:26:53,195 - mmseg - INFO - Iter [8300/40000]	lr: 6.340e-05, eta: 3:09:54, time: 0.303, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1360, decode.acc_seg: 94.5976, loss: 0.1360
2025-04-22 19:27:08,310 - mmseg - INFO - Iter [8350/40000]	lr: 6.330e-05, eta: 3:09:25, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1288, decode.acc_seg: 94.6677, loss: 0.1288
2025-04-22 19:27:23,460 - mmseg - INFO - Iter [8400/40000]	lr: 6.320e-05, eta: 3:08:57, time: 0.303, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1443, decode.acc_seg: 94.4358, loss: 0.1443
2025-04-22 19:27:38,627 - mmseg - INFO - Iter [8450/40000]	lr: 6.310e-05, eta: 3:08:28, time: 0.303, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1311, decode.acc_seg: 94.5681, loss: 0.1311
2025-04-22 19:27:53,771 - mmseg - INFO - Iter [8500/40000]	lr: 6.300e-05, eta: 3:08:00, time: 0.303, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1314, decode.acc_seg: 94.4343, loss: 0.1314
2025-04-22 19:28:08,911 - mmseg - INFO - Iter [8550/40000]	lr: 6.290e-05, eta: 3:07:32, time: 0.303, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1403, decode.acc_seg: 94.2456, loss: 0.1403
2025-04-22 19:28:24,019 - mmseg - INFO - Iter [8600/40000]	lr: 6.280e-05, eta: 3:07:04, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1243, decode.acc_seg: 94.6553, loss: 0.1243
2025-04-22 19:28:39,143 - mmseg - INFO - Iter [8650/40000]	lr: 6.270e-05, eta: 3:06:36, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1379, decode.acc_seg: 94.2169, loss: 0.1379
2025-04-22 19:28:54,260 - mmseg - INFO - Iter [8700/40000]	lr: 6.260e-05, eta: 3:06:08, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1292, decode.acc_seg: 94.6172, loss: 0.1292
2025-04-22 19:29:09,457 - mmseg - INFO - Iter [8750/40000]	lr: 6.250e-05, eta: 3:05:41, time: 0.304, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1480, decode.acc_seg: 93.6752, loss: 0.1480
2025-04-22 19:29:24,596 - mmseg - INFO - Iter [8800/40000]	lr: 6.240e-05, eta: 3:05:14, time: 0.303, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1587, decode.acc_seg: 93.2513, loss: 0.1587
2025-04-22 19:29:39,733 - mmseg - INFO - Iter [8850/40000]	lr: 6.230e-05, eta: 3:04:47, time: 0.303, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1489, decode.acc_seg: 94.0008, loss: 0.1489
2025-04-22 19:29:54,877 - mmseg - INFO - Iter [8900/40000]	lr: 6.220e-05, eta: 3:04:20, time: 0.303, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1355, decode.acc_seg: 94.3670, loss: 0.1355
2025-04-22 19:30:10,022 - mmseg - INFO - Iter [8950/40000]	lr: 6.210e-05, eta: 3:03:53, time: 0.303, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1677, decode.acc_seg: 92.8849, loss: 0.1677
2025-04-22 19:30:25,145 - mmseg - INFO - Exp name: vpd_config.py
2025-04-22 19:30:25,146 - mmseg - INFO - Iter [9000/40000]	lr: 6.200e-05, eta: 3:03:26, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1463, decode.acc_seg: 94.1967, loss: 0.1463
2025-04-22 19:30:40,904 - mmseg - INFO - Iter [9050/40000]	lr: 6.190e-05, eta: 3:03:01, time: 0.315, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1316, decode.acc_seg: 94.5838, loss: 0.1316
2025-04-22 19:30:56,048 - mmseg - INFO - Iter [9100/40000]	lr: 6.180e-05, eta: 3:02:35, time: 0.303, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1395, decode.acc_seg: 93.9216, loss: 0.1395
2025-04-22 19:31:11,177 - mmseg - INFO - Iter [9150/40000]	lr: 6.170e-05, eta: 3:02:08, time: 0.303, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1293, decode.acc_seg: 94.8982, loss: 0.1293
2025-04-22 19:31:26,303 - mmseg - INFO - Iter [9200/40000]	lr: 6.160e-05, eta: 3:01:42, time: 0.303, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1406, decode.acc_seg: 94.1819, loss: 0.1406
2025-04-22 19:31:41,436 - mmseg - INFO - Iter [9250/40000]	lr: 6.150e-05, eta: 3:01:16, time: 0.303, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1347, decode.acc_seg: 94.3079, loss: 0.1347
2025-04-22 19:31:56,571 - mmseg - INFO - Iter [9300/40000]	lr: 6.140e-05, eta: 3:00:49, time: 0.303, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1350, decode.acc_seg: 94.2890, loss: 0.1350
2025-04-22 19:32:11,693 - mmseg - INFO - Iter [9350/40000]	lr: 6.130e-05, eta: 3:00:23, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1306, decode.acc_seg: 94.5159, loss: 0.1306
2025-04-22 19:32:26,802 - mmseg - INFO - Iter [9400/40000]	lr: 6.120e-05, eta: 2:59:57, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1398, decode.acc_seg: 94.3922, loss: 0.1398
2025-04-22 19:32:41,909 - mmseg - INFO - Iter [9450/40000]	lr: 6.110e-05, eta: 2:59:32, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1368, decode.acc_seg: 94.2119, loss: 0.1368
2025-04-22 19:32:57,002 - mmseg - INFO - Iter [9500/40000]	lr: 6.100e-05, eta: 2:59:06, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1475, decode.acc_seg: 94.0646, loss: 0.1475
2025-04-22 19:33:12,095 - mmseg - INFO - Iter [9550/40000]	lr: 6.090e-05, eta: 2:58:40, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1290, decode.acc_seg: 94.6689, loss: 0.1290
2025-04-22 19:33:27,201 - mmseg - INFO - Iter [9600/40000]	lr: 6.080e-05, eta: 2:58:15, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1379, decode.acc_seg: 94.3957, loss: 0.1379
2025-04-22 19:33:42,310 - mmseg - INFO - Iter [9650/40000]	lr: 6.070e-05, eta: 2:57:49, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1395, decode.acc_seg: 94.3598, loss: 0.1395
2025-04-22 19:33:57,406 - mmseg - INFO - Iter [9700/40000]	lr: 6.060e-05, eta: 2:57:24, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1417, decode.acc_seg: 94.3527, loss: 0.1417
2025-04-22 19:34:12,536 - mmseg - INFO - Iter [9750/40000]	lr: 6.050e-05, eta: 2:56:59, time: 0.303, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1448, decode.acc_seg: 93.8201, loss: 0.1448
2025-04-22 19:34:27,630 - mmseg - INFO - Iter [9800/40000]	lr: 6.040e-05, eta: 2:56:34, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1328, decode.acc_seg: 94.1868, loss: 0.1328
2025-04-22 19:34:42,723 - mmseg - INFO - Iter [9850/40000]	lr: 6.030e-05, eta: 2:56:09, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1273, decode.acc_seg: 94.6317, loss: 0.1273
2025-04-22 19:34:57,822 - mmseg - INFO - Iter [9900/40000]	lr: 6.020e-05, eta: 2:55:44, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1246, decode.acc_seg: 94.8136, loss: 0.1246
2025-04-22 19:35:12,914 - mmseg - INFO - Iter [9950/40000]	lr: 6.010e-05, eta: 2:55:19, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1398, decode.acc_seg: 94.2046, loss: 0.1398
2025-04-22 19:35:28,009 - mmseg - INFO - Exp name: vpd_config.py
2025-04-22 19:35:28,010 - mmseg - INFO - Iter [10000/40000]	lr: 6.000e-05, eta: 2:54:54, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1382, decode.acc_seg: 94.3062, loss: 0.1382
2025-04-22 19:35:43,867 - mmseg - INFO - Iter [10050/40000]	lr: 5.990e-05, eta: 2:54:32, time: 0.317, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1385, decode.acc_seg: 94.3559, loss: 0.1385
2025-04-22 19:35:58,978 - mmseg - INFO - Iter [10100/40000]	lr: 5.980e-05, eta: 2:54:07, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1303, decode.acc_seg: 94.5559, loss: 0.1303
2025-04-22 19:36:14,082 - mmseg - INFO - Iter [10150/40000]	lr: 5.970e-05, eta: 2:53:43, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1325, decode.acc_seg: 94.6952, loss: 0.1325
2025-04-22 19:36:29,163 - mmseg - INFO - Iter [10200/40000]	lr: 5.960e-05, eta: 2:53:18, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1308, decode.acc_seg: 94.8019, loss: 0.1308
2025-04-22 19:36:44,250 - mmseg - INFO - Iter [10250/40000]	lr: 5.950e-05, eta: 2:52:54, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1454, decode.acc_seg: 94.1150, loss: 0.1454
2025-04-22 19:36:59,337 - mmseg - INFO - Iter [10300/40000]	lr: 5.940e-05, eta: 2:52:30, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1290, decode.acc_seg: 94.6676, loss: 0.1290
2025-04-22 19:37:14,427 - mmseg - INFO - Iter [10350/40000]	lr: 5.930e-05, eta: 2:52:06, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1247, decode.acc_seg: 94.9347, loss: 0.1247
2025-04-22 19:37:29,518 - mmseg - INFO - Iter [10400/40000]	lr: 5.920e-05, eta: 2:51:42, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1451, decode.acc_seg: 93.9381, loss: 0.1451
2025-04-22 19:37:44,605 - mmseg - INFO - Iter [10450/40000]	lr: 5.910e-05, eta: 2:51:18, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1257, decode.acc_seg: 94.6090, loss: 0.1257
2025-04-22 19:37:59,686 - mmseg - INFO - Iter [10500/40000]	lr: 5.900e-05, eta: 2:50:54, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1368, decode.acc_seg: 94.2543, loss: 0.1368
2025-04-22 19:38:14,774 - mmseg - INFO - Iter [10550/40000]	lr: 5.890e-05, eta: 2:50:30, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1389, decode.acc_seg: 94.1183, loss: 0.1389
2025-04-22 19:38:29,851 - mmseg - INFO - Iter [10600/40000]	lr: 5.880e-05, eta: 2:50:06, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1435, decode.acc_seg: 94.2489, loss: 0.1435
2025-04-22 19:38:44,940 - mmseg - INFO - Iter [10650/40000]	lr: 5.870e-05, eta: 2:49:43, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1256, decode.acc_seg: 94.5287, loss: 0.1256
2025-04-22 19:39:00,034 - mmseg - INFO - Iter [10700/40000]	lr: 5.860e-05, eta: 2:49:19, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1367, decode.acc_seg: 94.3705, loss: 0.1367
2025-04-22 19:39:15,122 - mmseg - INFO - Iter [10750/40000]	lr: 5.850e-05, eta: 2:48:56, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1386, decode.acc_seg: 94.1033, loss: 0.1386
2025-04-22 19:39:30,208 - mmseg - INFO - Iter [10800/40000]	lr: 5.840e-05, eta: 2:48:32, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1243, decode.acc_seg: 94.6328, loss: 0.1243
2025-04-22 19:39:45,307 - mmseg - INFO - Iter [10850/40000]	lr: 5.830e-05, eta: 2:48:09, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1548, decode.acc_seg: 93.6162, loss: 0.1548
2025-04-22 19:40:00,393 - mmseg - INFO - Iter [10900/40000]	lr: 5.820e-05, eta: 2:47:46, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1466, decode.acc_seg: 93.8524, loss: 0.1466
2025-04-22 19:40:15,487 - mmseg - INFO - Iter [10950/40000]	lr: 5.810e-05, eta: 2:47:23, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1332, decode.acc_seg: 94.3398, loss: 0.1332
2025-04-22 19:40:30,570 - mmseg - INFO - Exp name: vpd_config.py
2025-04-22 19:40:30,571 - mmseg - INFO - Iter [11000/40000]	lr: 5.800e-05, eta: 2:47:00, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1351, decode.acc_seg: 94.3503, loss: 0.1351
2025-04-22 19:40:46,410 - mmseg - INFO - Iter [11050/40000]	lr: 5.790e-05, eta: 2:46:39, time: 0.317, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1181, decode.acc_seg: 94.8699, loss: 0.1181
2025-04-22 19:41:01,561 - mmseg - INFO - Iter [11100/40000]	lr: 5.780e-05, eta: 2:46:16, time: 0.303, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1399, decode.acc_seg: 94.1994, loss: 0.1399
2025-04-22 19:41:16,703 - mmseg - INFO - Iter [11150/40000]	lr: 5.770e-05, eta: 2:45:53, time: 0.303, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1385, decode.acc_seg: 94.1499, loss: 0.1385
2025-04-22 19:41:31,823 - mmseg - INFO - Iter [11200/40000]	lr: 5.760e-05, eta: 2:45:30, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1308, decode.acc_seg: 94.5727, loss: 0.1308
2025-04-22 19:41:46,924 - mmseg - INFO - Iter [11250/40000]	lr: 5.750e-05, eta: 2:45:08, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1435, decode.acc_seg: 93.9573, loss: 0.1435
2025-04-22 19:42:02,033 - mmseg - INFO - Iter [11300/40000]	lr: 5.740e-05, eta: 2:44:45, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1378, decode.acc_seg: 94.1242, loss: 0.1378
2025-04-22 19:42:17,144 - mmseg - INFO - Iter [11350/40000]	lr: 5.730e-05, eta: 2:44:23, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1527, decode.acc_seg: 93.6624, loss: 0.1527
2025-04-22 19:42:32,254 - mmseg - INFO - Iter [11400/40000]	lr: 5.720e-05, eta: 2:44:00, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1342, decode.acc_seg: 94.2878, loss: 0.1342
2025-04-22 19:42:47,349 - mmseg - INFO - Iter [11450/40000]	lr: 5.710e-05, eta: 2:43:38, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1425, decode.acc_seg: 94.2062, loss: 0.1425
2025-04-22 19:43:02,457 - mmseg - INFO - Iter [11500/40000]	lr: 5.700e-05, eta: 2:43:15, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1546, decode.acc_seg: 93.6710, loss: 0.1546
2025-04-22 19:43:17,552 - mmseg - INFO - Iter [11550/40000]	lr: 5.690e-05, eta: 2:42:53, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1185, decode.acc_seg: 94.9827, loss: 0.1185
2025-04-22 19:43:32,650 - mmseg - INFO - Iter [11600/40000]	lr: 5.680e-05, eta: 2:42:31, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1465, decode.acc_seg: 93.9418, loss: 0.1465
2025-04-22 19:43:47,749 - mmseg - INFO - Iter [11650/40000]	lr: 5.670e-05, eta: 2:42:08, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1550, decode.acc_seg: 94.1351, loss: 0.1550
2025-04-22 19:44:02,841 - mmseg - INFO - Iter [11700/40000]	lr: 5.660e-05, eta: 2:41:46, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1486, decode.acc_seg: 94.0020, loss: 0.1486
2025-04-22 19:44:17,948 - mmseg - INFO - Iter [11750/40000]	lr: 5.650e-05, eta: 2:41:24, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1397, decode.acc_seg: 94.0521, loss: 0.1397
2025-04-22 19:44:33,039 - mmseg - INFO - Iter [11800/40000]	lr: 5.640e-05, eta: 2:41:02, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1410, decode.acc_seg: 94.2743, loss: 0.1410
2025-04-22 19:44:48,127 - mmseg - INFO - Iter [11850/40000]	lr: 5.630e-05, eta: 2:40:40, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1289, decode.acc_seg: 94.7285, loss: 0.1289
2025-04-22 19:45:03,216 - mmseg - INFO - Iter [11900/40000]	lr: 5.620e-05, eta: 2:40:18, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1537, decode.acc_seg: 93.6561, loss: 0.1537
2025-04-22 19:45:18,318 - mmseg - INFO - Iter [11950/40000]	lr: 5.610e-05, eta: 2:39:56, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1409, decode.acc_seg: 93.9362, loss: 0.1409
2025-04-22 19:45:33,392 - mmseg - INFO - Saving checkpoint at 12000 iterations
2025-04-22 19:45:42,702 - mmseg - INFO - Exp name: vpd_config.py
2025-04-22 19:45:42,703 - mmseg - INFO - Iter [12000/40000]	lr: 5.600e-05, eta: 2:39:56, time: 0.488, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1491, decode.acc_seg: 94.2839, loss: 0.1491
2025-04-22 19:49:16,752 - mmseg - INFO - per class results:
2025-04-22 19:49:16,759 - mmseg - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        | 42.68 | 60.14 |
|       building      | 54.43 |  64.1 |
|         sky         |  54.9 | 73.92 |
|        floor        | 31.92 | 76.43 |
|         tree        | 45.57 |  58.0 |
|       ceiling       | 62.68 | 67.18 |
|         road        | 32.94 | 61.48 |
|         bed         | 31.34 | 45.19 |
|      windowpane     | 35.99 | 45.57 |
|        grass        | 24.78 | 37.31 |
|       cabinet       | 29.08 | 38.84 |
|       sidewalk      | 18.07 | 35.45 |
|        person       | 30.67 | 42.01 |
|        earth        | 20.88 | 33.09 |
|         door        | 30.55 | 41.43 |
|        table        | 15.02 | 23.65 |
|       mountain      |  40.4 |  54.9 |
|        plant        | 21.03 | 27.16 |
|       curtain       | 45.23 | 55.16 |
|        chair        | 13.38 | 20.38 |
|         car         | 13.39 | 20.97 |
|        water        | 31.14 | 51.89 |
|       painting      | 32.61 | 42.52 |
|         sofa        | 15.08 | 24.14 |
|        shelf        | 26.92 | 37.61 |
|        house        | 27.49 |  42.4 |
|         sea         | 38.44 | 62.12 |
|        mirror       | 41.39 | 50.91 |
|         rug         | 14.53 | 21.12 |
|        field        | 20.51 | 40.22 |
|       armchair      | 11.52 | 20.56 |
|         seat        | 25.43 | 40.01 |
|        fence        | 10.26 | 15.52 |
|         desk        | 16.43 | 27.04 |
|         rock        | 24.71 | 40.04 |
|       wardrobe      | 36.26 | 47.16 |
|         lamp        | 20.49 | 30.44 |
|       bathtub       | 38.28 | 47.42 |
|       railing       | 12.45 | 19.69 |
|       cushion       |  7.4  | 11.68 |
|         base        | 14.14 | 28.73 |
|         box         |  9.33 | 13.02 |
|        column       | 28.61 | 36.26 |
|      signboard      | 10.07 | 14.41 |
|   chest of drawers  |  15.7 | 23.13 |
|       counter       | 10.44 | 18.44 |
|         sand        | 28.42 | 45.38 |
|         sink        | 16.66 | 24.16 |
|      skyscraper     | 47.35 | 61.82 |
|      fireplace      |  31.5 | 44.81 |
|     refrigerator    | 42.88 | 49.68 |
|      grandstand     | 30.04 | 60.18 |
|         path        |  5.5  |  7.92 |
|        stairs       |  8.08 | 10.63 |
|        runway       | 31.62 | 50.23 |
|         case        | 33.08 | 48.15 |
|      pool table     | 26.12 |  38.7 |
|        pillow       |  9.87 | 14.23 |
|     screen door     | 37.06 | 46.32 |
|       stairway      | 15.98 | 21.85 |
|        river        | 16.25 |  25.0 |
|        bridge       | 19.61 |  29.4 |
|       bookcase      | 24.16 | 32.71 |
|        blind        | 37.45 |  43.3 |
|     coffee table    |  4.16 |  7.59 |
|        toilet       | 17.91 | 25.77 |
|        flower       |  14.0 | 23.13 |
|         book        | 24.66 | 36.85 |
|         hill        |  8.98 | 14.67 |
|        bench        | 14.16 | 20.47 |
|      countertop     | 11.68 | 19.83 |
|        stove        | 23.17 | 33.31 |
|         palm        | 30.56 | 47.42 |
|    kitchen island   |  9.54 |  20.7 |
|       computer      | 33.16 | 47.62 |
|     swivel chair    | 15.12 | 24.46 |
|         boat        | 10.65 | 17.43 |
|         bar         |  24.5 | 35.54 |
|    arcade machine   | 21.22 | 26.06 |
|        hovel        | 16.57 | 19.78 |
|         bus         | 39.68 | 50.34 |
|        towel        |  16.8 | 27.15 |
|        light        | 21.21 | 27.54 |
|        truck        |  6.15 | 12.04 |
|        tower        |  5.61 | 10.57 |
|      chandelier     | 29.81 |  42.6 |
|        awning       |  4.88 |  7.29 |
|     streetlight     | 12.62 | 16.65 |
|        booth        | 21.59 | 30.43 |
| television receiver | 14.63 | 23.06 |
|       airplane      |  9.18 |  14.8 |
|      dirt track     |  2.02 | 11.85 |
|       apparel       | 17.45 | 25.88 |
|         pole        | 12.62 | 17.92 |
|         land        |  3.31 |  5.02 |
|      bannister      |  5.76 |  8.6  |
|      escalator      | 11.79 | 14.31 |
|       ottoman       |  1.98 |  3.29 |
|        bottle       |  7.17 | 10.91 |
|        buffet       | 26.84 |  32.2 |
|        poster       | 30.73 | 36.92 |
|        stage        | 10.52 | 22.42 |
|         van         |  6.68 | 11.04 |
|         ship        | 33.22 | 54.57 |
|       fountain      |  7.11 |  9.06 |
|    conveyer belt    | 28.61 | 46.37 |
|        canopy       |  17.3 | 23.55 |
|        washer       | 34.76 |  39.8 |
|      plaything      |  5.67 | 10.95 |
|    swimming pool    | 18.37 | 28.79 |
|        stool        |  8.47 |  12.7 |
|        barrel       |  0.68 |  3.08 |
|        basket       |  4.72 |  6.98 |
|      waterfall      | 38.58 | 52.86 |
|         tent        | 37.04 | 45.54 |
|         bag         |  1.09 |  1.3  |
|       minibike      | 14.88 | 21.68 |
|        cradle       | 32.66 | 46.51 |
|         oven        | 25.81 | 35.09 |
|         ball        | 16.09 | 23.27 |
|         food        | 24.54 | 30.25 |
|         step        |  0.0  |  0.0  |
|         tank        | 27.35 | 39.96 |
|      trade name     |  6.0  |  7.51 |
|      microwave      | 40.62 | 51.07 |
|         pot         | 10.53 | 15.37 |
|        animal       | 20.87 | 27.24 |
|       bicycle       |  3.92 |  6.54 |
|         lake        | 33.16 | 39.19 |
|      dishwasher     | 13.63 |  18.8 |
|        screen       | 37.22 | 53.31 |
|       blanket       |  2.79 |  3.55 |
|      sculpture      | 18.01 | 27.75 |
|         hood        | 25.82 |  38.0 |
|        sconce       | 11.38 | 16.27 |
|         vase        |  5.41 |  9.29 |
|    traffic light    | 14.42 | 21.67 |
|         tray        |  3.28 |  6.44 |
|        ashcan       |  1.23 |  2.05 |
|         fan         | 19.91 | 29.68 |
|         pier        |  0.33 |  0.56 |
|      crt screen     |  8.28 | 12.22 |
|        plate        | 10.43 | 16.45 |
|       monitor       | 35.41 | 47.58 |
|    bulletin board   | 33.33 | 42.04 |
|        shower       |  0.28 |  0.73 |
|       radiator      |  8.97 | 14.35 |
|        glass        |  0.28 |  0.33 |
|        clock        | 23.04 | 30.15 |
|         flag        | 36.15 | 43.49 |
+---------------------+-------+-------+
2025-04-22 19:49:16,759 - mmseg - INFO - Summary:
2025-04-22 19:49:16,759 - mmseg - INFO - 
+-------+-------+------+
|  aAcc |  mIoU | mAcc |
+-------+-------+------+
| 53.12 | 20.65 | 29.6 |
+-------+-------+------+
2025-04-22 19:49:16,760 - mmseg - INFO - Exp name: vpd_config.py
2025-04-22 19:49:16,760 - mmseg - INFO - Iter(val) [2000]	aAcc: 0.5312, mIoU: 0.2065, mAcc: 0.2960, IoU.wall: 0.4268, IoU.building: 0.5443, IoU.sky: 0.5490, IoU.floor: 0.3192, IoU.tree: 0.4557, IoU.ceiling: 0.6268, IoU.road: 0.3294, IoU.bed : 0.3134, IoU.windowpane: 0.3599, IoU.grass: 0.2478, IoU.cabinet: 0.2908, IoU.sidewalk: 0.1807, IoU.person: 0.3067, IoU.earth: 0.2088, IoU.door: 0.3055, IoU.table: 0.1502, IoU.mountain: 0.4040, IoU.plant: 0.2103, IoU.curtain: 0.4523, IoU.chair: 0.1338, IoU.car: 0.1339, IoU.water: 0.3114, IoU.painting: 0.3261, IoU.sofa: 0.1508, IoU.shelf: 0.2692, IoU.house: 0.2749, IoU.sea: 0.3844, IoU.mirror: 0.4139, IoU.rug: 0.1453, IoU.field: 0.2051, IoU.armchair: 0.1152, IoU.seat: 0.2543, IoU.fence: 0.1026, IoU.desk: 0.1643, IoU.rock: 0.2471, IoU.wardrobe: 0.3626, IoU.lamp: 0.2049, IoU.bathtub: 0.3828, IoU.railing: 0.1245, IoU.cushion: 0.0740, IoU.base: 0.1414, IoU.box: 0.0933, IoU.column: 0.2861, IoU.signboard: 0.1007, IoU.chest of drawers: 0.1570, IoU.counter: 0.1044, IoU.sand: 0.2842, IoU.sink: 0.1666, IoU.skyscraper: 0.4735, IoU.fireplace: 0.3150, IoU.refrigerator: 0.4288, IoU.grandstand: 0.3004, IoU.path: 0.0550, IoU.stairs: 0.0808, IoU.runway: 0.3162, IoU.case: 0.3308, IoU.pool table: 0.2612, IoU.pillow: 0.0987, IoU.screen door: 0.3706, IoU.stairway: 0.1598, IoU.river: 0.1625, IoU.bridge: 0.1961, IoU.bookcase: 0.2416, IoU.blind: 0.3745, IoU.coffee table: 0.0416, IoU.toilet: 0.1791, IoU.flower: 0.1400, IoU.book: 0.2466, IoU.hill: 0.0898, IoU.bench: 0.1416, IoU.countertop: 0.1168, IoU.stove: 0.2317, IoU.palm: 0.3056, IoU.kitchen island: 0.0954, IoU.computer: 0.3316, IoU.swivel chair: 0.1512, IoU.boat: 0.1065, IoU.bar: 0.2450, IoU.arcade machine: 0.2122, IoU.hovel: 0.1657, IoU.bus: 0.3968, IoU.towel: 0.1680, IoU.light: 0.2121, IoU.truck: 0.0615, IoU.tower: 0.0561, IoU.chandelier: 0.2981, IoU.awning: 0.0488, IoU.streetlight: 0.1262, IoU.booth: 0.2159, IoU.television receiver: 0.1463, IoU.airplane: 0.0918, IoU.dirt track: 0.0202, IoU.apparel: 0.1745, IoU.pole: 0.1262, IoU.land: 0.0331, IoU.bannister: 0.0576, IoU.escalator: 0.1179, IoU.ottoman: 0.0198, IoU.bottle: 0.0717, IoU.buffet: 0.2684, IoU.poster: 0.3073, IoU.stage: 0.1052, IoU.van: 0.0668, IoU.ship: 0.3322, IoU.fountain: 0.0711, IoU.conveyer belt: 0.2861, IoU.canopy: 0.1730, IoU.washer: 0.3476, IoU.plaything: 0.0567, IoU.swimming pool: 0.1837, IoU.stool: 0.0847, IoU.barrel: 0.0068, IoU.basket: 0.0472, IoU.waterfall: 0.3858, IoU.tent: 0.3704, IoU.bag: 0.0109, IoU.minibike: 0.1488, IoU.cradle: 0.3266, IoU.oven: 0.2581, IoU.ball: 0.1609, IoU.food: 0.2454, IoU.step: 0.0000, IoU.tank: 0.2735, IoU.trade name: 0.0600, IoU.microwave: 0.4062, IoU.pot: 0.1053, IoU.animal: 0.2087, IoU.bicycle: 0.0392, IoU.lake: 0.3316, IoU.dishwasher: 0.1363, IoU.screen: 0.3722, IoU.blanket: 0.0279, IoU.sculpture: 0.1801, IoU.hood: 0.2582, IoU.sconce: 0.1138, IoU.vase: 0.0541, IoU.traffic light: 0.1442, IoU.tray: 0.0328, IoU.ashcan: 0.0123, IoU.fan: 0.1991, IoU.pier: 0.0033, IoU.crt screen: 0.0828, IoU.plate: 0.1043, IoU.monitor: 0.3541, IoU.bulletin board: 0.3333, IoU.shower: 0.0028, IoU.radiator: 0.0897, IoU.glass: 0.0028, IoU.clock: 0.2304, IoU.flag: 0.3615, Acc.wall: 0.6014, Acc.building: 0.6410, Acc.sky: 0.7392, Acc.floor: 0.7643, Acc.tree: 0.5800, Acc.ceiling: 0.6718, Acc.road: 0.6148, Acc.bed : 0.4519, Acc.windowpane: 0.4557, Acc.grass: 0.3731, Acc.cabinet: 0.3884, Acc.sidewalk: 0.3545, Acc.person: 0.4201, Acc.earth: 0.3309, Acc.door: 0.4143, Acc.table: 0.2365, Acc.mountain: 0.5490, Acc.plant: 0.2716, Acc.curtain: 0.5516, Acc.chair: 0.2038, Acc.car: 0.2097, Acc.water: 0.5189, Acc.painting: 0.4252, Acc.sofa: 0.2414, Acc.shelf: 0.3761, Acc.house: 0.4240, Acc.sea: 0.6212, Acc.mirror: 0.5091, Acc.rug: 0.2112, Acc.field: 0.4022, Acc.armchair: 0.2056, Acc.seat: 0.4001, Acc.fence: 0.1552, Acc.desk: 0.2704, Acc.rock: 0.4004, Acc.wardrobe: 0.4716, Acc.lamp: 0.3044, Acc.bathtub: 0.4742, Acc.railing: 0.1969, Acc.cushion: 0.1168, Acc.base: 0.2873, Acc.box: 0.1302, Acc.column: 0.3626, Acc.signboard: 0.1441, Acc.chest of drawers: 0.2313, Acc.counter: 0.1844, Acc.sand: 0.4538, Acc.sink: 0.2416, Acc.skyscraper: 0.6182, Acc.fireplace: 0.4481, Acc.refrigerator: 0.4968, Acc.grandstand: 0.6018, Acc.path: 0.0792, Acc.stairs: 0.1063, Acc.runway: 0.5023, Acc.case: 0.4815, Acc.pool table: 0.3870, Acc.pillow: 0.1423, Acc.screen door: 0.4632, Acc.stairway: 0.2185, Acc.river: 0.2500, Acc.bridge: 0.2940, Acc.bookcase: 0.3271, Acc.blind: 0.4330, Acc.coffee table: 0.0759, Acc.toilet: 0.2577, Acc.flower: 0.2313, Acc.book: 0.3685, Acc.hill: 0.1467, Acc.bench: 0.2047, Acc.countertop: 0.1983, Acc.stove: 0.3331, Acc.palm: 0.4742, Acc.kitchen island: 0.2070, Acc.computer: 0.4762, Acc.swivel chair: 0.2446, Acc.boat: 0.1743, Acc.bar: 0.3554, Acc.arcade machine: 0.2606, Acc.hovel: 0.1978, Acc.bus: 0.5034, Acc.towel: 0.2715, Acc.light: 0.2754, Acc.truck: 0.1204, Acc.tower: 0.1057, Acc.chandelier: 0.4260, Acc.awning: 0.0729, Acc.streetlight: 0.1665, Acc.booth: 0.3043, Acc.television receiver: 0.2306, Acc.airplane: 0.1480, Acc.dirt track: 0.1185, Acc.apparel: 0.2588, Acc.pole: 0.1792, Acc.land: 0.0502, Acc.bannister: 0.0860, Acc.escalator: 0.1431, Acc.ottoman: 0.0329, Acc.bottle: 0.1091, Acc.buffet: 0.3220, Acc.poster: 0.3692, Acc.stage: 0.2242, Acc.van: 0.1104, Acc.ship: 0.5457, Acc.fountain: 0.0906, Acc.conveyer belt: 0.4637, Acc.canopy: 0.2355, Acc.washer: 0.3980, Acc.plaything: 0.1095, Acc.swimming pool: 0.2879, Acc.stool: 0.1270, Acc.barrel: 0.0308, Acc.basket: 0.0698, Acc.waterfall: 0.5286, Acc.tent: 0.4554, Acc.bag: 0.0130, Acc.minibike: 0.2168, Acc.cradle: 0.4651, Acc.oven: 0.3509, Acc.ball: 0.2327, Acc.food: 0.3025, Acc.step: 0.0000, Acc.tank: 0.3996, Acc.trade name: 0.0751, Acc.microwave: 0.5107, Acc.pot: 0.1537, Acc.animal: 0.2724, Acc.bicycle: 0.0654, Acc.lake: 0.3919, Acc.dishwasher: 0.1880, Acc.screen: 0.5331, Acc.blanket: 0.0355, Acc.sculpture: 0.2775, Acc.hood: 0.3800, Acc.sconce: 0.1627, Acc.vase: 0.0929, Acc.traffic light: 0.2167, Acc.tray: 0.0644, Acc.ashcan: 0.0205, Acc.fan: 0.2968, Acc.pier: 0.0056, Acc.crt screen: 0.1222, Acc.plate: 0.1645, Acc.monitor: 0.4758, Acc.bulletin board: 0.4204, Acc.shower: 0.0073, Acc.radiator: 0.1435, Acc.glass: 0.0033, Acc.clock: 0.3015, Acc.flag: 0.4349
2025-04-22 19:49:32,512 - mmseg - INFO - Iter [12050/40000]	lr: 5.590e-05, eta: 2:47:52, time: 4.596, data_time: 4.289, memory: 75933, decode.loss_ce: 0.1386, decode.acc_seg: 94.2284, loss: 0.1386
2025-04-22 19:49:47,626 - mmseg - INFO - Iter [12100/40000]	lr: 5.580e-05, eta: 2:47:28, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1667, decode.acc_seg: 93.8650, loss: 0.1667
2025-04-22 19:50:02,767 - mmseg - INFO - Iter [12150/40000]	lr: 5.570e-05, eta: 2:47:03, time: 0.303, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1642, decode.acc_seg: 93.4454, loss: 0.1642
2025-04-22 19:50:17,912 - mmseg - INFO - Iter [12200/40000]	lr: 5.560e-05, eta: 2:46:39, time: 0.303, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1390, decode.acc_seg: 94.3051, loss: 0.1390
2025-04-22 19:50:33,057 - mmseg - INFO - Iter [12250/40000]	lr: 5.550e-05, eta: 2:46:14, time: 0.303, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1288, decode.acc_seg: 94.6578, loss: 0.1288
2025-04-22 19:50:48,194 - mmseg - INFO - Iter [12300/40000]	lr: 5.540e-05, eta: 2:45:50, time: 0.303, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1331, decode.acc_seg: 94.4967, loss: 0.1331
2025-04-22 19:51:03,348 - mmseg - INFO - Iter [12350/40000]	lr: 5.530e-05, eta: 2:45:26, time: 0.303, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1418, decode.acc_seg: 94.1483, loss: 0.1418
2025-04-22 19:51:18,514 - mmseg - INFO - Iter [12400/40000]	lr: 5.520e-05, eta: 2:45:01, time: 0.303, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1395, decode.acc_seg: 94.3157, loss: 0.1395
2025-04-22 19:51:33,687 - mmseg - INFO - Iter [12450/40000]	lr: 5.510e-05, eta: 2:44:37, time: 0.303, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1643, decode.acc_seg: 93.6624, loss: 0.1643
2025-04-22 19:51:48,830 - mmseg - INFO - Iter [12500/40000]	lr: 5.500e-05, eta: 2:44:13, time: 0.303, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1281, decode.acc_seg: 94.6947, loss: 0.1281
2025-04-22 19:52:03,961 - mmseg - INFO - Iter [12550/40000]	lr: 5.490e-05, eta: 2:43:49, time: 0.303, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1496, decode.acc_seg: 94.0106, loss: 0.1496
2025-04-22 19:52:19,088 - mmseg - INFO - Iter [12600/40000]	lr: 5.480e-05, eta: 2:43:25, time: 0.303, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1290, decode.acc_seg: 94.6728, loss: 0.1290
2025-04-22 19:52:34,224 - mmseg - INFO - Iter [12650/40000]	lr: 5.470e-05, eta: 2:43:02, time: 0.303, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1295, decode.acc_seg: 94.3761, loss: 0.1295
2025-04-22 19:52:49,357 - mmseg - INFO - Iter [12700/40000]	lr: 5.460e-05, eta: 2:42:38, time: 0.303, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1338, decode.acc_seg: 94.2234, loss: 0.1338
2025-04-22 19:53:04,478 - mmseg - INFO - Iter [12750/40000]	lr: 5.450e-05, eta: 2:42:14, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1218, decode.acc_seg: 95.1309, loss: 0.1218
2025-04-22 19:53:19,598 - mmseg - INFO - Iter [12800/40000]	lr: 5.440e-05, eta: 2:41:50, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1508, decode.acc_seg: 94.1353, loss: 0.1508
2025-04-22 19:53:34,708 - mmseg - INFO - Iter [12850/40000]	lr: 5.430e-05, eta: 2:41:27, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1455, decode.acc_seg: 94.1189, loss: 0.1455
2025-04-22 19:53:49,828 - mmseg - INFO - Iter [12900/40000]	lr: 5.420e-05, eta: 2:41:03, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1325, decode.acc_seg: 94.6285, loss: 0.1325
2025-04-22 19:54:04,919 - mmseg - INFO - Iter [12950/40000]	lr: 5.410e-05, eta: 2:40:40, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1401, decode.acc_seg: 94.2865, loss: 0.1401
2025-04-22 19:54:19,996 - mmseg - INFO - Exp name: vpd_config.py
2025-04-22 19:54:19,997 - mmseg - INFO - Iter [13000/40000]	lr: 5.400e-05, eta: 2:40:16, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1376, decode.acc_seg: 94.4313, loss: 0.1376
2025-04-22 19:54:35,863 - mmseg - INFO - Iter [13050/40000]	lr: 5.390e-05, eta: 2:39:54, time: 0.317, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1343, decode.acc_seg: 94.3930, loss: 0.1343
2025-04-22 19:54:50,992 - mmseg - INFO - Iter [13100/40000]	lr: 5.380e-05, eta: 2:39:31, time: 0.303, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1304, decode.acc_seg: 94.4595, loss: 0.1304
2025-04-22 19:55:06,114 - mmseg - INFO - Iter [13150/40000]	lr: 5.370e-05, eta: 2:39:08, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1347, decode.acc_seg: 94.1435, loss: 0.1347
2025-04-22 19:55:21,230 - mmseg - INFO - Iter [13200/40000]	lr: 5.360e-05, eta: 2:38:45, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1370, decode.acc_seg: 94.4484, loss: 0.1370
2025-04-22 19:55:36,341 - mmseg - INFO - Iter [13250/40000]	lr: 5.350e-05, eta: 2:38:21, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1297, decode.acc_seg: 94.6715, loss: 0.1297
2025-04-22 19:55:51,443 - mmseg - INFO - Iter [13300/40000]	lr: 5.340e-05, eta: 2:37:58, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1395, decode.acc_seg: 94.3595, loss: 0.1395
2025-04-22 19:56:06,535 - mmseg - INFO - Iter [13350/40000]	lr: 5.330e-05, eta: 2:37:35, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1291, decode.acc_seg: 94.6939, loss: 0.1291
2025-04-22 19:56:21,632 - mmseg - INFO - Iter [13400/40000]	lr: 5.320e-05, eta: 2:37:12, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1423, decode.acc_seg: 94.1038, loss: 0.1423
2025-04-22 19:56:36,729 - mmseg - INFO - Iter [13450/40000]	lr: 5.310e-05, eta: 2:36:49, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1343, decode.acc_seg: 94.4994, loss: 0.1343
2025-04-22 19:56:51,829 - mmseg - INFO - Iter [13500/40000]	lr: 5.300e-05, eta: 2:36:26, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1330, decode.acc_seg: 94.5754, loss: 0.1330
2025-04-22 19:57:06,930 - mmseg - INFO - Iter [13550/40000]	lr: 5.290e-05, eta: 2:36:04, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1385, decode.acc_seg: 94.0826, loss: 0.1385
2025-04-22 19:57:22,040 - mmseg - INFO - Iter [13600/40000]	lr: 5.280e-05, eta: 2:35:41, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1449, decode.acc_seg: 93.7253, loss: 0.1449
2025-04-22 19:57:37,130 - mmseg - INFO - Iter [13650/40000]	lr: 5.270e-05, eta: 2:35:18, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1396, decode.acc_seg: 94.2387, loss: 0.1396
2025-04-22 19:57:52,222 - mmseg - INFO - Iter [13700/40000]	lr: 5.260e-05, eta: 2:34:56, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1343, decode.acc_seg: 94.2977, loss: 0.1343
2025-04-22 19:58:07,309 - mmseg - INFO - Iter [13750/40000]	lr: 5.250e-05, eta: 2:34:33, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1408, decode.acc_seg: 94.3712, loss: 0.1408
2025-04-22 19:58:22,399 - mmseg - INFO - Iter [13800/40000]	lr: 5.240e-05, eta: 2:34:10, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1313, decode.acc_seg: 94.2939, loss: 0.1313
2025-04-22 19:58:37,487 - mmseg - INFO - Iter [13850/40000]	lr: 5.230e-05, eta: 2:33:48, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1338, decode.acc_seg: 94.4970, loss: 0.1338
2025-04-22 19:58:52,596 - mmseg - INFO - Iter [13900/40000]	lr: 5.220e-05, eta: 2:33:25, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1362, decode.acc_seg: 94.2937, loss: 0.1362
2025-04-22 19:59:07,702 - mmseg - INFO - Iter [13950/40000]	lr: 5.210e-05, eta: 2:33:03, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1375, decode.acc_seg: 94.0312, loss: 0.1375
2025-04-22 19:59:22,800 - mmseg - INFO - Exp name: vpd_config.py
2025-04-22 19:59:22,801 - mmseg - INFO - Iter [14000/40000]	lr: 5.200e-05, eta: 2:32:41, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1224, decode.acc_seg: 94.7396, loss: 0.1224
2025-04-22 19:59:38,616 - mmseg - INFO - Iter [14050/40000]	lr: 5.190e-05, eta: 2:32:20, time: 0.316, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1405, decode.acc_seg: 93.9443, loss: 0.1405
2025-04-22 19:59:53,737 - mmseg - INFO - Iter [14100/40000]	lr: 5.180e-05, eta: 2:31:58, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1228, decode.acc_seg: 94.7372, loss: 0.1228
2025-04-22 20:00:08,850 - mmseg - INFO - Iter [14150/40000]	lr: 5.170e-05, eta: 2:31:35, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1338, decode.acc_seg: 94.2952, loss: 0.1338
2025-04-22 20:00:23,971 - mmseg - INFO - Iter [14200/40000]	lr: 5.160e-05, eta: 2:31:13, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1349, decode.acc_seg: 94.2714, loss: 0.1349
2025-04-22 20:00:39,085 - mmseg - INFO - Iter [14250/40000]	lr: 5.150e-05, eta: 2:30:51, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1334, decode.acc_seg: 94.9507, loss: 0.1334
2025-04-22 20:00:54,193 - mmseg - INFO - Iter [14300/40000]	lr: 5.140e-05, eta: 2:30:29, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1563, decode.acc_seg: 93.6637, loss: 0.1563
2025-04-22 20:01:09,277 - mmseg - INFO - Iter [14350/40000]	lr: 5.130e-05, eta: 2:30:07, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1477, decode.acc_seg: 93.9784, loss: 0.1477
2025-04-22 20:01:24,366 - mmseg - INFO - Iter [14400/40000]	lr: 5.120e-05, eta: 2:29:45, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1333, decode.acc_seg: 94.4525, loss: 0.1333
2025-04-22 20:01:39,466 - mmseg - INFO - Iter [14450/40000]	lr: 5.110e-05, eta: 2:29:23, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1332, decode.acc_seg: 94.1565, loss: 0.1332
2025-04-22 20:01:54,565 - mmseg - INFO - Iter [14500/40000]	lr: 5.100e-05, eta: 2:29:02, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1470, decode.acc_seg: 93.9367, loss: 0.1470
2025-04-22 20:02:09,663 - mmseg - INFO - Iter [14550/40000]	lr: 5.090e-05, eta: 2:28:40, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1277, decode.acc_seg: 94.5670, loss: 0.1277
2025-04-22 20:02:24,752 - mmseg - INFO - Iter [14600/40000]	lr: 5.080e-05, eta: 2:28:18, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1255, decode.acc_seg: 94.9153, loss: 0.1255
2025-04-22 20:02:39,839 - mmseg - INFO - Iter [14650/40000]	lr: 5.070e-05, eta: 2:27:56, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1370, decode.acc_seg: 94.5865, loss: 0.1370
2025-04-22 20:02:54,936 - mmseg - INFO - Iter [14700/40000]	lr: 5.060e-05, eta: 2:27:35, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1428, decode.acc_seg: 94.2674, loss: 0.1428
2025-04-22 20:03:10,036 - mmseg - INFO - Iter [14750/40000]	lr: 5.050e-05, eta: 2:27:13, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1569, decode.acc_seg: 93.4380, loss: 0.1569
2025-04-22 20:03:25,124 - mmseg - INFO - Iter [14800/40000]	lr: 5.040e-05, eta: 2:26:52, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1332, decode.acc_seg: 94.3620, loss: 0.1332
2025-04-22 20:03:41,526 - mmseg - INFO - Iter [14850/40000]	lr: 5.030e-05, eta: 2:26:32, time: 0.328, data_time: 0.033, memory: 75933, decode.loss_ce: 0.1372, decode.acc_seg: 94.2664, loss: 0.1372
2025-04-22 20:03:56,714 - mmseg - INFO - Iter [14900/40000]	lr: 5.020e-05, eta: 2:26:11, time: 0.304, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1384, decode.acc_seg: 94.0420, loss: 0.1384
2025-04-22 20:04:11,861 - mmseg - INFO - Iter [14950/40000]	lr: 5.010e-05, eta: 2:25:49, time: 0.303, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1213, decode.acc_seg: 94.8336, loss: 0.1213
2025-04-22 20:04:27,007 - mmseg - INFO - Exp name: vpd_config.py
2025-04-22 20:04:27,007 - mmseg - INFO - Iter [15000/40000]	lr: 5.000e-05, eta: 2:25:28, time: 0.303, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1349, decode.acc_seg: 94.3704, loss: 0.1349
2025-04-22 20:04:42,886 - mmseg - INFO - Iter [15050/40000]	lr: 4.990e-05, eta: 2:25:08, time: 0.318, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1412, decode.acc_seg: 94.2120, loss: 0.1412
2025-04-22 20:04:58,047 - mmseg - INFO - Iter [15100/40000]	lr: 4.980e-05, eta: 2:24:47, time: 0.303, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1336, decode.acc_seg: 94.0693, loss: 0.1336
2025-04-22 20:05:13,177 - mmseg - INFO - Iter [15150/40000]	lr: 4.970e-05, eta: 2:24:26, time: 0.303, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1199, decode.acc_seg: 94.8473, loss: 0.1199
2025-04-22 20:05:28,337 - mmseg - INFO - Iter [15200/40000]	lr: 4.960e-05, eta: 2:24:04, time: 0.303, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1351, decode.acc_seg: 94.5800, loss: 0.1351
2025-04-22 20:05:43,482 - mmseg - INFO - Iter [15250/40000]	lr: 4.950e-05, eta: 2:23:43, time: 0.303, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1272, decode.acc_seg: 94.6729, loss: 0.1272
2025-04-22 20:05:58,632 - mmseg - INFO - Iter [15300/40000]	lr: 4.940e-05, eta: 2:23:22, time: 0.303, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1586, decode.acc_seg: 93.4084, loss: 0.1586
2025-04-22 20:06:13,789 - mmseg - INFO - Iter [15350/40000]	lr: 4.930e-05, eta: 2:23:01, time: 0.303, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1326, decode.acc_seg: 94.6355, loss: 0.1326
2025-04-22 20:06:28,953 - mmseg - INFO - Iter [15400/40000]	lr: 4.920e-05, eta: 2:22:40, time: 0.303, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1368, decode.acc_seg: 94.3507, loss: 0.1368
2025-04-22 20:06:44,097 - mmseg - INFO - Iter [15450/40000]	lr: 4.910e-05, eta: 2:22:19, time: 0.303, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1248, decode.acc_seg: 94.3943, loss: 0.1248
2025-04-22 20:06:59,240 - mmseg - INFO - Iter [15500/40000]	lr: 4.900e-05, eta: 2:21:58, time: 0.303, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1309, decode.acc_seg: 94.5221, loss: 0.1309
2025-04-22 20:07:14,399 - mmseg - INFO - Iter [15550/40000]	lr: 4.890e-05, eta: 2:21:37, time: 0.303, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1480, decode.acc_seg: 94.0920, loss: 0.1480
2025-04-22 20:07:29,531 - mmseg - INFO - Iter [15600/40000]	lr: 4.880e-05, eta: 2:21:16, time: 0.303, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1350, decode.acc_seg: 94.2709, loss: 0.1350
2025-04-22 20:07:44,636 - mmseg - INFO - Iter [15650/40000]	lr: 4.870e-05, eta: 2:20:56, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1371, decode.acc_seg: 94.1564, loss: 0.1371
2025-04-22 20:07:59,758 - mmseg - INFO - Iter [15700/40000]	lr: 4.860e-05, eta: 2:20:35, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1176, decode.acc_seg: 95.0671, loss: 0.1176
2025-04-22 20:08:14,864 - mmseg - INFO - Iter [15750/40000]	lr: 4.850e-05, eta: 2:20:14, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1349, decode.acc_seg: 94.3265, loss: 0.1349
2025-04-22 20:08:29,983 - mmseg - INFO - Iter [15800/40000]	lr: 4.840e-05, eta: 2:19:53, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1455, decode.acc_seg: 93.8043, loss: 0.1455
2025-04-22 20:08:45,101 - mmseg - INFO - Iter [15850/40000]	lr: 4.830e-05, eta: 2:19:32, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1504, decode.acc_seg: 94.0817, loss: 0.1504
2025-04-22 20:09:00,228 - mmseg - INFO - Iter [15900/40000]	lr: 4.820e-05, eta: 2:19:12, time: 0.303, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1451, decode.acc_seg: 93.9353, loss: 0.1451
2025-04-22 20:09:15,352 - mmseg - INFO - Iter [15950/40000]	lr: 4.810e-05, eta: 2:18:51, time: 0.302, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1352, decode.acc_seg: 94.3507, loss: 0.1352
2025-04-22 20:09:30,463 - mmseg - INFO - Saving checkpoint at 16000 iterations
2025-04-22 20:09:39,506 - mmseg - INFO - Exp name: vpd_config.py
2025-04-22 20:09:39,506 - mmseg - INFO - Iter [16000/40000]	lr: 4.800e-05, eta: 2:18:44, time: 0.483, data_time: 0.008, memory: 75933, decode.loss_ce: 0.1215, decode.acc_seg: 94.8527, loss: 0.1215
2025-04-22 20:13:11,800 - mmseg - INFO - per class results:
2025-04-22 20:13:11,807 - mmseg - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        | 46.04 | 59.29 |
|       building      | 54.76 |  64.1 |
|         sky         | 49.27 | 73.79 |
|        floor        | 31.76 | 77.12 |
|         tree        | 44.63 | 57.78 |
|       ceiling       | 62.43 | 66.21 |
|         road        |  36.2 | 71.17 |
|         bed         |  29.3 | 41.29 |
|      windowpane     | 36.13 | 47.07 |
|        grass        | 25.73 | 38.53 |
|       cabinet       | 29.55 | 40.63 |
|       sidewalk      | 15.32 | 25.83 |
|        person       | 31.04 | 43.79 |
|        earth        | 20.71 | 33.25 |
|         door        | 30.41 | 42.79 |
|        table        | 15.58 | 25.15 |
|       mountain      | 41.11 | 58.64 |
|        plant        | 21.41 | 28.25 |
|       curtain       | 45.26 | 54.41 |
|        chair        |  13.8 | 21.73 |
|         car         | 13.13 | 20.32 |
|        water        | 31.58 | 55.19 |
|       painting      | 32.63 | 42.46 |
|         sofa        | 14.08 | 21.81 |
|        shelf        | 26.45 | 35.63 |
|        house        | 29.29 |  45.8 |
|         sea         | 38.29 | 64.08 |
|        mirror       |  41.9 | 51.85 |
|         rug         | 14.79 | 22.06 |
|        field        | 20.82 | 41.51 |
|       armchair      | 11.44 | 19.15 |
|         seat        | 26.21 | 40.01 |
|        fence        | 10.47 | 16.29 |
|         desk        | 16.88 | 28.46 |
|         rock        | 23.75 | 36.68 |
|       wardrobe      | 37.28 | 45.91 |
|         lamp        |  20.3 | 29.01 |
|       bathtub       | 38.54 | 48.42 |
|       railing       | 12.76 |  18.7 |
|       cushion       |  7.26 | 11.08 |
|         base        | 14.07 |  24.0 |
|         box         |  9.72 | 14.06 |
|        column       | 28.59 | 35.27 |
|      signboard      | 10.33 | 14.74 |
|   chest of drawers  |  15.6 | 22.88 |
|       counter       |  9.17 | 14.13 |
|         sand        | 27.33 | 45.78 |
|         sink        | 16.49 | 24.08 |
|      skyscraper     | 44.84 | 56.34 |
|      fireplace      | 31.77 | 44.83 |
|     refrigerator    | 42.32 | 50.55 |
|      grandstand     | 28.06 | 61.87 |
|         path        |  7.0  | 10.46 |
|        stairs       |  9.13 | 12.38 |
|        runway       | 31.23 |  48.2 |
|         case        | 35.63 | 55.43 |
|      pool table     | 26.09 | 38.16 |
|        pillow       | 10.26 | 15.29 |
|     screen door     | 36.18 | 44.76 |
|       stairway      | 15.64 | 23.28 |
|        river        | 16.96 | 27.45 |
|        bridge       |  18.6 | 30.65 |
|       bookcase      | 25.97 | 36.51 |
|        blind        | 34.35 |  37.8 |
|     coffee table    |  4.1  |  7.62 |
|        toilet       | 18.32 | 26.51 |
|        flower       | 13.69 | 22.63 |
|         book        | 24.65 | 34.23 |
|         hill        |  8.88 | 14.39 |
|        bench        | 14.39 | 21.01 |
|      countertop     | 11.99 | 20.69 |
|        stove        | 23.72 | 33.98 |
|         palm        | 30.47 | 46.87 |
|    kitchen island   |  9.53 | 21.32 |
|       computer      | 32.45 |  46.9 |
|     swivel chair    | 15.23 | 21.61 |
|         boat        | 10.36 | 18.14 |
|         bar         | 27.98 | 43.64 |
|    arcade machine   | 18.53 | 22.37 |
|        hovel        | 18.21 | 23.39 |
|         bus         | 40.44 | 51.01 |
|        towel        | 16.35 |  25.7 |
|        light        | 21.27 | 28.23 |
|        truck        |  6.37 | 13.94 |
|        tower        |  5.67 | 10.27 |
|      chandelier     |  29.5 | 41.43 |
|        awning       |  4.65 |  6.5  |
|     streetlight     | 12.97 | 18.43 |
|        booth        | 22.22 | 34.89 |
| television receiver | 14.02 | 20.89 |
|       airplane      |  9.72 | 15.67 |
|      dirt track     |  1.17 |  6.51 |
|       apparel       | 17.02 | 27.43 |
|         pole        | 10.51 |  14.4 |
|         land        |  2.83 |  4.39 |
|      bannister      |  6.1  |  9.27 |
|      escalator      | 14.09 | 19.66 |
|       ottoman       |  1.79 |  2.9  |
|        bottle       | 13.03 | 23.98 |
|        buffet       | 26.51 | 30.31 |
|        poster       | 28.62 |  39.0 |
|        stage        | 10.82 | 23.27 |
|         van         |  6.63 |  10.3 |
|         ship        | 34.36 | 54.12 |
|       fountain      |  7.41 |  9.07 |
|    conveyer belt    | 27.59 | 46.84 |
|        canopy       | 19.04 | 28.12 |
|        washer       | 34.96 | 39.58 |
|      plaything      |  6.2  |  11.2 |
|    swimming pool    | 18.64 | 28.52 |
|        stool        |  8.15 | 12.31 |
|        barrel       |  1.02 |  5.39 |
|        basket       |  4.61 |  7.11 |
|      waterfall      | 38.69 | 51.69 |
|         tent        |  37.1 |  45.5 |
|         bag         |  2.32 |  3.08 |
|       minibike      | 14.91 | 22.23 |
|        cradle       | 32.77 | 46.74 |
|         oven        | 19.73 | 36.77 |
|         ball        | 14.71 | 21.54 |
|         food        | 25.68 | 32.23 |
|         step        |  0.01 |  0.01 |
|         tank        | 28.11 | 36.35 |
|      trade name     |  5.88 |  7.46 |
|      microwave      | 28.29 | 34.54 |
|         pot         |  9.66 | 13.79 |
|        animal       | 21.17 | 27.98 |
|       bicycle       |  3.87 |  6.83 |
|         lake        | 32.95 | 38.88 |
|      dishwasher     | 14.57 | 19.97 |
|        screen       | 37.53 | 52.16 |
|       blanket       |  2.73 |  3.53 |
|      sculpture      | 18.82 | 30.84 |
|         hood        | 25.42 | 36.72 |
|        sconce       | 11.83 | 17.05 |
|         vase        |  5.28 |  9.25 |
|    traffic light    | 14.89 | 21.93 |
|         tray        |  3.23 |  5.69 |
|        ashcan       |  1.61 |  2.82 |
|         fan         | 20.83 | 31.31 |
|         pier        |  0.37 |  0.63 |
|      crt screen     |  7.82 | 12.28 |
|        plate        | 10.81 | 16.48 |
|       monitor       | 37.16 |  46.8 |
|    bulletin board   | 32.93 | 43.65 |
|        shower       |  0.26 |  0.72 |
|       radiator      |  8.76 |  13.7 |
|        glass        |  0.33 |  0.38 |
|        clock        | 24.66 | 30.93 |
|         flag        | 36.51 | 43.33 |
+---------------------+-------+-------+
2025-04-22 20:13:11,807 - mmseg - INFO - Summary:
2025-04-22 20:13:11,807 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 53.34 | 20.62 | 29.77 |
+-------+-------+-------+
2025-04-22 20:13:11,808 - mmseg - INFO - Exp name: vpd_config.py
2025-04-22 20:13:11,808 - mmseg - INFO - Iter(val) [2000]	aAcc: 0.5334, mIoU: 0.2062, mAcc: 0.2977, IoU.wall: 0.4604, IoU.building: 0.5476, IoU.sky: 0.4927, IoU.floor: 0.3176, IoU.tree: 0.4463, IoU.ceiling: 0.6243, IoU.road: 0.3620, IoU.bed : 0.2930, IoU.windowpane: 0.3613, IoU.grass: 0.2573, IoU.cabinet: 0.2955, IoU.sidewalk: 0.1532, IoU.person: 0.3104, IoU.earth: 0.2071, IoU.door: 0.3041, IoU.table: 0.1558, IoU.mountain: 0.4111, IoU.plant: 0.2141, IoU.curtain: 0.4526, IoU.chair: 0.1380, IoU.car: 0.1313, IoU.water: 0.3158, IoU.painting: 0.3263, IoU.sofa: 0.1408, IoU.shelf: 0.2645, IoU.house: 0.2929, IoU.sea: 0.3829, IoU.mirror: 0.4190, IoU.rug: 0.1479, IoU.field: 0.2082, IoU.armchair: 0.1144, IoU.seat: 0.2621, IoU.fence: 0.1047, IoU.desk: 0.1688, IoU.rock: 0.2375, IoU.wardrobe: 0.3728, IoU.lamp: 0.2030, IoU.bathtub: 0.3854, IoU.railing: 0.1276, IoU.cushion: 0.0726, IoU.base: 0.1407, IoU.box: 0.0972, IoU.column: 0.2859, IoU.signboard: 0.1033, IoU.chest of drawers: 0.1560, IoU.counter: 0.0917, IoU.sand: 0.2733, IoU.sink: 0.1649, IoU.skyscraper: 0.4484, IoU.fireplace: 0.3177, IoU.refrigerator: 0.4232, IoU.grandstand: 0.2806, IoU.path: 0.0700, IoU.stairs: 0.0913, IoU.runway: 0.3123, IoU.case: 0.3563, IoU.pool table: 0.2609, IoU.pillow: 0.1026, IoU.screen door: 0.3618, IoU.stairway: 0.1564, IoU.river: 0.1696, IoU.bridge: 0.1860, IoU.bookcase: 0.2597, IoU.blind: 0.3435, IoU.coffee table: 0.0410, IoU.toilet: 0.1832, IoU.flower: 0.1369, IoU.book: 0.2465, IoU.hill: 0.0888, IoU.bench: 0.1439, IoU.countertop: 0.1199, IoU.stove: 0.2372, IoU.palm: 0.3047, IoU.kitchen island: 0.0953, IoU.computer: 0.3245, IoU.swivel chair: 0.1523, IoU.boat: 0.1036, IoU.bar: 0.2798, IoU.arcade machine: 0.1853, IoU.hovel: 0.1821, IoU.bus: 0.4044, IoU.towel: 0.1635, IoU.light: 0.2127, IoU.truck: 0.0637, IoU.tower: 0.0567, IoU.chandelier: 0.2950, IoU.awning: 0.0465, IoU.streetlight: 0.1297, IoU.booth: 0.2222, IoU.television receiver: 0.1402, IoU.airplane: 0.0972, IoU.dirt track: 0.0117, IoU.apparel: 0.1702, IoU.pole: 0.1051, IoU.land: 0.0283, IoU.bannister: 0.0610, IoU.escalator: 0.1409, IoU.ottoman: 0.0179, IoU.bottle: 0.1303, IoU.buffet: 0.2651, IoU.poster: 0.2862, IoU.stage: 0.1082, IoU.van: 0.0663, IoU.ship: 0.3436, IoU.fountain: 0.0741, IoU.conveyer belt: 0.2759, IoU.canopy: 0.1904, IoU.washer: 0.3496, IoU.plaything: 0.0620, IoU.swimming pool: 0.1864, IoU.stool: 0.0815, IoU.barrel: 0.0102, IoU.basket: 0.0461, IoU.waterfall: 0.3869, IoU.tent: 0.3710, IoU.bag: 0.0232, IoU.minibike: 0.1491, IoU.cradle: 0.3277, IoU.oven: 0.1973, IoU.ball: 0.1471, IoU.food: 0.2568, IoU.step: 0.0001, IoU.tank: 0.2811, IoU.trade name: 0.0588, IoU.microwave: 0.2829, IoU.pot: 0.0966, IoU.animal: 0.2117, IoU.bicycle: 0.0387, IoU.lake: 0.3295, IoU.dishwasher: 0.1457, IoU.screen: 0.3753, IoU.blanket: 0.0273, IoU.sculpture: 0.1882, IoU.hood: 0.2542, IoU.sconce: 0.1183, IoU.vase: 0.0528, IoU.traffic light: 0.1489, IoU.tray: 0.0323, IoU.ashcan: 0.0161, IoU.fan: 0.2083, IoU.pier: 0.0037, IoU.crt screen: 0.0782, IoU.plate: 0.1081, IoU.monitor: 0.3716, IoU.bulletin board: 0.3293, IoU.shower: 0.0026, IoU.radiator: 0.0876, IoU.glass: 0.0033, IoU.clock: 0.2466, IoU.flag: 0.3651, Acc.wall: 0.5929, Acc.building: 0.6410, Acc.sky: 0.7379, Acc.floor: 0.7712, Acc.tree: 0.5778, Acc.ceiling: 0.6621, Acc.road: 0.7117, Acc.bed : 0.4129, Acc.windowpane: 0.4707, Acc.grass: 0.3853, Acc.cabinet: 0.4063, Acc.sidewalk: 0.2583, Acc.person: 0.4379, Acc.earth: 0.3325, Acc.door: 0.4279, Acc.table: 0.2515, Acc.mountain: 0.5864, Acc.plant: 0.2825, Acc.curtain: 0.5441, Acc.chair: 0.2173, Acc.car: 0.2032, Acc.water: 0.5519, Acc.painting: 0.4246, Acc.sofa: 0.2181, Acc.shelf: 0.3563, Acc.house: 0.4580, Acc.sea: 0.6408, Acc.mirror: 0.5185, Acc.rug: 0.2206, Acc.field: 0.4151, Acc.armchair: 0.1915, Acc.seat: 0.4001, Acc.fence: 0.1629, Acc.desk: 0.2846, Acc.rock: 0.3668, Acc.wardrobe: 0.4591, Acc.lamp: 0.2901, Acc.bathtub: 0.4842, Acc.railing: 0.1870, Acc.cushion: 0.1108, Acc.base: 0.2400, Acc.box: 0.1406, Acc.column: 0.3527, Acc.signboard: 0.1474, Acc.chest of drawers: 0.2288, Acc.counter: 0.1413, Acc.sand: 0.4578, Acc.sink: 0.2408, Acc.skyscraper: 0.5634, Acc.fireplace: 0.4483, Acc.refrigerator: 0.5055, Acc.grandstand: 0.6187, Acc.path: 0.1046, Acc.stairs: 0.1238, Acc.runway: 0.4820, Acc.case: 0.5543, Acc.pool table: 0.3816, Acc.pillow: 0.1529, Acc.screen door: 0.4476, Acc.stairway: 0.2328, Acc.river: 0.2745, Acc.bridge: 0.3065, Acc.bookcase: 0.3651, Acc.blind: 0.3780, Acc.coffee table: 0.0762, Acc.toilet: 0.2651, Acc.flower: 0.2263, Acc.book: 0.3423, Acc.hill: 0.1439, Acc.bench: 0.2101, Acc.countertop: 0.2069, Acc.stove: 0.3398, Acc.palm: 0.4687, Acc.kitchen island: 0.2132, Acc.computer: 0.4690, Acc.swivel chair: 0.2161, Acc.boat: 0.1814, Acc.bar: 0.4364, Acc.arcade machine: 0.2237, Acc.hovel: 0.2339, Acc.bus: 0.5101, Acc.towel: 0.2570, Acc.light: 0.2823, Acc.truck: 0.1394, Acc.tower: 0.1027, Acc.chandelier: 0.4143, Acc.awning: 0.0650, Acc.streetlight: 0.1843, Acc.booth: 0.3489, Acc.television receiver: 0.2089, Acc.airplane: 0.1567, Acc.dirt track: 0.0651, Acc.apparel: 0.2743, Acc.pole: 0.1440, Acc.land: 0.0439, Acc.bannister: 0.0927, Acc.escalator: 0.1966, Acc.ottoman: 0.0290, Acc.bottle: 0.2398, Acc.buffet: 0.3031, Acc.poster: 0.3900, Acc.stage: 0.2327, Acc.van: 0.1030, Acc.ship: 0.5412, Acc.fountain: 0.0907, Acc.conveyer belt: 0.4684, Acc.canopy: 0.2812, Acc.washer: 0.3958, Acc.plaything: 0.1120, Acc.swimming pool: 0.2852, Acc.stool: 0.1231, Acc.barrel: 0.0539, Acc.basket: 0.0711, Acc.waterfall: 0.5169, Acc.tent: 0.4550, Acc.bag: 0.0308, Acc.minibike: 0.2223, Acc.cradle: 0.4674, Acc.oven: 0.3677, Acc.ball: 0.2154, Acc.food: 0.3223, Acc.step: 0.0001, Acc.tank: 0.3635, Acc.trade name: 0.0746, Acc.microwave: 0.3454, Acc.pot: 0.1379, Acc.animal: 0.2798, Acc.bicycle: 0.0683, Acc.lake: 0.3888, Acc.dishwasher: 0.1997, Acc.screen: 0.5216, Acc.blanket: 0.0353, Acc.sculpture: 0.3084, Acc.hood: 0.3672, Acc.sconce: 0.1705, Acc.vase: 0.0925, Acc.traffic light: 0.2193, Acc.tray: 0.0569, Acc.ashcan: 0.0282, Acc.fan: 0.3131, Acc.pier: 0.0063, Acc.crt screen: 0.1228, Acc.plate: 0.1648, Acc.monitor: 0.4680, Acc.bulletin board: 0.4365, Acc.shower: 0.0072, Acc.radiator: 0.1370, Acc.glass: 0.0038, Acc.clock: 0.3093, Acc.flag: 0.4333
2025-04-22 20:13:27,627 - mmseg - INFO - Iter [16050/40000]	lr: 4.790e-05, eta: 2:23:41, time: 4.562, data_time: 4.255, memory: 75933, decode.loss_ce: 0.1477, decode.acc_seg: 94.0567, loss: 0.1477
2025-04-22 20:13:42,831 - mmseg - INFO - Iter [16100/40000]	lr: 4.780e-05, eta: 2:23:19, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1369, decode.acc_seg: 94.1056, loss: 0.1369
2025-04-22 20:13:58,024 - mmseg - INFO - Iter [16150/40000]	lr: 4.770e-05, eta: 2:22:57, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1217, decode.acc_seg: 94.9725, loss: 0.1217
2025-04-22 20:14:13,240 - mmseg - INFO - Iter [16200/40000]	lr: 4.760e-05, eta: 2:22:35, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1332, decode.acc_seg: 94.5230, loss: 0.1332
2025-04-22 20:14:28,437 - mmseg - INFO - Iter [16250/40000]	lr: 4.750e-05, eta: 2:22:13, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1323, decode.acc_seg: 94.6451, loss: 0.1323
2025-04-22 20:14:43,640 - mmseg - INFO - Iter [16300/40000]	lr: 4.740e-05, eta: 2:21:51, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1472, decode.acc_seg: 94.1504, loss: 0.1472
2025-04-22 20:14:58,848 - mmseg - INFO - Iter [16350/40000]	lr: 4.730e-05, eta: 2:21:29, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1311, decode.acc_seg: 94.3569, loss: 0.1311
2025-04-22 20:15:14,039 - mmseg - INFO - Iter [16400/40000]	lr: 4.720e-05, eta: 2:21:07, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1586, decode.acc_seg: 93.8059, loss: 0.1586
2025-04-22 20:15:29,206 - mmseg - INFO - Iter [16450/40000]	lr: 4.710e-05, eta: 2:20:45, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1287, decode.acc_seg: 94.5301, loss: 0.1287
2025-04-22 20:15:44,370 - mmseg - INFO - Iter [16500/40000]	lr: 4.700e-05, eta: 2:20:23, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1353, decode.acc_seg: 94.1847, loss: 0.1353
2025-04-22 20:15:59,522 - mmseg - INFO - Iter [16550/40000]	lr: 4.690e-05, eta: 2:20:01, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1363, decode.acc_seg: 94.3993, loss: 0.1363
2025-04-22 20:16:14,666 - mmseg - INFO - Iter [16600/40000]	lr: 4.680e-05, eta: 2:19:40, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1472, decode.acc_seg: 93.9924, loss: 0.1472
2025-04-22 20:16:29,815 - mmseg - INFO - Iter [16650/40000]	lr: 4.670e-05, eta: 2:19:18, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1479, decode.acc_seg: 93.9004, loss: 0.1479
2025-04-22 20:16:44,957 - mmseg - INFO - Iter [16700/40000]	lr: 4.660e-05, eta: 2:18:56, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1269, decode.acc_seg: 94.6050, loss: 0.1269
2025-04-22 20:17:00,082 - mmseg - INFO - Iter [16750/40000]	lr: 4.650e-05, eta: 2:18:34, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1406, decode.acc_seg: 94.1225, loss: 0.1406
2025-04-22 20:17:15,220 - mmseg - INFO - Iter [16800/40000]	lr: 4.640e-05, eta: 2:18:13, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1410, decode.acc_seg: 94.1639, loss: 0.1410
2025-04-22 20:17:30,348 - mmseg - INFO - Iter [16850/40000]	lr: 4.630e-05, eta: 2:17:51, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1278, decode.acc_seg: 94.5177, loss: 0.1278
2025-04-22 20:17:45,485 - mmseg - INFO - Iter [16900/40000]	lr: 4.620e-05, eta: 2:17:29, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1312, decode.acc_seg: 94.2692, loss: 0.1312
2025-04-22 20:18:00,614 - mmseg - INFO - Iter [16950/40000]	lr: 4.610e-05, eta: 2:17:08, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1242, decode.acc_seg: 94.7347, loss: 0.1242
2025-04-22 20:18:15,743 - mmseg - INFO - Exp name: vpd_config.py
2025-04-22 20:18:15,744 - mmseg - INFO - Iter [17000/40000]	lr: 4.600e-05, eta: 2:16:46, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1509, decode.acc_seg: 94.0430, loss: 0.1509
2025-04-22 20:18:31,619 - mmseg - INFO - Iter [17050/40000]	lr: 4.590e-05, eta: 2:16:26, time: 0.318, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1198, decode.acc_seg: 94.8198, loss: 0.1198
2025-04-22 20:18:46,797 - mmseg - INFO - Iter [17100/40000]	lr: 4.580e-05, eta: 2:16:04, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1439, decode.acc_seg: 94.3817, loss: 0.1439
2025-04-22 20:19:01,945 - mmseg - INFO - Iter [17150/40000]	lr: 4.570e-05, eta: 2:15:43, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1319, decode.acc_seg: 94.8246, loss: 0.1319
2025-04-22 20:19:17,128 - mmseg - INFO - Iter [17200/40000]	lr: 4.560e-05, eta: 2:15:22, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1155, decode.acc_seg: 95.1133, loss: 0.1155
2025-04-22 20:19:32,307 - mmseg - INFO - Iter [17250/40000]	lr: 4.550e-05, eta: 2:15:00, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1452, decode.acc_seg: 94.0114, loss: 0.1452
2025-04-22 20:19:47,511 - mmseg - INFO - Iter [17300/40000]	lr: 4.540e-05, eta: 2:14:39, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1307, decode.acc_seg: 94.3255, loss: 0.1307
2025-04-22 20:20:02,704 - mmseg - INFO - Iter [17350/40000]	lr: 4.530e-05, eta: 2:14:18, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1579, decode.acc_seg: 93.5849, loss: 0.1579
2025-04-22 20:20:17,902 - mmseg - INFO - Iter [17400/40000]	lr: 4.520e-05, eta: 2:13:57, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1399, decode.acc_seg: 94.4256, loss: 0.1399
2025-04-22 20:20:33,092 - mmseg - INFO - Iter [17450/40000]	lr: 4.510e-05, eta: 2:13:36, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1297, decode.acc_seg: 94.7606, loss: 0.1297
2025-04-22 20:20:48,277 - mmseg - INFO - Iter [17500/40000]	lr: 4.500e-05, eta: 2:13:15, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1561, decode.acc_seg: 94.0896, loss: 0.1561
2025-04-22 20:21:03,478 - mmseg - INFO - Iter [17550/40000]	lr: 4.490e-05, eta: 2:12:54, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1423, decode.acc_seg: 93.8955, loss: 0.1423
2025-04-22 20:21:18,641 - mmseg - INFO - Iter [17600/40000]	lr: 4.480e-05, eta: 2:12:33, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1358, decode.acc_seg: 94.2948, loss: 0.1358
2025-04-22 20:21:33,812 - mmseg - INFO - Iter [17650/40000]	lr: 4.470e-05, eta: 2:12:12, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1416, decode.acc_seg: 94.0368, loss: 0.1416
2025-04-22 20:21:48,984 - mmseg - INFO - Iter [17700/40000]	lr: 4.460e-05, eta: 2:11:51, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1305, decode.acc_seg: 94.5311, loss: 0.1305
2025-04-22 20:22:04,161 - mmseg - INFO - Iter [17750/40000]	lr: 4.450e-05, eta: 2:11:30, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1305, decode.acc_seg: 94.5718, loss: 0.1305
2025-04-22 20:22:19,345 - mmseg - INFO - Iter [17800/40000]	lr: 4.440e-05, eta: 2:11:09, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1362, decode.acc_seg: 94.2292, loss: 0.1362
2025-04-22 20:22:34,544 - mmseg - INFO - Iter [17850/40000]	lr: 4.430e-05, eta: 2:10:48, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1340, decode.acc_seg: 94.4280, loss: 0.1340
2025-04-22 20:22:49,714 - mmseg - INFO - Iter [17900/40000]	lr: 4.420e-05, eta: 2:10:27, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1291, decode.acc_seg: 94.6937, loss: 0.1291
2025-04-22 20:23:04,889 - mmseg - INFO - Iter [17950/40000]	lr: 4.410e-05, eta: 2:10:06, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1199, decode.acc_seg: 95.0088, loss: 0.1199
2025-04-22 20:23:20,074 - mmseg - INFO - Exp name: vpd_config.py
2025-04-22 20:23:20,075 - mmseg - INFO - Iter [18000/40000]	lr: 4.400e-05, eta: 2:09:45, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1286, decode.acc_seg: 94.4085, loss: 0.1286
2025-04-22 20:23:36,060 - mmseg - INFO - Iter [18050/40000]	lr: 4.390e-05, eta: 2:09:26, time: 0.320, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1331, decode.acc_seg: 94.5185, loss: 0.1331
2025-04-22 20:23:51,267 - mmseg - INFO - Iter [18100/40000]	lr: 4.380e-05, eta: 2:09:05, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1286, decode.acc_seg: 94.6155, loss: 0.1286
2025-04-22 20:24:06,461 - mmseg - INFO - Iter [18150/40000]	lr: 4.370e-05, eta: 2:08:44, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1357, decode.acc_seg: 94.1966, loss: 0.1357
2025-04-22 20:24:21,690 - mmseg - INFO - Iter [18200/40000]	lr: 4.360e-05, eta: 2:08:24, time: 0.305, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1295, decode.acc_seg: 94.3805, loss: 0.1295
2025-04-22 20:24:36,891 - mmseg - INFO - Iter [18250/40000]	lr: 4.350e-05, eta: 2:08:03, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1194, decode.acc_seg: 94.6795, loss: 0.1194
2025-04-22 20:24:52,057 - mmseg - INFO - Iter [18300/40000]	lr: 4.340e-05, eta: 2:07:42, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1312, decode.acc_seg: 94.7045, loss: 0.1312
2025-04-22 20:25:07,229 - mmseg - INFO - Iter [18350/40000]	lr: 4.330e-05, eta: 2:07:22, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1277, decode.acc_seg: 94.5060, loss: 0.1277
2025-04-22 20:25:22,420 - mmseg - INFO - Iter [18400/40000]	lr: 4.320e-05, eta: 2:07:01, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1436, decode.acc_seg: 93.7825, loss: 0.1436
2025-04-22 20:25:37,615 - mmseg - INFO - Iter [18450/40000]	lr: 4.310e-05, eta: 2:06:41, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1298, decode.acc_seg: 94.7780, loss: 0.1298
2025-04-22 20:25:52,779 - mmseg - INFO - Iter [18500/40000]	lr: 4.300e-05, eta: 2:06:20, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1427, decode.acc_seg: 94.2737, loss: 0.1427
2025-04-22 20:26:07,936 - mmseg - INFO - Iter [18550/40000]	lr: 4.290e-05, eta: 2:06:00, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1401, decode.acc_seg: 94.2933, loss: 0.1401
2025-04-22 20:26:23,101 - mmseg - INFO - Iter [18600/40000]	lr: 4.280e-05, eta: 2:05:39, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1556, decode.acc_seg: 93.7083, loss: 0.1556
2025-04-22 20:26:38,260 - mmseg - INFO - Iter [18650/40000]	lr: 4.270e-05, eta: 2:05:19, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1343, decode.acc_seg: 94.5768, loss: 0.1343
2025-04-22 20:26:53,415 - mmseg - INFO - Iter [18700/40000]	lr: 4.260e-05, eta: 2:04:58, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1439, decode.acc_seg: 94.1414, loss: 0.1439
2025-04-22 20:27:08,585 - mmseg - INFO - Iter [18750/40000]	lr: 4.250e-05, eta: 2:04:38, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1353, decode.acc_seg: 94.2306, loss: 0.1353
2025-04-22 20:27:23,749 - mmseg - INFO - Iter [18800/40000]	lr: 4.240e-05, eta: 2:04:18, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1292, decode.acc_seg: 94.5426, loss: 0.1292
2025-04-22 20:27:38,915 - mmseg - INFO - Iter [18850/40000]	lr: 4.230e-05, eta: 2:03:57, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1318, decode.acc_seg: 94.6963, loss: 0.1318
2025-04-22 20:27:54,076 - mmseg - INFO - Iter [18900/40000]	lr: 4.220e-05, eta: 2:03:37, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1122, decode.acc_seg: 95.2750, loss: 0.1122
2025-04-22 20:28:09,243 - mmseg - INFO - Iter [18950/40000]	lr: 4.210e-05, eta: 2:03:17, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1298, decode.acc_seg: 94.7152, loss: 0.1298
2025-04-22 20:28:24,395 - mmseg - INFO - Exp name: vpd_config.py
2025-04-22 20:28:24,396 - mmseg - INFO - Iter [19000/40000]	lr: 4.200e-05, eta: 2:02:57, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1459, decode.acc_seg: 94.3589, loss: 0.1459
2025-04-22 20:28:40,325 - mmseg - INFO - Iter [19050/40000]	lr: 4.190e-05, eta: 2:02:37, time: 0.319, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1493, decode.acc_seg: 94.1301, loss: 0.1493
2025-04-22 20:28:55,500 - mmseg - INFO - Iter [19100/40000]	lr: 4.180e-05, eta: 2:02:17, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1254, decode.acc_seg: 94.7009, loss: 0.1254
2025-04-22 20:29:10,689 - mmseg - INFO - Iter [19150/40000]	lr: 4.170e-05, eta: 2:01:57, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1412, decode.acc_seg: 94.1660, loss: 0.1412
2025-04-22 20:29:25,873 - mmseg - INFO - Iter [19200/40000]	lr: 4.160e-05, eta: 2:01:37, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1542, decode.acc_seg: 93.6396, loss: 0.1542
2025-04-22 20:29:41,053 - mmseg - INFO - Iter [19250/40000]	lr: 4.150e-05, eta: 2:01:17, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1296, decode.acc_seg: 94.6028, loss: 0.1296
2025-04-22 20:29:56,233 - mmseg - INFO - Iter [19300/40000]	lr: 4.140e-05, eta: 2:00:57, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1338, decode.acc_seg: 94.1148, loss: 0.1338
2025-04-22 20:30:11,410 - mmseg - INFO - Iter [19350/40000]	lr: 4.130e-05, eta: 2:00:37, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1297, decode.acc_seg: 94.6499, loss: 0.1297
2025-04-22 20:30:26,585 - mmseg - INFO - Iter [19400/40000]	lr: 4.120e-05, eta: 2:00:17, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1429, decode.acc_seg: 94.2925, loss: 0.1429
2025-04-22 20:30:41,758 - mmseg - INFO - Iter [19450/40000]	lr: 4.110e-05, eta: 1:59:57, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1377, decode.acc_seg: 94.1587, loss: 0.1377
2025-04-22 20:30:56,933 - mmseg - INFO - Iter [19500/40000]	lr: 4.100e-05, eta: 1:59:37, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1459, decode.acc_seg: 93.4984, loss: 0.1459
2025-04-22 20:31:12,115 - mmseg - INFO - Iter [19550/40000]	lr: 4.090e-05, eta: 1:59:17, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1300, decode.acc_seg: 94.5535, loss: 0.1300
2025-04-22 20:31:27,299 - mmseg - INFO - Iter [19600/40000]	lr: 4.080e-05, eta: 1:58:57, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1491, decode.acc_seg: 94.0218, loss: 0.1491
2025-04-22 20:31:42,516 - mmseg - INFO - Iter [19650/40000]	lr: 4.070e-05, eta: 1:58:37, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1399, decode.acc_seg: 94.3336, loss: 0.1399
2025-04-22 20:31:57,697 - mmseg - INFO - Iter [19700/40000]	lr: 4.060e-05, eta: 1:58:17, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1421, decode.acc_seg: 93.9340, loss: 0.1421
2025-04-22 20:32:12,887 - mmseg - INFO - Iter [19750/40000]	lr: 4.050e-05, eta: 1:57:57, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1308, decode.acc_seg: 94.2605, loss: 0.1308
2025-04-22 20:32:28,059 - mmseg - INFO - Iter [19800/40000]	lr: 4.040e-05, eta: 1:57:37, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1199, decode.acc_seg: 94.6177, loss: 0.1199
2025-04-22 20:32:43,240 - mmseg - INFO - Iter [19850/40000]	lr: 4.030e-05, eta: 1:57:18, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1311, decode.acc_seg: 94.4736, loss: 0.1311
2025-04-22 20:32:58,416 - mmseg - INFO - Iter [19900/40000]	lr: 4.020e-05, eta: 1:56:58, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1386, decode.acc_seg: 94.3646, loss: 0.1386
2025-04-22 20:33:13,602 - mmseg - INFO - Iter [19950/40000]	lr: 4.010e-05, eta: 1:56:38, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1588, decode.acc_seg: 93.7311, loss: 0.1588
2025-04-22 20:33:28,773 - mmseg - INFO - Saving checkpoint at 20000 iterations
2025-04-22 20:33:38,142 - mmseg - INFO - Exp name: vpd_config.py
2025-04-22 20:33:38,143 - mmseg - INFO - Iter [20000/40000]	lr: 4.000e-05, eta: 1:56:28, time: 0.491, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1291, decode.acc_seg: 94.2800, loss: 0.1291
2025-04-22 20:37:12,513 - mmseg - INFO - per class results:
2025-04-22 20:37:12,520 - mmseg - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        | 45.86 | 60.29 |
|       building      | 54.59 | 63.85 |
|         sky         | 51.54 | 73.46 |
|        floor        | 32.53 | 77.05 |
|         tree        | 45.47 | 58.44 |
|       ceiling       | 62.31 | 66.16 |
|         road        | 37.02 | 77.85 |
|         bed         | 29.96 |  42.5 |
|      windowpane     | 36.18 |  46.4 |
|        grass        |  25.8 | 40.75 |
|       cabinet       |  29.9 | 40.66 |
|       sidewalk      |  13.7 | 22.14 |
|        person       | 31.39 | 42.76 |
|        earth        | 20.85 | 33.77 |
|         door        | 31.11 | 40.91 |
|        table        | 15.38 | 25.47 |
|       mountain      |  39.7 | 60.09 |
|        plant        | 21.52 | 28.25 |
|       curtain       |  45.1 | 54.68 |
|        chair        | 13.52 | 20.86 |
|         car         | 12.89 |  20.0 |
|        water        | 31.63 | 52.37 |
|       painting      |  32.5 |  42.5 |
|         sofa        | 14.37 | 22.44 |
|        shelf        | 27.17 | 39.17 |
|        house        | 28.17 | 42.85 |
|         sea         | 38.57 | 66.12 |
|        mirror       |  40.8 | 50.14 |
|         rug         | 14.71 |  21.7 |
|        field        |  20.9 | 39.39 |
|       armchair      | 11.66 | 19.94 |
|         seat        | 25.79 | 40.16 |
|        fence        | 10.23 | 15.71 |
|         desk        | 16.72 | 27.18 |
|         rock        | 23.56 | 35.96 |
|       wardrobe      | 38.35 | 46.82 |
|         lamp        | 20.14 | 28.46 |
|       bathtub       |  38.6 | 49.71 |
|       railing       | 12.69 | 18.49 |
|       cushion       |  7.52 | 11.98 |
|         base        | 13.79 | 22.34 |
|         box         |  9.76 | 13.68 |
|        column       | 28.24 | 34.19 |
|      signboard      | 10.56 | 15.04 |
|   chest of drawers  | 15.52 | 22.88 |
|       counter       |  9.01 | 14.32 |
|         sand        | 27.58 | 45.48 |
|         sink        | 16.54 | 24.22 |
|      skyscraper     | 44.59 | 55.43 |
|      fireplace      | 31.44 | 44.54 |
|     refrigerator    | 42.73 | 50.35 |
|      grandstand     | 29.49 | 60.29 |
|         path        |  7.21 | 11.29 |
|        stairs       |  9.74 | 13.43 |
|        runway       | 31.03 | 47.78 |
|         case        | 31.67 | 46.26 |
|      pool table     | 25.76 |  37.6 |
|        pillow       |  9.94 | 14.48 |
|     screen door     | 36.28 | 43.88 |
|       stairway      | 15.58 |  22.1 |
|        river        | 17.41 |  27.8 |
|        bridge       | 18.18 | 31.04 |
|       bookcase      | 27.06 | 37.96 |
|        blind        | 34.88 | 38.76 |
|     coffee table    |  4.12 |  7.53 |
|        toilet       | 18.33 |  26.4 |
|        flower       | 13.98 | 23.89 |
|         book        |  24.3 |  34.7 |
|         hill        |  8.76 | 13.98 |
|        bench        | 13.53 | 19.47 |
|      countertop     | 11.67 | 19.63 |
|        stove        | 23.12 | 33.31 |
|         palm        | 29.59 | 42.63 |
|    kitchen island   |  9.54 | 19.42 |
|       computer      | 32.43 | 47.86 |
|     swivel chair    | 15.55 | 22.51 |
|         boat        | 10.47 | 18.61 |
|         bar         | 26.75 | 39.32 |
|    arcade machine   | 22.01 |  26.8 |
|        hovel        | 17.62 | 20.71 |
|         bus         | 39.77 | 50.22 |
|        towel        | 16.04 | 25.69 |
|        light        | 21.55 | 28.72 |
|        truck        |  6.15 | 11.78 |
|        tower        |  5.67 | 10.29 |
|      chandelier     | 29.39 | 41.58 |
|        awning       |  4.31 |  5.93 |
|     streetlight     | 11.88 | 14.96 |
|        booth        |  21.9 | 32.29 |
| television receiver | 14.85 | 22.86 |
|       airplane      |  8.94 | 13.92 |
|      dirt track     |  0.71 |  3.82 |
|       apparel       | 17.61 | 24.64 |
|         pole        | 12.93 | 18.09 |
|         land        |  2.85 |  4.12 |
|      bannister      |  5.86 |  8.64 |
|      escalator      | 12.93 | 17.72 |
|       ottoman       |  2.15 |  3.65 |
|        bottle       | 10.41 | 16.54 |
|        buffet       | 27.24 |  32.3 |
|        poster       | 29.86 | 37.05 |
|        stage        | 11.26 | 22.88 |
|         van         |  6.38 | 10.06 |
|         ship        | 24.77 |  36.5 |
|       fountain      |  7.29 |  8.89 |
|    conveyer belt    |  29.3 | 47.88 |
|        canopy       |  17.8 | 24.84 |
|        washer       |  35.0 | 39.85 |
|      plaything      |  5.54 | 10.04 |
|    swimming pool    | 18.67 | 29.15 |
|        stool        |  8.27 | 12.11 |
|        barrel       |  0.06 |  0.27 |
|        basket       |  4.58 |  7.02 |
|      waterfall      | 39.87 | 52.49 |
|         tent        | 37.02 | 45.32 |
|         bag         |  2.3  |  3.15 |
|       minibike      | 14.64 | 21.85 |
|        cradle       | 33.18 | 46.79 |
|         oven        | 24.65 | 30.38 |
|         ball        | 14.24 | 19.72 |
|         food        | 27.98 | 39.23 |
|         step        |  0.0  |  0.0  |
|         tank        | 29.15 | 37.06 |
|      trade name     |  5.81 |  7.31 |
|      microwave      | 41.43 |  52.6 |
|         pot         | 10.12 | 14.88 |
|        animal       |  20.9 | 26.93 |
|       bicycle       |  3.94 |  6.46 |
|         lake        | 33.66 | 39.12 |
|      dishwasher     | 14.17 | 18.98 |
|        screen       | 37.93 | 53.36 |
|       blanket       |  2.74 |  3.64 |
|      sculpture      |  16.9 | 27.04 |
|         hood        | 25.26 | 36.31 |
|        sconce       | 11.09 | 15.58 |
|         vase        |  5.32 |  8.93 |
|    traffic light    | 14.49 | 21.38 |
|         tray        |  2.29 |  4.55 |
|        ashcan       |  1.36 |  2.44 |
|         fan         | 19.98 | 27.96 |
|         pier        |  0.51 |  0.88 |
|      crt screen     |  8.69 | 12.22 |
|        plate        | 10.75 | 17.21 |
|       monitor       | 37.26 | 46.67 |
|    bulletin board   | 33.14 | 44.31 |
|        shower       |  0.35 |  1.11 |
|       radiator      |  8.33 | 12.54 |
|        glass        |  0.29 |  0.34 |
|        clock        | 24.45 | 30.51 |
|         flag        | 37.14 | 44.05 |
+---------------------+-------+-------+
2025-04-22 20:37:12,520 - mmseg - INFO - Summary:
2025-04-22 20:37:12,520 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 53.69 | 20.66 | 29.38 |
+-------+-------+-------+
2025-04-22 20:37:12,521 - mmseg - INFO - Exp name: vpd_config.py
2025-04-22 20:37:12,521 - mmseg - INFO - Iter(val) [2000]	aAcc: 0.5369, mIoU: 0.2066, mAcc: 0.2938, IoU.wall: 0.4586, IoU.building: 0.5459, IoU.sky: 0.5154, IoU.floor: 0.3253, IoU.tree: 0.4547, IoU.ceiling: 0.6231, IoU.road: 0.3702, IoU.bed : 0.2996, IoU.windowpane: 0.3618, IoU.grass: 0.2580, IoU.cabinet: 0.2990, IoU.sidewalk: 0.1370, IoU.person: 0.3139, IoU.earth: 0.2085, IoU.door: 0.3111, IoU.table: 0.1538, IoU.mountain: 0.3970, IoU.plant: 0.2152, IoU.curtain: 0.4510, IoU.chair: 0.1352, IoU.car: 0.1289, IoU.water: 0.3163, IoU.painting: 0.3250, IoU.sofa: 0.1437, IoU.shelf: 0.2717, IoU.house: 0.2817, IoU.sea: 0.3857, IoU.mirror: 0.4080, IoU.rug: 0.1471, IoU.field: 0.2090, IoU.armchair: 0.1166, IoU.seat: 0.2579, IoU.fence: 0.1023, IoU.desk: 0.1672, IoU.rock: 0.2356, IoU.wardrobe: 0.3835, IoU.lamp: 0.2014, IoU.bathtub: 0.3860, IoU.railing: 0.1269, IoU.cushion: 0.0752, IoU.base: 0.1379, IoU.box: 0.0976, IoU.column: 0.2824, IoU.signboard: 0.1056, IoU.chest of drawers: 0.1552, IoU.counter: 0.0901, IoU.sand: 0.2758, IoU.sink: 0.1654, IoU.skyscraper: 0.4459, IoU.fireplace: 0.3144, IoU.refrigerator: 0.4273, IoU.grandstand: 0.2949, IoU.path: 0.0721, IoU.stairs: 0.0974, IoU.runway: 0.3103, IoU.case: 0.3167, IoU.pool table: 0.2576, IoU.pillow: 0.0994, IoU.screen door: 0.3628, IoU.stairway: 0.1558, IoU.river: 0.1741, IoU.bridge: 0.1818, IoU.bookcase: 0.2706, IoU.blind: 0.3488, IoU.coffee table: 0.0412, IoU.toilet: 0.1833, IoU.flower: 0.1398, IoU.book: 0.2430, IoU.hill: 0.0876, IoU.bench: 0.1353, IoU.countertop: 0.1167, IoU.stove: 0.2312, IoU.palm: 0.2959, IoU.kitchen island: 0.0954, IoU.computer: 0.3243, IoU.swivel chair: 0.1555, IoU.boat: 0.1047, IoU.bar: 0.2675, IoU.arcade machine: 0.2201, IoU.hovel: 0.1762, IoU.bus: 0.3977, IoU.towel: 0.1604, IoU.light: 0.2155, IoU.truck: 0.0615, IoU.tower: 0.0567, IoU.chandelier: 0.2939, IoU.awning: 0.0431, IoU.streetlight: 0.1188, IoU.booth: 0.2190, IoU.television receiver: 0.1485, IoU.airplane: 0.0894, IoU.dirt track: 0.0071, IoU.apparel: 0.1761, IoU.pole: 0.1293, IoU.land: 0.0285, IoU.bannister: 0.0586, IoU.escalator: 0.1293, IoU.ottoman: 0.0215, IoU.bottle: 0.1041, IoU.buffet: 0.2724, IoU.poster: 0.2986, IoU.stage: 0.1126, IoU.van: 0.0638, IoU.ship: 0.2477, IoU.fountain: 0.0729, IoU.conveyer belt: 0.2930, IoU.canopy: 0.1780, IoU.washer: 0.3500, IoU.plaything: 0.0554, IoU.swimming pool: 0.1867, IoU.stool: 0.0827, IoU.barrel: 0.0006, IoU.basket: 0.0458, IoU.waterfall: 0.3987, IoU.tent: 0.3702, IoU.bag: 0.0230, IoU.minibike: 0.1464, IoU.cradle: 0.3318, IoU.oven: 0.2465, IoU.ball: 0.1424, IoU.food: 0.2798, IoU.step: 0.0000, IoU.tank: 0.2915, IoU.trade name: 0.0581, IoU.microwave: 0.4143, IoU.pot: 0.1012, IoU.animal: 0.2090, IoU.bicycle: 0.0394, IoU.lake: 0.3366, IoU.dishwasher: 0.1417, IoU.screen: 0.3793, IoU.blanket: 0.0274, IoU.sculpture: 0.1690, IoU.hood: 0.2526, IoU.sconce: 0.1109, IoU.vase: 0.0532, IoU.traffic light: 0.1449, IoU.tray: 0.0229, IoU.ashcan: 0.0136, IoU.fan: 0.1998, IoU.pier: 0.0051, IoU.crt screen: 0.0869, IoU.plate: 0.1075, IoU.monitor: 0.3726, IoU.bulletin board: 0.3314, IoU.shower: 0.0035, IoU.radiator: 0.0833, IoU.glass: 0.0029, IoU.clock: 0.2445, IoU.flag: 0.3714, Acc.wall: 0.6029, Acc.building: 0.6385, Acc.sky: 0.7346, Acc.floor: 0.7705, Acc.tree: 0.5844, Acc.ceiling: 0.6616, Acc.road: 0.7785, Acc.bed : 0.4250, Acc.windowpane: 0.4640, Acc.grass: 0.4075, Acc.cabinet: 0.4066, Acc.sidewalk: 0.2214, Acc.person: 0.4276, Acc.earth: 0.3377, Acc.door: 0.4091, Acc.table: 0.2547, Acc.mountain: 0.6009, Acc.plant: 0.2825, Acc.curtain: 0.5468, Acc.chair: 0.2086, Acc.car: 0.2000, Acc.water: 0.5237, Acc.painting: 0.4250, Acc.sofa: 0.2244, Acc.shelf: 0.3917, Acc.house: 0.4285, Acc.sea: 0.6612, Acc.mirror: 0.5014, Acc.rug: 0.2170, Acc.field: 0.3939, Acc.armchair: 0.1994, Acc.seat: 0.4016, Acc.fence: 0.1571, Acc.desk: 0.2718, Acc.rock: 0.3596, Acc.wardrobe: 0.4682, Acc.lamp: 0.2846, Acc.bathtub: 0.4971, Acc.railing: 0.1849, Acc.cushion: 0.1198, Acc.base: 0.2234, Acc.box: 0.1368, Acc.column: 0.3419, Acc.signboard: 0.1504, Acc.chest of drawers: 0.2288, Acc.counter: 0.1432, Acc.sand: 0.4548, Acc.sink: 0.2422, Acc.skyscraper: 0.5543, Acc.fireplace: 0.4454, Acc.refrigerator: 0.5035, Acc.grandstand: 0.6029, Acc.path: 0.1129, Acc.stairs: 0.1343, Acc.runway: 0.4778, Acc.case: 0.4626, Acc.pool table: 0.3760, Acc.pillow: 0.1448, Acc.screen door: 0.4388, Acc.stairway: 0.2210, Acc.river: 0.2780, Acc.bridge: 0.3104, Acc.bookcase: 0.3796, Acc.blind: 0.3876, Acc.coffee table: 0.0753, Acc.toilet: 0.2640, Acc.flower: 0.2389, Acc.book: 0.3470, Acc.hill: 0.1398, Acc.bench: 0.1947, Acc.countertop: 0.1963, Acc.stove: 0.3331, Acc.palm: 0.4263, Acc.kitchen island: 0.1942, Acc.computer: 0.4786, Acc.swivel chair: 0.2251, Acc.boat: 0.1861, Acc.bar: 0.3932, Acc.arcade machine: 0.2680, Acc.hovel: 0.2071, Acc.bus: 0.5022, Acc.towel: 0.2569, Acc.light: 0.2872, Acc.truck: 0.1178, Acc.tower: 0.1029, Acc.chandelier: 0.4158, Acc.awning: 0.0593, Acc.streetlight: 0.1496, Acc.booth: 0.3229, Acc.television receiver: 0.2286, Acc.airplane: 0.1392, Acc.dirt track: 0.0382, Acc.apparel: 0.2464, Acc.pole: 0.1809, Acc.land: 0.0412, Acc.bannister: 0.0864, Acc.escalator: 0.1772, Acc.ottoman: 0.0365, Acc.bottle: 0.1654, Acc.buffet: 0.3230, Acc.poster: 0.3705, Acc.stage: 0.2288, Acc.van: 0.1006, Acc.ship: 0.3650, Acc.fountain: 0.0889, Acc.conveyer belt: 0.4788, Acc.canopy: 0.2484, Acc.washer: 0.3985, Acc.plaything: 0.1004, Acc.swimming pool: 0.2915, Acc.stool: 0.1211, Acc.barrel: 0.0027, Acc.basket: 0.0702, Acc.waterfall: 0.5249, Acc.tent: 0.4532, Acc.bag: 0.0315, Acc.minibike: 0.2185, Acc.cradle: 0.4679, Acc.oven: 0.3038, Acc.ball: 0.1972, Acc.food: 0.3923, Acc.step: 0.0000, Acc.tank: 0.3706, Acc.trade name: 0.0731, Acc.microwave: 0.5260, Acc.pot: 0.1488, Acc.animal: 0.2693, Acc.bicycle: 0.0646, Acc.lake: 0.3912, Acc.dishwasher: 0.1898, Acc.screen: 0.5336, Acc.blanket: 0.0364, Acc.sculpture: 0.2704, Acc.hood: 0.3631, Acc.sconce: 0.1558, Acc.vase: 0.0893, Acc.traffic light: 0.2138, Acc.tray: 0.0455, Acc.ashcan: 0.0244, Acc.fan: 0.2796, Acc.pier: 0.0088, Acc.crt screen: 0.1222, Acc.plate: 0.1721, Acc.monitor: 0.4667, Acc.bulletin board: 0.4431, Acc.shower: 0.0111, Acc.radiator: 0.1254, Acc.glass: 0.0034, Acc.clock: 0.3051, Acc.flag: 0.4405
2025-04-22 20:37:28,384 - mmseg - INFO - Iter [20050/40000]	lr: 3.990e-05, eta: 1:59:42, time: 4.605, data_time: 4.296, memory: 75933, decode.loss_ce: 0.1349, decode.acc_seg: 94.7072, loss: 0.1349
2025-04-22 20:37:43,533 - mmseg - INFO - Iter [20100/40000]	lr: 3.980e-05, eta: 1:59:21, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1352, decode.acc_seg: 94.6361, loss: 0.1352
2025-04-22 20:37:58,696 - mmseg - INFO - Iter [20150/40000]	lr: 3.970e-05, eta: 1:59:00, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1287, decode.acc_seg: 94.7240, loss: 0.1287
2025-04-22 20:38:13,897 - mmseg - INFO - Iter [20200/40000]	lr: 3.960e-05, eta: 1:58:40, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1330, decode.acc_seg: 94.3636, loss: 0.1330
2025-04-22 20:38:29,093 - mmseg - INFO - Iter [20250/40000]	lr: 3.950e-05, eta: 1:58:19, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1293, decode.acc_seg: 94.5245, loss: 0.1293
2025-04-22 20:38:44,301 - mmseg - INFO - Iter [20300/40000]	lr: 3.940e-05, eta: 1:57:58, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1320, decode.acc_seg: 94.3050, loss: 0.1320
2025-04-22 20:38:59,507 - mmseg - INFO - Iter [20350/40000]	lr: 3.930e-05, eta: 1:57:38, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1316, decode.acc_seg: 94.5013, loss: 0.1316
2025-04-22 20:39:14,718 - mmseg - INFO - Iter [20400/40000]	lr: 3.920e-05, eta: 1:57:17, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1218, decode.acc_seg: 94.8928, loss: 0.1218
2025-04-22 20:39:29,932 - mmseg - INFO - Iter [20450/40000]	lr: 3.910e-05, eta: 1:56:57, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1678, decode.acc_seg: 93.2980, loss: 0.1678
2025-04-22 20:39:45,123 - mmseg - INFO - Iter [20500/40000]	lr: 3.900e-05, eta: 1:56:36, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1333, decode.acc_seg: 94.2711, loss: 0.1333
2025-04-22 20:40:00,325 - mmseg - INFO - Iter [20550/40000]	lr: 3.890e-05, eta: 1:56:15, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1467, decode.acc_seg: 93.9795, loss: 0.1467
2025-04-22 20:40:15,506 - mmseg - INFO - Iter [20600/40000]	lr: 3.880e-05, eta: 1:55:55, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1335, decode.acc_seg: 94.4137, loss: 0.1335
2025-04-22 20:40:30,699 - mmseg - INFO - Iter [20650/40000]	lr: 3.870e-05, eta: 1:55:34, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1401, decode.acc_seg: 94.3553, loss: 0.1401
2025-04-22 20:40:45,906 - mmseg - INFO - Iter [20700/40000]	lr: 3.860e-05, eta: 1:55:14, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1188, decode.acc_seg: 95.1024, loss: 0.1188
2025-04-22 20:41:01,126 - mmseg - INFO - Iter [20750/40000]	lr: 3.850e-05, eta: 1:54:54, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1355, decode.acc_seg: 94.4358, loss: 0.1355
2025-04-22 20:41:16,302 - mmseg - INFO - Iter [20800/40000]	lr: 3.840e-05, eta: 1:54:33, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1504, decode.acc_seg: 94.0019, loss: 0.1504
2025-04-22 20:41:31,472 - mmseg - INFO - Iter [20850/40000]	lr: 3.830e-05, eta: 1:54:13, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1334, decode.acc_seg: 94.5374, loss: 0.1334
2025-04-22 20:41:46,655 - mmseg - INFO - Iter [20900/40000]	lr: 3.820e-05, eta: 1:53:52, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1458, decode.acc_seg: 93.9502, loss: 0.1458
2025-04-22 20:42:01,833 - mmseg - INFO - Iter [20950/40000]	lr: 3.810e-05, eta: 1:53:32, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1355, decode.acc_seg: 94.5275, loss: 0.1355
2025-04-22 20:42:17,008 - mmseg - INFO - Exp name: vpd_config.py
2025-04-22 20:42:17,009 - mmseg - INFO - Iter [21000/40000]	lr: 3.800e-05, eta: 1:53:12, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1169, decode.acc_seg: 95.0638, loss: 0.1169
2025-04-22 20:42:33,040 - mmseg - INFO - Iter [21050/40000]	lr: 3.790e-05, eta: 1:52:52, time: 0.321, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1398, decode.acc_seg: 94.3877, loss: 0.1398
2025-04-22 20:42:48,259 - mmseg - INFO - Iter [21100/40000]	lr: 3.780e-05, eta: 1:52:32, time: 0.304, data_time: 0.010, memory: 75933, decode.loss_ce: 0.1452, decode.acc_seg: 93.9313, loss: 0.1452
2025-04-22 20:43:03,438 - mmseg - INFO - Iter [21150/40000]	lr: 3.770e-05, eta: 1:52:12, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1379, decode.acc_seg: 94.1840, loss: 0.1379
2025-04-22 20:43:18,611 - mmseg - INFO - Iter [21200/40000]	lr: 3.760e-05, eta: 1:51:51, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1228, decode.acc_seg: 94.8769, loss: 0.1228
2025-04-22 20:43:33,783 - mmseg - INFO - Iter [21250/40000]	lr: 3.750e-05, eta: 1:51:31, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1309, decode.acc_seg: 94.3111, loss: 0.1309
2025-04-22 20:43:48,973 - mmseg - INFO - Iter [21300/40000]	lr: 3.740e-05, eta: 1:51:11, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1251, decode.acc_seg: 94.7923, loss: 0.1251
2025-04-22 20:44:04,160 - mmseg - INFO - Iter [21350/40000]	lr: 3.730e-05, eta: 1:50:51, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1425, decode.acc_seg: 94.1216, loss: 0.1425
2025-04-22 20:44:19,329 - mmseg - INFO - Iter [21400/40000]	lr: 3.720e-05, eta: 1:50:31, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1353, decode.acc_seg: 94.3319, loss: 0.1353
2025-04-22 20:44:34,511 - mmseg - INFO - Iter [21450/40000]	lr: 3.710e-05, eta: 1:50:11, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1336, decode.acc_seg: 94.6864, loss: 0.1336
2025-04-22 20:44:49,689 - mmseg - INFO - Iter [21500/40000]	lr: 3.700e-05, eta: 1:49:51, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1257, decode.acc_seg: 94.5266, loss: 0.1257
2025-04-22 20:45:04,860 - mmseg - INFO - Iter [21550/40000]	lr: 3.690e-05, eta: 1:49:30, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1376, decode.acc_seg: 94.0098, loss: 0.1376
2025-04-22 20:45:20,009 - mmseg - INFO - Iter [21600/40000]	lr: 3.680e-05, eta: 1:49:10, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1525, decode.acc_seg: 93.7573, loss: 0.1525
2025-04-22 20:45:35,168 - mmseg - INFO - Iter [21650/40000]	lr: 3.670e-05, eta: 1:48:50, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1420, decode.acc_seg: 94.1343, loss: 0.1420
2025-04-22 20:45:50,360 - mmseg - INFO - Iter [21700/40000]	lr: 3.660e-05, eta: 1:48:30, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1310, decode.acc_seg: 94.4699, loss: 0.1310
2025-04-22 20:46:05,539 - mmseg - INFO - Iter [21750/40000]	lr: 3.650e-05, eta: 1:48:10, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1287, decode.acc_seg: 94.5358, loss: 0.1287
2025-04-22 20:46:20,709 - mmseg - INFO - Iter [21800/40000]	lr: 3.640e-05, eta: 1:47:50, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1328, decode.acc_seg: 94.2229, loss: 0.1328
2025-04-22 20:46:35,888 - mmseg - INFO - Iter [21850/40000]	lr: 3.630e-05, eta: 1:47:30, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1293, decode.acc_seg: 94.3843, loss: 0.1293
2025-04-22 20:46:51,058 - mmseg - INFO - Iter [21900/40000]	lr: 3.620e-05, eta: 1:47:11, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1245, decode.acc_seg: 94.6635, loss: 0.1245
2025-04-22 20:47:06,236 - mmseg - INFO - Iter [21950/40000]	lr: 3.610e-05, eta: 1:46:51, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1295, decode.acc_seg: 94.3427, loss: 0.1295
2025-04-22 20:47:21,404 - mmseg - INFO - Exp name: vpd_config.py
2025-04-22 20:47:21,405 - mmseg - INFO - Iter [22000/40000]	lr: 3.600e-05, eta: 1:46:31, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1213, decode.acc_seg: 94.8778, loss: 0.1213
2025-04-22 20:47:37,330 - mmseg - INFO - Iter [22050/40000]	lr: 3.590e-05, eta: 1:46:12, time: 0.319, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1411, decode.acc_seg: 94.1073, loss: 0.1411
2025-04-22 20:47:52,510 - mmseg - INFO - Iter [22100/40000]	lr: 3.580e-05, eta: 1:45:52, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1285, decode.acc_seg: 94.3003, loss: 0.1285
2025-04-22 20:48:07,688 - mmseg - INFO - Iter [22150/40000]	lr: 3.570e-05, eta: 1:45:32, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1388, decode.acc_seg: 93.8878, loss: 0.1388
2025-04-22 20:48:22,867 - mmseg - INFO - Iter [22200/40000]	lr: 3.560e-05, eta: 1:45:12, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1444, decode.acc_seg: 94.0858, loss: 0.1444
2025-04-22 20:48:38,042 - mmseg - INFO - Iter [22250/40000]	lr: 3.550e-05, eta: 1:44:52, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1257, decode.acc_seg: 94.7612, loss: 0.1257
2025-04-22 20:48:53,212 - mmseg - INFO - Iter [22300/40000]	lr: 3.540e-05, eta: 1:44:33, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1251, decode.acc_seg: 94.7258, loss: 0.1251
2025-04-22 20:49:08,387 - mmseg - INFO - Iter [22350/40000]	lr: 3.530e-05, eta: 1:44:13, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1234, decode.acc_seg: 94.4906, loss: 0.1234
2025-04-22 20:49:23,571 - mmseg - INFO - Iter [22400/40000]	lr: 3.520e-05, eta: 1:43:53, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1339, decode.acc_seg: 94.6428, loss: 0.1339
2025-04-22 20:49:38,755 - mmseg - INFO - Iter [22450/40000]	lr: 3.510e-05, eta: 1:43:33, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1456, decode.acc_seg: 93.6728, loss: 0.1456
2025-04-22 20:49:53,931 - mmseg - INFO - Iter [22500/40000]	lr: 3.500e-05, eta: 1:43:14, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1346, decode.acc_seg: 94.4491, loss: 0.1346
2025-04-22 20:50:09,113 - mmseg - INFO - Iter [22550/40000]	lr: 3.490e-05, eta: 1:42:54, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1224, decode.acc_seg: 94.6777, loss: 0.1224
2025-04-22 20:50:24,290 - mmseg - INFO - Iter [22600/40000]	lr: 3.480e-05, eta: 1:42:35, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1357, decode.acc_seg: 94.0071, loss: 0.1357
2025-04-22 20:50:39,459 - mmseg - INFO - Iter [22650/40000]	lr: 3.470e-05, eta: 1:42:15, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1703, decode.acc_seg: 93.0552, loss: 0.1703
2025-04-22 20:50:54,616 - mmseg - INFO - Iter [22700/40000]	lr: 3.460e-05, eta: 1:41:55, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1348, decode.acc_seg: 94.2127, loss: 0.1348
2025-04-22 20:51:09,765 - mmseg - INFO - Iter [22750/40000]	lr: 3.450e-05, eta: 1:41:36, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1247, decode.acc_seg: 94.7047, loss: 0.1247
2025-04-22 20:51:24,941 - mmseg - INFO - Iter [22800/40000]	lr: 3.440e-05, eta: 1:41:16, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1412, decode.acc_seg: 94.1843, loss: 0.1412
2025-04-22 20:51:40,124 - mmseg - INFO - Iter [22850/40000]	lr: 3.430e-05, eta: 1:40:57, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1490, decode.acc_seg: 93.7593, loss: 0.1490
2025-04-22 20:51:55,288 - mmseg - INFO - Iter [22900/40000]	lr: 3.420e-05, eta: 1:40:37, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1155, decode.acc_seg: 95.0866, loss: 0.1155
2025-04-22 20:52:10,490 - mmseg - INFO - Iter [22950/40000]	lr: 3.410e-05, eta: 1:40:18, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1390, decode.acc_seg: 94.0333, loss: 0.1390
2025-04-22 20:52:25,670 - mmseg - INFO - Exp name: vpd_config.py
2025-04-22 20:52:25,671 - mmseg - INFO - Iter [23000/40000]	lr: 3.400e-05, eta: 1:39:58, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1431, decode.acc_seg: 93.7441, loss: 0.1431
2025-04-22 20:52:41,568 - mmseg - INFO - Iter [23050/40000]	lr: 3.390e-05, eta: 1:39:39, time: 0.318, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1248, decode.acc_seg: 94.6538, loss: 0.1248
2025-04-22 20:52:56,756 - mmseg - INFO - Iter [23100/40000]	lr: 3.380e-05, eta: 1:39:20, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1383, decode.acc_seg: 93.9040, loss: 0.1383
2025-04-22 20:53:11,947 - mmseg - INFO - Iter [23150/40000]	lr: 3.370e-05, eta: 1:39:00, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1389, decode.acc_seg: 94.4654, loss: 0.1389
2025-04-22 20:53:27,109 - mmseg - INFO - Iter [23200/40000]	lr: 3.360e-05, eta: 1:38:41, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1384, decode.acc_seg: 94.3064, loss: 0.1384
2025-04-22 20:53:42,261 - mmseg - INFO - Iter [23250/40000]	lr: 3.350e-05, eta: 1:38:22, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1358, decode.acc_seg: 94.2461, loss: 0.1358
2025-04-22 20:53:57,420 - mmseg - INFO - Iter [23300/40000]	lr: 3.340e-05, eta: 1:38:02, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1334, decode.acc_seg: 94.2797, loss: 0.1334
2025-04-22 20:54:12,585 - mmseg - INFO - Iter [23350/40000]	lr: 3.330e-05, eta: 1:37:43, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1377, decode.acc_seg: 94.3540, loss: 0.1377
2025-04-22 20:54:27,747 - mmseg - INFO - Iter [23400/40000]	lr: 3.320e-05, eta: 1:37:23, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1349, decode.acc_seg: 94.1677, loss: 0.1349
2025-04-22 20:54:42,893 - mmseg - INFO - Iter [23450/40000]	lr: 3.310e-05, eta: 1:37:04, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1296, decode.acc_seg: 94.7245, loss: 0.1296
2025-04-22 20:54:58,060 - mmseg - INFO - Iter [23500/40000]	lr: 3.300e-05, eta: 1:36:45, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1251, decode.acc_seg: 94.6312, loss: 0.1251
2025-04-22 20:55:13,228 - mmseg - INFO - Iter [23550/40000]	lr: 3.290e-05, eta: 1:36:26, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1464, decode.acc_seg: 93.8701, loss: 0.1464
2025-04-22 20:55:28,383 - mmseg - INFO - Iter [23600/40000]	lr: 3.280e-05, eta: 1:36:06, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1359, decode.acc_seg: 94.3702, loss: 0.1359
2025-04-22 20:55:43,564 - mmseg - INFO - Iter [23650/40000]	lr: 3.270e-05, eta: 1:35:47, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1316, decode.acc_seg: 94.4957, loss: 0.1316
2025-04-22 20:55:58,723 - mmseg - INFO - Iter [23700/40000]	lr: 3.260e-05, eta: 1:35:28, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1421, decode.acc_seg: 94.1372, loss: 0.1421
2025-04-22 20:56:13,890 - mmseg - INFO - Iter [23750/40000]	lr: 3.250e-05, eta: 1:35:09, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1259, decode.acc_seg: 94.6992, loss: 0.1259
2025-04-22 20:56:29,042 - mmseg - INFO - Iter [23800/40000]	lr: 3.240e-05, eta: 1:34:49, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1341, decode.acc_seg: 94.4663, loss: 0.1341
2025-04-22 20:56:44,190 - mmseg - INFO - Iter [23850/40000]	lr: 3.230e-05, eta: 1:34:30, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1219, decode.acc_seg: 94.8673, loss: 0.1219
2025-04-22 20:56:59,335 - mmseg - INFO - Iter [23900/40000]	lr: 3.220e-05, eta: 1:34:11, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1371, decode.acc_seg: 94.3555, loss: 0.1371
2025-04-22 20:57:14,470 - mmseg - INFO - Iter [23950/40000]	lr: 3.210e-05, eta: 1:33:52, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1354, decode.acc_seg: 94.4932, loss: 0.1354
2025-04-22 20:57:29,610 - mmseg - INFO - Saving checkpoint at 24000 iterations
2025-04-22 20:57:38,938 - mmseg - INFO - Exp name: vpd_config.py
2025-04-22 20:57:38,938 - mmseg - INFO - Iter [24000/40000]	lr: 3.200e-05, eta: 1:33:39, time: 0.490, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1342, decode.acc_seg: 94.3464, loss: 0.1342
2025-04-22 21:01:13,146 - mmseg - INFO - per class results:
2025-04-22 21:01:13,153 - mmseg - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        | 47.01 |  59.3 |
|       building      | 54.63 | 63.72 |
|         sky         | 56.85 | 73.66 |
|        floor        | 33.27 | 80.55 |
|         tree        |  44.3 | 58.33 |
|       ceiling       | 63.23 | 67.66 |
|         road        | 37.07 | 82.36 |
|         bed         | 29.53 | 41.62 |
|      windowpane     | 36.21 | 47.18 |
|        grass        | 25.42 |  39.3 |
|       cabinet       | 29.33 | 38.74 |
|       sidewalk      | 14.78 | 24.22 |
|        person       | 31.12 |  42.8 |
|        earth        | 21.33 | 40.29 |
|         door        | 30.55 | 42.87 |
|        table        | 15.05 | 24.27 |
|       mountain      | 40.36 | 58.19 |
|        plant        | 21.47 | 28.28 |
|       curtain       | 45.06 |  53.6 |
|        chair        |  13.5 | 20.81 |
|         car         | 13.26 | 20.54 |
|        water        | 31.92 | 52.75 |
|       painting      | 32.58 |  43.2 |
|         sofa        | 13.82 | 21.07 |
|        shelf        | 27.26 | 38.02 |
|        house        |  28.2 | 43.38 |
|         sea         | 37.98 | 67.59 |
|        mirror       | 40.74 |  49.6 |
|         rug         | 14.47 | 21.27 |
|        field        | 20.03 | 45.19 |
|       armchair      | 11.56 | 19.69 |
|         seat        | 25.53 | 41.08 |
|        fence        | 10.24 | 15.33 |
|         desk        | 16.74 | 27.13 |
|         rock        | 24.42 | 37.42 |
|       wardrobe      | 36.55 | 45.56 |
|         lamp        | 20.11 | 28.61 |
|       bathtub       | 38.82 | 48.35 |
|       railing       | 12.88 | 19.47 |
|       cushion       |  7.46 |  12.0 |
|         base        |  13.9 | 21.25 |
|         box         |  9.69 | 13.84 |
|        column       | 28.38 | 35.29 |
|      signboard      |  10.0 | 13.86 |
|   chest of drawers  | 16.18 | 24.63 |
|       counter       |  9.45 | 15.52 |
|         sand        | 27.39 | 45.18 |
|         sink        | 16.52 | 24.13 |
|      skyscraper     | 43.53 | 53.34 |
|      fireplace      | 31.53 | 44.26 |
|     refrigerator    | 42.24 | 49.95 |
|      grandstand     | 29.53 | 60.95 |
|         path        |  7.4  | 11.72 |
|        stairs       | 10.01 | 13.93 |
|        runway       | 30.18 | 47.26 |
|         case        | 32.82 | 50.14 |
|      pool table     | 25.23 |  37.9 |
|        pillow       | 10.27 | 15.09 |
|     screen door     | 34.49 | 42.42 |
|       stairway      | 15.42 | 22.46 |
|        river        | 17.34 |  27.0 |
|        bridge       | 18.28 | 31.01 |
|       bookcase      | 25.41 | 35.23 |
|        blind        | 36.64 |  41.7 |
|     coffee table    |  4.14 |  7.61 |
|        toilet       | 18.26 | 26.35 |
|        flower       | 13.94 | 23.63 |
|         book        | 24.19 |  35.8 |
|         hill        |  8.72 | 14.61 |
|        bench        |  12.2 | 17.63 |
|      countertop     | 11.68 | 20.43 |
|        stove        | 23.07 | 32.24 |
|         palm        | 30.27 | 45.07 |
|    kitchen island   | 10.08 | 23.22 |
|       computer      | 32.66 | 47.85 |
|     swivel chair    | 15.25 |  23.5 |
|         boat        | 10.68 | 16.98 |
|         bar         | 26.24 | 39.19 |
|    arcade machine   | 21.64 | 26.44 |
|        hovel        | 16.97 | 19.75 |
|         bus         |  39.8 | 50.28 |
|        towel        | 17.03 | 25.93 |
|        light        | 20.74 | 26.67 |
|        truck        |  5.99 | 11.43 |
|        tower        |  6.03 | 11.86 |
|      chandelier     | 29.58 | 41.94 |
|        awning       |  4.44 |  5.93 |
|     streetlight     | 12.44 | 16.37 |
|        booth        | 22.26 | 34.23 |
| television receiver | 15.11 | 23.46 |
|       airplane      | 10.07 | 16.08 |
|      dirt track     |  1.79 |  8.9  |
|       apparel       | 17.68 | 27.23 |
|         pole        | 10.07 | 13.31 |
|         land        |  3.27 |  4.52 |
|      bannister      |  5.72 |  8.58 |
|      escalator      | 12.66 | 16.61 |
|       ottoman       |  2.15 |  3.67 |
|        bottle       | 11.61 | 18.75 |
|        buffet       |  26.2 | 34.29 |
|        poster       | 30.45 | 37.84 |
|        stage        | 10.72 | 23.93 |
|         van         |  7.12 | 12.32 |
|         ship        |  34.8 | 54.35 |
|       fountain      |  6.34 |  7.67 |
|    conveyer belt    | 27.96 | 45.05 |
|        canopy       | 18.22 | 24.45 |
|        washer       | 34.95 | 40.14 |
|      plaything      |  5.57 | 11.26 |
|    swimming pool    | 16.92 | 26.13 |
|        stool        |  8.3  | 11.22 |
|        barrel       |  1.6  |  7.98 |
|        basket       |  4.34 |  7.36 |
|      waterfall      | 38.51 |  50.8 |
|         tent        | 36.17 |  45.3 |
|         bag         |  2.43 |  3.46 |
|       minibike      | 14.84 | 22.47 |
|        cradle       | 33.16 | 46.82 |
|         oven        | 24.56 | 31.87 |
|         ball        | 16.95 | 26.22 |
|         food        | 26.26 | 32.55 |
|         step        |  0.0  |  0.0  |
|         tank        |  27.5 | 34.28 |
|      trade name     |  6.35 |  8.44 |
|      microwave      | 41.36 | 52.67 |
|         pot         |  8.53 |  12.2 |
|        animal       | 20.65 | 26.67 |
|       bicycle       |  3.96 |  6.66 |
|         lake        |  32.9 | 38.56 |
|      dishwasher     | 14.71 | 20.43 |
|        screen       | 38.67 | 51.11 |
|       blanket       |  2.69 |  3.67 |
|      sculpture      | 18.02 | 31.28 |
|         hood        | 25.39 | 36.25 |
|        sconce       | 11.25 | 16.08 |
|         vase        |  5.39 |  8.76 |
|    traffic light    |  14.9 | 23.21 |
|         tray        |  3.16 |  6.12 |
|        ashcan       |  1.2  |  1.97 |
|         fan         | 19.86 | 27.71 |
|         pier        |  0.48 |  0.76 |
|      crt screen     |  7.99 | 12.46 |
|        plate        | 10.75 | 16.05 |
|       monitor       | 36.98 | 47.25 |
|    bulletin board   | 33.46 | 41.86 |
|        shower       |  0.29 |  0.86 |
|       radiator      |  8.64 | 13.34 |
|        glass        |  0.31 |  0.35 |
|        clock        | 23.89 | 30.58 |
|         flag        |  37.1 | 43.86 |
+---------------------+-------+-------+
2025-04-22 21:01:13,153 - mmseg - INFO - Summary:
2025-04-22 21:01:13,153 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 54.12 | 20.72 | 29.77 |
+-------+-------+-------+
2025-04-22 21:01:13,154 - mmseg - INFO - Exp name: vpd_config.py
2025-04-22 21:01:13,154 - mmseg - INFO - Iter(val) [2000]	aAcc: 0.5412, mIoU: 0.2072, mAcc: 0.2977, IoU.wall: 0.4701, IoU.building: 0.5463, IoU.sky: 0.5685, IoU.floor: 0.3327, IoU.tree: 0.4430, IoU.ceiling: 0.6323, IoU.road: 0.3707, IoU.bed : 0.2953, IoU.windowpane: 0.3621, IoU.grass: 0.2542, IoU.cabinet: 0.2933, IoU.sidewalk: 0.1478, IoU.person: 0.3112, IoU.earth: 0.2133, IoU.door: 0.3055, IoU.table: 0.1505, IoU.mountain: 0.4036, IoU.plant: 0.2147, IoU.curtain: 0.4506, IoU.chair: 0.1350, IoU.car: 0.1326, IoU.water: 0.3192, IoU.painting: 0.3258, IoU.sofa: 0.1382, IoU.shelf: 0.2726, IoU.house: 0.2820, IoU.sea: 0.3798, IoU.mirror: 0.4074, IoU.rug: 0.1447, IoU.field: 0.2003, IoU.armchair: 0.1156, IoU.seat: 0.2553, IoU.fence: 0.1024, IoU.desk: 0.1674, IoU.rock: 0.2442, IoU.wardrobe: 0.3655, IoU.lamp: 0.2011, IoU.bathtub: 0.3882, IoU.railing: 0.1288, IoU.cushion: 0.0746, IoU.base: 0.1390, IoU.box: 0.0969, IoU.column: 0.2838, IoU.signboard: 0.1000, IoU.chest of drawers: 0.1618, IoU.counter: 0.0945, IoU.sand: 0.2739, IoU.sink: 0.1652, IoU.skyscraper: 0.4353, IoU.fireplace: 0.3153, IoU.refrigerator: 0.4224, IoU.grandstand: 0.2953, IoU.path: 0.0740, IoU.stairs: 0.1001, IoU.runway: 0.3018, IoU.case: 0.3282, IoU.pool table: 0.2523, IoU.pillow: 0.1027, IoU.screen door: 0.3449, IoU.stairway: 0.1542, IoU.river: 0.1734, IoU.bridge: 0.1828, IoU.bookcase: 0.2541, IoU.blind: 0.3664, IoU.coffee table: 0.0414, IoU.toilet: 0.1826, IoU.flower: 0.1394, IoU.book: 0.2419, IoU.hill: 0.0872, IoU.bench: 0.1220, IoU.countertop: 0.1168, IoU.stove: 0.2307, IoU.palm: 0.3027, IoU.kitchen island: 0.1008, IoU.computer: 0.3266, IoU.swivel chair: 0.1525, IoU.boat: 0.1068, IoU.bar: 0.2624, IoU.arcade machine: 0.2164, IoU.hovel: 0.1697, IoU.bus: 0.3980, IoU.towel: 0.1703, IoU.light: 0.2074, IoU.truck: 0.0599, IoU.tower: 0.0603, IoU.chandelier: 0.2958, IoU.awning: 0.0444, IoU.streetlight: 0.1244, IoU.booth: 0.2226, IoU.television receiver: 0.1511, IoU.airplane: 0.1007, IoU.dirt track: 0.0179, IoU.apparel: 0.1768, IoU.pole: 0.1007, IoU.land: 0.0327, IoU.bannister: 0.0572, IoU.escalator: 0.1266, IoU.ottoman: 0.0215, IoU.bottle: 0.1161, IoU.buffet: 0.2620, IoU.poster: 0.3045, IoU.stage: 0.1072, IoU.van: 0.0712, IoU.ship: 0.3480, IoU.fountain: 0.0634, IoU.conveyer belt: 0.2796, IoU.canopy: 0.1822, IoU.washer: 0.3495, IoU.plaything: 0.0557, IoU.swimming pool: 0.1692, IoU.stool: 0.0830, IoU.barrel: 0.0160, IoU.basket: 0.0434, IoU.waterfall: 0.3851, IoU.tent: 0.3617, IoU.bag: 0.0243, IoU.minibike: 0.1484, IoU.cradle: 0.3316, IoU.oven: 0.2456, IoU.ball: 0.1695, IoU.food: 0.2626, IoU.step: 0.0000, IoU.tank: 0.2750, IoU.trade name: 0.0635, IoU.microwave: 0.4136, IoU.pot: 0.0853, IoU.animal: 0.2065, IoU.bicycle: 0.0396, IoU.lake: 0.3290, IoU.dishwasher: 0.1471, IoU.screen: 0.3867, IoU.blanket: 0.0269, IoU.sculpture: 0.1802, IoU.hood: 0.2539, IoU.sconce: 0.1125, IoU.vase: 0.0539, IoU.traffic light: 0.1490, IoU.tray: 0.0316, IoU.ashcan: 0.0120, IoU.fan: 0.1986, IoU.pier: 0.0048, IoU.crt screen: 0.0799, IoU.plate: 0.1075, IoU.monitor: 0.3698, IoU.bulletin board: 0.3346, IoU.shower: 0.0029, IoU.radiator: 0.0864, IoU.glass: 0.0031, IoU.clock: 0.2389, IoU.flag: 0.3710, Acc.wall: 0.5930, Acc.building: 0.6372, Acc.sky: 0.7366, Acc.floor: 0.8055, Acc.tree: 0.5833, Acc.ceiling: 0.6766, Acc.road: 0.8236, Acc.bed : 0.4162, Acc.windowpane: 0.4718, Acc.grass: 0.3930, Acc.cabinet: 0.3874, Acc.sidewalk: 0.2422, Acc.person: 0.4280, Acc.earth: 0.4029, Acc.door: 0.4287, Acc.table: 0.2427, Acc.mountain: 0.5819, Acc.plant: 0.2828, Acc.curtain: 0.5360, Acc.chair: 0.2081, Acc.car: 0.2054, Acc.water: 0.5275, Acc.painting: 0.4320, Acc.sofa: 0.2107, Acc.shelf: 0.3802, Acc.house: 0.4338, Acc.sea: 0.6759, Acc.mirror: 0.4960, Acc.rug: 0.2127, Acc.field: 0.4519, Acc.armchair: 0.1969, Acc.seat: 0.4108, Acc.fence: 0.1533, Acc.desk: 0.2713, Acc.rock: 0.3742, Acc.wardrobe: 0.4556, Acc.lamp: 0.2861, Acc.bathtub: 0.4835, Acc.railing: 0.1947, Acc.cushion: 0.1200, Acc.base: 0.2125, Acc.box: 0.1384, Acc.column: 0.3529, Acc.signboard: 0.1386, Acc.chest of drawers: 0.2463, Acc.counter: 0.1552, Acc.sand: 0.4518, Acc.sink: 0.2413, Acc.skyscraper: 0.5334, Acc.fireplace: 0.4426, Acc.refrigerator: 0.4995, Acc.grandstand: 0.6095, Acc.path: 0.1172, Acc.stairs: 0.1393, Acc.runway: 0.4726, Acc.case: 0.5014, Acc.pool table: 0.3790, Acc.pillow: 0.1509, Acc.screen door: 0.4242, Acc.stairway: 0.2246, Acc.river: 0.2700, Acc.bridge: 0.3101, Acc.bookcase: 0.3523, Acc.blind: 0.4170, Acc.coffee table: 0.0761, Acc.toilet: 0.2635, Acc.flower: 0.2363, Acc.book: 0.3580, Acc.hill: 0.1461, Acc.bench: 0.1763, Acc.countertop: 0.2043, Acc.stove: 0.3224, Acc.palm: 0.4507, Acc.kitchen island: 0.2322, Acc.computer: 0.4785, Acc.swivel chair: 0.2350, Acc.boat: 0.1698, Acc.bar: 0.3919, Acc.arcade machine: 0.2644, Acc.hovel: 0.1975, Acc.bus: 0.5028, Acc.towel: 0.2593, Acc.light: 0.2667, Acc.truck: 0.1143, Acc.tower: 0.1186, Acc.chandelier: 0.4194, Acc.awning: 0.0593, Acc.streetlight: 0.1637, Acc.booth: 0.3423, Acc.television receiver: 0.2346, Acc.airplane: 0.1608, Acc.dirt track: 0.0890, Acc.apparel: 0.2723, Acc.pole: 0.1331, Acc.land: 0.0452, Acc.bannister: 0.0858, Acc.escalator: 0.1661, Acc.ottoman: 0.0367, Acc.bottle: 0.1875, Acc.buffet: 0.3429, Acc.poster: 0.3784, Acc.stage: 0.2393, Acc.van: 0.1232, Acc.ship: 0.5435, Acc.fountain: 0.0767, Acc.conveyer belt: 0.4505, Acc.canopy: 0.2445, Acc.washer: 0.4014, Acc.plaything: 0.1126, Acc.swimming pool: 0.2613, Acc.stool: 0.1122, Acc.barrel: 0.0798, Acc.basket: 0.0736, Acc.waterfall: 0.5080, Acc.tent: 0.4530, Acc.bag: 0.0346, Acc.minibike: 0.2247, Acc.cradle: 0.4682, Acc.oven: 0.3187, Acc.ball: 0.2622, Acc.food: 0.3255, Acc.step: 0.0000, Acc.tank: 0.3428, Acc.trade name: 0.0844, Acc.microwave: 0.5267, Acc.pot: 0.1220, Acc.animal: 0.2667, Acc.bicycle: 0.0666, Acc.lake: 0.3856, Acc.dishwasher: 0.2043, Acc.screen: 0.5111, Acc.blanket: 0.0367, Acc.sculpture: 0.3128, Acc.hood: 0.3625, Acc.sconce: 0.1608, Acc.vase: 0.0876, Acc.traffic light: 0.2321, Acc.tray: 0.0612, Acc.ashcan: 0.0197, Acc.fan: 0.2771, Acc.pier: 0.0076, Acc.crt screen: 0.1246, Acc.plate: 0.1605, Acc.monitor: 0.4725, Acc.bulletin board: 0.4186, Acc.shower: 0.0086, Acc.radiator: 0.1334, Acc.glass: 0.0035, Acc.clock: 0.3058, Acc.flag: 0.4386
2025-04-22 21:01:28,917 - mmseg - INFO - Iter [24050/40000]	lr: 3.190e-05, eta: 1:35:42, time: 4.599, data_time: 4.293, memory: 75933, decode.loss_ce: 0.1470, decode.acc_seg: 93.8974, loss: 0.1470
2025-04-22 21:01:44,083 - mmseg - INFO - Iter [24100/40000]	lr: 3.180e-05, eta: 1:35:22, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1338, decode.acc_seg: 94.3870, loss: 0.1338
2025-04-22 21:01:59,323 - mmseg - INFO - Iter [24150/40000]	lr: 3.170e-05, eta: 1:35:03, time: 0.305, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1351, decode.acc_seg: 94.2198, loss: 0.1351
2025-04-22 21:02:14,524 - mmseg - INFO - Iter [24200/40000]	lr: 3.160e-05, eta: 1:34:43, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1292, decode.acc_seg: 94.5584, loss: 0.1292
2025-04-22 21:02:29,714 - mmseg - INFO - Iter [24250/40000]	lr: 3.150e-05, eta: 1:34:23, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1440, decode.acc_seg: 94.0353, loss: 0.1440
2025-04-22 21:02:44,899 - mmseg - INFO - Iter [24300/40000]	lr: 3.140e-05, eta: 1:34:03, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1257, decode.acc_seg: 95.0449, loss: 0.1257
2025-04-22 21:03:00,064 - mmseg - INFO - Iter [24350/40000]	lr: 3.130e-05, eta: 1:33:43, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1183, decode.acc_seg: 94.9588, loss: 0.1183
2025-04-22 21:03:15,231 - mmseg - INFO - Iter [24400/40000]	lr: 3.120e-05, eta: 1:33:24, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1191, decode.acc_seg: 95.0530, loss: 0.1191
2025-04-22 21:03:30,392 - mmseg - INFO - Iter [24450/40000]	lr: 3.110e-05, eta: 1:33:04, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1249, decode.acc_seg: 94.6022, loss: 0.1249
2025-04-22 21:03:45,536 - mmseg - INFO - Iter [24500/40000]	lr: 3.100e-05, eta: 1:32:44, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1251, decode.acc_seg: 94.7600, loss: 0.1251
2025-04-22 21:04:00,687 - mmseg - INFO - Iter [24550/40000]	lr: 3.090e-05, eta: 1:32:24, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1736, decode.acc_seg: 93.1403, loss: 0.1736
2025-04-22 21:04:15,820 - mmseg - INFO - Iter [24600/40000]	lr: 3.080e-05, eta: 1:32:05, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1307, decode.acc_seg: 94.5161, loss: 0.1307
2025-04-22 21:04:30,952 - mmseg - INFO - Iter [24650/40000]	lr: 3.070e-05, eta: 1:31:45, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1293, decode.acc_seg: 94.5699, loss: 0.1293
2025-04-22 21:04:46,091 - mmseg - INFO - Iter [24700/40000]	lr: 3.060e-05, eta: 1:31:25, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1532, decode.acc_seg: 93.7936, loss: 0.1532
2025-04-22 21:05:01,234 - mmseg - INFO - Iter [24750/40000]	lr: 3.050e-05, eta: 1:31:06, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1411, decode.acc_seg: 93.9884, loss: 0.1411
2025-04-22 21:05:16,365 - mmseg - INFO - Iter [24800/40000]	lr: 3.040e-05, eta: 1:30:46, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1272, decode.acc_seg: 94.7278, loss: 0.1272
2025-04-22 21:05:31,508 - mmseg - INFO - Iter [24850/40000]	lr: 3.030e-05, eta: 1:30:26, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1376, decode.acc_seg: 94.2341, loss: 0.1376
2025-04-22 21:05:46,648 - mmseg - INFO - Iter [24900/40000]	lr: 3.020e-05, eta: 1:30:07, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1397, decode.acc_seg: 94.4987, loss: 0.1397
2025-04-22 21:06:01,785 - mmseg - INFO - Iter [24950/40000]	lr: 3.010e-05, eta: 1:29:47, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1531, decode.acc_seg: 93.7441, loss: 0.1531
2025-04-22 21:06:16,921 - mmseg - INFO - Exp name: vpd_config.py
2025-04-22 21:06:16,922 - mmseg - INFO - Iter [25000/40000]	lr: 3.000e-05, eta: 1:29:28, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1376, decode.acc_seg: 94.1446, loss: 0.1376
2025-04-22 21:06:32,752 - mmseg - INFO - Iter [25050/40000]	lr: 2.990e-05, eta: 1:29:09, time: 0.317, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1545, decode.acc_seg: 93.6844, loss: 0.1545
2025-04-22 21:06:47,907 - mmseg - INFO - Iter [25100/40000]	lr: 2.980e-05, eta: 1:28:49, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1324, decode.acc_seg: 94.2981, loss: 0.1324
2025-04-22 21:07:03,054 - mmseg - INFO - Iter [25150/40000]	lr: 2.970e-05, eta: 1:28:30, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1189, decode.acc_seg: 95.0587, loss: 0.1189
2025-04-22 21:07:18,229 - mmseg - INFO - Iter [25200/40000]	lr: 2.960e-05, eta: 1:28:10, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1171, decode.acc_seg: 95.0121, loss: 0.1171
2025-04-22 21:07:33,393 - mmseg - INFO - Iter [25250/40000]	lr: 2.950e-05, eta: 1:27:51, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1260, decode.acc_seg: 94.6113, loss: 0.1260
2025-04-22 21:07:48,555 - mmseg - INFO - Iter [25300/40000]	lr: 2.940e-05, eta: 1:27:31, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1351, decode.acc_seg: 94.4340, loss: 0.1351
2025-04-22 21:08:03,725 - mmseg - INFO - Iter [25350/40000]	lr: 2.930e-05, eta: 1:27:12, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1317, decode.acc_seg: 94.4424, loss: 0.1317
2025-04-22 21:08:18,894 - mmseg - INFO - Iter [25400/40000]	lr: 2.920e-05, eta: 1:26:52, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1281, decode.acc_seg: 94.5041, loss: 0.1281
2025-04-22 21:08:34,059 - mmseg - INFO - Iter [25450/40000]	lr: 2.910e-05, eta: 1:26:33, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1352, decode.acc_seg: 94.3961, loss: 0.1352
2025-04-22 21:08:49,226 - mmseg - INFO - Iter [25500/40000]	lr: 2.900e-05, eta: 1:26:14, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1388, decode.acc_seg: 94.3415, loss: 0.1388
2025-04-22 21:09:04,400 - mmseg - INFO - Iter [25550/40000]	lr: 2.890e-05, eta: 1:25:54, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1367, decode.acc_seg: 94.1905, loss: 0.1367
2025-04-22 21:09:19,570 - mmseg - INFO - Iter [25600/40000]	lr: 2.880e-05, eta: 1:25:35, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1197, decode.acc_seg: 94.8238, loss: 0.1197
2025-04-22 21:09:34,738 - mmseg - INFO - Iter [25650/40000]	lr: 2.870e-05, eta: 1:25:16, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1275, decode.acc_seg: 94.8038, loss: 0.1275
2025-04-22 21:09:49,917 - mmseg - INFO - Iter [25700/40000]	lr: 2.860e-05, eta: 1:24:56, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1442, decode.acc_seg: 94.1947, loss: 0.1442
2025-04-22 21:10:05,065 - mmseg - INFO - Iter [25750/40000]	lr: 2.850e-05, eta: 1:24:37, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1400, decode.acc_seg: 94.2706, loss: 0.1400
2025-04-22 21:10:20,219 - mmseg - INFO - Iter [25800/40000]	lr: 2.840e-05, eta: 1:24:18, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1336, decode.acc_seg: 94.6787, loss: 0.1336
2025-04-22 21:10:35,375 - mmseg - INFO - Iter [25850/40000]	lr: 2.830e-05, eta: 1:23:58, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1395, decode.acc_seg: 94.2198, loss: 0.1395
2025-04-22 21:10:50,526 - mmseg - INFO - Iter [25900/40000]	lr: 2.820e-05, eta: 1:23:39, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1127, decode.acc_seg: 95.0627, loss: 0.1127
2025-04-22 21:11:05,671 - mmseg - INFO - Iter [25950/40000]	lr: 2.810e-05, eta: 1:23:20, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1559, decode.acc_seg: 93.8123, loss: 0.1559
2025-04-22 21:11:20,816 - mmseg - INFO - Exp name: vpd_config.py
2025-04-22 21:11:20,817 - mmseg - INFO - Iter [26000/40000]	lr: 2.800e-05, eta: 1:23:01, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1332, decode.acc_seg: 94.5456, loss: 0.1332
2025-04-22 21:11:36,693 - mmseg - INFO - Iter [26050/40000]	lr: 2.790e-05, eta: 1:22:42, time: 0.318, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1312, decode.acc_seg: 94.2936, loss: 0.1312
2025-04-22 21:11:51,856 - mmseg - INFO - Iter [26100/40000]	lr: 2.780e-05, eta: 1:22:23, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1498, decode.acc_seg: 93.7733, loss: 0.1498
2025-04-22 21:12:07,016 - mmseg - INFO - Iter [26150/40000]	lr: 2.770e-05, eta: 1:22:04, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1284, decode.acc_seg: 94.5820, loss: 0.1284
2025-04-22 21:12:22,193 - mmseg - INFO - Iter [26200/40000]	lr: 2.760e-05, eta: 1:21:44, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1280, decode.acc_seg: 94.4368, loss: 0.1280
2025-04-22 21:12:37,350 - mmseg - INFO - Iter [26250/40000]	lr: 2.750e-05, eta: 1:21:25, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1364, decode.acc_seg: 94.6397, loss: 0.1364
2025-04-22 21:12:52,498 - mmseg - INFO - Iter [26300/40000]	lr: 2.740e-05, eta: 1:21:06, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1226, decode.acc_seg: 94.8179, loss: 0.1226
2025-04-22 21:13:07,642 - mmseg - INFO - Iter [26350/40000]	lr: 2.730e-05, eta: 1:20:47, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1365, decode.acc_seg: 94.1857, loss: 0.1365
2025-04-22 21:13:22,779 - mmseg - INFO - Iter [26400/40000]	lr: 2.720e-05, eta: 1:20:28, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1364, decode.acc_seg: 94.2515, loss: 0.1364
2025-04-22 21:13:37,923 - mmseg - INFO - Iter [26450/40000]	lr: 2.710e-05, eta: 1:20:09, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1353, decode.acc_seg: 94.4706, loss: 0.1353
2025-04-22 21:13:53,064 - mmseg - INFO - Iter [26500/40000]	lr: 2.700e-05, eta: 1:19:50, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1194, decode.acc_seg: 94.7351, loss: 0.1194
2025-04-22 21:14:08,199 - mmseg - INFO - Iter [26550/40000]	lr: 2.690e-05, eta: 1:19:31, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1529, decode.acc_seg: 94.0263, loss: 0.1529
2025-04-22 21:14:23,328 - mmseg - INFO - Iter [26600/40000]	lr: 2.680e-05, eta: 1:19:12, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1261, decode.acc_seg: 94.7918, loss: 0.1261
2025-04-22 21:14:38,457 - mmseg - INFO - Iter [26650/40000]	lr: 2.670e-05, eta: 1:18:53, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1397, decode.acc_seg: 94.3071, loss: 0.1397
2025-04-22 21:14:53,587 - mmseg - INFO - Iter [26700/40000]	lr: 2.660e-05, eta: 1:18:34, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1395, decode.acc_seg: 94.1972, loss: 0.1395
2025-04-22 21:15:08,718 - mmseg - INFO - Iter [26750/40000]	lr: 2.650e-05, eta: 1:18:15, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1458, decode.acc_seg: 93.9150, loss: 0.1458
2025-04-22 21:15:23,858 - mmseg - INFO - Iter [26800/40000]	lr: 2.640e-05, eta: 1:17:56, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1259, decode.acc_seg: 94.6154, loss: 0.1259
2025-04-22 21:15:39,001 - mmseg - INFO - Iter [26850/40000]	lr: 2.630e-05, eta: 1:17:37, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1375, decode.acc_seg: 94.1840, loss: 0.1375
2025-04-22 21:15:54,135 - mmseg - INFO - Iter [26900/40000]	lr: 2.620e-05, eta: 1:17:18, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1357, decode.acc_seg: 94.3143, loss: 0.1357
2025-04-22 21:16:09,298 - mmseg - INFO - Iter [26950/40000]	lr: 2.610e-05, eta: 1:16:59, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1237, decode.acc_seg: 94.7450, loss: 0.1237
2025-04-22 21:16:24,460 - mmseg - INFO - Exp name: vpd_config.py
2025-04-22 21:16:24,461 - mmseg - INFO - Iter [27000/40000]	lr: 2.600e-05, eta: 1:16:40, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1543, decode.acc_seg: 93.5560, loss: 0.1543
2025-04-22 21:16:40,880 - mmseg - INFO - Iter [27050/40000]	lr: 2.590e-05, eta: 1:16:22, time: 0.328, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1246, decode.acc_seg: 94.5746, loss: 0.1246
2025-04-22 21:16:56,069 - mmseg - INFO - Iter [27100/40000]	lr: 2.580e-05, eta: 1:16:03, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1283, decode.acc_seg: 94.5104, loss: 0.1283
2025-04-22 21:17:11,256 - mmseg - INFO - Iter [27150/40000]	lr: 2.570e-05, eta: 1:15:44, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1354, decode.acc_seg: 94.4145, loss: 0.1354
2025-04-22 21:17:26,442 - mmseg - INFO - Iter [27200/40000]	lr: 2.560e-05, eta: 1:15:25, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1408, decode.acc_seg: 94.2633, loss: 0.1408
2025-04-22 21:17:41,630 - mmseg - INFO - Iter [27250/40000]	lr: 2.550e-05, eta: 1:15:06, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1261, decode.acc_seg: 94.7530, loss: 0.1261
2025-04-22 21:17:56,826 - mmseg - INFO - Iter [27300/40000]	lr: 2.540e-05, eta: 1:14:47, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1374, decode.acc_seg: 93.8675, loss: 0.1374
2025-04-22 21:18:12,022 - mmseg - INFO - Iter [27350/40000]	lr: 2.530e-05, eta: 1:14:28, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1376, decode.acc_seg: 94.1321, loss: 0.1376
2025-04-22 21:18:27,216 - mmseg - INFO - Iter [27400/40000]	lr: 2.520e-05, eta: 1:14:10, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1314, decode.acc_seg: 94.4213, loss: 0.1314
2025-04-22 21:18:42,407 - mmseg - INFO - Iter [27450/40000]	lr: 2.510e-05, eta: 1:13:51, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1358, decode.acc_seg: 94.1308, loss: 0.1358
2025-04-22 21:18:57,583 - mmseg - INFO - Iter [27500/40000]	lr: 2.500e-05, eta: 1:13:32, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1305, decode.acc_seg: 94.5137, loss: 0.1305
2025-04-22 21:19:12,775 - mmseg - INFO - Iter [27550/40000]	lr: 2.490e-05, eta: 1:13:13, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1417, decode.acc_seg: 94.1319, loss: 0.1417
2025-04-22 21:19:27,968 - mmseg - INFO - Iter [27600/40000]	lr: 2.480e-05, eta: 1:12:55, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1523, decode.acc_seg: 93.4160, loss: 0.1523
2025-04-22 21:19:43,143 - mmseg - INFO - Iter [27650/40000]	lr: 2.470e-05, eta: 1:12:36, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1327, decode.acc_seg: 94.4586, loss: 0.1327
2025-04-22 21:19:58,313 - mmseg - INFO - Iter [27700/40000]	lr: 2.460e-05, eta: 1:12:17, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1411, decode.acc_seg: 94.2529, loss: 0.1411
2025-04-22 21:20:13,486 - mmseg - INFO - Iter [27750/40000]	lr: 2.450e-05, eta: 1:11:58, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1367, decode.acc_seg: 94.5077, loss: 0.1367
2025-04-22 21:20:28,667 - mmseg - INFO - Iter [27800/40000]	lr: 2.440e-05, eta: 1:11:40, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1407, decode.acc_seg: 94.2562, loss: 0.1407
2025-04-22 21:20:43,822 - mmseg - INFO - Iter [27850/40000]	lr: 2.430e-05, eta: 1:11:21, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1340, decode.acc_seg: 94.4264, loss: 0.1340
2025-04-22 21:20:58,983 - mmseg - INFO - Iter [27900/40000]	lr: 2.420e-05, eta: 1:11:02, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1388, decode.acc_seg: 94.3705, loss: 0.1388
2025-04-22 21:21:14,198 - mmseg - INFO - Iter [27950/40000]	lr: 2.410e-05, eta: 1:10:44, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1327, decode.acc_seg: 94.4786, loss: 0.1327
2025-04-22 21:21:29,398 - mmseg - INFO - Saving checkpoint at 28000 iterations
2025-04-22 21:21:38,996 - mmseg - INFO - Exp name: vpd_config.py
2025-04-22 21:21:38,996 - mmseg - INFO - Iter [28000/40000]	lr: 2.400e-05, eta: 1:10:29, time: 0.496, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1521, decode.acc_seg: 93.4830, loss: 0.1521
2025-04-22 21:25:11,664 - mmseg - INFO - per class results:
2025-04-22 21:25:11,670 - mmseg - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        | 46.97 | 59.77 |
|       building      | 54.58 | 64.18 |
|         sky         | 54.17 | 73.78 |
|        floor        | 32.88 | 77.58 |
|         tree        | 43.74 |  57.8 |
|       ceiling       | 62.67 |  66.7 |
|         road        | 36.45 | 77.77 |
|         bed         |  29.9 | 42.31 |
|      windowpane     | 36.07 | 46.48 |
|        grass        | 25.43 |  38.5 |
|       cabinet       | 29.65 | 40.18 |
|       sidewalk      | 15.37 | 25.52 |
|        person       | 31.03 | 41.88 |
|        earth        | 20.74 | 39.99 |
|         door        |  31.0 | 42.25 |
|        table        | 15.39 | 25.05 |
|       mountain      | 40.73 | 57.34 |
|        plant        | 21.39 | 28.23 |
|       curtain       | 45.28 | 54.36 |
|        chair        |  13.5 | 20.59 |
|         car         | 13.16 |  20.5 |
|        water        |  31.4 |  56.0 |
|       painting      | 32.62 | 42.85 |
|         sofa        | 14.13 |  21.8 |
|        shelf        |  26.9 | 36.63 |
|        house        | 27.29 | 41.65 |
|         sea         | 38.68 | 67.31 |
|        mirror       | 41.02 | 50.41 |
|         rug         | 15.17 | 22.75 |
|        field        | 20.04 | 45.61 |
|       armchair      | 11.67 | 20.23 |
|         seat        |  25.4 | 39.92 |
|        fence        | 10.48 | 16.45 |
|         desk        | 16.92 | 28.67 |
|         rock        | 24.69 | 38.43 |
|       wardrobe      | 36.93 | 46.21 |
|         lamp        | 19.98 |  27.9 |
|       bathtub       | 39.11 | 49.84 |
|       railing       | 12.61 | 18.75 |
|       cushion       |  7.33 | 11.45 |
|         base        | 14.17 | 24.41 |
|         box         |  9.91 | 14.36 |
|        column       | 28.61 | 36.32 |
|      signboard      | 10.28 | 15.06 |
|   chest of drawers  | 15.81 | 23.76 |
|       counter       |  9.67 | 16.24 |
|         sand        | 28.49 | 45.52 |
|         sink        | 16.48 | 24.16 |
|      skyscraper     | 45.05 | 56.51 |
|      fireplace      | 31.53 | 44.45 |
|     refrigerator    | 42.96 | 49.66 |
|      grandstand     | 28.14 | 61.96 |
|         path        |  6.94 |  9.92 |
|        stairs       |  8.65 | 11.86 |
|        runway       |  31.3 |  49.2 |
|         case        | 31.09 | 45.77 |
|      pool table     | 25.45 | 37.62 |
|        pillow       | 10.43 | 15.45 |
|     screen door     | 37.38 | 46.11 |
|       stairway      | 15.03 | 23.03 |
|        river        | 17.32 | 27.47 |
|        bridge       | 19.03 |  30.5 |
|       bookcase      | 25.67 | 35.63 |
|        blind        | 36.76 | 41.16 |
|     coffee table    |  4.16 |  7.54 |
|        toilet       | 18.84 | 27.58 |
|        flower       | 13.69 | 23.07 |
|         book        |  24.4 | 35.19 |
|         hill        |  8.8  | 14.95 |
|        bench        | 12.69 | 18.14 |
|      countertop     | 11.82 | 20.12 |
|        stove        | 23.49 | 33.62 |
|         palm        | 30.41 | 45.37 |
|    kitchen island   |  9.44 | 20.65 |
|       computer      | 32.49 | 47.15 |
|     swivel chair    | 15.49 | 23.18 |
|         boat        |  10.6 | 17.22 |
|         bar         | 24.81 | 35.88 |
|    arcade machine   | 24.31 |  30.8 |
|        hovel        | 17.97 | 21.37 |
|         bus         | 39.64 | 50.77 |
|        towel        | 16.23 | 25.43 |
|        light        | 21.23 | 28.03 |
|        truck        |  5.83 | 10.75 |
|        tower        |  5.51 | 10.26 |
|      chandelier     | 29.48 | 41.76 |
|        awning       |  4.66 |  6.49 |
|     streetlight     | 12.58 | 16.68 |
|        booth        | 21.11 | 33.67 |
| television receiver |  14.5 | 22.06 |
|       airplane      |  9.92 | 15.65 |
|      dirt track     |  1.6  |  8.05 |
|       apparel       | 17.75 |  26.0 |
|         pole        | 12.04 | 16.67 |
|         land        |  2.66 |  5.18 |
|      bannister      |  5.9  |  9.19 |
|      escalator      | 12.22 | 15.67 |
|       ottoman       |  2.11 |  3.53 |
|        bottle       |  11.5 | 19.25 |
|        buffet       | 26.65 | 31.03 |
|        poster       | 29.42 | 37.99 |
|        stage        | 11.23 | 23.52 |
|         van         |  6.83 |  11.6 |
|         ship        | 33.15 | 53.42 |
|       fountain      |  5.29 |  6.52 |
|    conveyer belt    | 26.11 | 46.21 |
|        canopy       | 16.96 | 23.18 |
|        washer       | 34.84 | 39.95 |
|      plaything      |  5.56 | 10.41 |
|    swimming pool    | 17.31 | 26.62 |
|        stool        |  8.12 | 12.34 |
|        barrel       |  1.18 |  5.58 |
|        basket       |  4.71 |  6.88 |
|      waterfall      | 38.68 | 50.32 |
|         tent        | 37.41 | 45.21 |
|         bag         |  2.16 |  2.71 |
|       minibike      | 14.66 | 22.49 |
|        cradle       | 33.18 | 46.86 |
|         oven        | 24.49 | 34.05 |
|         ball        |  16.3 | 23.49 |
|         food        |  26.0 | 33.48 |
|         step        |  0.0  |  0.01 |
|         tank        | 27.93 | 35.19 |
|      trade name     |  6.32 |  8.29 |
|      microwave      | 40.45 | 50.99 |
|         pot         | 10.37 | 14.71 |
|        animal       | 20.54 | 26.87 |
|       bicycle       |  3.91 |  6.45 |
|         lake        | 32.73 | 38.03 |
|      dishwasher     | 13.51 | 17.98 |
|        screen       |  37.8 | 51.36 |
|       blanket       |  2.76 |  3.6  |
|      sculpture      |  18.3 | 32.18 |
|         hood        | 25.64 | 37.21 |
|        sconce       | 11.76 | 16.91 |
|         vase        |  5.17 |  9.75 |
|    traffic light    |  15.3 | 23.88 |
|         tray        |  2.81 |  6.78 |
|        ashcan       |  1.37 |  2.32 |
|         fan         | 20.72 | 29.48 |
|         pier        |  0.43 |  0.72 |
|      crt screen     |  8.02 | 12.19 |
|        plate        | 10.89 | 16.31 |
|       monitor       | 38.33 | 46.42 |
|    bulletin board   | 32.28 | 43.17 |
|        shower       |  0.54 |  1.85 |
|       radiator      |  8.6  | 13.16 |
|        glass        |  0.32 |  0.38 |
|        clock        | 23.88 |  30.6 |
|         flag        | 37.42 | 44.62 |
+---------------------+-------+-------+
2025-04-22 21:25:11,671 - mmseg - INFO - Summary:
2025-04-22 21:25:11,671 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 53.85 | 20.71 | 29.81 |
+-------+-------+-------+
2025-04-22 21:25:11,671 - mmseg - INFO - Exp name: vpd_config.py
2025-04-22 21:25:11,672 - mmseg - INFO - Iter(val) [2000]	aAcc: 0.5385, mIoU: 0.2071, mAcc: 0.2981, IoU.wall: 0.4697, IoU.building: 0.5458, IoU.sky: 0.5417, IoU.floor: 0.3288, IoU.tree: 0.4374, IoU.ceiling: 0.6267, IoU.road: 0.3645, IoU.bed : 0.2990, IoU.windowpane: 0.3607, IoU.grass: 0.2543, IoU.cabinet: 0.2965, IoU.sidewalk: 0.1537, IoU.person: 0.3103, IoU.earth: 0.2074, IoU.door: 0.3100, IoU.table: 0.1539, IoU.mountain: 0.4073, IoU.plant: 0.2139, IoU.curtain: 0.4528, IoU.chair: 0.1350, IoU.car: 0.1316, IoU.water: 0.3140, IoU.painting: 0.3262, IoU.sofa: 0.1413, IoU.shelf: 0.2690, IoU.house: 0.2729, IoU.sea: 0.3868, IoU.mirror: 0.4102, IoU.rug: 0.1517, IoU.field: 0.2004, IoU.armchair: 0.1167, IoU.seat: 0.2540, IoU.fence: 0.1048, IoU.desk: 0.1692, IoU.rock: 0.2469, IoU.wardrobe: 0.3693, IoU.lamp: 0.1998, IoU.bathtub: 0.3911, IoU.railing: 0.1261, IoU.cushion: 0.0733, IoU.base: 0.1417, IoU.box: 0.0991, IoU.column: 0.2861, IoU.signboard: 0.1028, IoU.chest of drawers: 0.1581, IoU.counter: 0.0967, IoU.sand: 0.2849, IoU.sink: 0.1648, IoU.skyscraper: 0.4505, IoU.fireplace: 0.3153, IoU.refrigerator: 0.4296, IoU.grandstand: 0.2814, IoU.path: 0.0694, IoU.stairs: 0.0865, IoU.runway: 0.3130, IoU.case: 0.3109, IoU.pool table: 0.2545, IoU.pillow: 0.1043, IoU.screen door: 0.3738, IoU.stairway: 0.1503, IoU.river: 0.1732, IoU.bridge: 0.1903, IoU.bookcase: 0.2567, IoU.blind: 0.3676, IoU.coffee table: 0.0416, IoU.toilet: 0.1884, IoU.flower: 0.1369, IoU.book: 0.2440, IoU.hill: 0.0880, IoU.bench: 0.1269, IoU.countertop: 0.1182, IoU.stove: 0.2349, IoU.palm: 0.3041, IoU.kitchen island: 0.0944, IoU.computer: 0.3249, IoU.swivel chair: 0.1549, IoU.boat: 0.1060, IoU.bar: 0.2481, IoU.arcade machine: 0.2431, IoU.hovel: 0.1797, IoU.bus: 0.3964, IoU.towel: 0.1623, IoU.light: 0.2123, IoU.truck: 0.0583, IoU.tower: 0.0551, IoU.chandelier: 0.2948, IoU.awning: 0.0466, IoU.streetlight: 0.1258, IoU.booth: 0.2111, IoU.television receiver: 0.1450, IoU.airplane: 0.0992, IoU.dirt track: 0.0160, IoU.apparel: 0.1775, IoU.pole: 0.1204, IoU.land: 0.0266, IoU.bannister: 0.0590, IoU.escalator: 0.1222, IoU.ottoman: 0.0211, IoU.bottle: 0.1150, IoU.buffet: 0.2665, IoU.poster: 0.2942, IoU.stage: 0.1123, IoU.van: 0.0683, IoU.ship: 0.3315, IoU.fountain: 0.0529, IoU.conveyer belt: 0.2611, IoU.canopy: 0.1696, IoU.washer: 0.3484, IoU.plaything: 0.0556, IoU.swimming pool: 0.1731, IoU.stool: 0.0812, IoU.barrel: 0.0118, IoU.basket: 0.0471, IoU.waterfall: 0.3868, IoU.tent: 0.3741, IoU.bag: 0.0216, IoU.minibike: 0.1466, IoU.cradle: 0.3318, IoU.oven: 0.2449, IoU.ball: 0.1630, IoU.food: 0.2600, IoU.step: 0.0000, IoU.tank: 0.2793, IoU.trade name: 0.0632, IoU.microwave: 0.4045, IoU.pot: 0.1037, IoU.animal: 0.2054, IoU.bicycle: 0.0391, IoU.lake: 0.3273, IoU.dishwasher: 0.1351, IoU.screen: 0.3780, IoU.blanket: 0.0276, IoU.sculpture: 0.1830, IoU.hood: 0.2564, IoU.sconce: 0.1176, IoU.vase: 0.0517, IoU.traffic light: 0.1530, IoU.tray: 0.0281, IoU.ashcan: 0.0137, IoU.fan: 0.2072, IoU.pier: 0.0043, IoU.crt screen: 0.0802, IoU.plate: 0.1089, IoU.monitor: 0.3833, IoU.bulletin board: 0.3228, IoU.shower: 0.0054, IoU.radiator: 0.0860, IoU.glass: 0.0032, IoU.clock: 0.2388, IoU.flag: 0.3742, Acc.wall: 0.5977, Acc.building: 0.6418, Acc.sky: 0.7378, Acc.floor: 0.7758, Acc.tree: 0.5780, Acc.ceiling: 0.6670, Acc.road: 0.7777, Acc.bed : 0.4231, Acc.windowpane: 0.4648, Acc.grass: 0.3850, Acc.cabinet: 0.4018, Acc.sidewalk: 0.2552, Acc.person: 0.4188, Acc.earth: 0.3999, Acc.door: 0.4225, Acc.table: 0.2505, Acc.mountain: 0.5734, Acc.plant: 0.2823, Acc.curtain: 0.5436, Acc.chair: 0.2059, Acc.car: 0.2050, Acc.water: 0.5600, Acc.painting: 0.4285, Acc.sofa: 0.2180, Acc.shelf: 0.3663, Acc.house: 0.4165, Acc.sea: 0.6731, Acc.mirror: 0.5041, Acc.rug: 0.2275, Acc.field: 0.4561, Acc.armchair: 0.2023, Acc.seat: 0.3992, Acc.fence: 0.1645, Acc.desk: 0.2867, Acc.rock: 0.3843, Acc.wardrobe: 0.4621, Acc.lamp: 0.2790, Acc.bathtub: 0.4984, Acc.railing: 0.1875, Acc.cushion: 0.1145, Acc.base: 0.2441, Acc.box: 0.1436, Acc.column: 0.3632, Acc.signboard: 0.1506, Acc.chest of drawers: 0.2376, Acc.counter: 0.1624, Acc.sand: 0.4552, Acc.sink: 0.2416, Acc.skyscraper: 0.5651, Acc.fireplace: 0.4445, Acc.refrigerator: 0.4966, Acc.grandstand: 0.6196, Acc.path: 0.0992, Acc.stairs: 0.1186, Acc.runway: 0.4920, Acc.case: 0.4577, Acc.pool table: 0.3762, Acc.pillow: 0.1545, Acc.screen door: 0.4611, Acc.stairway: 0.2303, Acc.river: 0.2747, Acc.bridge: 0.3050, Acc.bookcase: 0.3563, Acc.blind: 0.4116, Acc.coffee table: 0.0754, Acc.toilet: 0.2758, Acc.flower: 0.2307, Acc.book: 0.3519, Acc.hill: 0.1495, Acc.bench: 0.1814, Acc.countertop: 0.2012, Acc.stove: 0.3362, Acc.palm: 0.4537, Acc.kitchen island: 0.2065, Acc.computer: 0.4715, Acc.swivel chair: 0.2318, Acc.boat: 0.1722, Acc.bar: 0.3588, Acc.arcade machine: 0.3080, Acc.hovel: 0.2137, Acc.bus: 0.5077, Acc.towel: 0.2543, Acc.light: 0.2803, Acc.truck: 0.1075, Acc.tower: 0.1026, Acc.chandelier: 0.4176, Acc.awning: 0.0649, Acc.streetlight: 0.1668, Acc.booth: 0.3367, Acc.television receiver: 0.2206, Acc.airplane: 0.1565, Acc.dirt track: 0.0805, Acc.apparel: 0.2600, Acc.pole: 0.1667, Acc.land: 0.0518, Acc.bannister: 0.0919, Acc.escalator: 0.1567, Acc.ottoman: 0.0353, Acc.bottle: 0.1925, Acc.buffet: 0.3103, Acc.poster: 0.3799, Acc.stage: 0.2352, Acc.van: 0.1160, Acc.ship: 0.5342, Acc.fountain: 0.0652, Acc.conveyer belt: 0.4621, Acc.canopy: 0.2318, Acc.washer: 0.3995, Acc.plaything: 0.1041, Acc.swimming pool: 0.2662, Acc.stool: 0.1234, Acc.barrel: 0.0558, Acc.basket: 0.0688, Acc.waterfall: 0.5032, Acc.tent: 0.4521, Acc.bag: 0.0271, Acc.minibike: 0.2249, Acc.cradle: 0.4686, Acc.oven: 0.3405, Acc.ball: 0.2349, Acc.food: 0.3348, Acc.step: 0.0001, Acc.tank: 0.3519, Acc.trade name: 0.0829, Acc.microwave: 0.5099, Acc.pot: 0.1471, Acc.animal: 0.2687, Acc.bicycle: 0.0645, Acc.lake: 0.3803, Acc.dishwasher: 0.1798, Acc.screen: 0.5136, Acc.blanket: 0.0360, Acc.sculpture: 0.3218, Acc.hood: 0.3721, Acc.sconce: 0.1691, Acc.vase: 0.0975, Acc.traffic light: 0.2388, Acc.tray: 0.0678, Acc.ashcan: 0.0232, Acc.fan: 0.2948, Acc.pier: 0.0072, Acc.crt screen: 0.1219, Acc.plate: 0.1631, Acc.monitor: 0.4642, Acc.bulletin board: 0.4317, Acc.shower: 0.0185, Acc.radiator: 0.1316, Acc.glass: 0.0038, Acc.clock: 0.3060, Acc.flag: 0.4462
2025-04-22 21:25:27,532 - mmseg - INFO - Iter [28050/40000]	lr: 2.390e-05, eta: 1:11:41, time: 4.571, data_time: 4.262, memory: 75933, decode.loss_ce: 0.1421, decode.acc_seg: 94.4878, loss: 0.1421
2025-04-22 21:25:42,680 - mmseg - INFO - Iter [28100/40000]	lr: 2.380e-05, eta: 1:11:22, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1374, decode.acc_seg: 94.4429, loss: 0.1374
2025-04-22 21:25:57,855 - mmseg - INFO - Iter [28150/40000]	lr: 2.370e-05, eta: 1:11:03, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1216, decode.acc_seg: 94.8292, loss: 0.1216
2025-04-22 21:26:13,037 - mmseg - INFO - Iter [28200/40000]	lr: 2.360e-05, eta: 1:10:44, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1257, decode.acc_seg: 94.7337, loss: 0.1257
2025-04-22 21:26:28,221 - mmseg - INFO - Iter [28250/40000]	lr: 2.350e-05, eta: 1:10:25, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1182, decode.acc_seg: 94.8354, loss: 0.1182
2025-04-22 21:26:43,430 - mmseg - INFO - Iter [28300/40000]	lr: 2.340e-05, eta: 1:10:06, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1325, decode.acc_seg: 94.5119, loss: 0.1325
2025-04-22 21:26:58,661 - mmseg - INFO - Iter [28350/40000]	lr: 2.330e-05, eta: 1:09:46, time: 0.305, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1238, decode.acc_seg: 94.8651, loss: 0.1238
2025-04-22 21:27:13,869 - mmseg - INFO - Iter [28400/40000]	lr: 2.320e-05, eta: 1:09:27, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1367, decode.acc_seg: 94.5581, loss: 0.1367
2025-04-22 21:27:29,097 - mmseg - INFO - Iter [28450/40000]	lr: 2.310e-05, eta: 1:09:08, time: 0.305, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1206, decode.acc_seg: 95.2535, loss: 0.1206
2025-04-22 21:27:44,314 - mmseg - INFO - Iter [28500/40000]	lr: 2.300e-05, eta: 1:08:49, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1369, decode.acc_seg: 94.0856, loss: 0.1369
2025-04-22 21:27:59,560 - mmseg - INFO - Iter [28550/40000]	lr: 2.290e-05, eta: 1:08:30, time: 0.305, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1382, decode.acc_seg: 94.3821, loss: 0.1382
2025-04-22 21:28:14,757 - mmseg - INFO - Iter [28600/40000]	lr: 2.280e-05, eta: 1:08:11, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1372, decode.acc_seg: 94.4182, loss: 0.1372
2025-04-22 21:28:29,941 - mmseg - INFO - Iter [28650/40000]	lr: 2.270e-05, eta: 1:07:52, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1197, decode.acc_seg: 94.9400, loss: 0.1197
2025-04-22 21:28:45,152 - mmseg - INFO - Iter [28700/40000]	lr: 2.260e-05, eta: 1:07:33, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1372, decode.acc_seg: 94.0110, loss: 0.1372
2025-04-22 21:29:00,337 - mmseg - INFO - Iter [28750/40000]	lr: 2.250e-05, eta: 1:07:14, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1226, decode.acc_seg: 94.9890, loss: 0.1226
2025-04-22 21:29:15,519 - mmseg - INFO - Iter [28800/40000]	lr: 2.240e-05, eta: 1:06:55, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1395, decode.acc_seg: 94.0797, loss: 0.1395
2025-04-22 21:29:30,770 - mmseg - INFO - Iter [28850/40000]	lr: 2.230e-05, eta: 1:06:36, time: 0.305, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1465, decode.acc_seg: 93.5703, loss: 0.1465
2025-04-22 21:29:45,985 - mmseg - INFO - Iter [28900/40000]	lr: 2.220e-05, eta: 1:06:17, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1480, decode.acc_seg: 93.8606, loss: 0.1480
2025-04-22 21:30:01,185 - mmseg - INFO - Iter [28950/40000]	lr: 2.210e-05, eta: 1:05:58, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1307, decode.acc_seg: 94.6014, loss: 0.1307
2025-04-22 21:30:16,369 - mmseg - INFO - Exp name: vpd_config.py
2025-04-22 21:30:16,370 - mmseg - INFO - Iter [29000/40000]	lr: 2.200e-05, eta: 1:05:39, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1455, decode.acc_seg: 94.1930, loss: 0.1455
2025-04-22 21:30:32,337 - mmseg - INFO - Iter [29050/40000]	lr: 2.190e-05, eta: 1:05:21, time: 0.319, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1291, decode.acc_seg: 94.4930, loss: 0.1291
2025-04-22 21:30:47,529 - mmseg - INFO - Iter [29100/40000]	lr: 2.180e-05, eta: 1:05:02, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1438, decode.acc_seg: 94.1907, loss: 0.1438
2025-04-22 21:31:02,732 - mmseg - INFO - Iter [29150/40000]	lr: 2.170e-05, eta: 1:04:43, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1183, decode.acc_seg: 94.9445, loss: 0.1183
2025-04-22 21:31:17,931 - mmseg - INFO - Iter [29200/40000]	lr: 2.160e-05, eta: 1:04:24, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1498, decode.acc_seg: 94.0419, loss: 0.1498
2025-04-22 21:31:33,129 - mmseg - INFO - Iter [29250/40000]	lr: 2.150e-05, eta: 1:04:05, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1284, decode.acc_seg: 94.7592, loss: 0.1284
2025-04-22 21:31:48,314 - mmseg - INFO - Iter [29300/40000]	lr: 2.140e-05, eta: 1:03:46, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1398, decode.acc_seg: 94.2229, loss: 0.1398
2025-04-22 21:32:03,497 - mmseg - INFO - Iter [29350/40000]	lr: 2.130e-05, eta: 1:03:27, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1263, decode.acc_seg: 94.8872, loss: 0.1263
2025-04-22 21:32:18,684 - mmseg - INFO - Iter [29400/40000]	lr: 2.120e-05, eta: 1:03:08, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1137, decode.acc_seg: 95.2038, loss: 0.1137
2025-04-22 21:32:33,879 - mmseg - INFO - Iter [29450/40000]	lr: 2.110e-05, eta: 1:02:50, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1317, decode.acc_seg: 94.6944, loss: 0.1317
2025-04-22 21:32:49,102 - mmseg - INFO - Iter [29500/40000]	lr: 2.100e-05, eta: 1:02:31, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1325, decode.acc_seg: 94.2897, loss: 0.1325
2025-04-22 21:33:04,301 - mmseg - INFO - Iter [29550/40000]	lr: 2.090e-05, eta: 1:02:12, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1227, decode.acc_seg: 94.6862, loss: 0.1227
2025-04-22 21:33:19,497 - mmseg - INFO - Iter [29600/40000]	lr: 2.080e-05, eta: 1:01:53, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1368, decode.acc_seg: 94.1745, loss: 0.1368
2025-04-22 21:33:34,682 - mmseg - INFO - Iter [29650/40000]	lr: 2.070e-05, eta: 1:01:34, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1270, decode.acc_seg: 94.6938, loss: 0.1270
2025-04-22 21:33:49,898 - mmseg - INFO - Iter [29700/40000]	lr: 2.060e-05, eta: 1:01:16, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1339, decode.acc_seg: 94.3180, loss: 0.1339
2025-04-22 21:34:05,089 - mmseg - INFO - Iter [29750/40000]	lr: 2.050e-05, eta: 1:00:57, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1345, decode.acc_seg: 94.2664, loss: 0.1345
2025-04-22 21:34:20,284 - mmseg - INFO - Iter [29800/40000]	lr: 2.040e-05, eta: 1:00:38, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1247, decode.acc_seg: 94.4565, loss: 0.1247
2025-04-22 21:34:35,475 - mmseg - INFO - Iter [29850/40000]	lr: 2.030e-05, eta: 1:00:19, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1177, decode.acc_seg: 94.9973, loss: 0.1177
2025-04-22 21:34:50,659 - mmseg - INFO - Iter [29900/40000]	lr: 2.020e-05, eta: 1:00:01, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1517, decode.acc_seg: 93.5913, loss: 0.1517
2025-04-22 21:35:05,837 - mmseg - INFO - Iter [29950/40000]	lr: 2.010e-05, eta: 0:59:42, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1221, decode.acc_seg: 94.6020, loss: 0.1221
2025-04-22 21:35:21,049 - mmseg - INFO - Exp name: vpd_config.py
2025-04-22 21:35:21,050 - mmseg - INFO - Iter [30000/40000]	lr: 2.000e-05, eta: 0:59:23, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1352, decode.acc_seg: 94.3218, loss: 0.1352
2025-04-22 21:35:37,054 - mmseg - INFO - Iter [30050/40000]	lr: 1.990e-05, eta: 0:59:05, time: 0.320, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1260, decode.acc_seg: 94.6346, loss: 0.1260
2025-04-22 21:35:52,250 - mmseg - INFO - Iter [30100/40000]	lr: 1.980e-05, eta: 0:58:46, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1238, decode.acc_seg: 94.7449, loss: 0.1238
2025-04-22 21:36:07,461 - mmseg - INFO - Iter [30150/40000]	lr: 1.970e-05, eta: 0:58:27, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1283, decode.acc_seg: 94.5743, loss: 0.1283
2025-04-22 21:36:22,678 - mmseg - INFO - Iter [30200/40000]	lr: 1.960e-05, eta: 0:58:09, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1186, decode.acc_seg: 94.8846, loss: 0.1186
2025-04-22 21:36:37,872 - mmseg - INFO - Iter [30250/40000]	lr: 1.950e-05, eta: 0:57:50, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1355, decode.acc_seg: 94.3655, loss: 0.1355
2025-04-22 21:36:53,073 - mmseg - INFO - Iter [30300/40000]	lr: 1.940e-05, eta: 0:57:32, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1441, decode.acc_seg: 93.9603, loss: 0.1441
2025-04-22 21:37:08,280 - mmseg - INFO - Iter [30350/40000]	lr: 1.930e-05, eta: 0:57:13, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1325, decode.acc_seg: 94.3600, loss: 0.1325
2025-04-22 21:37:23,473 - mmseg - INFO - Iter [30400/40000]	lr: 1.920e-05, eta: 0:56:54, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1266, decode.acc_seg: 94.6970, loss: 0.1266
2025-04-22 21:37:38,664 - mmseg - INFO - Iter [30450/40000]	lr: 1.910e-05, eta: 0:56:36, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1472, decode.acc_seg: 94.3227, loss: 0.1472
2025-04-22 21:37:53,875 - mmseg - INFO - Iter [30500/40000]	lr: 1.900e-05, eta: 0:56:17, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1280, decode.acc_seg: 94.6970, loss: 0.1280
2025-04-22 21:38:09,080 - mmseg - INFO - Iter [30550/40000]	lr: 1.890e-05, eta: 0:55:59, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1255, decode.acc_seg: 94.6516, loss: 0.1255
2025-04-22 21:38:24,265 - mmseg - INFO - Iter [30600/40000]	lr: 1.880e-05, eta: 0:55:40, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1399, decode.acc_seg: 94.2109, loss: 0.1399
2025-04-22 21:38:39,440 - mmseg - INFO - Iter [30650/40000]	lr: 1.870e-05, eta: 0:55:21, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1238, decode.acc_seg: 94.7571, loss: 0.1238
2025-04-22 21:38:54,614 - mmseg - INFO - Iter [30700/40000]	lr: 1.860e-05, eta: 0:55:03, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1223, decode.acc_seg: 94.8015, loss: 0.1223
2025-04-22 21:39:09,872 - mmseg - INFO - Iter [30750/40000]	lr: 1.850e-05, eta: 0:54:44, time: 0.305, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1271, decode.acc_seg: 94.4325, loss: 0.1271
2025-04-22 21:39:25,049 - mmseg - INFO - Iter [30800/40000]	lr: 1.840e-05, eta: 0:54:26, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1369, decode.acc_seg: 94.2870, loss: 0.1369
2025-04-22 21:39:40,233 - mmseg - INFO - Iter [30850/40000]	lr: 1.830e-05, eta: 0:54:07, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1372, decode.acc_seg: 94.4343, loss: 0.1372
2025-04-22 21:39:55,410 - mmseg - INFO - Iter [30900/40000]	lr: 1.820e-05, eta: 0:53:49, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1618, decode.acc_seg: 93.9309, loss: 0.1618
2025-04-22 21:40:10,615 - mmseg - INFO - Iter [30950/40000]	lr: 1.810e-05, eta: 0:53:30, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1344, decode.acc_seg: 94.2956, loss: 0.1344
2025-04-22 21:40:25,833 - mmseg - INFO - Exp name: vpd_config.py
2025-04-22 21:40:25,834 - mmseg - INFO - Iter [31000/40000]	lr: 1.800e-05, eta: 0:53:12, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1320, decode.acc_seg: 94.2771, loss: 0.1320
2025-04-22 21:40:41,703 - mmseg - INFO - Iter [31050/40000]	lr: 1.790e-05, eta: 0:52:54, time: 0.317, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1252, decode.acc_seg: 94.8216, loss: 0.1252
2025-04-22 21:40:56,956 - mmseg - INFO - Iter [31100/40000]	lr: 1.780e-05, eta: 0:52:35, time: 0.305, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1379, decode.acc_seg: 94.4988, loss: 0.1379
2025-04-22 21:41:12,159 - mmseg - INFO - Iter [31150/40000]	lr: 1.770e-05, eta: 0:52:17, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1321, decode.acc_seg: 94.7544, loss: 0.1321
2025-04-22 21:41:27,346 - mmseg - INFO - Iter [31200/40000]	lr: 1.760e-05, eta: 0:51:58, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1378, decode.acc_seg: 94.5035, loss: 0.1378
2025-04-22 21:41:42,550 - mmseg - INFO - Iter [31250/40000]	lr: 1.750e-05, eta: 0:51:40, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1347, decode.acc_seg: 94.4922, loss: 0.1347
2025-04-22 21:41:57,745 - mmseg - INFO - Iter [31300/40000]	lr: 1.740e-05, eta: 0:51:21, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1129, decode.acc_seg: 94.7494, loss: 0.1129
2025-04-22 21:42:12,960 - mmseg - INFO - Iter [31350/40000]	lr: 1.730e-05, eta: 0:51:03, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1281, decode.acc_seg: 94.7004, loss: 0.1281
2025-04-22 21:42:28,182 - mmseg - INFO - Iter [31400/40000]	lr: 1.720e-05, eta: 0:50:45, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1274, decode.acc_seg: 94.4133, loss: 0.1274
2025-04-22 21:42:43,413 - mmseg - INFO - Iter [31450/40000]	lr: 1.710e-05, eta: 0:50:26, time: 0.305, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1365, decode.acc_seg: 94.2984, loss: 0.1365
2025-04-22 21:42:58,655 - mmseg - INFO - Iter [31500/40000]	lr: 1.700e-05, eta: 0:50:08, time: 0.305, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1263, decode.acc_seg: 94.7631, loss: 0.1263
2025-04-22 21:43:13,848 - mmseg - INFO - Iter [31550/40000]	lr: 1.690e-05, eta: 0:49:50, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1338, decode.acc_seg: 94.3262, loss: 0.1338
2025-04-22 21:43:29,054 - mmseg - INFO - Iter [31600/40000]	lr: 1.680e-05, eta: 0:49:31, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1268, decode.acc_seg: 94.5171, loss: 0.1268
2025-04-22 21:43:44,281 - mmseg - INFO - Iter [31650/40000]	lr: 1.670e-05, eta: 0:49:13, time: 0.305, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1513, decode.acc_seg: 93.6005, loss: 0.1513
2025-04-22 21:43:59,499 - mmseg - INFO - Iter [31700/40000]	lr: 1.660e-05, eta: 0:48:55, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1279, decode.acc_seg: 94.5064, loss: 0.1279
2025-04-22 21:44:14,693 - mmseg - INFO - Iter [31750/40000]	lr: 1.650e-05, eta: 0:48:36, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1221, decode.acc_seg: 94.8409, loss: 0.1221
2025-04-22 21:44:29,878 - mmseg - INFO - Iter [31800/40000]	lr: 1.640e-05, eta: 0:48:18, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1290, decode.acc_seg: 94.5316, loss: 0.1290
2025-04-22 21:44:45,070 - mmseg - INFO - Iter [31850/40000]	lr: 1.630e-05, eta: 0:48:00, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1344, decode.acc_seg: 94.2938, loss: 0.1344
2025-04-22 21:45:00,254 - mmseg - INFO - Iter [31900/40000]	lr: 1.620e-05, eta: 0:47:41, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1422, decode.acc_seg: 94.0915, loss: 0.1422
2025-04-22 21:45:15,447 - mmseg - INFO - Iter [31950/40000]	lr: 1.610e-05, eta: 0:47:23, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1325, decode.acc_seg: 94.1425, loss: 0.1325
2025-04-22 21:45:30,637 - mmseg - INFO - Saving checkpoint at 32000 iterations
2025-04-22 21:45:39,948 - mmseg - INFO - Exp name: vpd_config.py
2025-04-22 21:45:39,949 - mmseg - INFO - Iter [32000/40000]	lr: 1.600e-05, eta: 0:47:07, time: 0.490, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1338, decode.acc_seg: 94.2777, loss: 0.1338
2025-04-22 21:49:15,187 - mmseg - INFO - per class results:
2025-04-22 21:49:15,194 - mmseg - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        | 46.54 | 59.61 |
|       building      | 54.36 | 63.22 |
|         sky         | 56.75 | 73.73 |
|        floor        | 32.67 | 82.71 |
|         tree        | 42.54 | 58.32 |
|       ceiling       | 62.72 | 66.79 |
|         road        | 36.65 | 74.31 |
|         bed         | 29.63 | 41.66 |
|      windowpane     | 36.18 | 46.54 |
|        grass        | 25.23 | 39.04 |
|       cabinet       | 29.42 |  39.5 |
|       sidewalk      | 15.78 | 26.51 |
|        person       | 31.14 |  42.1 |
|        earth        | 21.15 | 38.48 |
|         door        | 30.94 | 42.22 |
|        table        | 15.06 | 24.13 |
|       mountain      | 40.69 | 56.46 |
|        plant        | 21.26 |  28.1 |
|       curtain       | 45.11 | 55.23 |
|        chair        | 13.49 |  20.7 |
|         car         | 12.95 | 20.01 |
|        water        | 31.63 | 52.82 |
|       painting      | 32.63 | 42.41 |
|         sofa        | 14.09 | 21.99 |
|        shelf        | 27.19 | 38.08 |
|        house        | 28.66 | 45.04 |
|         sea         | 38.38 | 65.35 |
|        mirror       | 40.86 | 50.34 |
|         rug         | 14.51 | 21.25 |
|        field        | 20.18 |  44.5 |
|       armchair      | 11.57 |  19.6 |
|         seat        | 25.67 |  40.3 |
|        fence        | 10.36 | 16.29 |
|         desk        | 16.49 |  27.3 |
|         rock        | 24.92 | 39.23 |
|       wardrobe      | 36.58 | 45.78 |
|         lamp        | 20.03 |  28.0 |
|       bathtub       | 38.67 | 48.18 |
|       railing       | 12.42 | 18.41 |
|       cushion       |  7.39 | 11.72 |
|         base        |  14.3 | 24.31 |
|         box         |  9.46 | 13.49 |
|        column       | 28.39 | 35.46 |
|      signboard      | 10.33 | 14.89 |
|   chest of drawers  | 15.86 | 23.67 |
|       counter       |  9.41 | 14.94 |
|         sand        |  27.4 |  46.2 |
|         sink        |  16.4 | 24.65 |
|      skyscraper     | 45.38 | 56.71 |
|      fireplace      | 31.45 |  44.3 |
|     refrigerator    |  42.8 |  49.7 |
|      grandstand     | 29.27 | 60.82 |
|         path        |  7.15 | 10.65 |
|        stairs       |  9.09 | 12.51 |
|        runway       | 30.01 |  46.1 |
|         case        |  32.1 | 47.46 |
|      pool table     | 25.09 | 37.03 |
|        pillow       | 10.52 | 15.63 |
|     screen door     | 37.08 | 45.53 |
|       stairway      | 15.68 | 22.21 |
|        river        | 17.11 |  25.5 |
|        bridge       | 18.79 | 30.83 |
|       bookcase      | 26.15 | 36.27 |
|        blind        | 37.22 | 42.26 |
|     coffee table    |  4.08 |  7.27 |
|        toilet       | 18.32 | 26.48 |
|        flower       | 13.72 | 23.67 |
|         book        |  24.8 | 35.12 |
|         hill        |  8.86 | 14.57 |
|        bench        | 14.18 | 20.83 |
|      countertop     | 11.72 | 20.52 |
|        stove        | 22.91 | 32.27 |
|         palm        | 30.76 | 46.53 |
|    kitchen island   |  9.63 | 20.66 |
|       computer      | 32.05 | 47.04 |
|     swivel chair    |  15.2 | 22.23 |
|         boat        | 10.68 | 17.41 |
|         bar         | 27.01 |  40.4 |
|    arcade machine   | 19.74 | 23.97 |
|        hovel        |  16.4 |  19.2 |
|         bus         |  39.7 | 49.68 |
|        towel        | 16.76 | 25.89 |
|        light        | 21.58 | 28.88 |
|        truck        |  5.36 |  10.0 |
|        tower        |  6.35 |  12.7 |
|      chandelier     |  29.5 | 41.13 |
|        awning       |  4.74 |  6.8  |
|     streetlight     | 12.26 | 15.83 |
|        booth        | 21.08 | 32.52 |
| television receiver | 13.95 | 20.73 |
|       airplane      |  9.75 | 15.61 |
|      dirt track     |  0.83 |  3.81 |
|       apparel       | 17.78 | 26.84 |
|         pole        | 11.97 | 16.45 |
|         land        |  2.55 |  3.48 |
|      bannister      |  5.79 |  9.32 |
|      escalator      | 12.91 |  17.3 |
|       ottoman       |  2.1  |  3.48 |
|        bottle       |  7.45 | 11.57 |
|        buffet       | 26.83 | 32.67 |
|        poster       | 30.29 | 37.74 |
|        stage        | 11.06 | 23.34 |
|         van         |  6.69 |  10.9 |
|         ship        | 34.16 | 54.62 |
|       fountain      |  5.18 |  6.27 |
|    conveyer belt    | 27.16 |  45.5 |
|        canopy       | 16.31 | 22.29 |
|        washer       | 34.72 |  39.6 |
|      plaything      |  5.59 | 10.01 |
|    swimming pool    | 17.35 | 26.89 |
|        stool        |  7.98 | 11.28 |
|        barrel       |  0.5  |  2.17 |
|        basket       |  4.49 |  7.12 |
|      waterfall      | 38.59 | 50.36 |
|         tent        | 37.81 | 44.83 |
|         bag         |  2.33 |  3.04 |
|       minibike      | 14.83 | 22.25 |
|        cradle       | 33.07 | 46.45 |
|         oven        |  24.2 | 31.75 |
|         ball        | 16.87 |  25.1 |
|         food        | 25.37 | 30.96 |
|         step        |  0.01 |  0.01 |
|         tank        | 28.19 | 34.64 |
|      trade name     |  6.19 |  8.08 |
|      microwave      | 41.07 | 51.77 |
|         pot         | 10.48 | 15.12 |
|        animal       |  20.3 |  26.7 |
|       bicycle       |  3.92 |  6.61 |
|         lake        | 32.68 | 38.04 |
|      dishwasher     |  14.3 | 19.67 |
|        screen       | 37.65 | 51.23 |
|       blanket       |  2.75 |  3.65 |
|      sculpture      | 18.27 | 31.62 |
|         hood        | 25.77 | 37.57 |
|        sconce       | 11.79 |  17.0 |
|         vase        |  5.13 |  9.52 |
|    traffic light    | 14.77 | 23.03 |
|         tray        |  3.04 |  5.92 |
|        ashcan       |  1.28 |  2.11 |
|         fan         |  20.3 | 28.35 |
|         pier        |  0.48 |  0.86 |
|      crt screen     |  8.09 | 12.22 |
|        plate        |  10.6 | 16.54 |
|       monitor       | 37.42 | 46.53 |
|    bulletin board   |  32.7 | 42.08 |
|        shower       |  0.28 |  0.81 |
|       radiator      |  8.57 | 13.03 |
|        glass        |  0.33 |  0.38 |
|        clock        |  24.1 | 30.32 |
|         flag        | 37.12 |  44.3 |
+---------------------+-------+-------+
2025-04-22 21:49:15,194 - mmseg - INFO - Summary:
2025-04-22 21:49:15,194 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 53.85 | 20.67 | 29.53 |
+-------+-------+-------+
2025-04-22 21:49:15,195 - mmseg - INFO - Exp name: vpd_config.py
2025-04-22 21:49:15,195 - mmseg - INFO - Iter(val) [2000]	aAcc: 0.5385, mIoU: 0.2067, mAcc: 0.2953, IoU.wall: 0.4654, IoU.building: 0.5436, IoU.sky: 0.5675, IoU.floor: 0.3267, IoU.tree: 0.4254, IoU.ceiling: 0.6272, IoU.road: 0.3665, IoU.bed : 0.2963, IoU.windowpane: 0.3618, IoU.grass: 0.2523, IoU.cabinet: 0.2942, IoU.sidewalk: 0.1578, IoU.person: 0.3114, IoU.earth: 0.2115, IoU.door: 0.3094, IoU.table: 0.1506, IoU.mountain: 0.4069, IoU.plant: 0.2126, IoU.curtain: 0.4511, IoU.chair: 0.1349, IoU.car: 0.1295, IoU.water: 0.3163, IoU.painting: 0.3263, IoU.sofa: 0.1409, IoU.shelf: 0.2719, IoU.house: 0.2866, IoU.sea: 0.3838, IoU.mirror: 0.4086, IoU.rug: 0.1451, IoU.field: 0.2018, IoU.armchair: 0.1157, IoU.seat: 0.2567, IoU.fence: 0.1036, IoU.desk: 0.1649, IoU.rock: 0.2492, IoU.wardrobe: 0.3658, IoU.lamp: 0.2003, IoU.bathtub: 0.3867, IoU.railing: 0.1242, IoU.cushion: 0.0739, IoU.base: 0.1430, IoU.box: 0.0946, IoU.column: 0.2839, IoU.signboard: 0.1033, IoU.chest of drawers: 0.1586, IoU.counter: 0.0941, IoU.sand: 0.2740, IoU.sink: 0.1640, IoU.skyscraper: 0.4538, IoU.fireplace: 0.3145, IoU.refrigerator: 0.4280, IoU.grandstand: 0.2927, IoU.path: 0.0715, IoU.stairs: 0.0909, IoU.runway: 0.3001, IoU.case: 0.3210, IoU.pool table: 0.2509, IoU.pillow: 0.1052, IoU.screen door: 0.3708, IoU.stairway: 0.1568, IoU.river: 0.1711, IoU.bridge: 0.1879, IoU.bookcase: 0.2615, IoU.blind: 0.3722, IoU.coffee table: 0.0408, IoU.toilet: 0.1832, IoU.flower: 0.1372, IoU.book: 0.2480, IoU.hill: 0.0886, IoU.bench: 0.1418, IoU.countertop: 0.1172, IoU.stove: 0.2291, IoU.palm: 0.3076, IoU.kitchen island: 0.0963, IoU.computer: 0.3205, IoU.swivel chair: 0.1520, IoU.boat: 0.1068, IoU.bar: 0.2701, IoU.arcade machine: 0.1974, IoU.hovel: 0.1640, IoU.bus: 0.3970, IoU.towel: 0.1676, IoU.light: 0.2158, IoU.truck: 0.0536, IoU.tower: 0.0635, IoU.chandelier: 0.2950, IoU.awning: 0.0474, IoU.streetlight: 0.1226, IoU.booth: 0.2108, IoU.television receiver: 0.1395, IoU.airplane: 0.0975, IoU.dirt track: 0.0083, IoU.apparel: 0.1778, IoU.pole: 0.1197, IoU.land: 0.0255, IoU.bannister: 0.0579, IoU.escalator: 0.1291, IoU.ottoman: 0.0210, IoU.bottle: 0.0745, IoU.buffet: 0.2683, IoU.poster: 0.3029, IoU.stage: 0.1106, IoU.van: 0.0669, IoU.ship: 0.3416, IoU.fountain: 0.0518, IoU.conveyer belt: 0.2716, IoU.canopy: 0.1631, IoU.washer: 0.3472, IoU.plaything: 0.0559, IoU.swimming pool: 0.1735, IoU.stool: 0.0798, IoU.barrel: 0.0050, IoU.basket: 0.0449, IoU.waterfall: 0.3859, IoU.tent: 0.3781, IoU.bag: 0.0233, IoU.minibike: 0.1483, IoU.cradle: 0.3307, IoU.oven: 0.2420, IoU.ball: 0.1687, IoU.food: 0.2537, IoU.step: 0.0001, IoU.tank: 0.2819, IoU.trade name: 0.0619, IoU.microwave: 0.4107, IoU.pot: 0.1048, IoU.animal: 0.2030, IoU.bicycle: 0.0392, IoU.lake: 0.3268, IoU.dishwasher: 0.1430, IoU.screen: 0.3765, IoU.blanket: 0.0275, IoU.sculpture: 0.1827, IoU.hood: 0.2577, IoU.sconce: 0.1179, IoU.vase: 0.0513, IoU.traffic light: 0.1477, IoU.tray: 0.0304, IoU.ashcan: 0.0128, IoU.fan: 0.2030, IoU.pier: 0.0048, IoU.crt screen: 0.0809, IoU.plate: 0.1060, IoU.monitor: 0.3742, IoU.bulletin board: 0.3270, IoU.shower: 0.0028, IoU.radiator: 0.0857, IoU.glass: 0.0033, IoU.clock: 0.2410, IoU.flag: 0.3712, Acc.wall: 0.5961, Acc.building: 0.6322, Acc.sky: 0.7373, Acc.floor: 0.8271, Acc.tree: 0.5832, Acc.ceiling: 0.6679, Acc.road: 0.7431, Acc.bed : 0.4166, Acc.windowpane: 0.4654, Acc.grass: 0.3904, Acc.cabinet: 0.3950, Acc.sidewalk: 0.2651, Acc.person: 0.4210, Acc.earth: 0.3848, Acc.door: 0.4222, Acc.table: 0.2413, Acc.mountain: 0.5646, Acc.plant: 0.2810, Acc.curtain: 0.5523, Acc.chair: 0.2070, Acc.car: 0.2001, Acc.water: 0.5282, Acc.painting: 0.4241, Acc.sofa: 0.2199, Acc.shelf: 0.3808, Acc.house: 0.4504, Acc.sea: 0.6535, Acc.mirror: 0.5034, Acc.rug: 0.2125, Acc.field: 0.4450, Acc.armchair: 0.1960, Acc.seat: 0.4030, Acc.fence: 0.1629, Acc.desk: 0.2730, Acc.rock: 0.3923, Acc.wardrobe: 0.4578, Acc.lamp: 0.2800, Acc.bathtub: 0.4818, Acc.railing: 0.1841, Acc.cushion: 0.1172, Acc.base: 0.2431, Acc.box: 0.1349, Acc.column: 0.3546, Acc.signboard: 0.1489, Acc.chest of drawers: 0.2367, Acc.counter: 0.1494, Acc.sand: 0.4620, Acc.sink: 0.2465, Acc.skyscraper: 0.5671, Acc.fireplace: 0.4430, Acc.refrigerator: 0.4970, Acc.grandstand: 0.6082, Acc.path: 0.1065, Acc.stairs: 0.1251, Acc.runway: 0.4610, Acc.case: 0.4746, Acc.pool table: 0.3703, Acc.pillow: 0.1563, Acc.screen door: 0.4553, Acc.stairway: 0.2221, Acc.river: 0.2550, Acc.bridge: 0.3083, Acc.bookcase: 0.3627, Acc.blind: 0.4226, Acc.coffee table: 0.0727, Acc.toilet: 0.2648, Acc.flower: 0.2367, Acc.book: 0.3512, Acc.hill: 0.1457, Acc.bench: 0.2083, Acc.countertop: 0.2052, Acc.stove: 0.3227, Acc.palm: 0.4653, Acc.kitchen island: 0.2066, Acc.computer: 0.4704, Acc.swivel chair: 0.2223, Acc.boat: 0.1741, Acc.bar: 0.4040, Acc.arcade machine: 0.2397, Acc.hovel: 0.1920, Acc.bus: 0.4968, Acc.towel: 0.2589, Acc.light: 0.2888, Acc.truck: 0.1000, Acc.tower: 0.1270, Acc.chandelier: 0.4113, Acc.awning: 0.0680, Acc.streetlight: 0.1583, Acc.booth: 0.3252, Acc.television receiver: 0.2073, Acc.airplane: 0.1561, Acc.dirt track: 0.0381, Acc.apparel: 0.2684, Acc.pole: 0.1645, Acc.land: 0.0348, Acc.bannister: 0.0932, Acc.escalator: 0.1730, Acc.ottoman: 0.0348, Acc.bottle: 0.1157, Acc.buffet: 0.3267, Acc.poster: 0.3774, Acc.stage: 0.2334, Acc.van: 0.1090, Acc.ship: 0.5462, Acc.fountain: 0.0627, Acc.conveyer belt: 0.4550, Acc.canopy: 0.2229, Acc.washer: 0.3960, Acc.plaything: 0.1001, Acc.swimming pool: 0.2689, Acc.stool: 0.1128, Acc.barrel: 0.0217, Acc.basket: 0.0712, Acc.waterfall: 0.5036, Acc.tent: 0.4483, Acc.bag: 0.0304, Acc.minibike: 0.2225, Acc.cradle: 0.4645, Acc.oven: 0.3175, Acc.ball: 0.2510, Acc.food: 0.3096, Acc.step: 0.0001, Acc.tank: 0.3464, Acc.trade name: 0.0808, Acc.microwave: 0.5177, Acc.pot: 0.1512, Acc.animal: 0.2670, Acc.bicycle: 0.0661, Acc.lake: 0.3804, Acc.dishwasher: 0.1967, Acc.screen: 0.5123, Acc.blanket: 0.0365, Acc.sculpture: 0.3162, Acc.hood: 0.3757, Acc.sconce: 0.1700, Acc.vase: 0.0952, Acc.traffic light: 0.2303, Acc.tray: 0.0592, Acc.ashcan: 0.0211, Acc.fan: 0.2835, Acc.pier: 0.0086, Acc.crt screen: 0.1222, Acc.plate: 0.1654, Acc.monitor: 0.4653, Acc.bulletin board: 0.4208, Acc.shower: 0.0081, Acc.radiator: 0.1303, Acc.glass: 0.0038, Acc.clock: 0.3032, Acc.flag: 0.4430
2025-04-22 21:49:31,037 - mmseg - INFO - Iter [32050/40000]	lr: 1.590e-05, eta: 0:47:42, time: 4.622, data_time: 4.314, memory: 75933, decode.loss_ce: 0.1343, decode.acc_seg: 94.3352, loss: 0.1343
2025-04-22 21:49:46,190 - mmseg - INFO - Iter [32100/40000]	lr: 1.580e-05, eta: 0:47:24, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1306, decode.acc_seg: 94.7868, loss: 0.1306
2025-04-22 21:50:01,389 - mmseg - INFO - Iter [32150/40000]	lr: 1.570e-05, eta: 0:47:05, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1391, decode.acc_seg: 94.2466, loss: 0.1391
2025-04-22 21:50:16,609 - mmseg - INFO - Iter [32200/40000]	lr: 1.560e-05, eta: 0:46:46, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1334, decode.acc_seg: 94.4416, loss: 0.1334
2025-04-22 21:50:31,830 - mmseg - INFO - Iter [32250/40000]	lr: 1.550e-05, eta: 0:46:28, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1461, decode.acc_seg: 94.1361, loss: 0.1461
2025-04-22 21:50:47,059 - mmseg - INFO - Iter [32300/40000]	lr: 1.540e-05, eta: 0:46:09, time: 0.305, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1296, decode.acc_seg: 94.6544, loss: 0.1296
2025-04-22 21:51:02,291 - mmseg - INFO - Iter [32350/40000]	lr: 1.530e-05, eta: 0:45:50, time: 0.305, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1548, decode.acc_seg: 93.9447, loss: 0.1548
2025-04-22 21:51:17,516 - mmseg - INFO - Iter [32400/40000]	lr: 1.520e-05, eta: 0:45:32, time: 0.305, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1302, decode.acc_seg: 94.6724, loss: 0.1302
2025-04-22 21:51:32,727 - mmseg - INFO - Iter [32450/40000]	lr: 1.510e-05, eta: 0:45:13, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1286, decode.acc_seg: 94.8035, loss: 0.1286
2025-04-22 21:51:47,945 - mmseg - INFO - Iter [32500/40000]	lr: 1.500e-05, eta: 0:44:54, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1292, decode.acc_seg: 94.6997, loss: 0.1292
2025-04-22 21:52:03,144 - mmseg - INFO - Iter [32550/40000]	lr: 1.490e-05, eta: 0:44:36, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1321, decode.acc_seg: 94.4353, loss: 0.1321
2025-04-22 21:52:18,314 - mmseg - INFO - Iter [32600/40000]	lr: 1.480e-05, eta: 0:44:17, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1299, decode.acc_seg: 94.6920, loss: 0.1299
2025-04-22 21:52:33,487 - mmseg - INFO - Iter [32650/40000]	lr: 1.470e-05, eta: 0:43:59, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1181, decode.acc_seg: 95.0444, loss: 0.1181
2025-04-22 21:52:48,669 - mmseg - INFO - Iter [32700/40000]	lr: 1.460e-05, eta: 0:43:40, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1370, decode.acc_seg: 94.1350, loss: 0.1370
2025-04-22 21:53:03,872 - mmseg - INFO - Iter [32750/40000]	lr: 1.450e-05, eta: 0:43:22, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1266, decode.acc_seg: 94.6953, loss: 0.1266
2025-04-22 21:53:19,082 - mmseg - INFO - Iter [32800/40000]	lr: 1.440e-05, eta: 0:43:03, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1288, decode.acc_seg: 94.5636, loss: 0.1288
2025-04-22 21:53:34,290 - mmseg - INFO - Iter [32850/40000]	lr: 1.430e-05, eta: 0:42:44, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1212, decode.acc_seg: 94.9265, loss: 0.1212
2025-04-22 21:53:49,496 - mmseg - INFO - Iter [32900/40000]	lr: 1.420e-05, eta: 0:42:26, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1165, decode.acc_seg: 94.8213, loss: 0.1165
2025-04-22 21:54:04,688 - mmseg - INFO - Iter [32950/40000]	lr: 1.410e-05, eta: 0:42:07, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1222, decode.acc_seg: 94.9782, loss: 0.1222
2025-04-22 21:54:19,888 - mmseg - INFO - Exp name: vpd_config.py
2025-04-22 21:54:19,889 - mmseg - INFO - Iter [33000/40000]	lr: 1.400e-05, eta: 0:41:49, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1297, decode.acc_seg: 94.4680, loss: 0.1297
2025-04-22 21:54:35,789 - mmseg - INFO - Iter [33050/40000]	lr: 1.390e-05, eta: 0:41:31, time: 0.318, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1470, decode.acc_seg: 94.3059, loss: 0.1470
2025-04-22 21:54:50,975 - mmseg - INFO - Iter [33100/40000]	lr: 1.380e-05, eta: 0:41:12, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1160, decode.acc_seg: 95.1156, loss: 0.1160
2025-04-22 21:55:06,177 - mmseg - INFO - Iter [33150/40000]	lr: 1.370e-05, eta: 0:40:54, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1409, decode.acc_seg: 94.2812, loss: 0.1409
2025-04-22 21:55:21,350 - mmseg - INFO - Iter [33200/40000]	lr: 1.360e-05, eta: 0:40:35, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1443, decode.acc_seg: 94.1711, loss: 0.1443
2025-04-22 21:55:36,526 - mmseg - INFO - Iter [33250/40000]	lr: 1.350e-05, eta: 0:40:17, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1228, decode.acc_seg: 94.7581, loss: 0.1228
2025-04-22 21:55:51,717 - mmseg - INFO - Iter [33300/40000]	lr: 1.340e-05, eta: 0:39:58, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1369, decode.acc_seg: 94.4283, loss: 0.1369
2025-04-22 21:56:06,911 - mmseg - INFO - Iter [33350/40000]	lr: 1.330e-05, eta: 0:39:40, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1338, decode.acc_seg: 94.3577, loss: 0.1338
2025-04-22 21:56:22,106 - mmseg - INFO - Iter [33400/40000]	lr: 1.320e-05, eta: 0:39:21, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1316, decode.acc_seg: 94.0694, loss: 0.1316
2025-04-22 21:56:37,306 - mmseg - INFO - Iter [33450/40000]	lr: 1.310e-05, eta: 0:39:03, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1437, decode.acc_seg: 94.2112, loss: 0.1437
2025-04-22 21:56:52,501 - mmseg - INFO - Iter [33500/40000]	lr: 1.300e-05, eta: 0:38:44, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1186, decode.acc_seg: 95.0256, loss: 0.1186
2025-04-22 21:57:07,701 - mmseg - INFO - Iter [33550/40000]	lr: 1.290e-05, eta: 0:38:26, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1208, decode.acc_seg: 94.5499, loss: 0.1208
2025-04-22 21:57:22,933 - mmseg - INFO - Iter [33600/40000]	lr: 1.280e-05, eta: 0:38:08, time: 0.305, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1265, decode.acc_seg: 94.4329, loss: 0.1265
2025-04-22 21:57:38,136 - mmseg - INFO - Iter [33650/40000]	lr: 1.270e-05, eta: 0:37:49, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1230, decode.acc_seg: 94.6380, loss: 0.1230
2025-04-22 21:57:53,324 - mmseg - INFO - Iter [33700/40000]	lr: 1.260e-05, eta: 0:37:31, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1322, decode.acc_seg: 94.5365, loss: 0.1322
2025-04-22 21:58:08,519 - mmseg - INFO - Iter [33750/40000]	lr: 1.250e-05, eta: 0:37:13, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1418, decode.acc_seg: 93.5819, loss: 0.1418
2025-04-22 21:58:23,708 - mmseg - INFO - Iter [33800/40000]	lr: 1.240e-05, eta: 0:36:54, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1234, decode.acc_seg: 94.7579, loss: 0.1234
2025-04-22 21:58:38,899 - mmseg - INFO - Iter [33850/40000]	lr: 1.230e-05, eta: 0:36:36, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1445, decode.acc_seg: 93.9430, loss: 0.1445
2025-04-22 21:58:54,090 - mmseg - INFO - Iter [33900/40000]	lr: 1.220e-05, eta: 0:36:18, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1219, decode.acc_seg: 95.0004, loss: 0.1219
2025-04-22 21:59:09,286 - mmseg - INFO - Iter [33950/40000]	lr: 1.210e-05, eta: 0:35:59, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1270, decode.acc_seg: 94.5469, loss: 0.1270
2025-04-22 21:59:24,473 - mmseg - INFO - Exp name: vpd_config.py
2025-04-22 21:59:24,473 - mmseg - INFO - Iter [34000/40000]	lr: 1.200e-05, eta: 0:35:41, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1175, decode.acc_seg: 94.9859, loss: 0.1175
2025-04-22 21:59:40,446 - mmseg - INFO - Iter [34050/40000]	lr: 1.190e-05, eta: 0:35:23, time: 0.319, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1345, decode.acc_seg: 94.5620, loss: 0.1345
2025-04-22 21:59:55,636 - mmseg - INFO - Iter [34100/40000]	lr: 1.180e-05, eta: 0:35:04, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1262, decode.acc_seg: 94.4841, loss: 0.1262
2025-04-22 22:00:10,797 - mmseg - INFO - Iter [34150/40000]	lr: 1.170e-05, eta: 0:34:46, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1276, decode.acc_seg: 94.7581, loss: 0.1276
2025-04-22 22:00:25,971 - mmseg - INFO - Iter [34200/40000]	lr: 1.160e-05, eta: 0:34:28, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1272, decode.acc_seg: 94.6726, loss: 0.1272
2025-04-22 22:00:41,144 - mmseg - INFO - Iter [34250/40000]	lr: 1.150e-05, eta: 0:34:10, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1303, decode.acc_seg: 94.2323, loss: 0.1303
2025-04-22 22:00:56,324 - mmseg - INFO - Iter [34300/40000]	lr: 1.140e-05, eta: 0:33:51, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1409, decode.acc_seg: 94.3736, loss: 0.1409
2025-04-22 22:01:11,517 - mmseg - INFO - Iter [34350/40000]	lr: 1.130e-05, eta: 0:33:33, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1246, decode.acc_seg: 94.5425, loss: 0.1246
2025-04-22 22:01:26,691 - mmseg - INFO - Iter [34400/40000]	lr: 1.120e-05, eta: 0:33:15, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1335, decode.acc_seg: 94.1362, loss: 0.1335
2025-04-22 22:01:41,856 - mmseg - INFO - Iter [34450/40000]	lr: 1.110e-05, eta: 0:32:57, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1339, decode.acc_seg: 94.5516, loss: 0.1339
2025-04-22 22:01:57,029 - mmseg - INFO - Iter [34500/40000]	lr: 1.100e-05, eta: 0:32:38, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1528, decode.acc_seg: 93.4649, loss: 0.1528
2025-04-22 22:02:12,177 - mmseg - INFO - Iter [34550/40000]	lr: 1.090e-05, eta: 0:32:20, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1413, decode.acc_seg: 94.0800, loss: 0.1413
2025-04-22 22:02:27,347 - mmseg - INFO - Iter [34600/40000]	lr: 1.080e-05, eta: 0:32:02, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1509, decode.acc_seg: 93.7494, loss: 0.1509
2025-04-22 22:02:42,507 - mmseg - INFO - Iter [34650/40000]	lr: 1.070e-05, eta: 0:31:44, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1256, decode.acc_seg: 94.7239, loss: 0.1256
2025-04-22 22:02:57,663 - mmseg - INFO - Iter [34700/40000]	lr: 1.060e-05, eta: 0:31:25, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1307, decode.acc_seg: 94.4140, loss: 0.1307
2025-04-22 22:03:12,851 - mmseg - INFO - Iter [34750/40000]	lr: 1.050e-05, eta: 0:31:07, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1595, decode.acc_seg: 94.1189, loss: 0.1595
2025-04-22 22:03:28,043 - mmseg - INFO - Iter [34800/40000]	lr: 1.040e-05, eta: 0:30:49, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1261, decode.acc_seg: 94.5475, loss: 0.1261
2025-04-22 22:03:43,232 - mmseg - INFO - Iter [34850/40000]	lr: 1.030e-05, eta: 0:30:31, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1439, decode.acc_seg: 94.1079, loss: 0.1439
2025-04-22 22:03:58,412 - mmseg - INFO - Iter [34900/40000]	lr: 1.020e-05, eta: 0:30:13, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1615, decode.acc_seg: 93.9296, loss: 0.1615
2025-04-22 22:04:13,610 - mmseg - INFO - Iter [34950/40000]	lr: 1.010e-05, eta: 0:29:55, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1489, decode.acc_seg: 93.8693, loss: 0.1489
2025-04-22 22:04:28,805 - mmseg - INFO - Exp name: vpd_config.py
2025-04-22 22:04:28,806 - mmseg - INFO - Iter [35000/40000]	lr: 1.000e-05, eta: 0:29:36, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1315, decode.acc_seg: 94.5099, loss: 0.1315
2025-04-22 22:04:44,842 - mmseg - INFO - Iter [35050/40000]	lr: 9.902e-06, eta: 0:29:18, time: 0.321, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1273, decode.acc_seg: 94.7084, loss: 0.1273
2025-04-22 22:05:00,009 - mmseg - INFO - Iter [35100/40000]	lr: 9.802e-06, eta: 0:29:00, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1376, decode.acc_seg: 94.4548, loss: 0.1376
2025-04-22 22:05:15,177 - mmseg - INFO - Iter [35150/40000]	lr: 9.702e-06, eta: 0:28:42, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1168, decode.acc_seg: 95.0353, loss: 0.1168
2025-04-22 22:05:30,352 - mmseg - INFO - Iter [35200/40000]	lr: 9.602e-06, eta: 0:28:24, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1263, decode.acc_seg: 94.5374, loss: 0.1263
2025-04-22 22:05:45,523 - mmseg - INFO - Iter [35250/40000]	lr: 9.502e-06, eta: 0:28:06, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1388, decode.acc_seg: 94.2101, loss: 0.1388
2025-04-22 22:06:00,690 - mmseg - INFO - Iter [35300/40000]	lr: 9.402e-06, eta: 0:27:48, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1363, decode.acc_seg: 94.4973, loss: 0.1363
2025-04-22 22:06:15,857 - mmseg - INFO - Iter [35350/40000]	lr: 9.302e-06, eta: 0:27:30, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1269, decode.acc_seg: 94.6593, loss: 0.1269
2025-04-22 22:06:31,029 - mmseg - INFO - Iter [35400/40000]	lr: 9.202e-06, eta: 0:27:12, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1295, decode.acc_seg: 94.5058, loss: 0.1295
2025-04-22 22:06:46,229 - mmseg - INFO - Iter [35450/40000]	lr: 9.102e-06, eta: 0:26:54, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1355, decode.acc_seg: 94.2730, loss: 0.1355
2025-04-22 22:07:01,410 - mmseg - INFO - Iter [35500/40000]	lr: 9.002e-06, eta: 0:26:36, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1374, decode.acc_seg: 94.3613, loss: 0.1374
2025-04-22 22:07:16,580 - mmseg - INFO - Iter [35550/40000]	lr: 8.902e-06, eta: 0:26:18, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1337, decode.acc_seg: 94.4673, loss: 0.1337
2025-04-22 22:07:31,752 - mmseg - INFO - Iter [35600/40000]	lr: 8.802e-06, eta: 0:26:00, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1260, decode.acc_seg: 94.7736, loss: 0.1260
2025-04-22 22:07:46,936 - mmseg - INFO - Iter [35650/40000]	lr: 8.702e-06, eta: 0:25:41, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1150, decode.acc_seg: 95.1319, loss: 0.1150
2025-04-22 22:08:02,103 - mmseg - INFO - Iter [35700/40000]	lr: 8.602e-06, eta: 0:25:23, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1279, decode.acc_seg: 94.7537, loss: 0.1279
2025-04-22 22:08:17,268 - mmseg - INFO - Iter [35750/40000]	lr: 8.502e-06, eta: 0:25:05, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1397, decode.acc_seg: 94.4602, loss: 0.1397
2025-04-22 22:08:32,448 - mmseg - INFO - Iter [35800/40000]	lr: 8.402e-06, eta: 0:24:47, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1325, decode.acc_seg: 94.5788, loss: 0.1325
2025-04-22 22:08:47,643 - mmseg - INFO - Iter [35850/40000]	lr: 8.302e-06, eta: 0:24:29, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1341, decode.acc_seg: 94.3852, loss: 0.1341
2025-04-22 22:09:02,832 - mmseg - INFO - Iter [35900/40000]	lr: 8.202e-06, eta: 0:24:11, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1184, decode.acc_seg: 94.8327, loss: 0.1184
2025-04-22 22:09:18,020 - mmseg - INFO - Iter [35950/40000]	lr: 8.102e-06, eta: 0:23:53, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1299, decode.acc_seg: 94.4663, loss: 0.1299
2025-04-22 22:09:33,199 - mmseg - INFO - Saving checkpoint at 36000 iterations
2025-04-22 22:09:42,415 - mmseg - INFO - Exp name: vpd_config.py
2025-04-22 22:09:42,416 - mmseg - INFO - Iter [36000/40000]	lr: 8.002e-06, eta: 0:23:36, time: 0.488, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1341, decode.acc_seg: 94.4544, loss: 0.1341
2025-04-22 22:13:16,972 - mmseg - INFO - per class results:
2025-04-22 22:13:16,978 - mmseg - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        | 46.54 | 59.65 |
|       building      | 54.78 | 64.32 |
|         sky         | 60.81 | 73.21 |
|        floor        |  33.4 | 82.56 |
|         tree        | 42.76 |  58.6 |
|       ceiling       | 62.98 | 67.24 |
|         road        | 37.18 |  78.4 |
|         bed         | 29.53 | 41.53 |
|      windowpane     | 36.21 | 46.88 |
|        grass        | 25.39 | 38.88 |
|       cabinet       |  29.3 | 39.65 |
|       sidewalk      |  15.2 | 24.86 |
|        person       | 31.18 | 42.93 |
|        earth        | 21.16 | 38.59 |
|         door        | 30.89 | 42.81 |
|        table        | 15.57 | 25.03 |
|       mountain      | 40.57 | 56.77 |
|        plant        | 21.39 |  28.5 |
|       curtain       | 45.36 | 54.67 |
|        chair        | 13.56 | 20.93 |
|         car         | 13.24 | 20.61 |
|        water        | 31.79 | 56.46 |
|       painting      |  32.6 | 42.65 |
|         sofa        | 14.61 | 23.08 |
|        shelf        | 27.23 |  37.9 |
|        house        | 28.12 | 43.99 |
|         sea         | 38.85 | 66.08 |
|        mirror       | 40.89 | 50.24 |
|         rug         | 14.82 | 21.91 |
|        field        | 20.27 | 43.72 |
|       armchair      | 11.61 | 19.59 |
|         seat        | 25.74 | 40.81 |
|        fence        | 10.28 | 15.91 |
|         desk        | 16.73 | 28.17 |
|         rock        | 24.22 | 41.25 |
|       wardrobe      | 36.76 | 45.61 |
|         lamp        | 20.34 | 29.08 |
|       bathtub       | 39.26 | 49.96 |
|       railing       | 12.76 | 19.53 |
|       cushion       |  7.39 | 11.59 |
|         base        | 14.18 |  23.9 |
|         box         |  9.77 | 14.23 |
|        column       | 28.56 | 35.87 |
|      signboard      | 10.17 | 14.53 |
|   chest of drawers  | 16.42 | 25.18 |
|       counter       |  9.8  | 15.67 |
|         sand        | 26.35 | 46.32 |
|         sink        | 16.51 | 24.31 |
|      skyscraper     | 43.37 | 53.49 |
|      fireplace      | 31.59 | 44.88 |
|     refrigerator    | 42.33 |  50.3 |
|      grandstand     | 29.16 | 60.83 |
|         path        |  7.22 | 10.96 |
|        stairs       |  9.83 | 13.98 |
|        runway       | 31.11 | 48.05 |
|         case        | 32.78 | 48.71 |
|      pool table     | 25.29 | 37.53 |
|        pillow       | 10.57 | 15.77 |
|     screen door     | 36.62 | 45.05 |
|       stairway      | 16.06 | 22.22 |
|        river        | 17.15 | 26.25 |
|        bridge       | 18.58 | 31.02 |
|       bookcase      | 26.51 | 36.94 |
|        blind        | 37.04 | 42.16 |
|     coffee table    |  4.17 |  7.56 |
|        toilet       | 19.11 |  28.1 |
|        flower       | 13.87 | 23.06 |
|         book        | 24.66 | 35.13 |
|         hill        |  8.64 | 15.46 |
|        bench        | 14.21 | 20.77 |
|      countertop     | 12.04 | 21.16 |
|        stove        | 23.22 | 33.15 |
|         palm        | 29.74 | 43.33 |
|    kitchen island   |  9.88 | 22.83 |
|       computer      | 32.37 | 47.18 |
|     swivel chair    | 15.45 | 22.72 |
|         boat        | 10.51 | 17.46 |
|         bar         | 29.22 | 44.93 |
|    arcade machine   | 20.04 |  24.5 |
|        hovel        | 15.42 | 17.97 |
|         bus         | 39.67 | 49.89 |
|        towel        | 16.16 | 25.35 |
|        light        |  21.2 | 27.85 |
|        truck        |  5.87 | 11.36 |
|        tower        |  5.84 | 11.45 |
|      chandelier     | 29.67 | 41.43 |
|        awning       |  4.66 |  6.53 |
|     streetlight     |  13.0 | 17.59 |
|        booth        | 21.18 | 33.18 |
| television receiver | 14.62 | 22.18 |
|       airplane      |  9.03 | 14.04 |
|      dirt track     |  1.5  |  8.07 |
|       apparel       | 17.92 | 26.69 |
|         pole        | 12.48 | 17.83 |
|         land        |  2.65 |  4.37 |
|      bannister      |  5.9  |  8.75 |
|      escalator      | 12.76 | 16.72 |
|       ottoman       |  2.22 |  3.7  |
|        bottle       | 10.05 | 16.64 |
|        buffet       | 26.06 | 33.73 |
|        poster       |  29.9 | 37.71 |
|        stage        | 11.22 |  23.2 |
|         van         |  7.11 | 12.02 |
|         ship        | 34.15 | 55.82 |
|       fountain      |  5.17 |  6.3  |
|    conveyer belt    | 27.32 | 47.18 |
|        canopy       | 17.52 | 23.99 |
|        washer       | 35.04 | 39.88 |
|      plaything      |  6.19 | 11.15 |
|    swimming pool    |  17.8 | 27.19 |
|        stool        |  8.09 | 12.01 |
|        barrel       |  1.38 |  6.16 |
|        basket       |  4.72 |  7.09 |
|      waterfall      |  38.6 | 50.85 |
|         tent        | 37.77 | 45.03 |
|         bag         |  2.28 |  2.97 |
|       minibike      | 14.74 | 22.57 |
|        cradle       | 33.13 | 46.94 |
|         oven        | 24.62 | 32.08 |
|         ball        | 16.77 | 25.37 |
|         food        | 25.37 | 30.78 |
|         step        |  0.01 |  0.02 |
|         tank        | 28.51 | 36.47 |
|      trade name     |  6.06 |  7.87 |
|      microwave      | 41.37 | 52.48 |
|         pot         | 11.21 | 16.33 |
|        animal       | 20.34 | 26.41 |
|       bicycle       |  3.93 |  6.59 |
|         lake        | 32.96 |  38.4 |
|      dishwasher     | 13.58 |  18.3 |
|        screen       | 37.21 | 51.68 |
|       blanket       |  2.73 |  3.65 |
|      sculpture      | 18.29 | 30.62 |
|         hood        | 25.76 | 37.66 |
|        sconce       | 11.65 | 16.65 |
|         vase        |  5.19 |  9.49 |
|    traffic light    | 14.94 | 23.29 |
|         tray        |  3.2  |  6.69 |
|        ashcan       |  1.35 |  2.31 |
|         fan         | 20.31 | 29.13 |
|         pier        |  0.54 |  0.94 |
|      crt screen     |  8.35 | 12.22 |
|        plate        | 10.57 | 16.96 |
|       monitor       | 36.64 |  47.2 |
|    bulletin board   | 32.59 | 42.83 |
|        shower       |  0.5  |  1.56 |
|       radiator      |  8.49 | 13.07 |
|        glass        |  0.34 |  0.4  |
|        clock        | 24.07 | 31.12 |
|         flag        | 36.87 | 44.82 |
+---------------------+-------+-------+
2025-04-22 22:13:16,979 - mmseg - INFO - Summary:
2025-04-22 22:13:16,979 - mmseg - INFO - 
+-------+------+-------+
|  aAcc | mIoU |  mAcc |
+-------+------+-------+
| 54.26 | 20.8 | 29.98 |
+-------+------+-------+
2025-04-22 22:13:16,979 - mmseg - INFO - Exp name: vpd_config.py
2025-04-22 22:13:16,980 - mmseg - INFO - Iter(val) [2000]	aAcc: 0.5426, mIoU: 0.2080, mAcc: 0.2998, IoU.wall: 0.4654, IoU.building: 0.5478, IoU.sky: 0.6081, IoU.floor: 0.3340, IoU.tree: 0.4276, IoU.ceiling: 0.6298, IoU.road: 0.3718, IoU.bed : 0.2953, IoU.windowpane: 0.3621, IoU.grass: 0.2539, IoU.cabinet: 0.2930, IoU.sidewalk: 0.1520, IoU.person: 0.3118, IoU.earth: 0.2116, IoU.door: 0.3089, IoU.table: 0.1557, IoU.mountain: 0.4057, IoU.plant: 0.2139, IoU.curtain: 0.4536, IoU.chair: 0.1356, IoU.car: 0.1324, IoU.water: 0.3179, IoU.painting: 0.3260, IoU.sofa: 0.1461, IoU.shelf: 0.2723, IoU.house: 0.2812, IoU.sea: 0.3885, IoU.mirror: 0.4089, IoU.rug: 0.1482, IoU.field: 0.2027, IoU.armchair: 0.1161, IoU.seat: 0.2574, IoU.fence: 0.1028, IoU.desk: 0.1673, IoU.rock: 0.2422, IoU.wardrobe: 0.3676, IoU.lamp: 0.2034, IoU.bathtub: 0.3926, IoU.railing: 0.1276, IoU.cushion: 0.0739, IoU.base: 0.1418, IoU.box: 0.0977, IoU.column: 0.2856, IoU.signboard: 0.1017, IoU.chest of drawers: 0.1642, IoU.counter: 0.0980, IoU.sand: 0.2635, IoU.sink: 0.1651, IoU.skyscraper: 0.4337, IoU.fireplace: 0.3159, IoU.refrigerator: 0.4233, IoU.grandstand: 0.2916, IoU.path: 0.0722, IoU.stairs: 0.0983, IoU.runway: 0.3111, IoU.case: 0.3278, IoU.pool table: 0.2529, IoU.pillow: 0.1057, IoU.screen door: 0.3662, IoU.stairway: 0.1606, IoU.river: 0.1715, IoU.bridge: 0.1858, IoU.bookcase: 0.2651, IoU.blind: 0.3704, IoU.coffee table: 0.0417, IoU.toilet: 0.1911, IoU.flower: 0.1387, IoU.book: 0.2466, IoU.hill: 0.0864, IoU.bench: 0.1421, IoU.countertop: 0.1204, IoU.stove: 0.2322, IoU.palm: 0.2974, IoU.kitchen island: 0.0988, IoU.computer: 0.3237, IoU.swivel chair: 0.1545, IoU.boat: 0.1051, IoU.bar: 0.2922, IoU.arcade machine: 0.2004, IoU.hovel: 0.1542, IoU.bus: 0.3967, IoU.towel: 0.1616, IoU.light: 0.2120, IoU.truck: 0.0587, IoU.tower: 0.0584, IoU.chandelier: 0.2967, IoU.awning: 0.0466, IoU.streetlight: 0.1300, IoU.booth: 0.2118, IoU.television receiver: 0.1462, IoU.airplane: 0.0903, IoU.dirt track: 0.0150, IoU.apparel: 0.1792, IoU.pole: 0.1248, IoU.land: 0.0265, IoU.bannister: 0.0590, IoU.escalator: 0.1276, IoU.ottoman: 0.0222, IoU.bottle: 0.1005, IoU.buffet: 0.2606, IoU.poster: 0.2990, IoU.stage: 0.1122, IoU.van: 0.0711, IoU.ship: 0.3415, IoU.fountain: 0.0517, IoU.conveyer belt: 0.2732, IoU.canopy: 0.1752, IoU.washer: 0.3504, IoU.plaything: 0.0619, IoU.swimming pool: 0.1780, IoU.stool: 0.0809, IoU.barrel: 0.0138, IoU.basket: 0.0472, IoU.waterfall: 0.3860, IoU.tent: 0.3777, IoU.bag: 0.0228, IoU.minibike: 0.1474, IoU.cradle: 0.3313, IoU.oven: 0.2462, IoU.ball: 0.1677, IoU.food: 0.2537, IoU.step: 0.0001, IoU.tank: 0.2851, IoU.trade name: 0.0606, IoU.microwave: 0.4137, IoU.pot: 0.1121, IoU.animal: 0.2034, IoU.bicycle: 0.0393, IoU.lake: 0.3296, IoU.dishwasher: 0.1358, IoU.screen: 0.3721, IoU.blanket: 0.0273, IoU.sculpture: 0.1829, IoU.hood: 0.2576, IoU.sconce: 0.1165, IoU.vase: 0.0519, IoU.traffic light: 0.1494, IoU.tray: 0.0320, IoU.ashcan: 0.0135, IoU.fan: 0.2031, IoU.pier: 0.0054, IoU.crt screen: 0.0835, IoU.plate: 0.1057, IoU.monitor: 0.3664, IoU.bulletin board: 0.3259, IoU.shower: 0.0050, IoU.radiator: 0.0849, IoU.glass: 0.0034, IoU.clock: 0.2407, IoU.flag: 0.3687, Acc.wall: 0.5965, Acc.building: 0.6432, Acc.sky: 0.7321, Acc.floor: 0.8256, Acc.tree: 0.5860, Acc.ceiling: 0.6724, Acc.road: 0.7840, Acc.bed : 0.4153, Acc.windowpane: 0.4688, Acc.grass: 0.3888, Acc.cabinet: 0.3965, Acc.sidewalk: 0.2486, Acc.person: 0.4293, Acc.earth: 0.3859, Acc.door: 0.4281, Acc.table: 0.2503, Acc.mountain: 0.5677, Acc.plant: 0.2850, Acc.curtain: 0.5467, Acc.chair: 0.2093, Acc.car: 0.2061, Acc.water: 0.5646, Acc.painting: 0.4265, Acc.sofa: 0.2308, Acc.shelf: 0.3790, Acc.house: 0.4399, Acc.sea: 0.6608, Acc.mirror: 0.5024, Acc.rug: 0.2191, Acc.field: 0.4372, Acc.armchair: 0.1959, Acc.seat: 0.4081, Acc.fence: 0.1591, Acc.desk: 0.2817, Acc.rock: 0.4125, Acc.wardrobe: 0.4561, Acc.lamp: 0.2908, Acc.bathtub: 0.4996, Acc.railing: 0.1953, Acc.cushion: 0.1159, Acc.base: 0.2390, Acc.box: 0.1423, Acc.column: 0.3587, Acc.signboard: 0.1453, Acc.chest of drawers: 0.2518, Acc.counter: 0.1567, Acc.sand: 0.4632, Acc.sink: 0.2431, Acc.skyscraper: 0.5349, Acc.fireplace: 0.4488, Acc.refrigerator: 0.5030, Acc.grandstand: 0.6083, Acc.path: 0.1096, Acc.stairs: 0.1398, Acc.runway: 0.4805, Acc.case: 0.4871, Acc.pool table: 0.3753, Acc.pillow: 0.1577, Acc.screen door: 0.4505, Acc.stairway: 0.2222, Acc.river: 0.2625, Acc.bridge: 0.3102, Acc.bookcase: 0.3694, Acc.blind: 0.4216, Acc.coffee table: 0.0756, Acc.toilet: 0.2810, Acc.flower: 0.2306, Acc.book: 0.3513, Acc.hill: 0.1546, Acc.bench: 0.2077, Acc.countertop: 0.2116, Acc.stove: 0.3315, Acc.palm: 0.4333, Acc.kitchen island: 0.2283, Acc.computer: 0.4718, Acc.swivel chair: 0.2272, Acc.boat: 0.1746, Acc.bar: 0.4493, Acc.arcade machine: 0.2450, Acc.hovel: 0.1797, Acc.bus: 0.4989, Acc.towel: 0.2535, Acc.light: 0.2785, Acc.truck: 0.1136, Acc.tower: 0.1145, Acc.chandelier: 0.4143, Acc.awning: 0.0653, Acc.streetlight: 0.1759, Acc.booth: 0.3318, Acc.television receiver: 0.2218, Acc.airplane: 0.1404, Acc.dirt track: 0.0807, Acc.apparel: 0.2669, Acc.pole: 0.1783, Acc.land: 0.0437, Acc.bannister: 0.0875, Acc.escalator: 0.1672, Acc.ottoman: 0.0370, Acc.bottle: 0.1664, Acc.buffet: 0.3373, Acc.poster: 0.3771, Acc.stage: 0.2320, Acc.van: 0.1202, Acc.ship: 0.5582, Acc.fountain: 0.0630, Acc.conveyer belt: 0.4718, Acc.canopy: 0.2399, Acc.washer: 0.3988, Acc.plaything: 0.1115, Acc.swimming pool: 0.2719, Acc.stool: 0.1201, Acc.barrel: 0.0616, Acc.basket: 0.0709, Acc.waterfall: 0.5085, Acc.tent: 0.4503, Acc.bag: 0.0297, Acc.minibike: 0.2257, Acc.cradle: 0.4694, Acc.oven: 0.3208, Acc.ball: 0.2537, Acc.food: 0.3078, Acc.step: 0.0002, Acc.tank: 0.3647, Acc.trade name: 0.0787, Acc.microwave: 0.5248, Acc.pot: 0.1633, Acc.animal: 0.2641, Acc.bicycle: 0.0659, Acc.lake: 0.3840, Acc.dishwasher: 0.1830, Acc.screen: 0.5168, Acc.blanket: 0.0365, Acc.sculpture: 0.3062, Acc.hood: 0.3766, Acc.sconce: 0.1665, Acc.vase: 0.0949, Acc.traffic light: 0.2329, Acc.tray: 0.0669, Acc.ashcan: 0.0231, Acc.fan: 0.2913, Acc.pier: 0.0094, Acc.crt screen: 0.1222, Acc.plate: 0.1696, Acc.monitor: 0.4720, Acc.bulletin board: 0.4283, Acc.shower: 0.0156, Acc.radiator: 0.1307, Acc.glass: 0.0040, Acc.clock: 0.3112, Acc.flag: 0.4482
2025-04-22 22:13:32,772 - mmseg - INFO - Iter [36050/40000]	lr: 7.902e-06, eta: 0:23:42, time: 4.607, data_time: 4.300, memory: 75933, decode.loss_ce: 0.1315, decode.acc_seg: 94.3125, loss: 0.1315
2025-04-22 22:13:47,922 - mmseg - INFO - Iter [36100/40000]	lr: 7.802e-06, eta: 0:23:24, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1263, decode.acc_seg: 94.4665, loss: 0.1263
2025-04-22 22:14:03,106 - mmseg - INFO - Iter [36150/40000]	lr: 7.702e-06, eta: 0:23:05, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1300, decode.acc_seg: 94.5408, loss: 0.1300
2025-04-22 22:14:18,313 - mmseg - INFO - Iter [36200/40000]	lr: 7.602e-06, eta: 0:22:47, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1398, decode.acc_seg: 93.9361, loss: 0.1398
2025-04-22 22:14:33,535 - mmseg - INFO - Iter [36250/40000]	lr: 7.502e-06, eta: 0:22:29, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1259, decode.acc_seg: 94.7308, loss: 0.1259
2025-04-22 22:14:48,754 - mmseg - INFO - Iter [36300/40000]	lr: 7.402e-06, eta: 0:22:11, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1215, decode.acc_seg: 94.9185, loss: 0.1215
2025-04-22 22:15:03,983 - mmseg - INFO - Iter [36350/40000]	lr: 7.302e-06, eta: 0:21:52, time: 0.305, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1332, decode.acc_seg: 94.6665, loss: 0.1332
2025-04-22 22:15:19,205 - mmseg - INFO - Iter [36400/40000]	lr: 7.202e-06, eta: 0:21:34, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1298, decode.acc_seg: 94.6060, loss: 0.1298
2025-04-22 22:15:34,408 - mmseg - INFO - Iter [36450/40000]	lr: 7.102e-06, eta: 0:21:16, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1556, decode.acc_seg: 93.8494, loss: 0.1556
2025-04-22 22:15:49,610 - mmseg - INFO - Iter [36500/40000]	lr: 7.002e-06, eta: 0:20:58, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1383, decode.acc_seg: 94.0123, loss: 0.1383
2025-04-22 22:16:04,797 - mmseg - INFO - Iter [36550/40000]	lr: 6.902e-06, eta: 0:20:39, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1452, decode.acc_seg: 94.1707, loss: 0.1452
2025-04-22 22:16:20,015 - mmseg - INFO - Iter [36600/40000]	lr: 6.802e-06, eta: 0:20:21, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1321, decode.acc_seg: 94.3867, loss: 0.1321
2025-04-22 22:16:35,231 - mmseg - INFO - Iter [36650/40000]	lr: 6.702e-06, eta: 0:20:03, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1411, decode.acc_seg: 94.1035, loss: 0.1411
2025-04-22 22:16:50,464 - mmseg - INFO - Iter [36700/40000]	lr: 6.602e-06, eta: 0:19:45, time: 0.305, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1477, decode.acc_seg: 93.6304, loss: 0.1477
2025-04-22 22:17:05,685 - mmseg - INFO - Iter [36750/40000]	lr: 6.502e-06, eta: 0:19:26, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1235, decode.acc_seg: 94.7574, loss: 0.1235
2025-04-22 22:17:20,939 - mmseg - INFO - Iter [36800/40000]	lr: 6.402e-06, eta: 0:19:08, time: 0.305, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1260, decode.acc_seg: 94.7480, loss: 0.1260
2025-04-22 22:17:36,168 - mmseg - INFO - Iter [36850/40000]	lr: 6.302e-06, eta: 0:18:50, time: 0.305, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1339, decode.acc_seg: 94.3655, loss: 0.1339
2025-04-22 22:17:51,413 - mmseg - INFO - Iter [36900/40000]	lr: 6.202e-06, eta: 0:18:32, time: 0.305, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1228, decode.acc_seg: 94.5288, loss: 0.1228
2025-04-22 22:18:06,626 - mmseg - INFO - Iter [36950/40000]	lr: 6.102e-06, eta: 0:18:14, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1411, decode.acc_seg: 94.1400, loss: 0.1411
2025-04-22 22:18:21,836 - mmseg - INFO - Exp name: vpd_config.py
2025-04-22 22:18:21,837 - mmseg - INFO - Iter [37000/40000]	lr: 6.002e-06, eta: 0:17:56, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1378, decode.acc_seg: 94.2436, loss: 0.1378
2025-04-22 22:18:37,827 - mmseg - INFO - Iter [37050/40000]	lr: 5.902e-06, eta: 0:17:38, time: 0.320, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1220, decode.acc_seg: 94.5724, loss: 0.1220
2025-04-22 22:18:53,023 - mmseg - INFO - Iter [37100/40000]	lr: 5.802e-06, eta: 0:17:19, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1358, decode.acc_seg: 94.3503, loss: 0.1358
2025-04-22 22:19:08,220 - mmseg - INFO - Iter [37150/40000]	lr: 5.702e-06, eta: 0:17:01, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1306, decode.acc_seg: 94.4904, loss: 0.1306
2025-04-22 22:19:23,423 - mmseg - INFO - Iter [37200/40000]	lr: 5.602e-06, eta: 0:16:43, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1339, decode.acc_seg: 94.6449, loss: 0.1339
2025-04-22 22:19:38,625 - mmseg - INFO - Iter [37250/40000]	lr: 5.502e-06, eta: 0:16:25, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1347, decode.acc_seg: 94.0422, loss: 0.1347
2025-04-22 22:19:53,828 - mmseg - INFO - Iter [37300/40000]	lr: 5.402e-06, eta: 0:16:07, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1399, decode.acc_seg: 94.2120, loss: 0.1399
2025-04-22 22:20:09,064 - mmseg - INFO - Iter [37350/40000]	lr: 5.302e-06, eta: 0:15:49, time: 0.305, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1277, decode.acc_seg: 94.7258, loss: 0.1277
2025-04-22 22:20:24,262 - mmseg - INFO - Iter [37400/40000]	lr: 5.202e-06, eta: 0:15:31, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1253, decode.acc_seg: 94.7511, loss: 0.1253
2025-04-22 22:20:39,456 - mmseg - INFO - Iter [37450/40000]	lr: 5.102e-06, eta: 0:15:13, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1374, decode.acc_seg: 94.1661, loss: 0.1374
2025-04-22 22:20:54,643 - mmseg - INFO - Iter [37500/40000]	lr: 5.002e-06, eta: 0:14:54, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1335, decode.acc_seg: 94.4121, loss: 0.1335
2025-04-22 22:21:09,826 - mmseg - INFO - Iter [37550/40000]	lr: 4.902e-06, eta: 0:14:36, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1276, decode.acc_seg: 94.5503, loss: 0.1276
2025-04-22 22:21:25,012 - mmseg - INFO - Iter [37600/40000]	lr: 4.802e-06, eta: 0:14:18, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1431, decode.acc_seg: 93.8355, loss: 0.1431
2025-04-22 22:21:40,214 - mmseg - INFO - Iter [37650/40000]	lr: 4.702e-06, eta: 0:14:00, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1553, decode.acc_seg: 93.6323, loss: 0.1553
2025-04-22 22:21:55,412 - mmseg - INFO - Iter [37700/40000]	lr: 4.602e-06, eta: 0:13:42, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1435, decode.acc_seg: 94.1575, loss: 0.1435
2025-04-22 22:22:10,613 - mmseg - INFO - Iter [37750/40000]	lr: 4.502e-06, eta: 0:13:24, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1265, decode.acc_seg: 94.8885, loss: 0.1265
2025-04-22 22:22:25,808 - mmseg - INFO - Iter [37800/40000]	lr: 4.402e-06, eta: 0:13:06, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1306, decode.acc_seg: 94.4037, loss: 0.1306
2025-04-22 22:22:40,992 - mmseg - INFO - Iter [37850/40000]	lr: 4.302e-06, eta: 0:12:48, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1401, decode.acc_seg: 94.4676, loss: 0.1401
2025-04-22 22:22:56,206 - mmseg - INFO - Iter [37900/40000]	lr: 4.202e-06, eta: 0:12:30, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1366, decode.acc_seg: 94.3821, loss: 0.1366
2025-04-22 22:23:11,410 - mmseg - INFO - Iter [37950/40000]	lr: 4.102e-06, eta: 0:12:12, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1454, decode.acc_seg: 94.0786, loss: 0.1454
2025-04-22 22:23:26,600 - mmseg - INFO - Exp name: vpd_config.py
2025-04-22 22:23:26,601 - mmseg - INFO - Iter [38000/40000]	lr: 4.002e-06, eta: 0:11:54, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1248, decode.acc_seg: 94.5513, loss: 0.1248
2025-04-22 22:23:42,488 - mmseg - INFO - Iter [38050/40000]	lr: 3.902e-06, eta: 0:11:36, time: 0.318, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1337, decode.acc_seg: 94.6508, loss: 0.1337
2025-04-22 22:23:57,658 - mmseg - INFO - Iter [38100/40000]	lr: 3.802e-06, eta: 0:11:18, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1280, decode.acc_seg: 94.7292, loss: 0.1280
2025-04-22 22:24:12,843 - mmseg - INFO - Iter [38150/40000]	lr: 3.702e-06, eta: 0:11:00, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1292, decode.acc_seg: 94.6252, loss: 0.1292
2025-04-22 22:24:28,023 - mmseg - INFO - Iter [38200/40000]	lr: 3.602e-06, eta: 0:10:42, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1442, decode.acc_seg: 94.2785, loss: 0.1442
2025-04-22 22:24:43,204 - mmseg - INFO - Iter [38250/40000]	lr: 3.502e-06, eta: 0:10:24, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1232, decode.acc_seg: 94.5568, loss: 0.1232
2025-04-22 22:24:58,373 - mmseg - INFO - Iter [38300/40000]	lr: 3.402e-06, eta: 0:10:06, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1251, decode.acc_seg: 94.8573, loss: 0.1251
2025-04-22 22:25:13,556 - mmseg - INFO - Iter [38350/40000]	lr: 3.302e-06, eta: 0:09:48, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1333, decode.acc_seg: 94.3770, loss: 0.1333
2025-04-22 22:25:28,733 - mmseg - INFO - Iter [38400/40000]	lr: 3.202e-06, eta: 0:09:30, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1231, decode.acc_seg: 94.8614, loss: 0.1231
2025-04-22 22:25:43,930 - mmseg - INFO - Iter [38450/40000]	lr: 3.102e-06, eta: 0:09:12, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1477, decode.acc_seg: 93.8153, loss: 0.1477
2025-04-22 22:25:59,093 - mmseg - INFO - Iter [38500/40000]	lr: 3.002e-06, eta: 0:08:54, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1669, decode.acc_seg: 93.6607, loss: 0.1669
2025-04-22 22:26:14,251 - mmseg - INFO - Iter [38550/40000]	lr: 2.902e-06, eta: 0:08:36, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1380, decode.acc_seg: 94.5042, loss: 0.1380
2025-04-22 22:26:29,420 - mmseg - INFO - Iter [38600/40000]	lr: 2.802e-06, eta: 0:08:19, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1310, decode.acc_seg: 94.4653, loss: 0.1310
2025-04-22 22:26:44,585 - mmseg - INFO - Iter [38650/40000]	lr: 2.702e-06, eta: 0:08:01, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1178, decode.acc_seg: 95.0471, loss: 0.1178
2025-04-22 22:26:59,751 - mmseg - INFO - Iter [38700/40000]	lr: 2.602e-06, eta: 0:07:43, time: 0.303, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1353, decode.acc_seg: 94.3217, loss: 0.1353
2025-04-22 22:27:14,929 - mmseg - INFO - Iter [38750/40000]	lr: 2.502e-06, eta: 0:07:25, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1557, decode.acc_seg: 93.6611, loss: 0.1557
2025-04-22 22:27:30,118 - mmseg - INFO - Iter [38800/40000]	lr: 2.402e-06, eta: 0:07:07, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1221, decode.acc_seg: 94.8791, loss: 0.1221
2025-04-22 22:27:45,304 - mmseg - INFO - Iter [38850/40000]	lr: 2.302e-06, eta: 0:06:49, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1529, decode.acc_seg: 93.8221, loss: 0.1529
2025-04-22 22:28:00,499 - mmseg - INFO - Iter [38900/40000]	lr: 2.202e-06, eta: 0:06:31, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1288, decode.acc_seg: 94.5020, loss: 0.1288
2025-04-22 22:28:15,687 - mmseg - INFO - Iter [38950/40000]	lr: 2.102e-06, eta: 0:06:13, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1293, decode.acc_seg: 94.3255, loss: 0.1293
2025-04-22 22:28:30,885 - mmseg - INFO - Exp name: vpd_config.py
2025-04-22 22:28:30,886 - mmseg - INFO - Iter [39000/40000]	lr: 2.002e-06, eta: 0:05:55, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1269, decode.acc_seg: 94.2767, loss: 0.1269
2025-04-22 22:28:46,796 - mmseg - INFO - Iter [39050/40000]	lr: 1.902e-06, eta: 0:05:38, time: 0.318, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1236, decode.acc_seg: 94.8839, loss: 0.1236
2025-04-22 22:29:01,995 - mmseg - INFO - Iter [39100/40000]	lr: 1.802e-06, eta: 0:05:20, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1196, decode.acc_seg: 94.9818, loss: 0.1196
2025-04-22 22:29:17,193 - mmseg - INFO - Iter [39150/40000]	lr: 1.702e-06, eta: 0:05:02, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1408, decode.acc_seg: 94.1993, loss: 0.1408
2025-04-22 22:29:32,414 - mmseg - INFO - Iter [39200/40000]	lr: 1.602e-06, eta: 0:04:44, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1298, decode.acc_seg: 94.5806, loss: 0.1298
2025-04-22 22:29:47,635 - mmseg - INFO - Iter [39250/40000]	lr: 1.502e-06, eta: 0:04:26, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1125, decode.acc_seg: 95.2448, loss: 0.1125
2025-04-22 22:30:02,859 - mmseg - INFO - Iter [39300/40000]	lr: 1.402e-06, eta: 0:04:08, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1514, decode.acc_seg: 94.0418, loss: 0.1514
2025-04-22 22:30:18,074 - mmseg - INFO - Iter [39350/40000]	lr: 1.302e-06, eta: 0:03:51, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1487, decode.acc_seg: 94.1108, loss: 0.1487
2025-04-22 22:30:33,288 - mmseg - INFO - Iter [39400/40000]	lr: 1.202e-06, eta: 0:03:33, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1295, decode.acc_seg: 94.7795, loss: 0.1295
2025-04-22 22:30:48,491 - mmseg - INFO - Iter [39450/40000]	lr: 1.102e-06, eta: 0:03:15, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1385, decode.acc_seg: 94.0231, loss: 0.1385
2025-04-22 22:31:03,712 - mmseg - INFO - Iter [39500/40000]	lr: 1.002e-06, eta: 0:02:57, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1393, decode.acc_seg: 94.1187, loss: 0.1393
2025-04-22 22:31:18,894 - mmseg - INFO - Iter [39550/40000]	lr: 9.020e-07, eta: 0:02:39, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1319, decode.acc_seg: 94.3765, loss: 0.1319
2025-04-22 22:31:34,107 - mmseg - INFO - Iter [39600/40000]	lr: 8.020e-07, eta: 0:02:22, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1201, decode.acc_seg: 94.8105, loss: 0.1201
2025-04-22 22:31:49,316 - mmseg - INFO - Iter [39650/40000]	lr: 7.020e-07, eta: 0:02:04, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1499, decode.acc_seg: 93.9634, loss: 0.1499
2025-04-22 22:32:04,523 - mmseg - INFO - Iter [39700/40000]	lr: 6.020e-07, eta: 0:01:46, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1284, decode.acc_seg: 94.5865, loss: 0.1284
2025-04-22 22:32:19,733 - mmseg - INFO - Iter [39750/40000]	lr: 5.020e-07, eta: 0:01:28, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1175, decode.acc_seg: 94.8600, loss: 0.1175
2025-04-22 22:32:34,938 - mmseg - INFO - Iter [39800/40000]	lr: 4.020e-07, eta: 0:01:10, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1469, decode.acc_seg: 94.7264, loss: 0.1469
2025-04-22 22:32:50,156 - mmseg - INFO - Iter [39850/40000]	lr: 3.020e-07, eta: 0:00:53, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1418, decode.acc_seg: 94.0169, loss: 0.1418
2025-04-22 22:33:05,371 - mmseg - INFO - Iter [39900/40000]	lr: 2.020e-07, eta: 0:00:35, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1268, decode.acc_seg: 94.6780, loss: 0.1268
2025-04-22 22:33:20,548 - mmseg - INFO - Iter [39950/40000]	lr: 1.020e-07, eta: 0:00:17, time: 0.304, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1761, decode.acc_seg: 93.4923, loss: 0.1761
2025-04-22 22:33:35,729 - mmseg - INFO - Saving checkpoint at 40000 iterations
2025-04-22 22:33:45,277 - mmseg - INFO - Exp name: vpd_config.py
2025-04-22 22:33:45,277 - mmseg - INFO - Iter [40000/40000]	lr: 2.000e-09, eta: 0:00:00, time: 0.495, data_time: 0.009, memory: 75933, decode.loss_ce: 0.1378, decode.acc_seg: 94.2504, loss: 0.1378
User defined signal 2
